[{"categories":[],"content":"MapReduce 中文\n摘要 MapReduce 是一个编程模型，也是一个处理和生成超大数据集的算法模型的相关实现。用户首先创建一 个 Map 函数处理一个基于 key/value pair 的数据集合，输出中间的基于 key/value pair 的数据集合；然后再创建 一个 Reduce 函数用来合并所有的具有相同中间 key 值的中间 value 值。现实世界中有很多满足上述处理模型 的例子，本论文将详细描述这个模型。 MapReduce 架构的程序能够在大量的普通配置的计算机上实现并行化处理。这个系统在运行时只关心： 如何分割输入数据，在大量计算机组成的集群上的调度，集群中计算机的错误处理，管理集群中计算机之间 必要的通信。采用 MapReduce 架构可以使那些没有并行计算和分布式处理系统开发经验的程序员有效利用分 布式系统的丰富资源。 我们的 MapReduce 实现运行在规模可以灵活调整的由普通机器组成的集群上：一个典型的 MapReduce 计算往往由几千台机器组成、处理以 TB 计算的数据。程序员发现这个系统非常好用：已经实现了数以百计 的 MapReduce 程序，在 Google 的集群上，每天都有 1000 多个 MapReduce 程序在执行\n1 介绍 在过去的 5 年里，包括本文作者在内的 Google 的很多程序员，为了处理海量的原始数据，已经实现了数 以百计的、专用的计算方法。这些计算方法用来处理大量的原始数据，比如，文档抓取（类似网络爬虫的程 序）、Web 请求日志等等；也为了计算处理各种类型的衍生数据，比如倒排索引、Web 文档的图结构的各种表 示形势、每台主机上网络爬虫抓取的页面数量的汇总、每天被请求的最多的查询的集合等等。大多数这样的 数据处理运算在概念上很容易理解。然而由于输入的数据量巨大，因此要想在可接受的时间内完成运算，只 有将这些计算分布在成百上千的主机上。如何处理并行计算、如何分发数据、如何处理错误？所有这些问题 综合在一起，需要大量的代码处理，因此也使得原本简单的运算变得难以处理。 为了解决上述复杂的问题，我们设计一个新的抽象模型，使用这个抽象模型，我们只要表述我们想要执 行的简单运算即可，而不必关心并行计算、容错、数据分布、负载均衡等复杂的细节，这些问题都被封装在 了一个库里面。设计这个抽象模型的灵感来自 Lisp 和许多其他函数式语言的 Map 和 Reduce 的原语。我们意 识到我们大多数的运算都包含这样的操作：在输入数据的“逻辑”记录上应用 Map 操作得出一个中间 key/value pair 集合，然后在所有具有相同 key 值的 value 值上应用 Reduce 操作，从而达到合并中间的数据，得到一个想要的结果的目的。使用 MapReduce 模型，再结合用户实现的 Map 和 Reduce 函数，我们就可以非常容易的 实现大规模并行化计算；通过 MapReduce 模型自带的“再次执行”（re-execution）功能，也提供了初级的容 灾实现方案。 这个工作(实现一个 MapReduce 框架模型)的主要贡献是通过简单的接口来实现自动的并行化和大规模 的分布式计算，通过使用 MapReduce 模型接口实现在大量普通的 PC 机上高性能计算。 第二部分描述基本的编程模型和一些使用案例。 第三部分描述了一个经过裁剪的、适合我们的基于集群的计算环境的 MapReduce 实现。 第四部分描述我们认为在 MapReduce 编程模型中一些实用的技巧。 第五部分对于各种不同的任务，测量我们 MapReduce 实现的性能。 第六部分揭示了在 Google 内部如何使用 MapReduce 作为基础重写我们的索引系统产品，包括其它一些 使用 MapReduce 的经验。 第七部分讨论相关的和未来的工作。\n2 编程模型 MapReduce 编程模型的原理是：利用一个输入 key/value pair 集合来产生一个输出的 key/value pair 集合。 MapReduce 库的用户用两个函数表达这个计算：Map 和 Reduce。 用户自定义的 Map 函数接受一个输入的 key/value pair 值，然后产生一个中间 key/value pair 值的集合。 MapReduce 库把所有具有相同中间 key 值 I 的中间 value 值集合在一起后传递给 reduce 函数。 用户自定义的 Reduce 函数接受一个中间 key 的值 I 和相关的一个 value 值的集合。Reduce 函数合并这些 value 值，形成一个较小的 value 值的集合。一般的，每次 Reduce 函数调用只产生 0 或 1 个输出 value 值。通 常我们通过一个迭代器把中间 value 值提供给 Reduce 函数，这样我们就可以处理无法全部放入内存中的大量 的 value 值的集合。\n2.1 例子 例如，计算一个大的文档集合中每个单词出现的次数，下面是伪代码段：\n1map(String key, String value): 2 // key: document name 3 // value: document contents 4 for each word w in value: 5 EmitIntermediate(w, “1″); 1reduce(String key, Iterator values): 2 // key: a word 3 // values: a list of counts 4 int result = 0; 5 for each v in values: 6 result += ParseInt(v); 7 Emit(AsString(result)); Map 函数输出文档中的每个词、以及这个词的出现次数(在这个简单的例子里就是 1)。Reduce 函数把 Map 函数产生的每一个特定的词的计数累加起来。 另外，用户编写代码，使用输入和输出文件的名字、可选的调节参数来完成一个符合 MapReduce 模型规 范的对象，然后调用 MapReduce 函数，并把这个规范对象传递给它。用户的代码和 MapReduce 库链接在一起 (用 C++实现)。附录 A 包含了这个实例的全部程序代码。\n2.2 类型 尽管在前面例子的伪代码中使用了以字符串表示的输入输出值，但是在概念上，用户定义的Map和Reduce 函数都有相关联的类型：\n1map(k1,v1) -\u0026gt;list(k2,v2) 2reduce(k2,list(v2)) -\u0026gt;list(v2) 比如，输入的 key 和 value 值与输出的 key 和 value 值在类型上推导的域不同。此外，中间 key 和 value 值与输出 key 和 value 值在类型上推导的域相同。2 我们的 C++中使用字符串类型作为用户自定义函数的输入输出，用户在自己的代码中对字符串进行适当 的类型转换。\n2.3 更多的例子 这里还有一些有趣的简单例子，可以很容易的使用 MapReduce 模型来表示： 分布式的 Grep：Map 函数输出匹配某个模式的一行，Reduce 函数是一个恒等函数，即把中间数据复制到 输出。 计算 URL 访问频率：Map 函数处理日志中 web 页面请求的记录，然后输出(URL,1)。Reduce 函数把相同URL 的 value 值都累加起来，产生(URL,记录总数)结果。 倒转网络链接图：Map 函数在源页面（source）中搜索所有的链接目标（target）并输出为(target,source)。 Reduce 函数把给定链接目标（target）的链接组合成一个列表，输出(target,list(source))。 每个主机的检索词向量：检索词向量用一个(词,频率)列表来概述出现在文档或文档集中的最重要的一些 词。Map 函数为每一个输入文档输出(主机名,检索词向量)，其中主机名来自文档的 URL。Reduce 函数接收给 定主机的所有文档的检索词向量，并把这些检索词向量加在一起，丢弃掉低频的检索词，输出一个最终的(主 机名,检索词向量)。 倒排索引：Map 函数分析每个文档输出一个(词,文档号)的列表，Reduce 函数的输入是一个给定词的所有 （词，文档号），排序所有的文档号，输出(词,list（文档号）)。所有的输出集合形成一个简单的倒排索引，它 以一种简单的算法跟踪词在文档中的位置。 分布式排序：Map 函数从每个记录提取 key，输出(key,record)。Reduce 函数不改变任何的值。这个运算 依赖分区机制(在 4.1 描述)和排序属性(在 4.2 描述)。\n3 实现 MapReduce 模型可以有多种不同的实现方式。如何正确选择取决于具体的环境。例如，一种实现方式适 用于小型的共享内存方式的机器，另外一种实现方式则适用于大型 NUMA 架构的多处理器的主机，而有的实 现方式更适合大型的网络连接集群。 本章节描述一个适用于 Google 内部广泛使用的运算环境的实现：用以太网交换机连接、由普通 PC 机组 成的大型集群。在我们的环境里包括：\nx86 架构、运行 Linux 操作系统、双处理器、2-4GB 内存的机器。 普通的网络硬件设备，每个机器的带宽为百兆或者千兆，但是远小于网络的平均带宽的一半。 集群中包含成百上千的机器，因此，机器故障是常态。 存储为廉价的内置 IDE 硬盘。一个内部分布式文件系统用来管理存储在这些磁盘上的数据。文件系 统通过数据复制来在不可靠的硬件上保证数据的可靠性和有效性。 用户提交工作（job）给调度系统。每个工作（job）都包含一系列的任务（task），调度系统将这些任 务调度到集群中多台可用的机器上。 3.1 执行概括 通过将 Map 调用的输入数据自动分割为 M 个数据片段的集合，Map 调用被分布到多台机器上执行。输 入的数据片段能够在不同的机器上并行处理。使用分区函数将 Map 调用产生的中间 key 值分成 R 个不同分区（例如，hash(key) mod R），Reduce 调用也被分布到多台机器上执行。分区数量（R）和分区函数由用户来指 定。\n图 1 展示了我们的 MapReduce 实现中操作的全部流程。当用户调用 MapReduce 函数时，将发生下面的一 系列动作（下面的序号和图 1 中的序号一一对应）： 1. 用户程序首先调用的 MapReduce 库将输入文件分成 M 个数据片度，每个数据片段的大小一般从 16MB 到 64MB(可以通过可选的参数来控制每个数据片段的大小)。然后用户程序在机群中创建大量 的程序副本。 2. 这些程序副本中的有一个特殊的程序–master。副本中其它的程序都是 worker 程序，由 master 分配 任务。有 M 个 Map 任务和 R 个 Reduce 任务将被分配，master 将一个 Map 任务或 Reduce 任务分配 给一个空闲的 worker。 3. 被分配了 map 任务的 worker 程序读取相关的输入数据片段，从输入的数据片段中解析出 key/value pair，然后把 key/value pair 传递给用户自定义的 Map 函数，由 Map 函数生成并输出的中间 key/value pair，并缓存在内存中。 4. 缓存中的 key/value pair 通过分区函数分成 R 个区域，之后周期性的写入到本地磁盘上。缓存的 key/value pair 在本地磁盘上的存储位置将被回传给 master，由 master 负责把这些存储位置再传送给 Reduce worker。\n\\5. 当 Reduce worker 程序接收到 master 程序发来的数据存储位置信息后，使用 RPC 从 Map worker 所在 主机的磁盘上读取这些缓存数据。当 Reduce worker 读取了所有的中间数据后，通过对 key 进行排序 后使得具有相同 key 值的数据聚合在一起。由于许多不同的 key 值会映射到相同的 Reduce 任务上， 因此必须进行排序。如果中间数据太大无法在内存中完成排序，那么就要在外部进行排序。 6. Reduce worker 程序遍历排序后的中间数据，对于每一个唯一的中间 key 值，Reduce worker 程序将这 个 key 值和它相关的中间 value 值的集合传递给用户自定义的 Reduce 函数。Reduce 函数的输出被追 加到所属分区的输出文件。 7. 当所有的 Map 和 Reduce 任务都完成之后，master 唤醒用户程序。在这个时候，在用户程序里的对 MapReduce 调用才返回。 在成功完成任务之后，MapReduce 的输出存放在 R 个输出文件中（对应每个 Reduce 任务产生一个输出 文件，文件名由用户指定）。一般情况下，用户不需要将这 R 个输出文件合并成一个文件–他们经常把这些文 件作为另外一个 MapReduce 的输入，或者在另外一个可以处理多个分割文件的分布式应用中使用。\n3.2 Master 数据结构 Master 持有一些数据结构，它存储每一个 Map 和 Reduce 任务的状态（空闲、工作中或完成)，以及 Worker 机器(非空闲任务的机器)的标识。 Master 就像一个数据管道，中间文件存储区域的位置信息通过这个管道从 Map 传递到 Reduce。因此， 对于每个已经完成的 Map 任务，master 存储了 Map 任务产生的 R 个中间文件存储区域的大小和位置。当 Map 任务完成时，Master 接收到位置和大小的更新信息，这些信息被逐步递增的推送给那些正在工作的 Reduce 任 务。\n3.3 容错 因为 MapReduce 库的设计初衷是使用由成百上千的机器组成的集群来处理超大规模的数据，所以，这个 库必须要能很好的处理机器故障。\n3.3.1 worker 故障 master 周期性的 ping 每个 worker。如果在一个约定的时间范围内没有收到 worker 返回的信息，master 将 把这个 worker 标记为失效。所有由这个失效的 worker 完成的 Map 任务被重设为初始的空闲状态，之后这些 任务就可以被安排给其他的 worker。同样的，worker 失效时正在运行的 Map 或 Reduce 任务也将被重新置为 空闲状态，等待重新调度。 当 worker 故障时，由于已经完成的 Map 任务的输出存储在这台机器上，Map 任务的输出已不可访问了，因此必须重新执行。而已经完成的 Reduce 任务的输出存储在全局文件系统上，因此不需要再次执行。 当一个 Map 任务首先被 worker A 执行，之后由于 worker A 失效了又被调度到 worker B 执行，这个“重 新执行”的动作会被通知给所有执行 Reduce 任务的 worker。任何还没有从 worker A 读取数据的 Reduce 任务 将从 worker B 读取数据。 MapReduce 可以处理大规模 worker 失效的情况。比如，在一个 MapReduce 操作执行期间，在正在运行 的集群上进行网络维护引起 80 台机器在几分钟内不可访问了，MapReduce master 只需要简单的再次执行那些 不可访问的 worker 完成的工作，之后继续执行未完成的任务，直到最终完成这个 MapReduce 操作。\n3.3.2 master 失败 一个简单的解决办法是让 master 周期性的将上面描述的数据结构（alex 注：指 3.2 节）的写入磁盘，即 检查点（checkpoint）。如果这个 master 任务失效了，可以从最后一个检查点（checkpoint）开始启动另一个 master 进程。然而，由于只有一个 master 进程，master 失效后再恢复是比较麻烦的，因此我们现在的实现是 如果 master 失效，就中止 MapReduce 运算。客户可以检查到这个状态，并且可以根据需要重新执行 MapReduce 操作。\n3.3.3 在失效方面的处理机制 当用户提供的 Map 和 Reduce 操作是输入确定性函数（即相同的输入产生相同的输出）时，我们的分布 式实现在任何情况下的输出都和所有程序没有出现任何错误、顺序的执行产生的输出是一样的。 我们依赖对 Map 和 Reduce 任务的输出是原子提交的来完成这个特性。每个工作中的任务把它的输出写 到私有的临时文件中。每个 Reduce 任务生成一个这样的文件，而每个 Map 任务则生成 R 个这样的文件（一 个 Reduce 任务对应一个文件）。当一个 Map 任务完成的时，worker 发送一个包含 R 个临时文件名的完成消息 给 master。如果 master 从一个已经完成的 Map 任务再次接收到到一个完成消息，master 将忽略这个消息；否 则，master 将这 R 个文件的名字记录在数据结构里。 当 Reduce 任务完成时，Reduce worker 进程以原子的方式把临时文件重命名为最终的输出文件。如果同 一个 Reduce 任务在多台机器上执行，针对同一个最终的输出文件将有多个重命名操作执行。我们依赖底层文 件系统提供的重命名操作的原子性来保证最终的文件系统状态仅仅包含一个 Reduce 任务产生的数据。 使用 MapReduce 模型的程序员可以很容易的理解他们程序的行为，因为我们绝大多数的 Map 和 Reduce 操作是确定性的，而且存在这样的一个事实：我们的失效处理机制等价于一个顺序的执行的操作。当 Map 或 /和 Reduce 操作是不确定性的时候，我们提供虽然较弱但是依然合理的处理机制。当使用非确定操作的时候， 一个 Reduce 任务 R1 的输出等价于一个非确定性程序顺序执行产生时的输出。但是，另一个 Reduce 任务 R2的输出也许符合一个不同的非确定顺序程序执行产生的 R2 的输出。 考虑 Map 任务 M 和 Reduce 任务 R1、R2 的情况。我们设定 e(Ri)是 Ri 已经提交的执行过程（有且仅有 一个这样的执行过程）。当 e(R1)读取了由 M 一次执行产生的输出，而 e(R2)读取了由 M 的另一次执行产生的 输出，导致了较弱的失效处理。\n3.4 存储位置 在我们的计算运行环境中，网络带宽是一个相当匮乏的资源。我们通过尽量把输入数据(由 GFS 管理)存 储在集群中机器的本地磁盘上来节省网络带宽。GFS 把每个文件按 64MB 一个 Block 分隔，每个 Block 保存 在多台机器上，环境中就存放了多份拷贝(一般是 3 个拷贝)。MapReduce 的 master 在调度 Map 任务时会考虑 输入文件的位置信息，尽量将一个 Map 任务调度在包含相关输入数据拷贝的机器上执行；如果上述努力失败 了，master 将尝试在保存有输入数据拷贝的机器附近的机器上执行 Map 任务(例如，分配到一个和包含输入数 据的机器在一个 switch 里的 worker 机器上执行)。当在一个足够大的 cluster 集群上运行大型 MapReduce 操作 的时候，大部分的输入数据都能从本地机器读取，因此消耗非常少的网络带宽。\n3.5 任务粒度 如前所述，我们把 Map 拆分成了 M 个片段、把 Reduce 拆分成 R 个片段执行。理想情况下，M 和 R 应当 比集群中 worker 的机器数量要多得多。在每台 worker 机器都执行大量的不同任务能够提高集群的动态的负载 均衡能力，并且能够加快故障恢复的速度：失效机器上执行的大量 Map 任务都可以分布到所有其他的 worker 机器上去执行。 但是实际上，在我们的具体实现中对 M 和 R 的取值都有一定的客观限制，因为 master 必须执行 O(M+R) 次调度，并且在内存中保存 O(MR)个状态（对影响内存使用的因素还是比较小的：O(MR)块状态，大概每 对 Map 任务/Reduce 任务 1 个字节就可以了）。 更进一步，R 值通常是由用户指定的，因为每个 Reduce 任务最终都会生成一个独立的输出文件。实际使 用时我们也倾向于选择合适的 M 值，以使得每一个独立任务都是处理大约 16M 到 64M 的输入数据（这样， 上面描写的输入数据本地存储优化策略才最有效），另外，我们把 R 值设置为我们想使用的 worker 机器数量 的小的倍数。我们通常会用这样的比例来执行 MapReduce：M=200000，R=5000，使用 2000 台 worker 机器。\n3.6 备用任务 影响一个 MapReduce 的总执行时间最通常的因素是“落伍者”：在运算过程中，如果有一台机器花了很 长的时间才完成最后几个 Map 或 Reduce 任务，导致 MapReduce 操作总的执行时间超过预期。出现“落伍者” 的原因非常多。比如：如果一个机器的硬盘出了问题，在读取的时候要经常的进行读取纠错操作，导致读取数据的速度从 30M/s 降低到 1M/s。如果 cluster 的调度系统在这台机器上又调度了其他的任务，由于 CPU、内 存、本地硬盘和网络带宽等竞争因素的存在，导致执行 MapReduce 代码的执行效率更加缓慢。我们最近遇到 的一个问题是由于机器的初始化代码有 bug，导致关闭了的处理器的缓存：在这些机器上执行任务的性能和 正常情况相差上百倍。 我们有一个通用的机制来减少“落伍者”出现的情况。当一个 MapReduce 操作接近完成的时候，master 调度备用（backup）任务进程来执行剩下的、处于处理中状态（in-progress）的任务。无论是最初的执行进程、 还是备用（backup）任务进程完成了任务，我们都把这个任务标记成为已经完成。我们调优了这个机制，通 常只会占用比正常操作多几个百分点的计算资源。我们发现采用这样的机制对于减少超大 MapReduce 操作的 总处理时间效果显著。例如，在 5.3 节描述的排序任务，在关闭掉备用任务的情况下要多花 44%的时间完成 排序任务。\n4 技巧 虽然简单的 Map 和 Reduce 函数提供的基本功能已经能够满足大部分的计算需要，我们还是发掘出了一 些有价值的扩展功能。本节将描述这些扩展功能。\n4.1 分区函数 MapReduce 的使用者通常会指定 Reduce 任务和 Reduce 任务输出文件的数量（R）。我们在中间 key 上使 用分区函数来对数据进行分区，之后再输入到后续任务执行进程。一个缺省的分区函数是使用 hash 方法(比如， hash(key) mod R)进行分区。hash 方法能产生非常平衡的分区。然而，有的时候，其它的一些分区函数对 key 值进行的分区将非常有用。比如，输出的 key 值是 URLs，我们希望每个主机的所有条目保持在同一个输出文 件中。为了支持类似的情况，MapReduce库的用户需要提供专门的分区函数。例如，使用“hash(Hostname(urlkey)) mod R”作为分区函数就可以把所有来自同一个主机的 URLs 保存在同一个输出文件中。\n4.2 顺序保证 我们确保在给定的分区中，中间 key/value pair 数据的处理顺序是按照 key 值增量顺序处理的。这样的顺 序保证对每个分成生成一个有序的输出文件，这对于需要对输出文件按 key 值随机存取的应用非常有意义， 对在排序输出的数据集也很有帮助。\n4.3 Combiner 函数 在某些情况下，Map 函数产生的中间 key 值的重复数据会占很大的比重，并且，用户自定义的 Reduce 函 数满足结合律和交换律。在 2.1 节的词数统计程序是个很好的例子。由于词频率倾向于一个 zipf 分布(齐夫分布)，每个 Map 任务将产生成千上万个这样的记录。所有的这些记录将通过网络被发送到一个单独的 Reduce 任务，然后由这个 Reduce 任务把所有这些记录累加起来产生一个数字。我们允许用户指定一个可选 的 combiner 函数，combiner 函数首先在本地将这些记录进行一次合并，然后将合并的结果再通过网络发送出 去。 Combiner 函数在每台执行 Map 任务的机器上都会被执行一次。一般情况下，Combiner 和 Reduce 函数是 一样的。Combiner 函数和 Reduce 函数之间唯一的区别是 MapReduce 库怎样控制函数的输出。Reduce 函数的 输出被保存在最终的输出文件里，而 Combiner 函数的输出被写到中间文件里，然后被发送给 Reduce 任务。 部分的合并中间结果可以显著的提高一些 MapReduce 操作的速度。附录 A 包含一个使用 combiner 函数 的例子。\n4.4 输入和输出的类型 MapReduce 库支持几种不同的格式的输入数据。比如，文本模式的输入数据的每一行被视为是一个 key/value pair。key 是文件的偏移量，value 是那一行的内容。另外一种常见的格式是以 key 进行排序来存储 的 key/value pair 的序列。每种输入类型的实现都必须能够把输入数据分割成数据片段，该数据片段能够由单 独的 Map 任务来进行后续处理(例如，文本模式的范围分割必须确保仅仅在每行的边界进行范围分割)。虽然 大多数 MapReduce 的使用者仅仅使用很少的预定义输入类型就满足要求了，但是使用者依然可以通过提供一 个简单的 Reader 接口实现就能够支持一个新的输入类型。 Reader 并非一定要从文件中读取数据，比如，我们可以很容易的实现一个从数据库里读记录的 Reader， 或者从内存中的数据结构读取数据的 Reader。 类似的，我们提供了一些预定义的输出数据的类型，通过这些预定义类型能够产生不同格式的数据。用 户采用类似添加新的输入数据类型的方式增加新的输出类型。\n4.5 副作用 在某些情况下，MapReduce 的使用者发现，如果在 Map 和/或 Reduce 操作过程中增加辅助的输出文件会 比较省事。我们依靠程序 writer 把这种“副作用”变成原子的和幂等的3。通常应用程序首先把输出结果写到 一个临时文件中，在输出全部数据之后，在使用系统级的原子操作 rename 重新命名这个临时文件。 如果一个任务产生了多个输出文件，我们没有提供类似两阶段提交的原子操作支持这种情况。因此，对 于会产生多个输出文件、并且对于跨文件有一致性要求的任务，都必须是确定性的任务。但是在实际应用过 程中，这个限制还没有给我们带来过麻烦。\n4.6 跳过损坏的记录 有时候，用户程序中的 bug 导致 Map 或者 Reduce 函数在处理某些记录的时候 crash 掉，MapReduce 操作 无法顺利完成。惯常的做法是修复 bug 后再次执行 MapReduce 操作，但是，有时候找出这些 bug 并修复它们 不是一件容易的事情；这些 bug 也许是在第三方库里边，而我们手头没有这些库的源代码。而且在很多时候， 忽略一些有问题的记录也是可以接受的，比如在一个巨大的数据集上进行统计分析的时候。我们提供了一种 执行模式，在这种模式下，为了保证保证整个处理能继续进行，MapReduce会检测哪些记录导致确定性的crash， 并且跳过这些记录不处理。 每个 worker 进程都设置了信号处理函数捕获内存段异常（segmentation violation）和总线错误（bus error）。 在执行 Map 或者 Reduce 操作之前，MapReduce 库通过全局变量保存记录序号。如果用户程序触发了一个系 统信号，消息处理函数将用“最后一口气”通过 UDP 包向 master 发送处理的最后一条记录的序号。当 master 看到在处理某条特定记录不止失败一次时，master 就标志着条记录需要被跳过，并且在下次重新执行相关的 Map 或者 Reduce 任务的时候跳过这条记录。\n4.7 本地执行 调试 Map 和 Reduce 函数的 bug 是非常困难的，因为实际执行操作时不但是分布在系统中执行的，而且 通常是在好几千台计算机上执行，具体的执行位置是由 master 进行动态调度的，这又大大增加了调试的难度。 为了简化调试、profile 和小规模测试，我们开发了一套 MapReduce 库的本地实现版本，通过使用本地版本的 MapReduce 库，MapReduce 操作在本地计算机上顺序的执行。用户可以控制 MapReduce 操作的执行，可以把 操作限制到特定的 Map 任务上。用户通过设定特别的标志来在本地执行他们的程序，之后就可以很容易的使 用本地调试和测试工具（比如 gdb）。\n4.8 状态信息 master 使用嵌入式的 HTTP 服务器（如 Jetty）显示一组状态信息页面，用户可以监控各种执行状态。状 态信息页面显示了包括计算执行的进度，比如已经完成了多少任务、有多少任务正在处理、输入的字节数、 中间数据的字节数、输出的字节数、处理百分比等等。页面还包含了指向每个任务的 stderr 和 stdout 文件的链 接。用户根据这些数据预测计算需要执行大约多长时间、是否需要增加额外的计算资源。这些页面也可以用 来分析什么时候计算执行的比预期的要慢。 另外，处于最顶层的状态页面显示了哪些 worker 失效了，以及他们失效的时候正在运行的 Map 和 Reduce 任务。这些信息对于调试用户代码中的 bug 很有帮助。\n4.9 计数器 MapReduce 库使用计数器统计不同事件发生次数。比如，用户可能想统计已经处理了多少个单词、已经 索引的多少篇 German 文档等等。 为了使用这个特性，用户在程序中创建一个命名的计数器对象，在 Map 和 Reduce 函数中相应的增加计 数器的值。例如：\n1Counter* uppercase; 2uppercase = GetCounter(“uppercase”); 3map(String name, String contents): 4for each word w in contents: 5 if (IsCapitalized(w)): 6 uppercase-\u0026gt;Increment(); 7 EmitIntermediate(w, “1″); 这些计数器的值周期性的从各个单独的worker机器上传递给master（附加在ping的应答包中传递）。master 把执行成功的 Map 和 Reduce 任务的计数器值进行累计，当 MapReduce 操作完成之后，返回给用户代码。 计数器当前的值也会显示在 master 的状态页面上，这样用户就可以看到当前计算的进度。当累加计数器 的值的时候，master 要检查重复运行的 Map 或者 Reduce 任务，避免重复累加（之前提到的备用任务和失效 后重新执行任务这两种情况会导致相同的任务被多次执行）。 有些计数器的值是由 MapReduce 库自动维持的，比如已经处理的输入的 key/value pair 的数量、输出的 key/value pair 的数量等等。 计数器机制对于 MapReduce 操作的完整性检查非常有用。比如，在某些 MapReduce 操作中，用户需要确 保输出的 key value pair 精确的等于输入的 key value pair，或者处理的 German 文档数量在处理的整个文档数 量中属于合理范围。\n5 性能 本节我们用在一个大型集群上运行的两个计算来衡量 MapReduce 的性能。一个计算在大约 1TB 的数据中 进行特定的模式匹配，另一个计算对大约 1TB 的数据进行排序。 这两个程序在大量的使用 MapReduce 的实际应用中是非常典型的 — 一类是对数据格式进行转换，从一 种表现形式转换为另外一种表现形式；另一类是从海量数据中抽取少部分的用户感兴趣的数据。\n5.1 集群配置 所有这些程序都运行在一个大约由 1800 台机器构成的集群上。每台机器配置 2 个 2G 主频、支持超线程 的 Intel Xeon 处理器，4GB 的物理内存，两个 160GB 的 IDE 硬盘和一个千兆以太网卡。这些机器部署在一个 两层的树形交换网络中，在 root 节点大概有 100-200GBPS 的传输带宽。所有这些机器都采用相同的部署（对 等部署），因此任意两点之间的网络来回时间小于 1 毫秒。 在 4GB 内存里，大概有 1-1.5G 用于运行在集群上的其他任务。测试程序在周末下午开始执行，这时主机 的 CPU、磁盘和网络基本上处于空闲状态。\n5.2 GREP 这个分布式的 grep 程序需要扫描大概 10 的 10 次方个由 100 个字节组成的记录，查找出现概率较小的 3 个字符的模式（这个模式在 92337 个记录中出现）。输入数据被拆分成大约 64M 的 Block（M=15000），整个 输出数据存放在一个文件中（R=1）。\n图 2 显示了这个运算随时间的处理过程。其中 Y 轴表示输入数据的处理速度。处理速度随着参与 MapReduce 计算的机器数量的增加而增加，当 1764 台 worker 参与计算的时，处理速度达到了 30GB/s。当 Map 任务结束的时候，即在计算开始后 80 秒，输入的处理速度降到 0。整个计算过程从开始到结束一共花了 大概 150 秒。这包括了大约一分钟的初始启动阶段。初始启动阶段消耗的时间包括了是把这个程序传送到各 个 worker 机器上的时间、等待 GFS 文件系统打开 1000 个输入文件集合的时间、获取相关的文件本地位置优 化信息的时间。\n5.3 排序 排序程序处理 10 的 10 次方个 100 个字节组成的记录（大概 1TB 的数据）。这个程序模仿 TeraSort benchmark[10]。\n排序程序由不到 50 行代码组成。只有三行的 Map 函数从文本行中解析出 10 个字节的 key 值作为排序的 key，并且把这个 key 和原始文本行作为中间的 key/value pair 值输出。我们使用了一个内置的恒等函数作为 Reduce 操作函数。这个函数把中间的 key/value pair 值不作任何改变输出。最终排序结果输出到两路复制的 GFS 文件系统（也就是说，程序输出 2TB 的数据）。 如前所述，输入数据被分成 64MB 的 Block（M=15000）。我们把排序后的输出结果分区后存储到 4000 个文件（R=4000）。分区函数使用 key 的原始字节来把数据分区到 R 个片段中。 在这个 benchmark 测试中，我们使用的分区函数知道 key 的分区情况。通常对于排序程序来说，我们会 增加一个预处理的 MapReduce 操作用于采样 key 值的分布情况，通过采样的数据来计算对最终排序处理的分 区点\n图三（a）显示了这个排序程序的正常执行过程。左上的图显示了输入数据读取的速度。数据读取速度峰 值会达到 13GB/s，并且所有 Map 任务完成之后，即大约 200 秒之后迅速滑落到 0。值得注意的是，排序程序 输入数据读取速度小于分布式 grep 程序。这是因为排序程序的 Map 任务花了大约一半的处理时间和 I/O 带宽 把中间输出结果写到本地硬盘。相应的分布式 grep 程序的中间结果输出几乎可以忽略不计。 左边中间的图显示了中间数据从 Map 任务发送到 Reduce 任务的网络速度。这个过程从第一个 Map 任务 完成之后就开始缓慢启动了。图示的第一个高峰是启动了第一批大概 1700 个 Reduce 任务（整个 MapReduce 分布到大概 1700 台机器上，每台机器 1 次最多执行 1 个 Reduce 任务）。排序程序运行大约 300 秒后，第一批 启动的 Reduce 任务有些完成了，我们开始执行剩下的 Reduce 任务。所有的处理在大约 600 秒后结束。\n左下图表示 Reduce 任务把排序后的数据写到最终的输出文件的速度。在第一个排序阶段结束和数据开始 写入磁盘之间有一个小的延时，这是因为 worker 机器正在忙于排序中间数据。磁盘写入速度在 2-4GB/s 持续 一段时间。输出数据写入磁盘大约持续 850 秒。计入初始启动部分的时间，整个运算消耗了 891 秒。这个速 度和 TeraSort benchmark[18]的最高纪录 1057 秒相差不多。 还有一些值得注意的现象：输入数据的读取速度比排序速度和输出数据写入磁盘速度要高不少，这是因 为我们的输入数据本地化优化策略起了作用 — 绝大部分数据都是从本地硬盘读取的，从而节省了网络带宽。 排序速度比输出数据写入到磁盘的速度快，这是因为输出数据写了两份（我们使用了 2 路的 GFS 文件系统， 写入复制节点的原因是为了保证数据可靠性和可用性）。我们把输出数据写入到两个复制节点的原因是因为这 是底层文件系统的保证数据可靠性和可用性的实现机制。如果底层文件系统使用类似容错编码[14](erasure coding)的方式而不是复制的方式保证数据的可靠性和可用性，那么在输出数据写入磁盘的时候，就可以降低 网络带宽的使用。\n5.4 高效的 backup 任务 图三（b）显示了关闭了备用任务后排序程序执行情况。执行的过程和图 3（a）很相似，除了输出数据写 磁盘的动作在时间上拖了一个很长的尾巴，而且在这段时间里，几乎没有什么写入动作。在 960 秒后，只有 5 个 Reduce 任务没有完成。这些拖后腿的任务又执行了 300 秒才完成。整个计算消耗了 1283 秒，多了 44% 的执行时间。\n5.5 失效的机器 在图三（c）中演示的排序程序执行的过程中，我们在程序开始后几分钟有意的 kill 了 1746 个 worker 中 的 200 个。集群底层的调度立刻在这些机器上重新开始新的 worker 处理进程（因为只是 worker 机器上的处理 进程被 kill 了，机器本身还在工作）。 图三（c）显示出了一个“负”的输入数据读取速度，这是因为一些已经完成的 Map 任务丢失了（由于 相应的执行 Map 任务的 worker 进程被 kill 了），需要重新执行这些任务。相关 Map 任务很快就被重新执行了。 整个运算在 933 秒内完成，包括了初始启动时间（只比正常执行多消耗了 5%的时间）。\n6 经验 我们在 2003 年 1 月完成了第一个版本的 MapReduce 库，在 2003 年 8 月的版本有了显著的增强，这包括 了输入数据本地优化、worker 机器之间的动态负载均衡等等。从那以后，我们惊喜的发现，MapReduce 库能 广泛应用于我们日常工作中遇到的各类问题。它现在在 Google 内部各个领域得到广泛应用，包括：\n\\1. 大规模机器学习问题\n\\2. Google News 和 Froogle 产品的集群问题 3. 从公众查询产品（比如 Google 的 Zeitgeist）的报告中抽取数据。 4. 从大量的新应用和新产品的网页中提取有用信息（比如，从大量的位置搜索网页中抽取地理位置信 息）。 5. 大规模的图形计算。\n图四显示了在我们的源代码管理系统中，随着时间推移，独立的 MapReduce 程序数量的显著增加。从 2003 年早些时候的0个增长到2004年9月份的差不多900个不同的程序。MapReduce的成功取决于采用MapReduce 库能够在不到半个小时时间内写出一个简单的程序，这个简单的程序能够在上千台机器的组成的集群上做大 规模并发处理，这极大的加快了开发和原形设计的周期。另外，采用 MapReduce 库，可以让完全没有分布式 和/或并行系统开发经验的程序员很容易的利用大量的资源，开发出分布式和/或并行处理的应用。\n在每个任务结束的时候，MapReduce 库统计计算资源的使用状况。在表 1，我们列出了 2004 年 8 月份 MapReduce 运行的任务所占用的相关资源。\n6.1 大规模索引 到目前为止，MapReduce 最成功的应用就是重写了 Google 网络搜索服务所使用到的 index 系统。索引系 统的输入数据是网络爬虫抓取回来的海量的文档，这些文档数据都保存在 GFS 文件系统里。这些文档原始内 容4的大小超过了 20TB。索引程序是通过一系列的 MapReduce 操作（大约 5 到 10 次）来建立索引。使用 MapReduce（替换上一个特别设计的、分布式处理的索引程序）带来这些好处： 实现索引部分的代码简单、小巧、容易理解，因为对于容错、分布式以及并行计算的处理都是 MapReduce 库提供的。比如，使用 MapReduce 库，计算的代码行数从原来的 3800 行 C++代码减少到大概 700 行代码。 MapReduce 库的性能已经足够好了，因此我们可以把在概念上不相关的计算步骤分开处理，而不是混在 一起以期减少数据传递的额外消耗。概念上不相关的计算步骤的隔离也使得我们可以很容易改变索引处理方 式。比如，对之前的索引系统的一个小更改可能要耗费好几个月的时间，但是在使用 MapReduce 的新系统上， 这样的更改只需要花几天时间就可以了。 索引系统的操作管理更容易了。因为由机器失效、机器处理速度缓慢、以及网络的瞬间阻塞等引起的绝 大部分问题都已经由 MapReduce 库解决了，不再需要操作人员的介入了。另外，我们可以通过在索引系统集 群中增加机器的简单方法提高整体处理性能。\n7 相关工作 很多系统都提供了严格的编程模式，并且通过对编程的严格限制来实现并行计算。例如，一个结合函数可以通过把 N 个元素的数组的前缀在 N 个处理器上使用并行前缀算法，在 log N 的时间内计算完[6，9，13]5。 MapReduce 可以看作是我们结合在真实环境下处理海量数据的经验，对这些经典模型进行简化和萃取的成果。 更加值得骄傲的是，我们还实现了基于上千台处理器的集群的容错处理。相比而言，大部分并发处理系统都 只在小规模的集群上实现，并且把容错处理交给了程序员。 Bulk Synchronous Programming[17]和一些 MPI 原语[11]提供了更高级别的并行处理抽象，可以更容易写 出并行处理的程序。MapReduce 和这些系统的关键不同之处在于，MapReduce 利用限制性编程模式实现了用 户程序的自动并发处理，并且提供了透明的容错处理。 我们数据本地优化策略的灵感来源于 active disks[12,15]等技术，在 active disks 中，计算任务是尽量推送 到数据存储的节点处理6，这样就减少了网络和 IO 子系统的吞吐量。我们在挂载几个硬盘的普通机器上执行 我们的运算，而不是在磁盘处理器上执行我们的工作，但是达到的目的一样的。 我们的备用任务机制和 Charlotte System[3]提出的 eager 调度机制比较类似。Eager 调度机制的一个缺点是 如果一个任务反复失效，那么整个计算就不能完成。我们通过忽略引起故障的记录的方式在某种程度上解决 了这个问题。 MapReduce 的实现依赖于一个内部的集群管理系统，这个集群管理系统负责在一个超大的、共享机器的 集群上分布和运行用户任务。虽然这个不是本论文的重点，但是有必要提一下，这个集群管理系统在理念上 和其它系统，如 Condor[16]是一样。 MapReduce 库的排序机制和 NOW-Sort[1]的操作上很类似。读取输入源的机器（map workers）把待排序 的数据进行分区后，发送到 R 个 Reduce worker 中的一个进行处理。每个 Reduce worker 在本地对数据进行排 序（尽可能在内存中排序）。当然，NOW-Sort 没有给用户自定义的 Map 和 Reduce 函数的机会，因此不具备 MapReduce 库广泛的实用性。River[2]提供了一个编程模型：处理进程通过分布式队列传送数据的方式进行互相通讯。和 MapReduce 类似，River 系统尝试在不对等的硬件环境下，或者在系统颠簸的情况下也能提供近似平均的性能。River 是 通过精心调度硬盘和网络的通讯来平衡任务的完成时间。MapReduce 库采用了其它的方法。通过对编程模型 进行限制，MapReduce 框架把问题分解成为大量的“小”任务。这些任务在可用的 worker 集群上动态的调度， 这样快速的 worker 就可以执行更多的任务。通过对编程模型进行限制，我们可用在工作接近完成的时候调度 备用任务，缩短在硬件配置不均衡的情况下缩小整个操作完成的时间（比如有的机器性能差、或者机器被某 些操作阻塞了）。 BAD-FS[5]采用了和 MapReduce 完全不同的编程模式，它是面向广域网（alex 注：wide-area network）的。不过，这两个系统有两个基础功能很类似。（1）两个系统采用重新执行的方式来防止由于失效导致的数据丢 失。（2）两个都使用数据本地化调度策略，减少网络通讯的数据量。 TACC[7]是一个用于简化构造高可用性网络服务的系统。和 MapReduce 一样，它也依靠重新执行机制来 实现的容错处理。\n8 结束语 MapReduce 编程模型在 Google 内部成功应用于多个领域。我们把这种成功归结为几个方面：首先，由于 MapReduce 封装了并行处理、容错处理、数据本地化优化、负载均衡等等技术难点的细节，这使得 MapReduce 库易于使用。即便对于完全没有并行或者分布式系统开发经验的程序员而言；其次，大量不同类型的问题都 可以通过 MapReduce 简单的解决。比如，MapReduce 用于生成 Google 的网络搜索服务所需要的数据、用来 排序、用来数据挖掘、用于机器学习，以及很多其它的系统；第三，我们实现了一个在数千台计算机组成的 大型集群上灵活部署运行的 MapReduce。这个实现使得有效利用这些丰富的计算资源变得非常简单，因此也 适合用来解决 Google 遇到的其他很多需要大量计算的问题。 我们也从 MapReduce 开发过程中学到了不少东西。首先，约束编程模式使得并行和分布式计算非常容易， 也易于构造容错的计算环境；其次，网络带宽是稀有资源。大量的系统优化是针对减少网络传输量为目的的： 本地优化策略使大量的数据从本地磁盘读取，中间文件写入本地磁盘、并且只写一份中间文件也节约了网络 带宽；第三，多次执行相同的任务可以减少性能缓慢的机器带来的负面影响（alex 注：即硬件配置的不平衡）， 同时解决了由于机器失效导致的数据丢失问题。\n","date":"2022-09-05","img":"","permalink":"/posts/6db6b747/","series":["MIT6.824"],"tags":["MapReduce"],"title":"Google MapReduce翻译"},{"categories":[],"content":"本文对 MIT 6.824 Lab 1:MapReduce 的说明文档进行了全文翻译。需要注意的是文中的 job 和 task，其中，job 是指整个 MapReduce 计算，表示的是任务整体，而 task 则是指一次 Map/Reduce 调用，表示的是任务局部，一个完整的 MapReduce job 由一些 Map task 和 Reduce task 组成。\n翻译 引言 本实验的目标是引导您构建一个 MapReduce 系统，您需要实现两个程序：worker 和 master。其中 worker 进程负责处理文件读写操作以及调用 Map/Reduce 函数处理 Task。而 master 进程则负责为 worker 进程分配 Task 并处理崩溃的 worker 进程。您构建的系统与MapReduce 论文中所描述的系统类似。\n协作政策 除了我们提供给您的代码外，您必须独立完成实验要求的代码。实现过程中杜绝参考其他同学和前几年课程实验的解决方案。允许您与同学讨论，但不允许您抄袭他们的代码。之所以设立这条规则，是因为我们认为只有独立完成实验，您的能力才会得到最大的提升。\n请不要公布您的代码，也不要让它被选修 6.824 的学生通过某种方式获取到。github.com中的仓库权限默认是公开的，除非您将仓库权限设为私有，否则请勿用其存储实验代码。保存代码可以使用MIT 的 Github，但请确保您创建的是私有仓库。\n软件 本实验（以及 6.824 的其他实验）使用的编程语言是Go语言，如果您不熟悉 Go 语言，其官方网站上有很多教程供您学习。我们将使用 1.13 版本的 Go 语言来评判您的代码，因此您也应该使用这一版本。另外，如果您要查看计算机中已有的 Go 语言版本，可以执行go version命令。\n我们推荐您在自己的机器上完成实验，这样您就可以使用您熟悉的环境，比如工具，文本编辑器等。另外，您也可以在 Athena 上完成实验。\nmacOS 您可以使用Homebrew来安装 Go 语言。安装好 Homebrew 后，执行brew install go命令即可。\nLinux 根据您使用的 Linux 发行版，您可以从相应的软件包库中下载最新版的 Go 语言，比如在 Ubuntu 中可以执行apt install golang命令来安装 Go 语言。此外，您还可以从 Go 语言的官方网站中手动下载二进制包。首先，确保您使用的是 64 位的 Linux 内核（uname -a会提示\u0026quot;x86_64 GNU/Linux\u0026quot;），然后执行如下命令即可：\n1$ wget -qO- https://dl.google.com/go/go1.13.6.linux-amd64.tar.gz | sudo tar xz -C /usr/local 需要确保/usr/local/bin在您的环境变量PATH中。\nWindows 实验可能无法直接运行于 Windows 上。如果您敢于尝试，可以试试Windows Subsystem for Linux，并执行上述 Linux 命令。否则还是乖乖使用 Athena 吧。\nAthena 您可以通过ssh {your kerberos}@athena.dialup.mit.edu命令登录公共 Athena 主机。一旦登录成功，便可通过如下命令获取 1.13 版本的 Go 语言：\n1$ setup ggo 开始 您将使用git（版本控制系统）拉取实验初始版本代码。如果您不熟悉 git，可以通过查阅Git-Book和Git User Manual自行学习。执行以下命令，即可从远端拉取 6.824 的初始实验代码：\n1$ git clone git://g.csail.mit.edu/6.824-golabs-2020 6.824 2$ cd 6.824 3$ ls 4Makefile src 5$ 在src/main/mrsequential.go中，我们为您实现了一个简单的顺序 MapReduce。由于使用的是单进程，因此该程序同一时刻仅能执行一个 Map/Reduce task。此外，我们还为您提供了多组处理不同 task 的 Map/Reduce 应用程序代码：如mrapps/wc.go中包含单词计数所需的 Map/Reduce 方法，mrapps/indexr.go中包含计算文档索引的 Map/Reduce 方法。您可以执行以下命令来运行单词计数的顺序版本 MapReduce：\n1$ cd ~/6.824 2$ cd src/main 3$ go build -buildmode=plugin ../mrapps/wc.go 4$ rm mr-out* 5$ go run mrsequential.go wc.so pg*.txt 6$ more mr-out-0 7A 509 8ABOUT 2 9ACT 8 10... mrsequential.go所需的输入数据来自名为pg-xxx.txt的文本文件，输出则保存在文件mr-out-0中。\n您可以从mrsequential.go中随意借鉴您需要的代码，同时也可以阅读mrapps/wc.go来了解 MapReduce 的应用程序代码长啥样。\n您的任务 您的任务是实现一个分布式的 MapReduce 系统，该系统由两个程序组成：master 和 worker，在系统运行期间共包含一个 master 进程和多个并行运行的 worker 进程。在实际应用的 MapReduce 系统中，worker 进程运行在很多不同的机器上，而在本实验中，您只需要在一台机器上运行它们即可。worker 进程和 master 进程之间使用 RPC 通信。每个 worker 进程需完成以下工作：向 master 进程请求 task，从若干文件中读取输入数据，执行 task，并将 task 的输出写入到若干文件中。master 进程除了为 worker 进程分配 task 外，还需要检查在一定时间内（本实验中为 10 秒）每个 worker 进程是否完成了相应的 task，如果未完成的话则将该 task 转交给其他 worker 进程。\n我们为您提供了一些上下文代码。master 程序和 worker 程序的 main 函数入口分别位于main/mrmaster.go和main/mrworker.go中，不要修改这些文件，您应该将您需要实现的代码写在mr/master.go，mr/worker.go和mr/rpc.go中。\n下面说明如何运行您写的代码，以单词计数应用程序为例。首先，执行以下命令以确保被构建的单词计数插件是最新版：\n1$ go build -buildmode=plugin ../mrapps/wc.go cd 到src/main/中，运行 master 程序：\n1$ rm mr-out* 2$ go run mrmaster.go pg-*.txt 其中pg-*.txt参数是文件路径，这些文件中保存着 master 程序的输入数据；每个文件都可以作为单个 Map task 的输入。\n在其他若干窗口中，您可以运行如下命令来执行一个或多个 worker 进程：\n1$ go run mrworker.go wc.so 当 worker 进程和 master 进程执行完毕后，可以显示 mr-out-*中的内容以查看程序输出。如果您的实验代码没有错误的话，经过排序后的输出结果应与mrsequential.go的输出相同，如下所示：\n1$ cat mr-out-* | sort | more 2A 509 3ABOUT 2 4ACT 8 5... main/test-mr.sh是我们为您提供的测试脚本。当给定pg-xxx.txt作为输入时，该脚本会检查您实现的 MapReduce 系统对两个不同类型的 Job（单词计数和计算文档索引）是否产生了正确的输出。该脚本也会检查您实现的 MapReduce 系统的 worker 进程在处理 Map task 和 Reduce task 时是否是并行运行的，以及您的系统是否能正确处理发生崩溃的 worker 进程。\n如果您现在运行测试脚本，它将会挂起，因为 master 并没有被实现：\n1$ cd ~/6.824/src/main 2$ sh test-mr.sh 3*** Starting wc test. 您可以将mr/master.go中Done函数内的ret := false语句修改为 true 来使主程序立刻退出，您将会得到如下输出：\n1$ sh ./test-mr.sh 2*** Starting wc test. 3sort: No such file or directory 4cmp: EOF on mr-wc-all 5--- wc output is not the same as mr-correct-wc.txt 6--- wc test: FAIL 7$ 测试脚本期望对于每个 reduce task，都会生成一个被命名为mr-out-X的输出文件。空的mr/master.go和mr/worker.go不会生成这些文件（也少做了很多其他事情），进而导致测试失败。\n当将全部代码实现完毕后，运行测试脚本后的输出应该看起来像这样：\n1$ sh ./test-mr.sh 2*** Starting wc test. 3--- wc test: PASS 4*** Starting indexer test. 5--- indexer test: PASS 6*** Starting map parallelism test. 7--- map parallelism test: PASS 8*** Starting reduce parallelism test. 9--- reduce parallelism test: PASS 10*** Starting crash test. 11--- crash test: PASS 12*** PASSED ALL TESTS 13$ 您也会看到一些来自 Go RPC 包输出的错误，看起来像这样：\n12019/12/16 13:27:09 rpc.Register: method \u0026#34;Done\u0026#34; has 1 input parameters; needs exactly three 忽略这些信息即可。\n一些规则：\nmap 阶段应将中间键分割为不同的桶（译者注：中间键指的是 MapReduce 论文中的 intermediate key，这句话的意思是将 map Task 的输出以某种形式保存为 reduce 函数能够读取的输入），方便后续nReduce个 reduce task 读取，而nReduce则是main/mrmaster.go传递给MakeMaster的参数； worker 进程应把第 X 个 reduce task 的输出保存到文件mr-out-X中； mr-out-X中每行都应该是调用一次 Reduce 函数的输出，应该按照 Go 语言的\u0026quot;%v %v\u0026quot;的格式生成，也即 key 和 value，如在main/mrsequential.go中注释\u0026quot;this is the correct format\u0026quot;的位置所示。如果您的实现和这一格式相差太多，测试脚本将会执行失败； 您需要修改的文件为：mr/worker.go，mr/master.go和mr/rpc.go。尽管您可以暂时地修改其他文件来辅助您测试，但请确保其他文件被还原为初始状态（原始版本）后您的程序仍能正常工作，我们将会使用原始版本的代码进行评判； woker 进程应该将 Map 函数的输出（intermediate key）保存在当前目录的文件中，使得后续 worker 进程可以读取它们并将其作为 Reduce task 的输入； 当 MapReduce Job 被计算完毕后，main/mrmaster.go希望您实现的mr/master.go中的Done()方法会返回 true。这样mrmaster.go就能知道 Job 已经顺利完成，进程即可退出； 当 MapReduce job 被做完后，worker 进程就应该退出。实现这一功能的一种笨方法就是令 woker 程序检查call()函数的返回值：如果 woker 进程无法和 master 进程通信，那么 worker 进程就可以认为整个 Job 已经全被做完了，自己也就可以退出了。当然是否这么做还是要取决于您的设计，您也可以设计一个”please exit“的伪任务，当 worker 进程收到这一任务，就自动退出。 提示 如果您觉得无从下手，可以从修改mr/worker.go中的Worker()函数开始，在函数中首先实现以下逻辑：向 master 发送 RPC 来请求 task。然后修改 master：将文件名作为尚未开始的 map task 响应给 worker。然后修改 worker：读取文件并像mrsequential.go程序一样，调用 Map 方法来处理读取的数;\nMapReduce 应用程序的 Map/Reduce 函数被保存在以.so结尾的文件中，在运行时使用 Go plugin 包读取；\n如果您改变了mr/文件夹中的文件，并且该文件也被用到，那您需要将该文件使用类似于go build -buildmode=plugin ../mrapps/wc.go的命令重新编译成 MapReduce 插件；\n本实验要求 worker 进程使用同一个文件系统，因此所有的 worker 进程必须运行于一台机器上。如果想要让 worker 程序运行在不同的机器上，那您需要为他们提供一个全局的文件系统，比如 GFS；\n一个命名中间文件的合理形式是mr-X-Y，其中 X 是 Map task 的编号，Y 是 Reduce task 编号；\nworker 程序处理 Map task 的代码中需要一种将中间键值对存储为文件的方式，也需要一种在处理 Reduce task 时能从文件中正确读回键值对的方式。一种可能的实现是使用 Go 语言的encoding/json包。将键值对写入 JSON 文件的代码如下：\n1 enc := json.NewEncoder(file) 2 for _, kv := ... { 3 err := enc.Encode(\u0026amp;kv) 从 JSON 文件中读回键值对的代码如下：\n1 dec := json.NewDecoder(file) 2 for { 3 var kv KeyValue 4 if err := dec.Decode(\u0026amp;kv); err != nil { 5 break 6 } 7 kva = append(kva, kv) 8 } 在 worker 中处理 map Task 的部分，对于一个给定键，您可以使用ihash(key)函数（在worker.go中）来选择它属于哪一个 reduce task；\n您可以将mrsequential.go中一些功能的代码拿来直接用，比如：读取 map task 的输入文件，在调用 Map 方法和调用 Reduce 方法之间对中间键值对进行排序，以及存储 Reduce 函数的输出到文件。\n作为一个 RPC 服务器，master 进程将是并发的，因此不要忘记给共享资源加锁。\n可以执行命令go build -race和go run -race来使用 Go 语言的 race detector，在test.sh中有一条注释为您展示如何为测试开启 race detector；\nworker 进程有时需要等待，比如在最后一个 map task 处理完之前，worker 不能开始对 reduce task 的处理。实现这一功能的一种可能方案是 worker 进程周期性的向 master 请求 task，在每次请求间使用time.Sleep()阻塞一段时间。另一种可能的方案是 master 在收到 rpc 请求后额外开启一个 RPC 处理线程，在这个线程中执行循环等待（也可以使用time.Sleep()和sync.Cond），这样使得阻塞的 RPC 不会影响 master 响应其他 RPC；\nmaster 进程无法可靠的区分崩溃的 worker 进程、活着但因某些原因停止运行的 worker 进程和正在运行但太慢导致无法使用的 worker 进程。这一问题最好的解决方案是令 master 等待一段时间，如果某个 worker 进程在这段时间（在本实验中，这段时间被设置为 10 秒）内没有完成相应的 task，就放弃继续等待并将该 task 重新分配给其他 worker。之后，master 应该假设这个 worker 进程已经死亡了（当然，它可能还活着）；\n为了测试容错，您可以使用mrapps/crash.go插件，它在 Map 和 Reduce 函数中增加了随机退出功能；\n为了确保没人能看到被崩溃进程写了一半的文件，MapReduce 论文提到了一个小技巧，那就是使用临时文件，一旦该文件完全写完，就自动重命名。您可以使用ioutil.TempFile创建临时文件，并使用os.Rename去自动重命名它。\ntest-mr.sh将会在子目录mr-tmp中运行所有的进程，因此如果有错误发生并且您想查看中间输出文件的话，可以查看这一目录中的文件。\n提交步骤 注意：在正式提交前，请运行test-mr.sh。\n使用命令make lab1命令打包您的实验代码并将其上传到班级的提交网站，其网址为：https://6824.scripts.mit.edu/2020/handin.py/。\n第一次提交时您可能需要通过以下方式之一进行登录：1. 使用您的 MIT 证书；2. 通过 email 申请一个 API key。一旦登录成功，您的 API key（XXX）将会被显示，在控制台中输入以下命令上传 lab1 时会用到这一 API key：\n1$ cd ~/6.824 2$ echo XXX \u0026gt; api.key 3$ make lab1 注意：检查提交网站以确保您的实验代码已经成功提交！\n提示：您可能提交了多次。我们将会使用时间戳来检查您的提交是否是最新的。\n原文 http://nil.csail.mit.edu/6.824/2020/labs/lab-mr.html\n","date":"2022-09-05","img":"","permalink":"/posts/f6adfb46/","series":["MIT6.824"],"tags":["MapReduce"],"title":"6.824 Spring 2020 Lab1 MapReduce文档翻译"},{"categories":["学习"],"content":"本篇文章主要会介绍我为什么会选择使用 notion，以及我在 notion 中的规划。\n为什么选择 notion 起初，我的笔记是本地 markdown+goodnotes ，如果电脑和 ipad在身边还好，可以实时看到自己的笔记。但是如果没有带其中的一样，那么笔记就不全。\n之后的一段时间还使用过 OneNote ，它的同步速度很快，无论是在手机、电脑、iPad 随时随地都可以看到自己的笔记，但是OneNote 的逻辑不是很清楚，它就像一大张草稿纸等待我去填充，就像小时候的手抄报一样要自己设置格式，在调整格式上对于我来说要花费很多的时间。\n再之后用过两个多月的 飞书，起初用飞书的感觉真的不错，可以多端同步、支持 markdown、免费，这些都很不错，但是这些自从实习后换了电脑就都不是重要的了。飞书在电脑上无论你是否安装了客户端都会在网页中打开飞书文档，当标签页开的多之后，飞书文档的网页就会很卡，这当然和我的配置有关，目前公司配的是丐版的 MacBookPro只有 8GB 内存。\n目前使用的 notion 没有了其它三个的缺点，但是有一个致命的缺点——服务器在国外，这说不定那天就不能用了。但是我还是选择了它。\n我的第一版的 notion 刚开始使用 notion 发现它的嵌套页面非常不错，notion 中万物都是 block，block 中有 block ，就连页面都是 block。我按照之前的逻辑设计了一版的 workspace。\n我是按照自己的使用习惯来分类的。\n我有个网站需要写一些博客，但是博客不一定每次都是一次性写完的，需要有待写的以及写完的、发布的。\n同时自己之前学习过一段时间的 Vim 目前开发用的也是 Neovim，自己也需要记录，这一部分可能是可以公开的(写成博客)，也可能是不想公开的。同理学习 MongoDB、Linux、Go、Git等等都是这样的。\n同时看到不错的文章、书籍、教学视频、官方文档在学习之后也要做一些笔记，要不然忘得很快。\n这时候就出现了一个问题，有的内容属于多个目录时候该怎么办？\n比如我写了篇关于 Vim 使用的文章，我想把它分享出去，这时候应该属于Blog 呢还是 Vim 呢？当然我可以使用 link 的方式链接过去，但是这种分类方式可能就不太适合这种情况了。\n我的需求是什么？ 当我觉得上述分类不太合理的时候，想要换一种方式来管理这些，但是有没有好的思路的时候，我将自己的需求整理了出来。\n看别人的博客，进行总结 看视频进行学习，记笔记 看官方文档学习，记笔记 记录工作的情况，记笔记 保存自己的想法，或者是未发布、正在写的博客 记笔记 上面这六点是我书写文档的目的，上面其实可以分为两大类，一个是工作另一个就是学习，当然可能会有生活上的事情，但是这些可能不会通过写文档的方式进行保存。\n对于看别人的博客、视频、文档等都是自己摄取知识的来源，我把这些称之为资源。\n对于要学习的内容，比如说 Go 这个是学习下面的一个模块，而我通过什么样的途径来学习就是资源。\n在学习的过程中会有输出，我把笔记和博客称为输出。\n我目前已经抽象出来了 工作 和 学习 ，笔记、博客、视频、文档、书籍几种资源，学习的内容：Go、Linux… 这些如何关联起来呢，这就需要使用 notion 的一个特殊的 block ——database。\n这里的 database 和计算机中的 database 是类似的，只不过这里的一个 database 就是一张表，有了表之后就可以通过某种方式把他们关联起来——这就是relation，通过 relation 可以把多个 database 关联起来一起管理。\n根据不同的资源分类那么就有——笔记 database、博客 database、视频 database、文档 database、书籍 database。\n根据大类工作和学习，我重新进行了划分，他们下面又有子分类。\n工作 公司 1 公司 2 学习 go vim Git … 每种资源会和上面的分类进行组合。这样就不会出现有内容不知道放在那个分类的尴尬处境了。\n当然每种资源都有各自同的属性，\n除此之外，我还添加了阅读或者完成的状态。\n将状态和资源进行关联起来就可以看到不同学习内容当前的进度了。\n每添加一条数据的时候，有些数据可能是计算出来的，或者是固定的，我们可以使用 template 生成。\n我的数据库都使用了模板生成。每次只需要要填上标题和标签即可。\n对 database 的视图也可以生成模板\n我想看到每个二级标签中都有哪些内容，就可以使用不同的视图+filter 进行展示。如果不用模板，我每一条都要使用手动复制 database link 过来处理，有了模板之后，就可以在添加记录的时候将这些视图都添加好。\n总结 以上就是我目前 notion 的规划。这是模板链接\n参考 https://theblock.notion.site/theBlock-fa78e71c91bc4023a9c045520a848846\n","date":"2022-08-07","img":"","permalink":"/posts/14976c16/","series":[],"tags":["notion"],"title":"我的notion规划"},{"categories":[],"content":"我们平时开发的时候都是从主仓库 fork 到自己仓库，然后将 fork 的仓库 clone 到本地进行开发，本地创建对应的开发分支A，开发完成以后再将A分支提交到 fork 的仓库，之后提交 pr 到主仓库。 但是一般而言，我们都是整个团队在开发，等开发完了，需要合并到远程分支的时候，远程分支已经有很多次提交（commit)了，自己的分支已经落后主分支很多版本，切换回主分支的时候就不在最新commit上了。\n解决思路 远程仓库主分支为 qbox/develop , fork 仓库主分支orgin/develop\n假设当前开发的分支名为 KODO-11324 ,\n在 fork 仓库主分支拉取最新的代码 根据主分支（develop）代码在本地创建新的临时分支，命名为tmp 将临时分支（tmp）合并到开发分支 KODO-11324 解决合并后的冲突 提交开发分支（KODO-11324）并push到fork仓库 开发分支（KODO-11324）提交 pr 到主仓库 实现 在 fork 仓库主分支拉取最新的代码 切换到本地主分支\n1git checkout orgin/develop 拉取最新代码\n1git pull qbox develop 根据主分支在本地创建新的临时分支 1git checkout -b tmp 将临时分支合并到开发分支 切换到开发分支 KODO-11324\n1git checkout KODO-11324 临时分支合并到开发分支\n1git merge tmp 解决冲突 手动解决冲突\n开发分支 push 到 fork 仓库 1git push orgin HEAD 2枚举对象中: 186, 完成. 3对象计数中: 100% (172/172), 完成. 4使用 4 个线程进行压缩 5压缩对象中: 100% (108/108), 完成. 6写入对象中: 100% (134/134), 12.87 KiB | 1.07 MiB/s, 完成. 7总共 134（差异 91），复用 0（差异 0），包复用 0 8remote: Resolving deltas: 100% (91/91), completed with 25 local objects. 9remote: 10remote: Create a pull request for \u0026#39;KODO-11324\u0026#39; on GitHub by visiting: 11remote: \u0026lt;https://github.com/jimyag/project-name/pull/new/KODO-11324\u0026gt; 12remote: 13To github.com:jimyag/kodo.git 14 * [new branch] HEAD -\u0026gt; KODO-11324 提交 pr 点击 https://github.com/jimyag/project-name/pull/new/KODO-11324 即可提交 pr\n","date":"2022-08-02","img":"","permalink":"/posts/9c78a390/","series":[],"tags":["Git"],"title":"Git开发分支落后远程主分支"},{"categories":[],"content":"描述\n在 clone 下的 git 仓库中查看文件，发现很卡顿。一条ls的命令都需要 7,8 秒。\n这个是因为在进入目录的时候，oh-my-zsh 的 git prompt 每次都会在你的命令结束之后之心 git status 来检测当前的分支，当仓库很大的时候就会非常慢了。\n这个我们直接关闭就好了。\n设置 oh-my-zsh 不读取文件变化信息（在 git 项目目录执行下列命令）\n1git config --add oh-my-zsh.hide-dirty 1 如果想恢复显示，可以将 1 改为 0，或者\n1git config --remove-section oh-my-zsh 如果你还觉得慢，可以再设置 oh-my-zsh 不读取任何 git 信息\n1git config --add oh-my-zsh.hide-status 1 如果你实在太卡，以至于仓库都进不去了，那么可以添加 \u0026ndash;global ，在所有仓库都禁用这个功能\n1git config --global --add oh-my-zsh.hide-dirty 1 2git config --global --add oh-my-zsh.hide-status 1 查看配置信息\n1# 当前仓库 2git config --local -e 3# 全局设置 4git config --global -e ","date":"2022-07-26","img":"","permalink":"/posts/0f0b28a1/","series":[],"tags":["git","oh-my-zsh"],"title":"Oh My Zsh进入git目录卡顿"},{"categories":["vim","nvim"],"content":"Vimtutor 的中文翻译\nVim是一个具有很多命令的功能非常强大的编辑器。限于篇幅，在本教程当中就不详细介绍了。本教程的设计目标是讲述一些必要的基本命令，而掌握好这些命令，您就能够很容易地将Vim当作一个通用编辑器来使用了。\n完成本教程的内容大约需要25-30分钟，取决于您训练的时间。\n注意：\n每一节的命令操作将会更改本文。推荐您复制本文的一个副本，然后在副本上进行训练(如果您是通过vimtutor来启动教程的，那么本文就已经是副本了)。切记一点：本教程的设计思路是在使用中进行学习的。也就是说，您需要通过执行命令来学习它们本身的正确用法。如果您只是阅读而不操作，那么您可能会很快遗忘这些命令的！\n好了，现在请确定您的Shift-Lock(大小写锁定键)还没有按下，然后按键盘上的字母键 j 足够多次来移动光标，直到第一节的内容能够完全充满屏幕。\n第一讲第一节：移动光标 要移动光标，请依照说明分别按下h、j、k、l键。\nh 的键位于左边，每次按下就会向左移动。i 的键位于右边，每次按下就会向右移动。\nj 键看起来很象一支尖端方向朝下的箭头。k 键向上。\n请随意在屏幕内移动光标，直至您觉得舒服为止。 按下下行键(j)，直到出现光标重复下行。 \u0026mdash;\u0026gt;现在您应该已经学会如何移动到下一讲吧。\n现在请使用下行键，将光标移动到第一讲第二节。 提示：如果您不敢确定您所按下的字母，请按下\u0026lt;ESC\u0026gt;键回到正常(Normal)模式。然后再次从键盘输入您想要的命令。\n提示：光标键应当也能正常工作的。但是使用 hjkl 键，在习惯之后您就能够更快地在屏幕内四处移动光标。真的是这样！\n第一讲第二节：VIM的进入和退出 !!特别提示：敬请阅读本一节的完整内容，然后再执行以下所讲解的命令。\n按键(这是为了确保您处在正常模式)。\n然后输入：:q!\u0026lt;回车\u0026gt;\n这种方式的退出编辑器会丢弃您进入编辑器以来所做的改动。\n如果您看到了命令行提示符，请输入能够带您回到本教程的命令，那就是：vimtutor\u0026lt;回车\u0026gt;\n如果您自信已经牢牢记住了这些步骤的话，请从步骤1执行到步骤3退出，然后再次进入编辑器。\n提示：:q!\u0026lt;回车\u0026gt;会丢弃您所做的任何改动。几讲之后您将学会如何保存改动到文件。\n将光标下移到第一讲第三节。 第一讲第三节：文本编辑之删除 在正常(Normal)模式下，可以按下x键来删除光标所在位置的字符。\n请将光标移动到本节中下面标记有\u0026mdash;\u0026gt;的那一行。\n为了修正输入错误，请将光标移至准备删除的字符的位置处。\n然后按下x键将错误字符删除掉。\n重复步骤2到步骤4，直到句子修正为止。\n\u0026mdash;\u0026gt;Theccowjumpeddovverrthhemooon.\n好了，该行已经修正了，下面是第一讲第四节。 特别提示：在浏览本教程时，不要强行记忆。记住一点：在使用中学习。\n第一讲第四节：文本编辑之插入 在正常模式下，可以按下i键来插入文本。\n请将光标移动到本节中下面标记有\u0026mdash;\u0026gt;的第一行。 为了使得第一行内容雷同于第二行，请将光标移至文本第一个准备插入字符的位置。 然后按下i键，接着输入必要的文本字符。 每个错误修正完毕后，请按下键返回正常模式。 重复步骤2至步骤4以便修正句子。 \u0026mdash;\u0026gt;Thereistextmisngthis.\n\u0026mdash;\u0026gt;Thereissometextmissingfromthisline.\n如果您对文本插入操作已经很满意，请接着阅读下面的第一讲第五节。 第一讲第五节：文本编辑之添加 按A键以添加文本。\n移动光标到下面第一个标记有\u0026mdash;\u0026gt;的一行。光标放在那一行的哪个字符上并不重要。 按A键输入必要的添加内容。 文本添加完毕后，按键回到正常模式。 移动光标到下面第二个标记有\u0026mdash;\u0026gt;的一行。重复步骤2和步骤3以改正这个句子。 \u0026mdash;\u0026gt;Thereissometextmissingfromth\nThereissometextmissingfromthisline.\n\u0026mdash;\u0026gt;Thereisalsosometextmiss\nThereisalsosometextmissinghere.\n当您对添加文本操作感到满意时，请继续学习第一讲第六节。 第一讲第六节：编辑文件 使用:wq以保存文件并退出。\n特别提示：在执行以下步骤之前，请先读完整个小节！\n如您在第一讲第二节中所做的那样退出本教程：:q!或者，如果您可以访问另一个终端，请在那里执行以下操作。\n在shell的提示符下输入命令：vim tutor\u0026lt;回车\u0026gt;\n\u0026lsquo;vim\u0026rsquo;是启动Vim编辑器的命令，\u0026rsquo;tutor\u0026rsquo;是您希望编辑的文件的名字。请使用一个可以改动的文件。\n使用您在前面的教程中学到的命令插入删除文本。\n保存改动过的文件并退出Vim，按这些键：:wq\u0026lt;回车\u0026gt;\n如果您在步骤1中已经退出vimtutor，请重启vimtutor移动到下面的小结一节。\n阅读完以上步骤，弄懂它们的意义，然后在实践中进行练习。\n第一讲小结 光标在屏幕文本中的移动既可以用箭头键，也可以使用hjkl字母键。h(左移)j(下行)k(上行)l(右移)\n欲进入Vim编辑器(从命令行提示符)，请输入：vim文件名\u0026lt;回车\u0026gt;\n欲退出Vim编辑器，请输入:q!\u0026lt;回车\u0026gt;放弃所有改动。\n或者输入:wq\u0026lt;回车\u0026gt;保存改动。\n在正常模式下删除光标所在位置的字符，请按：x\n欲插入或添加文本，请输入：\ni 输入欲插入文本 在光标前插入文本 A输入欲添加文本 在一行后添加文本 特别提示：按下键会带您回到正常模式或者撤消一个不想输入或部分完整的命令。\n好了，第一讲到此结束。下面接下来继续第二讲的内容。\n第二讲第一节：删除类命令 输入dw可以从光标处删除至一个单词的末尾。\n请按下键确保您处于正常模式。 请将光标移动到本节中下面标记有\u0026mdash;\u0026gt;的那一行。 请将光标移至准备要删除的单词的起始处。 接着输入dw删除掉该单词。 特别提示：当您输入时，字母d会同时出现在屏幕的最后一行。Vim在等待您输入字母w。如果您看到的是除d外的其他字符，那表明您按错了；请按下键，然后重新再来。\n\u0026mdash;\u0026gt;Thereareasomewordsfunthatdon\u0026rsquo;tbelongpaperinthissentence.\n重复步骤3和步骤4，直至句子修正完毕。接着继续第二讲第二节内容。 第二讲第二节：更多删除类命令 输入d$从当前光标删除到行末。\n请按下键确保您处于正常模式。 请将光标移动到本节中下面标记有\u0026mdash;\u0026gt;的那一行。 请将光标移动到该行的尾部(也就是在第一个点号‘.’后面)。 然后输入d$从光标处删至当前行尾部。 \u0026mdash;\u0026gt;Somebodytypedtheendofthislinetwice.endofthislinetwice.\n请继续学习第二讲第三节就知道是怎么回事了。 第二讲第三节：关于命令和对象 许多改变文本的命令都由一个操作符和一个动作构成。使用删除操作符d的删除命令的格式如下： d motion\n其中：d-删除操作符。motion-操作符的操作对象(在下面列出)。\n一个简短的动作列表：\nw-从当前光标当前位置直到下一个单词起始处，不包括它的第一个字符。 e-从当前光标当前位置直到单词末尾，包括最后一个字符。 $-从当前光标当前位置直到当前行末。 因此输入 de 会从当前光标位置删除到单词末尾。\n特别提示：对于勇于探索者，请在正常模式下面仅按代表相应动作的键而不使用操作符，您将看到光标的移动正如上面的对象列表所代表的一样。\n第二讲第四节：使用计数指定动作 在动作前输入数字会使它重复那么多次。\n移动光标到下面标记有\u0026mdash;\u0026gt;的一行的开始。 输入2w使光标向前移动两个单词。 输入3e使光标向前移动到第三个单词的末尾。 输入0(数字零)移动光标到行首。 重复步骤2和步骤3，尝试不同的数字。 \u0026mdash;\u0026gt;Thisisjustalinewithwordsyoucanmovearoundin.\n请继续学习第二讲第五节。 第二讲第五节：使用计数以删除更多 使用操作符时输入数字可以使它重复那么多次。\n上面已经提到过删除操作符和动作的组合，您可以在组合中动作之前插入一个数字以删除更多：\nd number(数字) motion\n移动光标到下面标记有\u0026mdash;\u0026gt;的一行中第一个大写字母单词上。 输入d2w以删除两个大写字母单词。 重复步骤1和步骤2，使用不同的数字使得用一个命令就能删除全部相邻的大写字母单词 \u0026mdash;\u0026gt;thisABCDElineFGHIJKLMNOPofwordsisQRSTUVcleanedup.\n第二讲第六节：操作整行 输入dd可以删除整一个当前行。\n鉴于整行删除的高频度，Vi的设计者决定要简化整行删除操作，您仅需要在同一行上击打两次d就可以删除掉光标所在的整行了。\n请将光标移动到本节中下面的短句段落中的第二行。 输入dd删除该行。 然后移动到第四行。 接着输入2dd删除两行。 \u0026mdash;\u0026gt;1)Rosesarered,\n\u0026mdash;\u0026gt;2)Mudisfun,\n\u0026mdash;\u0026gt;3)Violetsareblue,\n\u0026mdash;\u0026gt;4)Ihaveacar,\n\u0026mdash;\u0026gt;5)Clockstelltime,\n\u0026mdash;\u0026gt;6)Sugarissweet\n\u0026mdash;\u0026gt;7)Andsoareyou.\n第二讲第七节：撤消类命令 输入u来撤消最后执行的命令，输入U来撤消对整行的修改。\n请将光标移动到本节中下面标记有\u0026mdash;\u0026gt;的那一行，并将其置于第一个错误处。 输入x删除第一个不想保留的字母。 然后输入u撤消最后执行的(一次)命令。 这次要使用x修正本行的所有错误。 现在输入一个大写的U，恢复到该行的原始状态。 接着多次输入u以撤消U以及更前的命令。 然后多次输入CTRL-R(先按下CTRL键不放开，接着按R键)，这样就可以重做被撤消的命令，也就是撤消掉撤消命令。 \u0026mdash;\u0026gt;Fiixtheerrorsoonthhislineandreeplacethemwitthundo.\n这些都是非常有用的命令。下面是第二讲的小结了。 第二讲小结 欲从当前光标删除至下一个单词，请输入：dw\n欲从当前光标删除至当前行末尾，请输入：d$\n欲删除整行，请输入：dd\n欲重复一个动作，请在它前面加上一个数字：2w\n在正常模式下修改命令的格式是：operator[number]motion ，其中：operator-操作符，代表要做的事情，比如d代表删除，[number]-可以附加的数字，代表动作重复的次数，motion-动作，代表在所操作的文本上的移动，例如w代表单词(word)，$代表行末等等。\n欲移动光标到行首，请按数字0键：0\n欲撤消以前的操作，请输入：u(小写的u)\n欲撤消在一行中所做的改动，请输入：U(大写的U) 欲撤消以前的撤消命令，恢复以前的操作结果，请输入：CTRL-R 第三讲第一节：置入类命令 输入p将最后一次删除的内容置入光标之后。\n请将光标移动到本节中下面第一个标记有\u0026mdash;\u0026gt;的一行。 输入dd将该行删除，这样会将该行保存到Vim的一个寄存器中。 接着将光标移动到c)一行，即准备置入的位置的上方。记住：是上方哦。 然后在正常模式下(键进入)输入p将该行粘贴置入。 重复步骤2至步骤4，将所有的行依序放置到正确的位置上。 \u0026mdash;\u0026gt;d)Canyoulearntoo?\n\u0026mdash;\u0026gt;b)Violetsareblue,\n\u0026mdash;\u0026gt;c)Intelligenceislearned,\n\u0026mdash;\u0026gt;a)Rosesarered,\n第三讲第二节：替换类命令 输入r和一个字符替换光标所在位置的字符。\n请将光标移动到本节中下面标记有\u0026mdash;\u0026gt;的第一行。 请移动光标到第一个出错的位置。 接着输入r和要替换成的字符，这样就能将错误替换掉了。 重复步骤2和步骤3，直到第一行已经修改完毕。 \u0026mdash;\u0026gt;Whanthislimewastuoedin,someonepresswdsomewrojgkeys!\n\u0026mdash;\u0026gt;Whenthislinewastypedin,someonepressedsomewrongkeys!\n然后我们继续学习第三讲第三节。 特别提示：切记您要在使用中学习，而不是在记忆中学习。\n第三讲第三节：更改类命令 要改变文本直到一个单词的末尾，请输入ce\n请将光标移动到本节中下面标记有\u0026mdash;\u0026gt;的第一行。 接着把光标放在单词lubw的字母u的位置那里。 然后输入cw以及正确的单词(在本例中是输入ine)。 最后按键，然后光标定位到下一个错误第一个准备更改的字母处。 重复步骤3和步骤4，直到第一个句子完全雷同第二个句子。 \u0026mdash;\u0026gt;Thislubwhasafewwptfdthatmrrfchangingusfthechangeoperator.\n\u0026mdash;\u0026gt;Thislinehasafewwordsthatneedchangingusingthechangeoperator.\n提示：请注意ce命令不仅仅是删除了一个单词，它也让您进入插入模式了。\n第三讲第四节：使用c更改更多 更改类操作符可以与删除中使用的同样的动作配合使用。\n更改类操作符的工作方式跟删除类是一致的。操作格式是：c[number]motion 动作参数(motion)也是一样的，比如w代表单词，$代表行末等等。 请将光标移动到本节中下面标记有\u0026mdash;\u0026gt;的第一行。 接着将光标移动到第一个错误处。 然后输入c$使得该行剩下的部分更正得同第二行一样。最后按键。 \u0026mdash;\u0026gt;Theendofthislineneedssomehelptomakeitlikethesecond.\n\u0026mdash;\u0026gt;Theendofthislineneedstobecorrectedusingthec$command.\n第三讲小结 要重新置入已经删除的文本内容，请按小写字母p键。该操作可以将已删除的文本内容置于光标之后。如果最后一次删除的是一个整行，那么该行将置于当前光标所在行的下一行。 要替换光标所在位置的字符，请输入小写的r和要替换掉原位置字符的新字符即可。 更改类命令允许您改变从当前光标所在位置直到动作指示的位置中间的文本。 比如输入ce可以替换当前光标到单词的末尾的内容；输入c$可以替换当前光标到行末的内容。 更改类命令的格式是：c[number]motion 现在我们继续学习下一讲。\n第四讲第一节：定位及文件状态 输入CTRL-G显示当前编辑文件中当前光标所在行位置以及文件状态信息。输入大写G则直接跳转到文件中的某一指定行。\n提示：切记要先通读本节内容，之后才可以执行以下步骤!!!\n按下CTRL键不放开然后按g键。我们称这个键组合为CTRL-G。您会看到页面最底部出现一个状态信息行，显示的内容是当前编辑的文件名和文件中光标位置。请记住行号，它会在步骤3中用到。提示：您也许会在屏幕的右下角看到光标位置，这会在\u0026rsquo;ruler\u0026rsquo;选项设置时发生(参见:help\u0026rsquo;ruler\u0026rsquo;) 输入大写G可以使得当前光标直接跳转到文件最后一行。输入gg可以使得当前光标直接跳转到文件第一行。 输入您曾停留的行号，然后输入大写G。这样就可以返回到您第一次按下CTRL-G时所在的行了。 如果您觉得没问题的话，请执行步骤1至步骤3的操作进行练习。 第四讲第二节：搜索类命令 输入/加上一个字符串可以用以在当前文件中查找该字符串。\n在正常模式下输入/字符。您此时会注意到该字符和光标都会出现在屏幕底部，这跟:命令是一样的。 接着输入errroor\u0026lt;回车\u0026gt;。那个errroor就是您要查找的字符串。 要查找同上一次的字符串，只需要按n键。要向相反方向查找同上一次的字符串，请输入大写N即可。 如果您想逆向查找字符串，请使用?代替/进行。 要回到您之前的位置按CTRL-O(按住Ctrl键不放同时按下字母o)。重复按可以回退更多步。CTRL-I会跳转到较新的位置。 \u0026mdash;\u0026gt;\u0026ldquo;errroor\u0026quot;isnotthewaytospellerror;errroorisanerror.\n提示：如果查找已经到达文件末尾，查找会自动从文件头部继续查找，除非\u0026rsquo;wrapscan\u0026rsquo;选项被复位。\n第四讲第三节：配对括号的查找 输入%可以查找配对的括号)、]、}。\n把光标放在本节下面标记有\u0026ndash;\u0026gt;那一行中的任何一个(、[或{处。 接着按%字符。 此时光标的位置应当是在配对的括号处。 再次按%就可以跳回配对的第一个括号处。 移动光标到另一个(、)、[、]、{或}处，按%查看其所作所为。 \u0026mdash;\u0026gt;This(isatestlinewith(\u0026rsquo;s,[\u0026rsquo;s]and{\u0026rsquo;s}init.))\n提示：在程序调试时，这个功能用来查找不配对的括号是很有用的。\n第四讲第四节：替换命令 输入:s/old/new/g可以替换old为new。\n请将光标移动到本节中下面标记有\u0026mdash;\u0026gt;的那一行。 输入:s/thee/the\u0026lt;回车\u0026gt;。请注意该命令只改变光标所在行的第一个匹配串。 输入:s/thee/the/g则是替换全行的匹配串，该行中所有的\u0026quot;thee\u0026quot;都会被改变。 \u0026mdash;\u0026gt;theebesttimetoseetheeflowersisintheespring.\n4.要替换两行之间出现的每个匹配串，请输入:#,#s/old/new/g其中#,#代表的是替换操作的若干行中首尾两行的行号。输入:%s/old/new/g则是替换整个文件中的每个匹配串。输入:%s/old/new/gc会找到整个文件中的每个匹配串，并且对每个匹配串提示是否进行替换。\n第四讲小结 CTRL-G用于显示当前光标所在位置和文件状态信息。G用于将光标跳转至文件最后一行。先敲入一个行号然后输入大写G则是将光标移动至该行号代表的行。gg用于将光标跳转至文件第一行。 输入/然后紧随一个字符串是在当前所编辑的文档中正向查找该字符串。输入?然后紧随一个字符串则是在当前所编辑的文档中反向查找该字符串。完成一次查找之后按n键是重复上一次的命令，可在同一方向上查找下一个匹配字符串所在；或者按大写N向相反方向查找下一匹配字符串所在。CTRL-O带您跳转回较旧的位置，CTRL-I则带您到较新的位置。 如果光标当前位置是括号(、)、[、]、{、}，按%会将光标移动到配对的括号上。 在一行内替换头一个字符串old为新的字符串new，请输入:s/old/new 在一行内替换所有的字符串old为新的字符串new，请输入:s/old/new/g 在两行内替换所有的字符串old为新的字符串new，请输入:#,#s/old/new/g 在文件内替换所有的字符串old为新的字符串new，请输入:%s/old/new/g 进行全文替换时询问用户确认每个替换需添加c标志:%s/old/new/gc 第五讲第一节：在VIM内执行外部命令的方法 输入:!然后紧接着输入一个外部命令可以执行该外部命令。\n按下我们所熟悉的:命令使光标移动到屏幕底部。这样您就可以输入一行命令了。 接着输入感叹号!这个字符，这样就允许您执行外部的shell命令了。 我们以ls命令为例。输入!ls\u0026lt;回车\u0026gt;。该命令就会列举出您当前目录的内容，就如同您在命令行提示符下输入ls命令的结果一样。如果!ls没起作用，您可以试试:!dir看看。 提示：所有的外部命令都可以以这种方式执行，包括带命令行参数的那些。\n提示：所有的:命令都必须以敲\u0026lt;回车\u0026gt;键结束。从今以后我们就不会总是提到这一点了。\n第五讲第二节：关于保存文件的更多信息 要将对文件的改动保存到文件中，请输入:wFILENAME。\n输入:!dir或者:!ls获知当前目录的内容。您应当已知道最后还得敲\u0026lt;回车\u0026gt;吧。 选择一个未被用到的文件名，比如TEST。 接着输入:wTEST(此处TEST是您所选择的文件名。) 该命令会以TEST为文件名保存整个文件(Vim教程)。为了验证这一点， 请再次输入:!dir或:!ls查看您的目录列表内容。 请注意：如果您退出Vim然后在以命令vimTEST再次启动Vim，那么该文件内容应该同您保存时的文件内容是完全一样的。 现在您可以删除TEST文件了。在MS-DOS下，请输入：:!delTEST。在Unix下，请输入：:!rmTEST 第五讲第三节：一个具有选择性的保存命令 要保存文件的部分内容，请输入vmotion:wFILENAME\n移动光标到本行。 接着按v键，将光标移动至下面第五个条目上。您会注意到之间的文本被高亮了。 然后按:字符。您将看到屏幕底部会出现:\u0026rsquo;\u0026lt;,\u0026rsquo;\u0026gt;。 现在请输入wTEST，其中TEST是一个未被使用的文件名。确认您看到了:\u0026rsquo;\u0026lt;,\u0026rsquo;\u0026gt;wTEST之后按\u0026lt;回车\u0026gt;键。 这时Vim会把选中的行写入到以TEST命名的文件中去。使用:!dir或:!ls 确认文件被正确保存。这次先别删除它！我们在下一讲中会用到它。 提示：按v键使Vim进入可视模式进行选取。您可以四处移动光标使选取区域变大或变小。接着您可以使用一个操作符对选中文本进行操作。例如，按d键会删除选中的文本内容。 第五讲第四节：提取和合并文件 要向当前文件中插入另外的文件的内容，请输入:rFILENAME\n请把光标移动到本行上面一行。 特别提示：执行步骤2之后您将看到第五讲第三节的文字，请届时往下移动以再次看到本讲内容。\n接着通过命令:rTEST将前面创建的名为TEST的文件提取进来。您所提取进来的文件将从光标所在位置处开始置入。 为了确认文件已经提取成功，移动光标回到原来的位置就可以注意有两份第五讲第三节的内容，一份是原始内容，另外一份是来自文件的副本。 提示：您还可以读取外部命令的输出。例如，:r!ls可以读取ls命令的输出，并把它放置在光标下面。\n第五讲小结 :!command用于执行一个外部命令command。请看一些实际例子：(MS-DOS)(Unix) :!dir:!ls-用于显示当前目录的内容。 :!delFILENAME:!rmFILENAME-用于删除名为FILENAME的文件。 :wFILENAME可将当前VIM中正在编辑的文件保存到名为FILENAME的文件中。 vmotion:wFILENAME可将当前编辑文件中可视模式下选中的内容保存到文件FILENAME中。 :rFILENAME可提取磁盘文件FILENAME并将其插入到当前文件的光标位置后面。 :r!dir可以读取dir命令的输出并将其放置到当前文件的光标位置后面。 第六讲第一节：打开类命令 输入o将在光标的下方打开新的一行并进入插入模式。\n请将光标移动到本节中下面标记有\u0026mdash;\u0026gt;的那一行。 接着输入小写的o在光标下方打开新的一行，这个命令会使您进入插入模式。 然后输入一些文字，之后按键退出插入模式而进入正常模式。 \u0026mdash;\u0026gt;AftertypingothecursorisplacedontheopenlineinInsertmode.\n为了在光标上方打开新的一行，只需要输入大写的O而不是小写的o就可以了。请在下行测试一下吧。 \u0026mdash;\u0026gt;OpenupalineabovethisbytypingOwhilethecursorisonthisline.\n第六讲第二节：附加类命令 输入a将可在光标之后插入文本。\n请在正常模式下将光标移动到本节中下面标记有\u0026mdash;\u0026gt;的第一行的行首。 接着输入e直到光标位于li的末尾。 输入小写的a则可在光标之后插入文本了。 将单词补充完整，就像下一行中的那样。之后按键退出插入模式回到正常模式。 使用e移动光标到下一步不完整的单词，重复步骤3和步骤4。 \u0026mdash;\u0026gt;Thisliwillallowyoutopractappenditexttoaline.\n\u0026mdash;\u0026gt;Thislinewillallowyoutopracticeappendingtexttoaline.\n提示：a、i和A都会带您进入插入模式，惟一的区别在于字符插入的位置。\n第六讲第三节：另外一个置换类命令的版本 输入大写的R可连续替换多个字符。\n请将光标移动到本节中下面标记有\u0026mdash;\u0026gt;的第一行。移动光标到第一个xxx的起始位置。 然后输入大写的R开始把第一行中的不同于第二行的剩余字符逐一输入，就可以全部替换掉原有的字符而使得第一行完全雷同第二行了。 接着按键退出替换模式回到正常模式。您可以注意到尚未替换的文本仍然保持原状。 重复以上步骤，将剩余的xxx也替换掉。 \u0026mdash;\u0026gt;Adding123toxxxgivesyouxxx.\n\u0026mdash;\u0026gt;Adding123to456givesyou579.\n提示：替换模式与插入模式相似，不过每个输入的字符都会删除一个已有的字符。\n第六讲第四节：复制粘贴文本 使用操作符y复制文本，使用p粘贴文本\n定位到下面标记有\u0026mdash;\u0026gt;的一行，将光标移动到\u0026quot;a)\u0026ldquo;之后。 接着使用v进入可视模式，移动光标到\u0026quot;first\u0026quot;的前面。 现在输入y以抽出(复制)高亮的文本。 然后移动光标到下一行的末尾：j$ 接着输入p以放置(粘贴)复制了的文本。然后输入：asecond。 使用可视模式选中\u0026quot;item.\u0026quot;，用y复制，再用j$将光标移动到下一行末尾，用p将文本粘贴到那里。 \u0026mdash;\u0026gt;a)thisisthefirstitem.\n提示：您还可以把y当作操作符来使用；例如yw可以用来复制一个单词。\n第六讲第五节：设置类命令的选项 设置可使查找或者替换可忽略大小写的选项\n要查找单词ignore可在正常模式下输入/ignore\u0026lt;回车\u0026gt;。要重复查找该词，可以重复按n键。 然后设置ic选项(IgnoreCase，忽略大小写)，请输入：:setic 现在可以通过键入n键再次查找单词ignore。注意到Ignore和IGNORE现在也被找到了。 然后设置hlsearch和incsearch这两个选项，请输入：:sethlsis 现在可以再次输入查找命令，看看会有什么效果：/ignore\u0026lt;回车\u0026gt; 要禁用忽略大小写，请输入：:setnoic 提示：要移除匹配项的高亮显示，请输入：:nohlsearch\n提示：如果您想要仅在一次查找时忽略字母大小写，您可以使用\\c：/ignore\\c\u0026lt;回车\u0026gt;\n第六讲小结 输入小写的o可以在光标下方打开新的一行并进入插入模式。输入大写的O可以在光标上方打开新的一行。 输入小写的a可以在光标所在位置之后插入文本。输入大写的A可以在光标所在行的行末之后插入文本。 e命令可以使光标移动到单词末尾。 操作符y复制文本，p粘贴先前复制的文本。 输入大写的R将进入替换模式，直至按键回到正常模式。 输入:setxxx可以设置xxx选项。一些有用的选项如下： \u0026lsquo;ic\u0026rsquo;\u0026lsquo;ignorecase\u0026rsquo;查找时忽略字母大小写,\u0026lsquo;is\u0026rsquo;\u0026lsquo;incsearch\u0026rsquo;查找短语时显示部分匹配,\u0026lsquo;hls\u0026rsquo;\u0026lsquo;hlsearch\u0026rsquo;高亮显示所有的匹配短语,选项名可以用完整版本，也可以用缩略版本。 在选项前加上no可以关闭选项：:setnoic 第七讲第一节：获取帮助信息 使用在线帮助系统\nVim拥有一个细致全面的在线帮助系统。要启动该帮助系统，请选择如下三种方法之一：\n按下键(如果键盘上有的话)\n按下键(如果键盘上有的话)\n输入:help\u0026lt;回车\u0026gt;\n请阅读帮助窗口中的文字以了解帮助是如何工作的。输入CTRL-WCTRL-W可以使您在窗口之间跳转。输入:q\u0026lt;回车\u0026gt;可以关闭帮助窗口。提供一个正确的参数给\u0026rdquo;:help\u0026quot;命令，您可以找到关于该主题的帮助。请试验以下参数(可别忘了按回车键哦)：\n:helpw :helpc_CTRL-D :helpinsert-index :helpuser-manual 第七讲第二节：创建启动脚本 启用Vim的特性\nVim的功能特性要比Vi多得多，但其中大部分都没有缺省启用。为了使用更多的特性，您得创建一个vimrc文件。\n开始编辑vimrc文件，具体命令取决于您所使用的操作系统： :edit ~/.vimrc这是Unix系统所使用的命令~ ~:edit~/_vimrc这是MS-Windows系统所使用的命令 接着读取vimrc示例文件的内容： :r$VIMRUNTIME/vimrc_example.vim 保存文件，命令为： :write 下次您启动Vim时，编辑器就会有了语法高亮的功能。您可以把您喜欢的各种设置添加到这个vimrc文件中。要了解更多信息请输入:helpvimrc-intro\n第七讲第三节：补全功能 使用CTRL-D和可以进行命令行补全\n请确保Vim不是在以兼容模式运行：:setnocp 查看一下当前目录下已经存在哪些文件，输入：:!ls或者:!dir 现在输入一个目录的起始部分，例如输入：:e 接着按CTRL-D键，Vim会显示以e开始的命令的列表。 然后按键，Vim会补全命令为:edit。 现在添加一个空格，以及一个已有文件的文件名的起始部分，例如：:editFIL 接着按键，Vim会补全文件名(如果它是惟一匹配的)。 提示：补全对于许多命令都有效。您只需尝试按CTRL-D和。它对于:help命令非常有用。\n第七讲小结 输入:help或者按键或键可以打开帮助窗口。 输入:helpcmd可以找到关于cmd命令的帮助。 输入CTRL-WCTRL-W可以使您在窗口之间跳转。 输入:q以关闭帮助窗口 您可以创建一个vimrc启动脚本文件用来保存您偏好的设置。 当输入:命令时，按CTRL-D可以查看可能的补全结果。按可以使用一个补全。 ","date":"2022-07-09","img":"","permalink":"/posts/e84c3531/","series":["vim"],"tags":["教程"],"title":"Vimtutor翻译"},{"categories":["教程"],"content":"七牛云对注册的用户提供永久免费存储和CDN额度CDN 优惠专场 (qiniu.com)，所以打算将自己博客迁移过来。\n账号以及环境准备 账号 如果是新用户首先在门户注册账号，注册完成之后要进行实名认证，这一步跟着官网教程走即可。 注册完成之后可以在七牛云 - 对象存储 - 空间管理 (qiniu.com)中可以自己新建bucket玩玩，或者新建存储空间_快速入门_对象存储 - 七牛开发者中心 (qiniu.com)进行操作。 新建一个放博客的 bucket ，我这里的 bucket 名称为 jimyag-blog Hugo 环境准备 根据官方文档和自己的系统进行安装\nQuick Start | Hugo (gohugo.io)\nWindows 10 hugo 安装\nMac\n使用 homebrew 进行安装\nbrew install hugo\nqshell qshell的安装\n配置 AccessKey/SecretKey 。在密钥管理中复制自己的 AK 和 SK\n在终端执行\n1qshell account AK Sk name name 是账号的别称，可以随便输入。\n同步 public 内容 qshell 提供了同步本地文件到 bucket 的参数使用 qshell 同步目录 - 七牛开发者中心 (qiniu.com)。\n我们先到 hugo 博客的目录，这里是我自己的目录\n1cd hugo-blog 创建同步目录的配置文件 1vi upload.conf 写入 1{ 2 \u0026#34;src_dir\u0026#34; : \u0026#34;./public\u0026#34;, 3 \u0026#34;bucket\u0026#34; : \u0026#34;jimyag-blog\u0026#34;, 4 \u0026#34;rescan_local\u0026#34;: true, 5 \u0026#34;overwrite\u0026#34; : true, 6 \u0026#34;check_exists\u0026#34; : true, 7 \u0026#34;check_hash\u0026#34; : true 8} “src_dir” 是要同步的文件夹\n“bucket” 是同步到的 bucket的name，在上面已经创建了\n“check_hash” = true 是检查文件的 hash ，如果一样就忽略改文件上传。\n详细的参数见：qshell/qupload.md at master · qiniu/qshell (github.com)\n生成 public 文件 1hugo -D 同步目录 1qshell qupload upload.conf 开启默认首页设置 在七牛云七牛云 - 对象存储 - 空间设置空间管理-\u0026gt;空间设置-\u0026gt; 打开默认首页设置。\n在 空间预览 中会生成一个测试的域名，可以通过qiniu的域名访问我们的博客了\n配置 CDN 和自定义域名 虽然我们现在能通过 域名 访问我们的博客了，但是这个测试域名是有期限的，并且不是我们自己的，很难记。\n配置 CDN 加速域名 在七牛云 - 添加域名 (qiniu.com)中 根据提示填写自己的域名\n如果没有证书的话可以在qiniu中申请，点击上面的 SSL证书服务即可申请，其余的默认即可。\n在七牛云 - 证书管理 (qiniu.com)可以上传或者购买证书。\n在上传证书中qiniu只支持 pem 格式的\n点击完成，按照提示进行配置CNAME。如何配置域名的 CNAME - 七牛开发者中心 (qiniu.com)\n这样CDN 加速就配置完成了\n(这里的域名和刚刚配置的不一样是，刚刚(newblog.jimyag.cn)的是演示的域名)\n自定义域名配置 点击 绑定域名 ，输入之前的域名。\n配置CANME\n配置HTTPS\n至此，博客就已经迁移到七牛云 OSS 存储了。\n","date":"2022-06-28","img":"","permalink":"/posts/3aafaaaf/","series":[],"tags":["Hugo","教程","七牛云"],"title":"将博客迁移到七牛云"},{"categories":["算法"],"content":"使用C++和Go实现LRU缓存\nLRU缓存介绍 LRU是Least Recently Used ，就是最近使用过的数据最有可能会继续使用的。很长时间没有用过的数据就认为是之后不会再用到了。在容量有限的情况下，如果数据存满了，又有新的数据过来了。那么就要把最久没被使用的给删了。\nLeeCode上有个老哥举例很生动\n举个简单的例子，安卓手机都可以把软件放到后台运行，比如我先后打开了「设置」「手机管家」「日历」，那么现在他们在后台排列的顺序是这样的：\n但是这时候如果我访问了一下「设置」界面，那么「设置」就会被提前到第一个，变成这样：\n假设我的手机只允许我同时开 3 个应用程序，现在已经满了。那么如果我新开了一个应用「时钟」，就必须关闭一个应用为「时钟」腾出一个位置，关那个呢？\n按照 LRU 的策略，就关最底下的「手机管家」，因为那是最久未使用的，然后把新开的应用放到最上面：\nLRU的操作 对于一个LRU缓存来说都是有一个缓冲区的大小(capacity),可以向缓存中放数据 put(key,val),也可以从缓存中拿到数据get(key),注意在put和get的时候都是O(1)的时间复杂度.\n/* 缓存容量为 2 */ LRUCache cache = new LRUCache(2); // 你可以把 cache 理解成一个队列 // 假设左边是队头，右边是队尾 // 最近使用的排在队头，久未使用的排在队尾 // 圆括号表示键值对 (key, val)\ncache.put(1, 1); // cache = [(1, 1)]\ncache.put(2, 2); // cache = [(2, 2), (1, 1)]\ncache.get(1); // 返回 1 // cache = [(1, 1), (2, 2)] // 解释：因为最近访问了键 1，所以提前至队头 // 返回键 1 对应的值 1\ncache.put(3, 3); // cache = [(3, 3), (1, 1)] // 解释：缓存容量已满，需要删除内容空出位置 // 优先删除久未使用的数据，也就是队尾的数据 // 然后把新的数据插入队头\ncache.get(2); // 返回 -1 (未找到) // cache = [(3, 3), (1, 1)] // 解释：cache 中不存在键为 2 的数据\ncache.put(1, 4); // cache = [(1, 4), (3, 3)] // 解释：键 1 已存在，把原始值 1 覆盖为 4 // 不要忘了也要将键值对提前到队头\nLRU的设计 根据上述的描述,对于put和get为O(1)的时间复杂度的数据结构要进行设计\n题目中有\u0026quot;最近使用\u0026quot;,就说明数据是有序的,这个有序是相对于使用的时间而言的 要在某个位置进行O(1)的插入 查找也是O(1) 要同时满足以上的条件单一的数据结构肯定是不行的.对于查找是来说可以使用哈希表来满足条件,有序可以使用链表,但是要进行O(1)的插入,就要使用双链表了,单链表不能进行O(1)的时间复杂度的插入.\nLRU 缓存算法的核心数据结构就是哈希链表，双向链表和哈希表的结合体。这个数据结构长这样：\n借助这个结构，我们来逐一分析上面的 3 个条件：\n1、如果我们每次默认从链表尾部添加元素，那么显然越靠尾部的元素就是最近使用的，越靠头部的元素就是最久未使用的,如果容量满了之后,要删的也是删除头部的。\n2、对于某一个 key，我们可以通过哈希表快速定位到链表中的节点，从而取得对应 val,也就是哈希表存的是值所对应的结点的地址,通过这个地址就可以拿到对应的val。\n3、链表显然是支持在任意位置快速插入和删除的，改改指针就行。只不过传统的链表无法按照索引快速访问某一个位置的元素，而这里借助哈希表，可以通过 key 快速映射到任意一个链表节点，然后进行插入和删除。\n也许读者会问，为什么要是双向链表，单链表行不行？另外，既然哈希表中已经存了 key，为什么链表中还要存 key 和 val 呢，只存 val 不就行了？\n想的时候都是问题，只有做的时候才有答案。这样设计的原因，必须等我们亲自实现 LRU 算法之后才能理解，所以我们开始看代码吧～\n代码实现 c++ 虽然系统中实现了双向链表,但是这里还是想自己实现一遍.\n实现Node 1struct Node{ 2 int key; 3 int val; 4 Node *pre; // 指向之前的结点 5 Node *next;// 指向之后的结点 6 Node(int key,int val):key(key),val(val){} 7} 实现双向链表 1struct DoubleList{ 2private: 3 Node *head; // 头结点,不存数据 4 Node *tail; // 尾结点,不存数据 5 int size; // 元素的个数 6 7public: 8 DoubleList(){ 9 head = new Node(0,0); 10 tail = new Node(0,0); 11 size = 0; 12 head-\u0026gt;next = tail; // 头结点的next指向尾结点 13 tail-\u0026gt;pre = head; // 尾结点的pre指向头结点 14 } 15 16 // 在尾部添加元素 17 void addTail(Node *x){ 18 x-\u0026gt;pre = tail-\u0026gt;pre; // 插入的之前的指向尾巴的前结点 19 x-\u0026gt;next = tail; // 插入的next指向尾结点 20 tail-\u0026gt;pre-\u0026gt;next = x; // 尾巴之前的结点的next指向x 21 tail-\u0026gt;pre = x; // 尾巴之前的变为x 22 size++; 23 } 24 25 // 移除某个结点 26 void remove(Node *x) { 27 x-\u0026gt;pre-\u0026gt;next = x-\u0026gt;next; 28 x-\u0026gt;next-\u0026gt;pre = x-\u0026gt;pre; 29 size--; 30 } 31 32 // 移除头结点 33 Node *removeFirst() { 34 if (head == nullptr) { 35 return nullptr; 36 } 37 Node *first = head-\u0026gt;next; 38 remove(first); 39 return first; 40 } 41 42 43 int len() { 44 return size; 45 } 46} 到这里就能回答刚才「为什么必须要用双向链表」的问题了，因为我们需要删除操作。删除一个节点不光要得到该节点本身的指针，也需要操作其前驱节点的指针，而双向链表才能支持直接查找前驱，保证操作的时间复杂度 O(1)。\n注意我们实现的双链表 API 只能从尾部插入，也就是说靠尾部的数据是最近使用的，靠头部的数据是最久为使用的。\n实现LRU LRU中要使用到之前实现的链表和哈希表。\n1struct LRU { 2 map\u0026lt;int, Node *\u0026gt; *m; 3 DoubleList *cache; 4 int cap; 5 6 // 初始化 7 LRU(int cap) { 8 this-\u0026gt;cap = cap; 9 m = new map\u0026lt;int, Node *\u0026gt;; 10 cache = new DoubleList(); 11 } 12 13// 封装底层的接口 14private: 15 // 将某个key提升为最近使用的 16 void makeRecently(int key) { 17 auto item = m-\u0026gt;find(key); 18 if (item == m-\u0026gt;end()) { 19 return; 20 } 21 // 先删除 22 cache-\u0026gt;remove(item-\u0026gt;second); 23 // 再加到链表的尾部 24 cache-\u0026gt;addLast(item-\u0026gt;second); 25 } 26 // 添加最近使用过的元素 27 void addRecently(int key, int val) { 28 Node *x = new Node(key, val); 29 // 添加到尾部 30 cache-\u0026gt;addLast(x); 31 // 在map中也要添加 32 m-\u0026gt;insert(pair\u0026lt;int, Node *\u0026gt;(key, x)); 33 } 34 35 // 删除某个缓存 36 void deleteKey(int key) { 37 auto temp = m-\u0026gt;find(key); 38 // 如果没有找到就算了 39 if (temp == m-\u0026gt;end()) { 40 return; 41 } 42 // 在链表和map中都删除 43 cache-\u0026gt;remove(temp-\u0026gt;second); 44 m-\u0026gt;erase(key); 45 } 46 47 // 删除最久没被使用的 48 void removedLeastRecently() { 49 // 链表删除头 50 Node *deleteNode = cache-\u0026gt;removeFirst(); 51 // map 直接删除 52 m-\u0026gt;erase(deleteNode-\u0026gt;key); 53 } 54 55// 封装对外的get和set 56public: 57 int get(int key) { 58 auto temp = m-\u0026gt;find(key); 59 if (temp == m-\u0026gt;end()) { 60 return -1; 61 } 62 // 找到之后要提升 63 makeRecently(key); 64 return temp-\u0026gt;second-\u0026gt;val; 65 } 66 67 void put(int key, int val) { 68 auto temp = m-\u0026gt;find(key); 69 // 如果找到了 就是要修改值 70 if (temp != m-\u0026gt;end()) { 71 // 先删除key 72 deleteKey(key); 73 // 再添加 74 addRecently(key, val); 75 return; 76 } 77 // 容量超了就删除最久没有使用的 78 if (cap == cache-\u0026gt;len()) { 79 removedLeastRecently(); 80 } 81 addRecently(key, val); 82 } 83}; c++另一个版本 使用iterator迭代器进行实现\n1class LRUCache { 2public: 3 LRUCache(int capacity) : cap(capacity) { 4 } 5 6 int get(int key) { 7 // 如果没有就返回-1 8 if (map.find(key) == map.end()) return -1; 9 auto keyAndValue = *map[key]; 10 cache.erase(map[key]); 11 cache.push_front(keyAndValue); 12 map[key] = cache.begin(); 13 return keyAndValue.second; 14 } 15 16 void put(int key, int value) { 17 // 如果缓存中没有 18 if (map.find(key) == map.end()) { 19 // 缓存中满了 20 if (cache.size() == cap) { 21 // 删除头部的元素，也就是最久没被使用的 22 map.erase(cache.back().first); 23 cache.pop_back(); 24 } 25 } else { 26 // 如果缓存中有就删除 27 cache.erase(map[key]); 28 } 29 // 重新插在末尾 30 cache.push_front({key, value}); 31 map[key] = cache.begin(); 32 } 33 34private: 35 int cap; 36 // 一个双向链表，存顺序 37 list\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt; cache; 38 // 加速访问 39 unordered_map\u0026lt;int, list\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;::iterator\u0026gt; map; 40}; 这个版本不用实现双向链表，只需要自己手动调用就行\ngo 和之前c++1.0版本一样自己实现一个双向链表，之后使用自带的map。这次使用了1.18的泛型进行实现。\nNode 1// 通用的结点，保存的val可以是任何类型 2type Node[T any] struct { 3\tVal T 4\tPre *Node[T] 5\tNext *Node[T] 6} 7 8func NewNode[T any](val T) *Node[T] { 9\treturn \u0026amp;Node[T]{ 10\tVal: val, 11\t} 12} 13 14// 一个key-value的数据结构 15type KeyValue[Key, Value any] struct { 16\tKey Key 17\tValue Value 18} double-list 1// 链表的数据结构 2// 使用的时候要给传入Node中val的类型 3type DoubleList[T any] struct { 4 head *Node[T] // 头结点 5 tail *Node[T] // 尾巴结点 6 size int 7} 8 9func NewDoubleList[T any]() *DoubleList[T] { 10 dl := DoubleList[T]{ 11 head: new(Node[T]), 12 tail: new(Node[T]), 13 size: 0, 14 } 15 dl.head.Next = dl.tail 16 dl.tail.Pre = dl.head 17 return \u0026amp;dl 18} 19 20// 在尾巴插入一个结点 21func (dl *DoubleList[T]) PushBack(node *Node[T]) { 22 node.Pre = dl.tail.Pre 23 node.Next = dl.tail 24 dl.tail.Pre.Next = node 25 dl.tail.Pre = node 26 dl.size++ 27} 28 29// 删除一个结点 30func (dl *DoubleList[T]) Remove(node *Node[T]) { 31 if node == nil || node.Pre == nil || node.Next == nil { 32 return 33 } 34 node.Pre.Next = node.Next 35 node.Next.Pre = node.Pre 36 dl.size-- 37} 38 39// 返回头结点 40func (dl *DoubleList[T]) Front() *Node[T] { 41 if dl.head == nil { 42 return nil 43 } 44 return dl.head.Next 45} 46 47// 删除头结点 48func (dl *DoubleList[T]) PopFront() { 49 if dl.head == nil { 50 return 51 } 52 dl.Remove(dl.head.Next) 53 return 54} 55 56// 返回链表长度 57func (dl *DoubleList[T]) Size() int { 58 return dl.size 59} LRU实现 1var ( 2 NotFoundErr = errors.New(\u0026#34;not found\u0026#34;) 3) 4 5// lru的数据结构 6type lru[K comparable, Value any] struct { 7 // lock sync.RWMutex 8 data map[K]*Node[KeyValue[K, Value]] 9 cache *DoubleList[KeyValue[K, Value]] 10 cap int 11} 12 13func NewLRU[K comparable, Value any](cap int) *lru[K, Value] { 14 return \u0026amp;lru[K, Value]{ 15 data: make(map[K]*Node[KeyValue[K, Value]]), 16 cache: NewDoubleList[KeyValue[K, Value]](), 17 cap: cap, 18 } 19} 20 21// 提升某个结点 22func (lru *lru[K, Value]) makeRecently(key K) { 23 find, ok := lru.data[key] 24 if !ok { 25 return 26 } 27 lru.cache.Remove(find) 28 lru.cache.PushBack(find) 29} 30 31// 新添加一个结点 32func (lru *lru[K, Value]) addRecently(key K, value Value) { 33 node := NewNode[KeyValue[K, Value]](KeyValue[K, Value]{Key: key, Value: value}) 34 lru.cache.PushBack(node) 35 lru.data[key] = node 36} 37 38// 删除某个结点 39func (lru *lru[K, Value]) deleteKey(key K) { 40 find, ok := lru.data[key] 41 if !ok { 42 return 43 } 44 lru.cache.Remove(find) 45 delete(lru.data, key) 46} 47 48// 删除最久没有使用的 49func (lru *lru[K, Value]) removerLeastRecently() { 50 head := lru.cache.Front() 51 lru.cache.PopFront() 52 delete(lru.data, head.Val.Key) 53} 54 55// Put 56func (lru *lru[K, Value]) Put(key K, val Value) { 57 _, ok := lru.data[key] 58 if ok { 59 lru.deleteKey(key) 60 } 61 if lru.cap == lru.cache.Size() { 62 lru.removerLeastRecently() 63 } 64 lru.addRecently(key, val) 65} 66 67// Get 68func (lru *lru[K, Value]) Get(key K) (Value, error) { 69 find, ok := lru.data[key] 70 if !ok { 71 var t Value 72 return t, NotFoundErr 73 } 74 lru.makeRecently(key) 75 return find.Val.Value, nil 76} 参考 LRU 策略详解和实现 - LRU 缓存 - 力扣（LeetCode）\n","date":"2022-05-30","img":"","permalink":"/posts/7a57e53d/","series":[],"tags":["LRU"],"title":"LRU缓存实现"},{"categories":[],"content":"软件测试技术的复习资料\n填空题 计算机软件是包括程序、数据和文档的完整集合。\n软件评估中常见的3个质量模型是McCall、Boehm和ISO9126。\n软件测试的过程模型包括V模型、W模型和H模型等。\n软件评估的主要方法包括缺陷评估、覆盖评测、质量评测\n常用的3种排错方法包括：原始类排错法、回溯法、归纳和演绎法\n最常用的覆盖评价是基于需求的测试覆盖、基于代码的测试覆盖。\n缺陷分析通常的度量形式包括缺陷发现率、缺陷密度、缺陷潜伏期、整体软件缺陷清除率\n根据测试文档的不同作用，通常分为前置作业文档、后置作业文档。\nPDCA的循环理念主要包括计划、执行、检查和改进四个阶段。\n风险管理的基本内容包括风险评估、风险控制。\n软件项目的成本主要包括项目直接成本、管理费用、期间费用。\n面向对象的集成测试中，对象交互的测试根据类的类型可以分为原始类测试、汇集类测试、协作类测试、\n对OOD的测试可以从三个方面考虑：对认定的类的测试、对构造的类层次结构的测试和对类库的支持的测试。\nHTTP协议的作用原理包括四个步骤，分别是：连接请求 、应答、关闭 。\n简答题 请简述软件危机的主要表现 软件生产不能满足日益增长的软件需求。\n软件生产率随软件规模与复杂性提高而下降，人力成本却不断增加。\n软件开发的进度与成本失控。\n软件系统实现的功能与实际需求 。\n软件难以维护。\n软件文档配置没有受到足够的重视。\n软件生存周期包括那几个阶段？其中第一阶段又可以分为哪两个阶段？ 软件定义\n软件开发\n软件测试\n软件使用与维护\n可行性研究和需求分析\n请列举软件产生错误的主要原因（至少6项） 软件的复杂性 交流不够、交流上有误解或者根本不进行交流 程序设计错误 需求变化 时间压力 代码文档贫乏 软件开发工具 列举常见的3个质量模型，并说明比较普遍的质量模型包含的两层结构。 McCall模型、Boehm模型和ISO9126。\n第一层是按大类划分质量特性，叫做基本质量特性\n第二层是每个大类所包含的子类质量特性\n最后在各个类别的质量特性中一一列出对应的或相关的标准\n请列出软件测试的基本原则。 所有的测试都应追溯到用户需求\n应当把“尽早和不断地测试”作为座右铭\n测试工作应该由独立的专业的软件测试机构来完成\nPareto原则\n设计测试用例时，应该考虑各种情况\n对测试出的错误结果一定要有一个确认的过程\n制定严格的测试计划\n完全测试是不可能的，测试需要终止\n注意回归测试的关联性\n妥善保存一切测试过程文档。\n按照过程分类，软件测试包括哪些过程？ 单元测试\n集成测试\n系统测试\n验收测试\n请介绍软件测试的一般流程 制定测试计划\n设计测试方案\n测试准备和测试环境的建立\n执行测试\n测试评估\n测试总结\n请介绍制定测试计划的原则 制定测试计划应尽早开始\n保持测试计划的灵活性\n保持测试计划简洁易读\n尽量争取多方面来评审测试计划\n计算测试计划的投入\n请介绍软件测试计划的作用 使软件测试工作进行更顺利\n增进项目参加人员之间的沟通\n及早发现和修正软件规格说明书的问题\n使软件测试工作更易于管理\n白盒测试的方法有哪些（至少说明5种）？ 静态测试\n程序插桩\n逻辑覆盖\n基本路径测试\n域测试\n符号测试\nZ路径测试\n程序变异\n黑盒测试主要是为了发现软件中的哪几类错误？ 是否有不正确或遗漏的功能\n在接口上，输入是否能正确的接受，能否输出正确的结果\n是否有数据结构错误或外部信息访问错误\n性能上是否能够满足要求\n是否有初始化或终止性错误\n白盒测试要对程序模块进行什么检查？ 保证一个模块中的所有独立路径至少被使用一次\n对所有逻辑值均测试true和false\n在循环的边界和运行的界限内执行循环体\n检查内部数据结构以确定其有效性\n什么是程序插桩法？ 程序插桩法是借助向被测程序中插入操作，来实现测试目的的方法，即向源程序中添加一些语句，实现对程序语句的执行、变量的变化等情况进行检查。\n请列举逻辑覆盖的类型，并按由弱到强的顺序排列。 语句覆盖\n判定覆盖\n条件覆盖\n判定/条件覆盖\n条件组合覆盖\n请列举功能测试包括的方法（至少6项） 等价类划分\n边界值分析法\n错误推测法\n因果图法\n场景法\n判定表驱动\n正交试验法\n功能图法\n请列举非功能测试包括的方法（至少6项） 强度测试\n性能测试\n安全测试\n安装与卸载测试\n配置测试\n兼容性测试\n故障修复测试\n使用性能测试\n帮助菜单及用户说明测试\n请介绍单元测试的原则 单元测试越早进行越好\n单元测试应该依据《软件详细设计规格说明》进行\n对于修改过的代码应该重做单元测试\n当测试用例的测试结果与设计规格说明上的预期结果不一致时，测试人员应如实记录实际的测试结果\n单元测试应注意选择好被测软件单元的大小\n一个完整的单元测试说明应该包含正面测试和负面测试\n注意使用单元测试工具\n请说明单元测试的主要任务 模块接口测试\n模块局部数据结构测试\n模块中所有独立路径执行路径测试\n各种错误处理测试\n模块边界条件测试\n请介绍集成测试的主要任务 将各模块连接起来，检查模块相互调用时，数据经过接口是否丢失\n将各子功能组合起来，检查能否达到预期要求的各项功能\n一个模块的功能是否会对另一个模块的功能产生不利的影响\n全局数据结构是否有问题，会不会被异常修改\n单个模块的误差积累起来，是否被放大，从而达到不可接受的程度\n请介绍系统测试需要完成的测试。 功能测试\n性能测试\n可靠性、稳定性测试\n兼容性测试\n恢复测试\n安全测试\n强度测试\n面向用户支持方面的测试\n请介绍验收测试的主要内容。 配置复审\n合法性检查\n文档检查\n软件一致性检查\n软件功能和性能测试\n软件结果评审\n什么是α和β测试？ α测试是在软件开发公司内模拟软件系统的运行环境下的一种验收测试，即软件开发公司组织内部人员、模拟各类用户行为对即将面市的软件产品进行测试。经过α测试调整的软件产品称为β版本，β测试是指软件开发公司组织各方面的典型用户在日常工作中实际使用β版本。\n请介绍测试用例的作用 有效性\n避免测试的盲目性\n可维护性\n可复用性\n可评估性\n可管理性\n测试用例设计的基本原则 用成熟测试用例设计方法来指导设计\n测试用例的正确性\n测试用例的代表性\n测试结果的可判定性\n测试结果的可再现性\n足够详细、准确和清晰的步骤\n测试用例执行中应该注意哪几个问题？ 全方位地观察测试用例执行结果\n加强测试过程记录\n及时确认发现的问题\n与开发人员良好的沟通\n及时更新测试用例\n提交一份优秀的问题报告单\n测试结果分析\n请介绍软件缺陷的有效性描述规则 单一准确\n可以再现\n完整统一\n短小简练\n特定条件\n补充完善\n不做评价\n请列举软件缺陷生命周期的状态 打开状态\n解决状态\n关闭状态\n审查状态\n推迟状态\n如果找到的软件缺陷要采取繁杂的步骤才能再现，应采取什么方法来分离和再现软件缺陷？ 确保所有的步骤都被记录\n注意时间和运行条件上的因素\n注意软件的边界条件、内存容量和数据溢出的问题\n注意事件发生次序导致的软件缺陷\n考虑资源依赖性和内存、网络、硬件共享的相互作用\n不要忽略硬件\n如何正确面对软件缺陷 并不是测试人员辛苦找出的每个软件缺陷都是必须修复的\n发现缺陷的数量说明不了软件的质量\n不要指望找出软件中所有的缺陷\n软件测试的评测方法主要包括哪两类？每类又包含哪些方法？ 包括：覆盖评测和质量评测\n覆盖评测包括基于需求的测试覆盖和基于代码的测试覆盖。\n质量评测主要通过缺陷分析来实现，具体包括：缺陷发现率、缺陷潜伏期、缺陷密度和整体软件缺陷清除率。\n软件测试评测的主要目的是什么？ 量化测试进程，判断软件测试进行的状态，决定什么时候软件测试可以结束\n为最后的测试或软件质量分析报告生成所需的量化数据。\n请说明测试项目的基本特性 项目的独特性\n项目的组织性\n测试项目的生命期\n测试项目的资源消耗特性\n测试项目的目标冲突性\n具有智力密集、劳动密集的特点\n测试项目结果的不确定性\n请介绍测试项目管理的基本原则 始终能够把质量放在第一位\n可靠的需求\n尽量留出足够的时间\n足够重视测试计划\n要适当地引入测试自动化或测试工具\n建立独立的测试环境\n通用项目管理原则\n软件测试文档的作用是什么？ 促进项目组成员之间的交流沟通\n便于对测试项目的管理\n决定测试的有效性\n检验测试资源\n明确任务的风险\n评价测试结果\n方便再测试\n验证需求的正确性\n软件测试项目的过程管理主要包括哪些？ 测试项目启动\n测试计划阶段\n测试设计阶段\n测试执行阶段\n测试结果的审查和分析\n软件测试配置管理包括哪几个基本活动 配置标识\n版本控制\n变更控制\n配置状态报告\n配置审计\n请说明面向对象软件测试的三个层次，并说明第一层测试充分性的三个标准 类测试、类簇测试、系统测试\n基于类状态的覆盖率、基于约束的覆盖率、基于代码的覆盖率\nOOA阶段的测试可以划分为哪几个方面？ 对认定的对象的测试\n对认定的结构的测试\n对认定的主题的测试\n对定义的属性和实例关联的测试\n对定义的服务和消息关联的测试\n请介绍自动化测试的好处 产生可靠的系统\n改进测试工作质量\n提高测试工作效率\n请说明软件自动化测试的引入条件 管理层要充分意识到软件测试自动化的重要性\n对软件测试自动化有正确的认识\n有一个很好的计划和稳定的应用行为\n实施测试自动化必须进行多方面的培训\n具有一个专注的、有着丰富技能的测试团队，并且被分配了足够的时间和资源\n请说明软件测试自动化的实施过程 熟悉、分析测试用例\n把已有的测试用例归类，写成比较简单的测试自动化计划书\n开始自动化测试程序的编写\n尽量用“数据驱动”来将测试覆盖率提高\n将测试用例写成自动化测试程序\n不断地完善自动化测试系统\nWeb性能测试具体目标包括哪些？ 确定Web应用系统的总体性能参数，包括所支持的最大并发用户数、事务处理成功率、请求相应的往返延迟等。\n确定在各个级别的负载及压力测试下服务器输出的具体性能参数。\nWeb应用系统性能测试人员应具有哪些能力？ 掌握常见自动化测试工具的使用。\n具备一定的编程能力。\n掌握常见的数据库知识。\n掌握常见的操作系统知识。\n掌握一些Web应用服务器例如IIS，Tomcat等的使用。\n具有综合分析问题的能力，例如通过综合分析测试结果来确定系统瓶颈。\nWeb性能测试包含哪些测试类型？ 压力测试\n负载测试\n强度测试\n数据库容量测试\n预期指标的性能测试\n独立业务性能测试\n组合业务性能测试\n疲劳强度性能测试\n网络性能测试\n大数据量测试\n服务器性能测试\nWeb全面性能测试模型中，Web性能测试的八个类别包括哪些主要内容？ 预期指标的性能测试\n独立业务性能测试\n组合业务性能测试\n疲劳强度性能测试\n大数据量性能测试\n网络性能测试\n服务器性能测试\n特殊测试\nWeb应用的功能测试包括哪些内容？ 链接测试\n表单测试\n设计语言测试\n数据库测试\nCookies测试\n相关性功能检查与测试\nWeb界面测试的目标包括哪些？ Web界面的实现与设计需求、设计图保持一致，或者符合可接受标准；\n使用恰当的控件，各个控件及其属性符合标准；\n通过浏览测试对象可正确反映业务的功能和需求；\n如果有不同浏览器兼容性的需求，则需要满足在不同内核浏览器中实现效果相同的目标。\nWeb界面测试的主要元素包括哪些？ 页面元素的容错性列表\n页面元素清单\n页面元素的容错性是否存在\n页面元素基本功能是否实现\n页面元素的外形、摆放位置\n页面元素是否显示正确\n元素是否显示\nWeb界面测试内容包括哪些？ 整体界面测试\n控件测试\n多媒体测试\n内容测试\n容器测试\n浏览器兼容性测试\nWeb应用级的安全测试主要包括哪些？ 注册与登录\n在线超时\n操作留痕\n备份与恢复\nWeb传输级的安全测试主要包括哪些？ HTTPS和SSL测试 服务器端的脚本漏洞检查 防火墙测试 数据加密测试 计算题 按照基本路径测试法的步骤确定出需要测试的独立路径 1int cal(int count, int num) { 2 int x = 0; 3 while (count \u0026gt; 0) { 4 if (num == 0) { 5 x = x * 2; 6 break; 7 } else { 8 x = x + 10; 9 } 10 count--; 11 num--; 12 } 13 return x; 14} 解答 给代码行标号 从判断逻辑开始进行处理 遇到关键字可以跳过 画图 标边 计算环形复杂度-给定流图G的圈复杂度V(G)，定义为V(G)=P+1，P是流图G中圈的数量。 找出路径 -路径一定要包含开始到结束，不能中断 写测试用例 解答\n画图 标边 计算环形复杂度 总共有两个环，环形复杂度是，也就是有三条基本路径。V（G）=3\n找出路径 第一条：A (3-13)\n第二条：B、C、D(3-4-5-13)\n第三条：B、E、F、G、H、A(3-4-8-10-11-3-13)\n写出测试用例 第一条：输入count =0,num = 0,。输出：x=0；\n第二条：输入count = 1，num=0,输出，x = 0\n第三条：输入count = 1,num = 2,输出：x=10\n按照基本路径测试法的步骤确定出需要测试的独立路径 1void sort(int num, int itype) { 2 int x = 0; 3 int y = 0; 4 while (num \u0026gt; 0) { 5 if (itype == 0) { 6 x = y + 2; 7 break; 8 } else { 9 y = y + 10; 10 } 11 } 12} A-D-E应该变为 ADEABC\n以下代码的功能是将a，b，c三个浮点数按从小到大的顺序排列。即代码运行结束后，a中存放的是三个数中最小的，c中存放的是三个数中最大的请画出流程图，并写出路径测试的测试用例。 1void exchange() { 2 float a, b, c, t; 3 if (a \u0026gt; b) { 4 t = a; 5 a = b; 6 b = t; 7 } 8 if (a \u0026gt; c) { 9 t = a; 10 a = c; 11 c = t; 12 } 13 if (b \u0026gt; c) { 14 t = b; 15 b = c; 16 c = t; 17 } 18} 请画出流程图，并写出路径测试的测试用例。 1void func(int n ,int flag) { 2 int i = 0; 3 int j = 0; 4 while (n \u0026gt; 0) { 5 if (flag == 0) { 6 i = j * 2; 7 if (i \u0026gt; 30) break; 8 } else { 9 j = j + 10; 10 flag = flag - 1; 11 } 12 n = n - 1; 13 } 14} ABFG变为ABFGABC\nADEG变为ADEGABC\n请设计测试用例，使得以下程序满足基本路径测试 1int Test(int num, int x) 2{ 3 int temp = 0; 4 while (num \u0026gt; 0) 5 { 6 if (x \u0026gt; 0) 7 { 8 temp = num + 100; 9 break; 10 } 11 else 12 { 13 if (x == 0) 14 { 15 temp = temp + 10; 16 } 17 else 18 { 19 temp = temp + 20; 20 } 21 } 22 num--; 23 } 24 return temp; 25} V（G）=3个判定结点+1=4\n1 B（4，24）\n2 C，E，J（4，6，8，24）\n3 C，D，F，H，A，B（4，6，13，15，22，4，24）\n4 C，D，G，I，A，B（4，6，13，19，22，4，24）\n1 B（4，24）\n​ 输入数据：num=0，或者是num\u0026lt;0的某一个值。\n​ 预期结果：temp=0.\n2 C，E，J（4，6，8，24）\n​ 输入数据：x =1;num=1\n​ 预期结果：temp=101.\n3 C，D，F，H，A，B（4，6，13，15，22，4，24）\n​ 输入数据：num=1;x=0\n​ 预期结果：temp=10.\n4 C，D，G，I，A，B（4，6，13，19，22，4，24）\n​ 输入数据：num =1;x=-1\n​ 预期结果：temp=20.\n功能描述：如果x\u003c=3000，y的值为0； 如果3000\u0026lt;x\u0026lt;=5000，则y的值为x超过3000部分的3%；如果5000\u0026lt;x\u0026lt;8000，则y 的值为：x超过5000部分的5%加上超过3000部分的3%。请用等价类划分和边界值分析相结合来设计测试用例。\n有效等价类\nx\u0026lt;=3000：\n3000\u0026lt;x\u0026lt;=5000\n如果5000\u0026lt;x\u0026lt;8000\n无效等价类\n小于3000\n大于等于8000\n功能描述：密码输入框的字符长度要求为最短4个字符， 最长20个字符。请用等价类划分和边界值分析相结合来设计测试用例。（要考虑字符的类型）\n同上\n“……对1.2米以下儿童免票，对1.2-1.5米的儿童半票，对教师、军人或70岁以上的老人，应给予优先的业务处理……”这里假设“优先的业务处理”已在别处有更严格的定义，请建立判定表。（15分） 条件桩：\n身高小于1.2m\n身高在1.2-1.5m\n是儿童\n是教师\n是军人\n年龄大于70岁\n动作桩：\n免票\n半票\n优先处理\n请用等价类划分法设计测试用例 1void triangle(float a, float b, float c) { 2 if (a \u0026gt; 0 \u0026amp;\u0026amp; b \u0026gt; 0 \u0026amp;\u0026amp; c \u0026gt; 0 \u0026amp;\u0026amp; a + b \u0026gt; c \u0026amp;\u0026amp; a + c \u0026gt; b \u0026amp;\u0026amp; b + c \u0026gt; a) { 3 if (a == b \u0026amp;\u0026amp; b == c) { printf(\u0026#34;等边三角形\u0026#34;); } 4 else if (a == b || a == c || b == c) { printf(\u0026#34;等腰三角形\u0026#34;); } 5 else { printf(\u0026#34;一般三角形\u0026#34;); } 6 } else { printf(\u0026#34;输入无效\u0026#34;); } 7} 请用等价类划分法设计下列代码的单元测试用例 1float jisuan(float a) { 2 if (a \u0026gt; 2000) { 3 if (a \u0026gt; 5000) 4 return 3000 * 0.2 + (a - 5000) * 0.3; 5 else 6 return (a - 2000) * 0.2; 7 } else { 8 if (a \u0026gt; 800) 9 return (a - 800) * 0.1; 10 } 11} (2000-5000]：\n5000-∞:\n(800-2000]:\n无效等价类\n(∞-800):\n某单位对其在大学以上学历的职工安排工作（工作岗位用AA-FF表示），方针如下 如果年龄不满18岁，文化程度为大学，若是男性，则任AA。\n若是女性，则任BB；\n如果年满18但不足50岁，文化程度是研究生，不分男女性，均任CC。\n文化程度是大学，则不分男女性均任DD；\n如果年满50岁以上，文化程度是研究生，若是男性，则任CC，\n文化程度是大学，若是男性，则任EE。\n若是女性，则任FF。\n请对以上说明绘制判定表。为了便于绘制，条件符号使用以下内容\n条件名 取值 符号 性别 男性、女性 M、F 年龄 \u0026lt;18、18\u0026lt;=年龄\u0026lt;50 、\u0026gt;=50 C、Y、L 文化程度 研究生、大学生 G、U 合并\n“……对军人、残疾人或70岁以上的老人，应给予优先的业务处理……” 这里假设“优先的业务处理”已在别处有更严格的定义，请建立判定表。\n功能描述：输入框的输入内容要求为数字或字母， 长度要求为最短6个字符，最长20个字符。请用等价类划分和边界值分析相结合来设计测试用例\n有效等价类：\n长度6-20： 内容只有数字 内容只有字母 内容只包含数字和字母 无效等价类：\n长度小于6： 长度大于20： 内容包含特殊字符 有效等价类的测试：\njimyag 测试了1和3\njimyagjimyagjimyagji 测试了1和3\njimyagjimyagj 测试了1和3\n123456 测试了1和 2\n1234567891234 测试了1和2\n12345678912345678912 测试了1和2\njim123 测试了1和4\njimyagjimyag12345678 测试了 1和4\n无效等价类的测试\n长度为5只包含数字\n长度为5只包含字母\n长度为5包含字母和数字\n长度为5 包含特殊字符\n长度为21也是\n“……对成绩积点在2.5以上，并且参加过竞赛或创新项目的同学，在各类奖励中应给予优先考虑……”请建立判定表 某保险公司对客户制定收费标准（标准等级用AA-GG表示）， 标准如下：如果年龄不满18岁，不分男女性，标准为AA；如果年满18但不足50岁，大病例史为无，不分男女，标准BB；如果年满18但不足50岁，大病例史为有，若是男性，标准为CC，若是女性，标准为DD；如果年满50岁以上，大病例史为无，若是男性，标准为EE，若是女性，标准为FF；如果年满50岁以上，大病例史为有，不分男女，标准为GG。请对以上说明绘制判定表。为了便于绘制，条件符号使用以下内容\n条件名 取值 符号 性别 男性、女性 M、F 年龄 \u0026lt;18、18\u0026lt;=年龄\u0026lt;50、\u0026gt;=50 C、Y、L 大病史情况 有、无 H、N 程序结构图如下图所示，请画出自顶向下集成的过程 程序结构图如下图所示，请画出自底向上集成的过程 需求描述如下：“输入三个整数a、b、c，分别作为三边的边长构成三角形。” 通过程序判定所构成的三角形的类型，当此三角形为一般三角形、等腰三角形及等边三角形时，用等价类划分方法为该程序进行测试用例设计\n有效等价类：\n三个数\na\u0026gt;0\nb\u0026gt;0\nc\u0026gt;0\na+b\u0026gt;c\na+c\u0026gt;b\nb+c\u0026gt;a\na=b\na=c\nb=c\na=b=c\n无效等价类，\n一个数\n两个数\na\u0026lt;=0\nb\u0026lt;=0\nc\u0026lt;=0\na+b\u0026lt;=c\na+c\u0026lt;=b\nb+c\u0026lt;=a\na=b a!=b \u0026amp;\u0026amp;a!=c\u0026amp;\u0026amp;b!=c\na！=c\nb！=c\nb！=c\n有一个处理单价为1元5角的盒装饮料的自动售货机软件， 若投入1元5角硬币，按下“可乐”、“雪碧”或“红茶”按钮，相应的饮料就送出来。若投入的是2元硬币，在送出饮料的同时退换5角硬币，试用因果图法设计测试用例\n分析程序的规格说明，列出原因和结果 找出原因于结果之间的因果关系，原因与原因之间的约束关系，画出因果图。 将因果图转换成决策表 根据决策表设计测试用例的输入预期输出 解答 原因：\n投入1.5元硬币 投入2元 按可乐 按雪碧 按红茶 中间状态：\n已投币 按钮 结果：\n退还5硬币 送出可乐 送出雪碧 送出红茶 手机号码验证的描述如下： 输入的内容必须是数字，并且位数为11位，满足以上情况显示输入正确；如果输入内容有非数字，则显示内容有误；如果输入位数不为11位，则显示位数有误。请用因果图法设计测试用例\n条件：\n位数为11位\n输入全是数字\n结果：\n输入正确，内容有误，位数有误\n","date":"2022-05-17","img":"","permalink":"/posts/a0aa4897/","series":[],"tags":["复习资料"],"title":"软件测试技术"},{"categories":["Go"],"content":"介绍Go语言如何优雅的处理错误。\nError vs Exception Go 的处理异常逻辑是不引入 exception，支持多参数返回，所以你很容易的在函数签名中带上实现了 error interface 的对象，交由调用者来判定。\n如果一个函数返回了 (value, error)，你不能对这个 value 做任何假设，必须先判定 error。唯一可以忽略 error 的情况就是，如果你连 value 也不关心。\nGo 中有 panic 的机制，如果你认为和其他语言的 exception 一样，那你就错了。\n当我们抛出异常的时候，相当于你把 exception 扔给了调用者来处理。比如，你在 C++ 中，把 string 转为 int，如果转换失败，会抛出异常。或者在 Java 中转换 String 为 Date 失败时，会抛出异常。\nGo panic 意味着 fatal error（就是挂了）。不能假设调用者来解决 panic，意味着代码不能继续运行。使用多个返回值和一个简单的约定，Go 解决了让程序员知道什么时候出了问题，并为真正的异常情况保留了 panic。panic和recover不要一起使用，自己panic了就不要recover了，但是第三方库的panic有时候需要recover。\n对于真正意外的情况，那些表示不可恢复的程序错误，例如索引越界、不可恢复的环境问题、栈溢出，我们才使用 panic。对于其他的错误情况，我们应该是期望使用 error 来进行判定。\nYou only need to check the error value if you care about the result. \u0026ndash; Dave\nThis blog post from Microsoft’s engineering blog in 2005 still holds true today, namely:\nMy point isn’t that exceptions are bad. My point is that exceptions are too hard and I’m not smart enough to handle them.\n简单 考虑失败，而不是成功（plan for failure, not success） 没有隐藏的控制流 完全交给你来控制 error Error are values Sentinel Error 预定义的特定错误，我们叫为 sentinel error，这个名字来源于计算机编程中使用一个特定值来表示不可能进行进一步处理的做法。所以对于 Go，我们使用特定的值来表示错误。\n1if err == ErrSomething { … } 类似的 io.EOF，或者更底层的 syscall.ENOENT。\n使用 sentinel 值是最不灵活的错误处理策略，因为调用方必须使用 == 将结果与预先声明的值进行比较。当您想要提供更多的上下文时，这就出现了一个问题，因为返回一个不同的错误将破坏相等性检查。\n甚至是一些有意义的 fmt.Errorf 携带一些上下文，也会破坏调用者的 == ，调用者将被迫查看 error.Error() 方法的输出，以查看它是否与特定的字符串匹配。 所以要不依赖于检查 error.Error 的输出。\n不应该依赖检测 error.Error 的输出，Error 方法存在于 error 接口主要用于方便程序员使用，但不是程序（编写测试可能会依赖这个返回）。这个输出的字符串用于记录日志、输出到 stdout 等。\nSentinel errors 成为你 API 公共部分。\n如果您的公共函数或方法返回一个特定值的错误，那么该值必须是公共的，当然要有文档记录，这会增加 API 的表面积。 如果 API 定义了一个返回特定错误的 interface，则该接口的所有实现都将被限制为仅返回该错误，即使它们可以提供更具描述性的错误。比如 io.Reader。像 io.Copy 这类函数需要 reader 的实现者返回 io.EOF 来告诉调用者没有更多数据了，但这又不是错误。 Sentinel errors 在两个包之间创建了依赖。\nsentinel errors 最糟糕的问题是它们在两个包之间创建了源代码依赖关系。**例如，检查错误是否等于 io.EOF，您的代码必须导入 io 包。**这个特定的例子听起来并不那么糟糕，因为它非常常见，但是想象一下，当项目中的许多包导出错误值时，存在耦合，项目中的其他包必须导入这些错误值才能检查特定的错误条件（in the form of an import loop）。\n结论: 尽可能避免 sentinel errors。 我的建议是避免在编写的代码中使用 sentinel errors。在标准库中有一些使用它们的情况，但这不是一个您应该模仿的模式。\nError types Error type 是实现了 error 接口的自定义类型。例如 MyError 类型记录了文件和行号以展示发生了什么。\n1type MyError struct { 2\tMsg string 3\tFile string 4\tLine int 5} 6 7func (e *MyError) Error() string { 8\treturn fmt.Sprintf(\u0026#34;%s:%d: %s\u0026#34;, e.File, e.Line, e.Msg) 9} 10func test() error { 11\treturn \u0026amp;MyError{\u0026#34;test\u0026#34;, \u0026#34;main.go\u0026#34;, 10} 12} 因为 MyError 是一个 type，调用者可以使用断言转换成这个类型，来获取更多的上下文信息。\n1func main() { 2\terr := test() 3\tswitch err.(type) { 4\tcase nil: 5\t// do nothing 6\tcase *MyError: 7\tfmt.Println(err.(*MyError).Msg) 8\tdefault: 9\tfmt.Println(err) 10\t} 与错误值相比，错误类型的一大改进是它们能够包装底层错误以提供更多上下文。 一个不错的例子就是 os.PathError 它提供了底层执行了什么操作、那个路径出了什么问题。\n1// go1.18/src/io/fs/fs.go:242 2// PathError records an error and the operation and file path that caused it. 3type PathError struct { 4\tOp string 5\tPath string 6\tErr error 7} 8 9func (e *PathError) Error() string { return e.Op + \u0026#34; \u0026#34; + e.Path + \u0026#34;: \u0026#34; + e.Err.Error() } 10 11func (e *PathError) Unwrap() error { return e.Err } 12 13// Timeout reports whether this error represents a timeout. 14func (e *PathError) Timeout() bool { 15\tt, ok := e.Err.(interface{ Timeout() bool }) 16\treturn ok \u0026amp;\u0026amp; t.Timeout() 17} 调用者要使用类型断言和类型 switch，就要让自定义的 error 变为 public。这种模型会导致和调用者产生强耦合，从而导致 API 变得脆弱。\n结论是尽量避免使用 error types，虽然错误类型比 sentinel errors 更好，因为它们可以捕获关于出错的更多上下文，但是 error types 共享 error values 许多相同的问题。因此，我(啊别人的)的建议是避免错误类型，或者至少避免将它们作为公共 API 的一部分。\nOpaque errors 在我看来，这是最灵活的错误处理策略，因为它要求代码和调用者之间的耦合最少。因为虽然您知道发生了错误，但您没有能力看到错误的内部。作为调用者，关于操作的结果，您所知道的就是它起作用了，或者没有起作用（成功还是失败）。这就是不透明错误处理的全部功能–只需返回错误而不假设其内容。\n1package main 2 3import \u0026#34;github.com/quux/bar\u0026#34; 4 5func fn()error { 6\tx,err:=bar.Foo() 7\tif err!=nil { 8\treturn err 9\t} 10\treturn nil 11} 12 13func main() { 14\tfn() 15} Assert errors for behaviour, not type\n在少数情况下，这种二分错误处理方法是不够的。例如，与进程外的世界进行交互（如网络活动），需要调用方调查错误的性质，以确定重试该操作是否合理。在这种情况下，我们可以断言错误实现了特定的行为，而不是断言错误是特定的类型或值。考虑这个例子：\n1type temporary interface { 2\tTemporary() bool 3} 4 5func IsTemporary(err error) bool { 6\tif temp, ok := err.(temporary); ok { 7\treturn ok \u0026amp;\u0026amp; temp.Temporary() 8\t} 9\treturn false 10} 这里的关键是，这个逻辑可以在不导入定义错误的包或者实际上不了解 err 的底层类型的情况下实现——我们只对它的行为感兴趣。\nHandling Error Indented flow is for errors 无错误的正常流程代码，将成为一条直线，而不是缩进的代码。\n1f,err:=os.Open(path) 2if err!=nil{ 3 // 处理错误 4} 5// 逻辑 6 7 8f,err:=os.Open(path) 9if err==nil{ 10\t// 逻辑 11} 12// 处理错误 Eliminate error handling by eliminating errors 下面的代码有啥问题？\n1func AuthRequest(r *Request)error{ 2 err:=auth(r.User) 3 if err!=nil{ 4 return err 5 } 6 return nil 7} 8 9func AuthRequest(r *Request)error{ 10 return auth(r.User) 11} 统计 io.Reader 读取内容的行数,处理了两次错误\n1func CountLines(r io.Reader) (int, error) { 2\tvar ( 3\tbr = bufio.NewReader(r) 4\tlines int 5\terr error 6\t) 7\tfor { 8\t_, err = br.ReadString(\u0026#39;\\n\u0026#39;) 9\tlines++ 10\tif err != nil { 11\tbreak 12\t} 13\t} 14\tif err != io.EOF { 15\treturn 0, err 16\t} 17\treturn lines, nil 18} 改进版，只需要接受最终有无错误就行\n1func CountLines(r io.Reader)(int,error){ 2 sc:=bufio.NewScanner(r) 3 lines:=0 4 for sc.Scan(){ 5 lines++ 6 } 7 return lines,sc.Err() 8} 例如下面的例子，总共要处理4次错误\n1type Header struct { 2\tKey, Value string 3} 4 5type Status struct { 6\tCode int 7\tReason string 8} 9 10func WriteResponse(w *io.Writer, status Status, headers []Header, body io.Reader) error { 11\t_, err := fmt.Fprint(*w, \u0026#34;HTTP/1.1\u0026#34;, status.Code, status.Reason) 12\tif err != nil { 13\treturn err 14\t} 15\tfor _, h := range headers { 16\t_, err := fmt.Fprint(*w, \u0026#34;\\n\u0026#34;, h.Key, \u0026#34;:\u0026#34;, h.Value) 17\tif err != nil { 18\treturn err 19\t} 20\t} 21\t_, err = fmt.Fprint(*w, \u0026#34;\\n\\n\u0026#34;) 22\tif err != nil { 23\treturn err 24\t} 25\t_, err = io.Copy(*w, body) 26\treturn err 27} 经过改进，将错误处理统一集中到Write中。并最终返回，看起来好像没有处理错误一样。\n1type errWrite struct { 2\tio.Writer 3\terr error 4} 5 6func (e *errWrite) Write(p []byte) (n int, err error) { 7\tif e.err != nil { 8\treturn 0, e.err 9\t} 10\tn, e.err = e.Writer.Write(p) 11\treturn n, e.err 12} 13 14func WriteResponse(w *io.Writer, status Status, headers []Header, body io.Reader) error { 15\tew := \u0026amp;errWrite{Writer: *w} 16\tfmt.Fprint(ew, \u0026#34;HTTP/1.1\u0026#34;, status.Code, status.Reason) 17 18\tfor _, h := range headers { 19\tfmt.Fprint(ew, \u0026#34;\\r\\n\u0026#34;, h.Key, \u0026#34;:\u0026#34;, h.Value) 20\t} 21\tfmt.Fprint(ew, \u0026#34;\\r\\n\\r\\n\u0026#34;) 22\tio.Copy(ew, body) 23 24\treturn ew.err 25} Wrap erros 如果 authenticate 返回错误，则 AuthenticateRequest 会将错误返回给调用方，调用者可能也会这样做，依此类推。在程序的顶部，程序的主体将把错误打印到屏幕或日志文件中，打印出来的只是：没有这样的文件或目录？？？？？到底是那个文件或者目录没有。\n1func AuthRequest(r *Request)error{ 2 return auth(r.User) 3} 没有生成错误的 file:line 信息。没有导致错误的调用堆栈的堆栈跟踪。这段代码的作者将被迫进行长时间的代码分割，以发现是哪个代码路径触发了文件未找到错误。\n1func AuthRequest(r *Request)error{ 2 err:=auth(r.User) 3 if err!=nil{ 4 return fmt.Errorf(\u0026#34;auth failed: %v\u0026#34;,err) 5 } 6 return nil 7} 但是正如我们前面看到的，这种模式与 sentinel errors 或 type assertions 的使用不兼容，因为将错误值转换为字符串，将其与另一个字符串合并，然后将其转换回 fmt.Errorf 破坏了原始错误，导致等值判定失败。\nYou should only handle errors once. Handling an error means inspecting the error value, and making a single decision.\n我们经常发现类似的代码，在错误处理中，带了两个任务: 记录日志并且再次返回错误。这个还是看要求，打印之后返回也可以。\n1func WriteAll(w io.Writer, b []byte) (err error) { 2\t_, err = w.Write(b) 3\tif err != nil { 4\tlog.Println(\u0026#34;unable WriteAll:\u0026#34;, err) 5\treturn err 6\t} 7\treturn nil 8} 在这个例子中，如果在 w.Write 过程中发生了一个错误，那么一行代码将被写入日志文件中，记录错误发生的文件和行，并且错误也会返回给调用者，调用者可能会记录并返回它，一直返回到程序的顶部。\n1func WriteConfig(w io.Writer, config *Config) (err error) { 2\tbuf, err := json.Marshal(config) 3\tif err != nil { 4\tlog.Println(\u0026#34;unable Marshal:\u0026#34;, err) 5\treturn err 6\t} 7\tif err := WriteAll(w, buf); err != nil { 8\tlog.Println(\u0026#34;unable WriteAll:\u0026#34;, err) 9\treturn err 10\t} 11\treturn nil 12} 13 14func main() { 15\terr := WriteConfig(os.Stdout, \u0026amp;config) 16\tfmt.Println(err) // io.EOF 17} Go 中的错误处理契约规定，在出现错误的情况下，不能对其他返回值的内容做出任何假设。由于 JSON 序列化失败，buf 的内容是未知的，可能它不包含任何内容，但更糟糕的是，它可能包含一个半写的 JSON 片段。 由于程序员在检查并记录错误后忘记 return，损坏的缓冲区将被传递给 WriteAll，这可能会成功，因此配置文件将被错误地写入。但是，该函数返回的结果是正确的。\n1func WriteConfig(w io.Writer, config *Config) (err error) { 2\tbuf, err := json.Marshal(config) 3\tif err != nil { 4\tlog.Println(\u0026#34;unable Marshal:\u0026#34;, err) 5\t// oops, forgot to return err 6\t} 7\tif err := WriteAll(w, buf); err != nil { 8\tlog.Println(\u0026#34;unable WriteAll:\u0026#34;, err) 9\treturn err 10\t} 11\treturn nil 12} 日志记录与错误无关且对调试没有帮助的信息应被视为噪音，应予以质疑。记录的原因是因为某些东西失败了，而日志包含了答案。\nThe error has been logged. The application is back to 100% integrity. The current error is not reported any longer. 错误要被日志记录。 应用程序处理错误，保证100%完整性。 之后不再报告当前错误。 pkg/errors 使用第三方的包处理错误\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;os\u0026#34; 6 7\t\u0026#34;github.com/pkg/errors\u0026#34; 8) 9 10func ReadFile(path string) ([]byte, error) { 11\tf, err := os.Open(path) 12\tif err != nil { 13\treturn nil, errors.Wrap(err, \u0026#34;open file failed\u0026#34;) 14\t} 15\tdefer f.Close() 16\t// ... 17\treturn nil, nil 18} 19 20func main() { 21\t_, err := ReadFile(\u0026#34;/tmp/file\u0026#34;) 22\tif err != nil { 23\tfmt.Printf(\u0026#34;original error: %T %v\\n\\n\u0026#34;, errors.Cause(err), errors.Cause(err)) 24\tfmt.Printf(\u0026#34;stack trace: \\n%+v\\n\u0026#34;, err) 25\tos.Exit(1) 26\t} 27} 打印有堆栈信息，以及其他的详细的信息\n1original error: *fs.PathError open /tmp/file: The system cannot find the path specified. 2 3 4stack trace: 5open /tmp/file: The system cannot find the path specified. 6open file failed 7main.ReadFile 8 D:/code/go/test/cto/001-error/main.go:13 9main.main 10 D:/code/go/test/cto/001-error/main.go:21 11runtime.main 12 C:/Users/jimyag/sdk/go1.18/src/runtime/proc.go:250 13runtime.goexit 14 C:/Users/jimyag/sdk/go1.18/src/runtime/asm_amd64.s:1571 区别WithMessage和Warp。前者是在原有的错误基础上添加一条错误消息，后者是通过当前的错误信息和堆栈信息组成一个新的错误。\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;os\u0026#34; 6 7\t\u0026#34;github.com/pkg/errors\u0026#34; 8) 9 10func ReadFile(path string) ([]byte, error) { 11\tf, err := os.Open(path) 12\tif err != nil { 13\treturn nil, errors.Wrap(err, \u0026#34;open file failed\u0026#34;) 14\t} 15\tdefer f.Close() 16\t// ... 17\treturn nil, nil 18} 19 20func ReadConfig(path string) ([]byte, error) { 21\tdata, err := ReadFile(path) 22\tif err != nil { 23\treturn nil, errors.WithMessage(err, \u0026#34;read file failed\u0026#34;) 24\t} 25\treturn data, nil 26} 27 28func main() { 29\t_, err := ReadConfig(\u0026#34;/tmp/file\u0026#34;) 30\tif err != nil { 31\tfmt.Printf(\u0026#34;%+v\\n\u0026#34;, err) 32\tos.Exit(1) 33\t} 34} 结果\n1C:\\Users\\jimyag\\AppData\\Local\\Temp\\GoLand\\___go_build_test_cto_001_error.exe 2open /tmp/file: The system cannot find the path specified. 3open file failed 4main.ReadFile 5 D:/code/go/test/cto/001-error/main.go:13 6main.ReadConfig 7 D:/code/go/test/cto/001-error/main.go:21 8main.main 9 D:/code/go/test/cto/001-error/main.go:29 10runtime.main 11 C:/Users/jimyag/sdk/go1.18/src/runtime/proc.go:250 12runtime.goexit 13 C:/Users/jimyag/sdk/go1.18/src/runtime/asm_amd64.s:1571 14read file failed 在你的应用代码中，使用 errors.New 或者 errros.Errorf 返回错误。\n如果调用其他包内的函数，通常简单的直接返回。\n1func parseArgs(args []string) error { 2\tif len(args) != 2 { 3\treturn errors.Errorf(\u0026#34;two arguments required\u0026#34;) 4\t} 5\treturn nil 6} 7 8func fo() error { 9\terr := parseArgs([]string{\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;}) 10\tif err != nil { 11\treturn err 12\t} 13\treturn nil 14} 如果和其他库进行协作，考虑使用 errors.Wrap 或者 errors.Wrapf 保存堆栈信息。同样适用于和标准库协作的时候。\n1f,err:=os.Open(path) 2if err!=nil{ 3 return errors.Warpf(err,\u0026#34;failed to open %q\u0026#34;,path) 4} 直接返回错误，而不是每个错误产生的地方到处打日志。\n在程序的顶部或者是工作的 goroutine 顶部（请求入口），使用 %+v 把堆栈详情记录。\n1func main(){ 2 err:=app.Run() 3 if err!=nil{ 4 fmt.Printf(\u0026#34;FATAL:%+v\\n\u0026#34;,err) 5 os.Exit(1) 6 } 7} 使用 errors.Cause 获取 root error，再进行和 sentinel error 判定。\n总结:\nPackages that are reusable across many projects only return root error values.\n选择 wrap error 是只有 applications 可以选择应用的策略。具有最高可重用性的包只能返回根错误值。此机制与 Go 标准库中使用的相同（kit 库的 sql.ErrNoRows）。\nIf the error is not going to be handled, wrap and return up the call stack.\n这是关于函数/方法调用返回的每个错误的基本问题。如果函数/方法不打算处理错误，那么用足够的上下文 wrap errors 并将其返回到调用堆栈中。例如，额外的上下文可以是使用的输入参数或失败的查询语句。确定您记录的上下文是足够多还是太多的一个好方法是检查日志并验证它们在开发期间是否为您工作。\nOnce an error is handled, it is not allowed to be passed up the call stack any longer.\n一旦确定函数/方法将处理错误，错误就不再是错误。如果函数/方法仍然需要发出返回，则它不能返回错误值。它应该只返回零（比如降级处理中，你返回了降级数据，然后需要 return nil）。\n1.13新特性 go1.13为 errors 和 fmt 标准库包引入了新特性，以简化处理包含其他错误的错误。其中最重要的是: 包含另一个错误的 error 可以实现返回底层错误的 Unwrap 方法。如果 e1.Unwrap() 返回 e2，那么我们说 e1 包装 e2，您可以展开 e1 以获得 e2。 按照此约定，我们可以为的 QueryError 类型指定一个 Unwrap 方法，该方法返回其包含的错误。\n1func (e *QueryError)Unwarp()error{ 2 return e.Err 3} go1.13 errors 包包含两个用于检查错误的新函数：Is 和 As。\n1// if err == ErrNotFound 2if errors.Is(err,ErrorNotFound){ 3 // 4} 5 6// if e,ok:=err.(*QueryError);ok{ ...} 7var e *QueryError 8if errors.As(err,\u0026amp;e){ 9 // 10} 如前所述，使用 fmt.Errorf 向错误添加附加信息\n1if err!=nil{ 2 return fmt.Errorf(\u0026#34;decompress %v: %v\u0026#34;,name,err) 3} 在 Go 1.13中 fmt.Errorf 支持新的 %w 谓词。\n1if err!=nil{ 2 return fmt.Errorf(\u0026#34;decompress %v: %w\u0026#34;,name,err) 3} 用 %w 包装错误可用于 errors.Is 以及 errors.As:\n1err:=fmt.Errorf(\u0026#34;access denied %w\u0026#34;,ErrPermisson) 2... 3if errors.Is(err,ErrPermisson){ 4 5} 6... 总结 对于错误处理用pkg/errors好一点，它也兼容了1.13的Is和As。\n对于一个底层库的开发不要使用pkg/errors,要生成对应的根错误来进行排查。\n版权 以上内容根据极客时间的0.99元的错误处理课程总结而来。本文仅供学习和交流使用，如有不当之处，请联系我删除。\n","date":"2022-05-08","img":"","permalink":"/posts/608465d8/","series":[],"tags":["错误处理"],"title":"Go如何优雅进行错误处理"},{"categories":["算法"],"content":"牛客算法必刷TOP101，包含：链表、二分查找/排序、二叉树、堆/栈/队列、哈希、递归/回溯、动态规划、字符串、双指针、贪心算法、模拟总共101道题。\n此部分是二叉树专题。\n牛客网 (nowcoder.com)\n二叉树的前序遍历 描述 给你二叉树的根节点 root ，返回它节点值的 前序 遍历。\n数据范围：二叉树的节点数量满足$ 0 \\le n \\le 100$ ，二叉树节点的值满足 $1 \\le val \\le 100$ ，树的各节点的值各不相同\n示例 1：\n解析 解析1-递归 按照前序遍历的定义，先遍历中间结点，接着遍历左孩子，在遍历右孩子。\n1void preorderTraversal(vector\u0026lt;int\u0026gt; \u0026amp;res,TreeNode*root){ 2 if(root==nullptr){ 3 return ; 4 } 5 res.push_back(root-\u0026gt;val); 6 preorderTraversal(res, root-\u0026gt;left); 7 preorderTraversal(res, root-\u0026gt;right); 8 } 9 10 vector\u0026lt;int\u0026gt; preorderTraversal(TreeNode* root) { 11 vector\u0026lt;int\u0026gt; res; 12 preorderTraversal(res,root); 13 return res; 14 } 解析2-迭代法 递归的方式使用到了函数栈，我们也可以自己用栈进行模拟。\n对于前序遍历，我们先访问中间结点，再访问左边结点，最后访问右结点。但是根据栈的特性：先进后出。应该先放入右结点，再放入左结点。\n1vector\u0026lt;int\u0026gt; preorderTraversal(TreeNode* root){ 2 vector\u0026lt;int\u0026gt; res; 3 if(root==nullptr){ 4 return res; 5 } 6 // 辅助栈 7 stack\u0026lt;TreeNode*\u0026gt; help; 8 help.push(root); 9 // 不为空就继续 10 while(!help.empty()){ 11 TreeNode*temp = help.top(); 12 help.pop(); 13 res.push_back(temp-\u0026gt;val); 14 // 要先放入右孩子 15 if(temp-\u0026gt;right){ 16 help.push(temp-\u0026gt;right); 17 } 18 // 再放入左孩子 19 if(temp-\u0026gt;left){ 20 help.push(temp-\u0026gt;left); 21 } 22 } 23 return res; 24} 二叉树的中序遍历 描述 给定一个二叉树的根节点root，返回它的中序遍历结果。\n数据范围：树上节点数满足 $0 \\le n \\le 1000$，树上每个节点的值满足 $0 \\le val \\le 1000$ 进阶：空间复杂度 O(n)，时间复杂度 O(n)\n示例1 输入：\n1{1,2,#,#,3} 返回值：\n1[2,3,1] 说明：\n示例2 输入：\n1{} 返回值：\n1[] 示例3 输入：\n1{1,2} 返回值：\n1[2,1] 说明：\n示例4 输入：\n1{1,#,2} 返回值：\n1[1,2] 说明：\n解析 解析1-递归法 根据题意进行模拟\n1void inorderTraversal(vector\u0026lt;int\u0026gt; \u0026amp;res,TreeNode* root){ 2 if(root==nullptr){ 3 return ; 4 } 5 if(root-\u0026gt;left){ 6 inorderTraversal(res,root-\u0026gt;left); 7 } 8 res.push_back(root-\u0026gt;val); 9 if(root-\u0026gt;right){ 10 inorderTraversal(res,root-\u0026gt;right); 11 } 12 } 13 vector\u0026lt;int\u0026gt; inorderTraversal(TreeNode* root) { 14 vector\u0026lt;int\u0026gt;res; 15 inorderTraversal(res,root); 16 return res; 17 } 解析2-迭代法 由于中序遍历是先访问左孩子，我们就要先找到左孩子，一直要找到树叶的左孩子。一直深度优先找到左孩子，然后访问左孩子，之后访问中间结点，之后对右孩子进行这样迭代遍历。\n1vector\u0026lt;int\u0026gt; inorderTraversal(TreeNode* root){ 2 vector\u0026lt;int\u0026gt;res; 3 if(root==nullptr){ 4 return res; 5 } 6 stack\u0026lt;TreeNode*\u0026gt;help; 7 while(root||!help.empty()){ 8 while(root){ 9 help.push(root); 10 root = root-\u0026gt;left; 11 } 12 TreeNode*temp = help.top(); 13 help.pop(); 14 res.push_back(temp-\u0026gt;val); 15 root = temp-\u0026gt;right; 16 } 17 return res; 18} 二叉树的后序遍历 描述 给定一个二叉树，返回他的后序遍历的序列。\n后序遍历是值按照 左节点-\u0026gt;右节点-\u0026gt;根节点 的顺序的遍历。\n数据范围：二叉树的节点数量满足 $0 \\le n \\le 100$，二叉树节点的值满足 $1 \\le val \\le 100$ ，树的各节点的值各不相同\n样例图\n解析 解析1-递归 根据题意进行模拟\n1 void postorderTraversal(vector\u0026lt;int\u0026gt;\u0026amp;res,TreeNode*root){ 2 if(root==nullptr){ 3 return; 4 } 5 postorderTraversal(res,root-\u0026gt;left); 6 postorderTraversal(res,root-\u0026gt;right); 7 res.push_back(root-\u0026gt;val); 8 } 9 vector\u0026lt;int\u0026gt; postorderTraversal(TreeNode* root) { 10 vector\u0026lt;int\u0026gt;res; 11 postorderTraversal(res,root); 12 return res; 13 } 解析2-迭代 根据后序遍历“左右中”的顺序，那么后序遍历也与中序遍历类似，要先找到每棵子树的最左端节点：\n1//每次找到最左节点 2while(root != NULL){ 3 s.push(root); 4 root = root-\u0026gt;left; 5} 然后我们就要访问该节点了嘛？不不不，如果它还有一个右节点呢？根据“左右根”的原则，我还要先访问右子树。我们只能说它是最左端的节点，它左边为空，但是右边不一定，因此这个节点必须被看成是这棵最小的子树的根。要怎么访问根节点呢？\n我们都知道从栈中弹出根节点，一定是左节点已经被访问过了，因为左节点是子问题，访问完了才回到父问题，那么我们还必须要确保右边也已经被访问过了。如果右边为空，那肯定不用去了，如果右边不为空，那我们肯定优先进入右边，此时再将根节点加入栈中，等待右边的子树结束。\n1//该节点再次入栈 2s.push(node); 3//先访问右边 4root = node-\u0026gt;right; 不过，当右边被访问了，又回到了根，我们的根怎么知道右边被访问了呢？用一个前序指针pre标记一下，每个根节点只对它的右节点需要标记，而每个右节点自己本身就是一个根节点，因此每次访问根节点的时候，我们可以用pre标记为该节点，回到上一个根节点时，检查一下，如果pre确实是它的右子节点，哦那正好，刚刚已经访问过了，我现在可以安心访问这个根了。\n1//如果该元素的右边没有或是已经访问过 2if(node-\u0026gt;right == NULL || node-\u0026gt;right == pre){ 3 //访问中间的节点 4 res.push_back(node-\u0026gt;val); 5 //且记录为访问过了 6 pre = node; 7} 具体做法：\nstep 1：开辟一个辅助栈，用于记录要访问的子节点，开辟一个前序指针pre。 step 2：从根节点开始，每次优先进入每棵的子树的最左边一个节点，我们将其不断加入栈中，用来保存父问题。 step 3：弹出一个栈元素，看成该子树的根，判断这个根的右边有没有节点或是有没有被访问过，如果没有右节点或是被访问过了，可以访问这个根，并将前序节点标记为这个根。 step 4：如果没有被访问，那这个根必须入栈，进入右子树继续访问，只有右子树结束了回到这里才能继续访问根。 图示：\n1 vector\u0026lt;int\u0026gt; postorderTraversal(TreeNode* root) { 2 vector\u0026lt;int\u0026gt;res; 3 stack\u0026lt;TreeNode*\u0026gt;help; 4 TreeNode*pre = nullptr; 5 while(root||!help.empty()){ 6 //每次先找到最左边的节点 7 while(root){ 8 help.push(root); 9 root = root-\u0026gt;left; 10 } 11 //弹出栈顶 12 TreeNode*temp = help.top(); 13 help.pop(); 14 //如果该元素的右边没有或是已经访问过 15 if(temp-\u0026gt;right==nullptr||temp-\u0026gt;right==pre){ 16 //访问中间的节点 17 res.push_back(temp-\u0026gt;val); 18 //且记录为访问过了 19 pre = temp; 20 }else{ 21 //该节点入栈 22 help.push(temp); 23 //先访问右边 24 root = temp-\u0026gt;right; 25 } 26 } 27 return res; 28 } 求二叉树的层序遍历 描述 给定一个二叉树，返回该二叉树层序遍历的结果，（从左到右，一层一层地遍历） 例如： 给定的二叉树是{3,9,20,#,#,15,7},\n该二叉树层序遍历的结果是\n[[3], [9,20], [15,7]]\n数据范围：二叉树的节点数满足 $1 \\le n \\le 10^5$\n解析 主要思路：广度优先，一层一层的遍历二叉树， 1、遍历到一个节点，将左右个孩子加入队列； 2、一次遍历二叉树的一层； 3、怎么确定能遍历一层：每次遍历队列，先记录队列的大小size，出队size次，这些值即为一层，存入res数组，并通过1、2将下一层的节点存入队列；\n1 vector\u0026lt;vector\u0026lt;int\u0026gt; \u0026gt; levelOrder(TreeNode* root) { 2 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res; 3 if(root==nullptr){ 4 return res; 5 } 6 queue\u0026lt;TreeNode*\u0026gt; q; 7 q.push(root); 8 while(!q.empty()){ 9 // 对每一层都进行处理 10 int size = q.size(); 11 vector\u0026lt;int\u0026gt; levelVals; 12 // 这一层右多少个结点 13 while(size--){ 14 15 TreeNode* cur = q.front(); 16 q.pop(); 17 levelVals.push_back(cur-\u0026gt;val); 18 // 将这层的孩子结点加入队列 19 if(cur-\u0026gt;left){ 20 q.push(cur-\u0026gt;left); 21 } 22 if(cur-\u0026gt;right){ 23 q.push(cur-\u0026gt;right); 24 } 25 } 26 // 这层的结果 27 res.push_back(levelVals); 28 } 29 return res; 30 } 按之字形顺序打印二叉树 描述 给定一个二叉树，返回该二叉树的之字形层序遍历，（第一层从左向右，下一层从右向左，一直这样交替）\n数据范围：0≤n≤1500,树上每个节点的val满足 |val| \u0026lt;= 1500\n要求：空间复杂度：O(n)，时间复杂度：O(n)\n解析 如果我们不按照之字形打印二叉树，只是按照层遍历，那么就成了层序遍历。在层序遍历中都是从左到右遍历，之字形是要相反的，先放进“队列”里面的要最后出来。如下图\n可以用两个栈交替保存“父节点和子节点”。\n1vector\u0026lt;vector\u0026lt;int\u0026gt; \u0026gt; Print(TreeNode* pRoot) { 2 TreeNode* head = pRoot; 3 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res; 4 if(head==nullptr){ 5 return res; 6 } 7 // 交替保存 父亲节点和子节点 8 stack\u0026lt;TreeNode*\u0026gt; cen; 9 stack\u0026lt;TreeNode*\u0026gt; children; 10 cen.push(head); 11 // 如果有一个不为空就可以执行 12 while(!cen.empty() || !children.empty()){ 13 vector\u0026lt;int\u0026gt; temp; 14 // 父亲节点有 这里的父亲节点和子节点是相对的，由于这里一次可以遍历两层，所以第一层就是父亲节点， 15 while(!cen.empty()){ 16 TreeNode*node = cen.top(); 17 temp.push_back(node-\u0026gt;val); 18 // 父亲节点，是从左到右 要先从左孩子判断 19 if(node-\u0026gt;left){ 20 children.push(node-\u0026gt;left); 21 } 22 if(node-\u0026gt;right){ 23 children.push(node-\u0026gt;right); 24 } 25 cen.pop(); 26 } 27 if(temp.size()){ 28 res.push_back(temp); 29 } 30 temp.clear(); 31 // 孩子不为空就是 32 while(!children.empty()){ 33 TreeNode*node = children.top(); 34 temp.push_back(node-\u0026gt;val); 35 // 偶数层是从右向左遍历的，要先开始判断右边的。 36 if(node-\u0026gt;right){ 37 cen.push(node-\u0026gt;right); 38 } 39 if(node-\u0026gt;left){ 40 cen.push(node-\u0026gt;left); 41 } 42 children.pop(); 43 } 44 if(temp.size()){ 45 res.push_back(temp); 46 } 47 } 48 return res; 49 } 总结 刷题时间 时间 题目 5-3 前序遍历 5-3 中序遍历 5-3 后序遍历 5-4 层序遍历 6-22 按之字形打印二叉树 总结 前序遍历要先遍历中间结点，之后遍历左孩子，再遍历右孩子，但是要先在栈中放入右孩子，再放入左孩子。 中序遍历是要先遍历左孩子，之后遍历中间结点，再遍历右孩子。要找到最左边的孩子，就要深度优先可是进行搜索(root = root-\u0026gt;left),之后访问中间结点。对访问的中间结点的右孩子也执行这个过程。 后序遍历看解析 层序遍历是要记录当前层有多少个结点，对这些结点进行遍历。 按之字形打印是交替打印的，要考虑好两层的打印方式 ","date":"2022-05-03","img":"","permalink":"/posts/e62967f0/","series":["牛客TOP101"],"tags":["算法","牛客TOP101"],"title":"Newcoder Top 101 二叉树"},{"categories":["计算机网络"],"content":"介绍SSL/TLS的原理及其加密方式。\n我猜你们中的许多人都知道 HTTPS，有些人可能已经为你的 web 服务器设置了 SSL/TLS。但是，有多少人深刻理解 SSL/TLS 是如何工作的呢？\n你知道吗:\nTLS 握手过程中到底发生了什么？\nTLS 使用哪些加密算法来保护数据？\n客户机和服务器如何交换密钥？\nDiffie-Hellman Ephemeral临时密钥交换是如何工作的？\n我们为何需要数字证书？\n为什么需要由证书颁发机构签署？\n什么是数字签名? 如何签名和验证？\n完备的前向安全性是什么意思？\nAEAD, MAC, HKDF, 0-RTT如何运作？\n什么是Elliptic-Curve加密体制？\n与 TLS 1.2相比，TLS 1.3有什么新特性？\n有很多问题，我不想只触及表面。因此，这将是一篇非常详尽的文章，告诉您关于 SSL/TLS 的一切，SSL/TLS 是构建互联网安全性的一个极其重要的构件。\n什么是 SSL/TLS? SSL(Secure Socket Layer)代表安全套接字层，它是 TLS 的前身。\nTLS(Transport Layer Security)是传输层安全的简称，它是一个安全协议安全协议，通过计算机网络提供安全通信。\nSSL/TLS的历史 SSL 和 TLS 的一些历史 SSL 最初是由 Netscape 开发的，1995年第一次发布了2.0版本 由于一些严重的安全缺陷，SSL 版本1.0从未公开发布。 1996年，SSL 版本3.0作为协议的重新设计发布。 3年后，IETF 在 RFC 2246中首次定义了 TLS 1.0，作为 SSL Version 3.0的升级 2006年，我们花了7年时间将其升级到 TLS 1.1 1.2紧随其后在2008年发布。 最终，经过10年的努力，我们在2018年得到了一个巨大的改进: TLS 1.3。 目前哪个 SSL/TLS 版本仍然存在 2.0在2011年就被弃用了 3.0在2015年就被否决了 最近，在2020年3月，TLS 1.0和 TLS 1.1也消失了。这意味着只有 TLS 1.2和1.3仍处于活动状态。 TLS被用在哪里 首先，它在网络上被广泛使用。所有你用 HTTPS 访问的网站都是用 TLS 保护的，或者我们常说的 HTTP over TLS。\n类似地，使用 SMTPS 协议的电子邮件实际上是 SMTP 和 TLS。\n然后 FTPS 的安全文件传输协议也是 FTP 加上 TLS。\n为什么我们需要TLS 因为 TLS 给了我们三样东西:\n认证 TLS 验证通信方的身份，通常是客户端和服务器。 在非对称加密的帮助下，TLS 确保我们访问的是真实的网站，而不是假的网站。 加密 TLS 通过使用对称加密算法对交换的数据进行加密来保护数据不受未经授权的访问。 完整性 在传输过程中，TLS 可以通过检查消息代码来识别数据的任何变化，我们稍后将了解这一点。 TLS是怎么工作的？ 基本上，TLS 由两个阶段或两个协议组成:\n握手协议 在这个阶段，客户机和服务器将:\n协商协议版本 选择加密算法(或密码组合) 使用非对称密码系统进行身份验证 建立一个共享密钥，该密钥将在下一阶段用于对称加密。 因此，握手的主要目的是为了进行身份验证和密钥交换。\n记录协议 在这个阶段\n所有发出的消息都将使用在握手中建立的共享密钥进行加密。 然后将加密的消息传送到另一端。 他们将验证，在传输过程中看看是否有任何修改。 如果没有，则将使用相同的对称密钥解密消息。 因此，我们将实现该记录协议的保密性和完整性。\n由于此阶段的加密数据量很大，因此通常称为批量加密。\n为什么 TLS 同时使用对称和非对称加密 为什么不把一个用于所有目的呢？\n很容易看出，对称加密不能提供身份验证。由于客户机和服务器只有一个秘密密钥，因此它们不知道对方的任何信息以供验证。更不用说他们如何在不向公众泄露密钥的情况下找到相同的密钥是很困难的。\n那么非对称密码学呢？听起来是个不错的候选人。不幸的是，它比对称加密慢得多。我说的“很多”是指从100倍甚至10000倍慢下来。所以它显然不适合大容量加密。\n对称加密 好了，现在让我们学习更多关于对称密码学的知识。我想您已经了解了基础知识。\n首先，爱丽丝有一条纯文本信息，她想发给鲍勃，但不想让公共区域的任何人看到。 所以她用他们之前共享的密钥加密了信息。然后她通过公共互联网将加密的信息发送给鲍勃。 在收到加密消息后，Bob 将很容易地使用相同的秘密密钥对其进行解密。 由于使用相同的密钥进行加密和解密，所以它是对称的，因此我们称之为对称密码术。 现在可能有一个黑客哈里，他可以在公共网络上捕捉他们交换的信息。然而，消息已经被加密了，而 Harry 没有秘密密钥，所以他无法解密。 但是他仍然可以改变它！\nBit-flipping攻击 有一种技术叫做位翻转攻击，它是这样工作的:\n假设这次爱丽丝不是在和鲍勃说话，而是在和她的网上银行说话。她想寄100美元给某人。该信息用一个秘密密钥加密，并通过互联网发送到银行。\n现在哈利捕捉到了加密的信息。虽然他不能解密，但他可以将其中的一些比特从1翻转到0，从0翻转到1，然后将修改后的消息转发给银行。\n现在当银行解密它时，他们会得到一个不同的纯文本内容。在这种情况下，它变成了900美元而不是100美元。\n所以这是非常危险的，这就是为什么我们需要确保加密的信息在传输过程中没有被改变。\n但是怎么做呢？\n认证加密Authenticated Encryption (AE) 一种方法是使用身份验证加密。这个想法不仅要加密，还要验证加密的消息。\nThe first step is to encrypt Alice 的明文消息通过一个对称加密算法，如 AES-256-GCM 或 cha20。\n这种加密算法还接受一个共享的密钥和一个随机的 nonce（Number once，一个只被使用一次的任意或非重复的随机数值），或者一个初始向量密码(IV，Initialization Vector)作为输入。它会返回加密的消息。\nThe second step is to authenticate 加密的消息、密钥和 nonce 成为 MAC 算法的输入，如果使用 AES-256-GCM，则为 GMAC; 如果使用 cha20加密算法，则为 POLY1305。\n这个 MAC 算法就像一个密码HASH函数，它的输出是一个 MAC（message authentication code消息的认证码）。\n现在，这个 MAC 将与加密的消息一起被标记，最终的结果将发送给 Bob。正因为如此，我们有时把这个 MAC 称为身份验证标记。\nAdd some Associated Data (AD) 在 TLS 1.3中，除了加密消息之外，我们还希望对一些相关数据进行身份验证，例如: 地址、端口、协议版本或序列号。此信息未经加密，通信双方都知道。\n所以相关的数据也是 MAC 算法的输入。正因为如此，整个过程被称为带有相关数据的认证加密，或简称为 AEAD。\nDecryption and MAC verification 现在让我们看看 Bob 如何检查加密消息在传输过程中是否被更改。\n这只是一个简单的反向过程，从加密的 MAC 消息开始，我们从加密的消息中取消标记 MAC。\n然后将加密的消息与共享密钥和现有密钥一起送到 MAC 算法。注意，这与加密过程中使用的 nonce 是相同的。通常，nonce 在发送到接收方之前被填充到加密的消息中。\n相关的数据也将进入 MAC 算法，并且它的输出将是另一个 MAC。\n现在 Bob 可以简单地比较2个 MAC 值。如果他们是不同的，那么他知道加密的信息已经被更改。否则，他可以安全地解密消息，并使用它的信心，它是相同的明文信息，爱丽丝发送。\nSecret key exchange 但是，有一个问题: Bob 和 Alice 如何在不泄露给公众的情况下彼此共享密钥？\n答案是: 他们需要使用不对称或者公开密钥加密。具体地说，他们可以使用 Diffie-Hellman Ephemeral，或者椭圆曲线 Diffie-Hellman Ephemeral。\nDiffie-Hellman key exchange 首先，Alice 和 Bobs 都同意两个数字: 基数 g 和模数 p。这些数字众所周知的。\n然后他们每个人秘密地选择一个私人号码。Alice 的私钥是 a ，Bob 的私钥是 b 。\n然后 Alice 计算她的公钥并发送给 Bob\n1A = (g^a) mod p 类似地，Bob 计算他的公钥并将其发送给 Alice\n1B = (g^b) mod p 然后爱丽丝将接收到鲍勃的公钥 b，而鲍勃将接收爱丽丝的公钥 a。\n现在奇迹发生了！\n爱丽丝计算:\n1S = (B^a) mod p Bob计算：\n1S = (A^b) mod p 这两个值神奇地等于同一个数 s。\n为什么? 我们来算算\n1(B^a) mod p = (g^b)^a mod p = ( g^(b*a) ) mod p 2(A^b) mod p = (g^a)^b mod p = ( g^(a*b) ) mod p 所以爱丽丝和鲍勃想出了同样的密码 s，而没有泄露给公众\nKey Derivation Function(秘钥导出函数) - KDF 每种加密算法可能需要不同长度的密钥。因此，为了创建密钥，Alice 和 Bob 必须将 s 放到相同的密钥导出函数，并且输出将是一个所需长度的共享密钥。\n在 TLS 1.3中，我们使用了一个基于 hmac 的密钥导出函数，这就是为什么 HKDF 这个名字的原因\n一般而言，KDF采用以下输入:\n输入键材料(或 IKM)。在我们的例子中，IKM 是数字 s。 我们希望输出键有多长，比如128位。 一个密码杂凑函数，例如 HMAC-SHA256。 可以选择一些特定于上下文或应用程序的信息 一种可选的盐。 有了所有这些输入，KDF 将生成一个所需长度的密钥。\nTrapdoor function（陷门函数） 现在让我们回到Diffie-Hellman密钥交换。\n我们知道公众知道 p，g，A，B，这意味着黑客 Harry 也可以访问这些数字。\n我们可能会想: 这个密钥交换机制安全吗？或者给定 p，g，A，B，Harry 能算出秘密数字: a，b，s 吗？\n幸运的是，如果我们为 p，g，a，b 选择好的值，这些函数就会成为陷门。\n例如:\n选择 p 作为2048位素数, 选择 g 作为模 p 的基本根, 然后选择 a，b 作为256位随机整数。 一个陷门函数基本上意味着一种方法很容易计算，而另一种方法很难计算:\n给定 p，g，a，很容易计算A 。 但是给定 p，g，A，很难计算a。 显而易见，使用 o (log (a))时间复杂度可以非常快地计算 A。这是一个众所周知的模幂运算问题。\n计算一个a要困难得多。这是一个离散对数的问题，需要我们现在这一代的计算机花费很长的时间来解决。\n所以我们至少现在是安全的，或者直到下一代强大的量子计算机投入使用。\n然而，就目前而言，“需要很长时间才能解决”并不意味着无法解决，对吗？\nStatic or Ephemeral（临时） key? 如果 Alice 和 Bob 对他们通信的每个会话使用相同的私钥 a 和 b，那么会发生的是，Harry 可以记录所有这些会话，并从会话1开始求解 a。\n尽管他需要很长时间来解决这个问题，但是我们假设在第 n 个会话之后，他得到了正确的 a。现在他可以用它来计算秘密数字 s，这样，他就能够解密所有的对话录音。\n这听起来可怕吗? 我们如何预防它？\n答案是临时的钥匙。顾名思义，我们使用不同的私钥或每个会话。因此，即使 Harry 能够在一个会话中解决这个密钥，他也不能在其他会话中使用它。\n这在 TLS 中被称为完备的前向安全性。\n所以现在你明白了 Diffie-Hellman Ephemeral 的意思，它只是 Diffie-Hellman 的短命音调。\nElliptic-Curve Diffie-Hellman Ephemeral如何？\nElliptic-Curve(椭圆曲线) Cryptography 椭圆曲线密码体制(ECC)是一种非对称密码体制，其算法相似，但使用了不同的陷门函数。\n这个陷门函数是基于椭圆曲线的代数结构，这就是为什么这个名字。\n椭圆曲线密码学的一个惊人的价值是: 它需要更小的密钥来提供同等的安全级别。你可以在这个与 RSA 的比较中看到它。\n美国国家安全局(NSA)过去用 ECC 384位密钥来保护他们的最高机密，这种密钥用 rsa-7680位密钥提供同样的安全级别。\n听起来很棒，对吧？\n然而，量子计算攻击的目标更容易对付椭圆曲线密码学。肖尔的算法可以用比破解 RSA 更少的量子资源在假想的量子计算机上破解 ECC。\n这种强大的量子计算机可能需要几十年的时间才能真正建成并投入使用。但是我们为此准备好了什么吗？有没有什么量子抵抗算法？\n是的，有超分子同源迪菲－赫尔曼密钥交换算法，这也是基于椭圆曲线密码学的。\n但那是另一回事了。\n非对称加密 现在让我们回到非对称密码学上来! 这是一项了不起的技术，有着广泛的应用。\n我们已经研究了它的一个应用，即用于对称密钥交换的 Diffie-Hellman ephemal 和椭圆曲线 Diffie-Hellman ephemal。\n实际上，RSA 算法过去也用于密钥交换，但在 TLS 1.3中由于各种攻击和没有前向保密能力而被删除。\n非对称加密法也用于加密系统。以下是非对称加密算法:\n具有最佳非对称加密填充(RSA-oaep)的 RSA。\nRSA 与公钥加密标准1(RSA-pkcs1)的最新版本2.2\nElgamal 加密算法。\n最后，非对称密码学的另一个重要特征是用于数字签名，TLS 广泛用于身份验证。\nTLS 中使用的一些流行的数字签名算法如下:\n基于概率签名的 RSA 方案。\n椭圆曲线数字签名算法。\nEdwards 曲线数字签名算法。\n我们将很快学习数字签名，但在此之前，让我们学习非对称加密系统是如何工作的。\nAsymmetric Encryption 如果使用公钥进行加密，就只能用私钥解密。如果用私钥加密，就只能用公钥解密。\n与对称加密类似，Alice 有一条明文消息要发送给 Bob。\n但是这一次，没有共享的密钥。相反，Alice 使用 Bob 的公钥对消息进行加密，并将加密的消息发送给 Bob。\n当 Bob 收到消息时，他使用自己的私钥对其进行解密。\n虽然公钥和私钥是不同的，但它们仍然通过一些活门函数连接，就像我们在 Diffie-Hellman 算法中看到的那样。\n其思想是: 密钥成对存在，只有同一对的私钥才能解密使用其公钥加密的消息。\n因此，即使黑客 Harry 可以访问 Alice 的加密消息和 Bob 的公钥，他也不能使用该公钥解密消息。\nPublic key sharing 公开密钥共享非常简单。鲍勃只需通过公共互联网直接将密钥发送给爱丽丝，而不用担心密钥可以用来解密任何消息。\n密钥是公开的，因此任何人都可以使用它来加密只有 Bob 能够读取的消息，即使他们之前从未交谈过。这真是令人兴奋，不是吗？\n然而，生活并不是那么简单！\n中间人交换key 尽管我们知道 Harry 不能用 Bob 的公钥解密消息，但他仍然可以干扰公钥共享，并用自己的公钥替换 Bob 的公钥。\n现在，当 Alice 收到密钥时，她仍然认为那是 Bob 的公钥，但实际上那是 Harry 的。所以如果 Alice 用这个密钥加密她的消息，Harry 就能用他的私钥解密它。\n之所以会发生这种情况，是因为钥匙只是一个数字，没有身份信息告诉我们钥匙的主人是谁。\n那么我们能做些什么呢？显然，我们应该把密钥和一些身份信息放在一起。这只不过是一个数字证书。\n数字证书 所以 Bob 将他的钥匙放在证书中，证书上有他的名字和其他身份信息。这张证书在现实世界中起到了护照的作用。\n但是我们怎么知道真的是 Bob 拥有那张证书呢？是什么阻止了哈里用鲍勃的名字但是用哈里的公共钥匙制作一个假证书？\n嗯，就像在现实世界中一样，护照必须经过身份验证后由护照当局签发。在数字世界中，证书必须由证书颁发机构进行验证和签名。\n该证书颁发机构和护照颁发机构是值得信赖的第三方，帮助我们防止伪造护照和数字证书。\n证书签发 证书签名过程如下:\nBob 有一对公钥和私钥。 在第一步中，他创建一个证书签名请求，或 CSR。这个 CSR 包含他的公钥和一些身份信息，例如他的名字、组织和电子邮件。 然后，第二步，他用自己的私钥签署 CSR，并将其发送给证书颁发机构。 证书颁发机构将在证书中验证 Bob 的身份。如果有必要，他们可以联系他要求更多的证据。 然后，他们使用证书中 Bob 的公钥来验证他的签名。这是为了确保 Bob 真正拥有与证书中的公钥配对的私钥。 如果所有内容都有效，CA 将使用自己的私钥对证书进行签名，并将其发送回 Bob。 证书共享 现在，Bob 将与 Alice 共享这个包含他的公钥的证书，而不是像以前那样只发送公钥。\n在接收到证书后，Alice 可以使用证书颁发机构的公钥轻松地验证其真实性。\n因此，Harry 再也不能用他的密钥替换 Bob 的公钥，因为他没有 CA 的私钥来签署假证书。\n请注意，这仅仅是因为我们都信任证书颁发机构。如果 CA 不值得信任，例如，如果他们给了 Harry 他们的私钥，那么我们就有大麻烦了！\n证书颁发机构-信任链 在现实中,有一个证书authori链\n在最高层是一个根证书认证机构，他们签署自己的认证证书，也签署他们的下属的认证证书，\n这是一个中级认证机构。该机构可以签署其他中间机构的证书，也可以签署最终实体证书(或叶证书)。\n每个证书将引用回到其更高级别的权威的证书，直到根目录。\n你的操作系统和浏览器会存储一系列受信任的根证书证书。这样他们就可以很容易地验证所有证书的真实性。\n数字签名 我们已经讨论了很多关于签署数字签名的问题，所以让我们来看看它是如何工作的！\n签署文件:\n签名者首先需要对其进行hash处理。 然后使用签名者的私钥对散列值进行加密。 结果就是数字签名。 然后这个签名将附在原始文件上。 这就是签名过程。现在我们如何验证签名是否有效？\n好吧，我们只是做一个相反的过程:\n首先我们将签名从文档中分离出来\n使用签名者的公钥对其进行解密，以获得哈希值。\n然后，我们使用签名过程中使用的相同散列算法对文档进行散列。\n结果是另一个散列值。\n然后我们只需要比较两个散列值。\n如果它们是相同的，那么签名就是有效的。\nTLS 1.3 handshake protocol 好了，现在我们已经掌握了所有的知识，让我们仔细看看它们在 TLS 握手协议中是如何使用的。\nFull handshake TLS 1.3完整的握手以客户端发送给服务器的 hello 消息开始。实际上，这条信息包含了很多东西，但在这里我只列出一些重要的信息:\n首先，客户端支持的协议版本列表。\n然后一个支持 AEAD 的对称密码套件列表。在这种情况下，有两个选项: AES-256-GCM 或 cha20-poly1305\n在此之后，还有一个受支持的关键交换组列表。例如，此客户端同时支持有限域 Diffie-Hellman 和椭圆曲线 Diffie-Hellman 。\n这就是为什么 client 也分享它的2个公钥，1个是 Diffie-Hellman 的，另一个是椭圆曲线 Diffie-Hellman 的。这样，无论选择什么算法，服务器都能够计算共享密钥。\n此消息中的最后一个字段客户端发送的是它支持的签名算法的列表。这是让服务器选择它应该使用哪个算法来签署整个握手。稍后我们将看到它是如何工作的。\n在收到客户端 hello 消息后，服务器还会发回 hello 消息，其中包含:\n选定的协议版本 TLS 1.3\n选定的密码套件: AES-256-GCM\n选定的密钥交换方法: Diffie-Hellman Ephemeral\n以及所选方法的服务器公钥。\n下一个字段是对客户端证书的请求，这是可选的，只有当服务器希望通过其证书对客户端进行身份验证时才会发送这个请求。\n通常在一个 HTTPS 网站上，只有服务器端需要将其证书发送到客户端。这是在这个信息的下一个字段中发送的。\n下一个字段是 certificate verify，它实际上是到目前为止整个握手的签名。以下是如何生成它的: 从握手开始到证书请求的整个数据称为握手上下文。我们将此上下文与服务器的证书连接起来，对其进行哈希处理，并使用客户机支持的签名算法中的1个用服务器的私钥对哈希值进行签名。\n以类似的方式，服务器完成是通过连接握手上下文、证书和证书验证、散列，并将散列值通过所选密码组的 MAC 算法来生成的。结果就是整个握手过程的 MAC。\n在这里，服务器证书、证书验证和服务器完成被称为身份验证消息，因为它们用于对服务器进行身份验证。有了整个握手的签名和 MAC，TLS 1.3可以安全地抵御几种类型的中间人降级攻击。\n现在，当客户端收到来自服务器的 hello 消息后，它将使用root权限验证服务器的证书，并检查整个握手过程的签名和 MAC，以确保它没有被篡改。\n如果一切正常，那么客户端就会在整个握手过程中用 MAC 发送完成消息，并且在服务器请求的情况下，还可以选择客户端的证书和证书进行验证。\n这就是整个 TLS 握手的流程。\n简短的握手和PSK恢复 为了提高性能，客户机和服务器并不总是进行这种完整的握手。有时，他们使用预先按下的按键恢复来进行简短的握手。\n其思想是: 在上一次握手之后，客户机和服务器已经互相认识，因此它们不需要再次验证。\n因此，服务器可以向客户端发送一个或多个会话票据，这些票据可以在下一次握手中用作预共享密钥(PSK)标识。它伴随着一张票的生命周期以及其他一些信息。\n现在，在下一次握手中，客户端将发送一个简单的 hello 消息，其中包含:\n从前一次握手中获得的 PSK 身份(或门票)列表\n一种 PSK 密钥交换模式，可以是只 PSK，也可以是与 Diffie-Hellman 的 PSK。\n如果使用 Diffie-Hellman 模式的 PSK，那么客户端还需要共享 Diffie-Hellman 公钥。这将提供完备的前向安全性服务，并允许服务器在需要时回到完整的握手。\n当服务器收到这个客户端 hello 消息时，它会发回 hello:\n选定的预共享密钥标识\n服务器的可选 Diffie-Hellman 公钥\n和服务器完成就像在完整的握手。\n最后，客户端返回其 Finish，这就是 PSK 恢复的结束。\n正如您所看到的，在这种简短的握手中，客户机和服务器之间没有证书身份验证。\n这也为零往返时间(0-RTT)数据打开了一个机会，这意味着客户机不需要等到握手完成后才将其第一个应用程序数据发送到服务器。\n0-RTT handshake 在0-rtt 中，客户机将应用程序数据与客户机 hello 消息一起发送。此数据使用从票据列表中的第一个 PSK 中派生的密钥进行加密。\n它还增加了另外一个字段: 早期数据指示，告诉服务器有早期应用程序数据被发送。\n如果服务器接受这个0-rtt 请求，它将像正常的 PSK 恢复一样发送回服务器 hello，还可以选择发送一些应用程序数据。\n客户端将以一个包含 MAC 的消息和一个早期数据结束指示器结束。这就是 TLS 1.3中0往返时间的工作原理。\n它的优点是减少了1个往返时间的延迟。但是反对派正在挑起重放攻击的潜在威胁。这意味着，黑客可以将相同的加密的0-rtt 请求多次复制并发送到服务器。为了避免这种情况，服务器应用程序的实现方式必须能够弹性地抵御重复请求。\nCompare TLS 1.3 vs TLS 1.2 在我们结束之前，让我们对 TLS 1.3和 TLS 1.2做一个快速比较，看看有什么新的东西！\n1.3具有更安全的密钥交换机制，去除了易受攻击的 RSA 和其他静态密钥交换方法，只保留了 Diffie-Hellman 或者椭圆曲线 Diffie-Hellman 的临时密钥交换方法，从而实现了完备的前向安全性密钥交换。\nTLS 1.3握手至少比 TLS 1.2握手快1个来回。\nTLS 1.3中的对称加密更加安全，因为 AEAD 密码套件是强制的，而且它还从列表中删除了一些弱算法，如块密码模式(CBC)、 rc4或三重 DES。\nTLS 1.3中的密码套件也更简单，因为它只包含 AEAD 算法和哈希算法。密钥交换和签名算法被移动到不同的字段。在 TLS 1.2中，它们被合并到密码套件中。这使得推荐的密码组合数量变得太大，如果我没有记错的话，TLS 1.2中有37个选项。而在 TLS 1.3中，只有5个。\n接下来，TLS 1.3也给了我们更强有力的信号，因为它标志着整个握手过程，而不是像 TLS 1.2那样仅仅覆盖其中的某些部分。\n最后，椭圆曲线密码体制在 TLS 1.3中得到了广泛的关注，增加了一些更好的曲线算法，如 edward 曲线数字签名算法，该算法在不牺牲安全性的前提下速度更快。\n参考 A complete overview of SSL/TLS and its cryptographic system - YouTube\n","date":"2022-05-02","img":"","permalink":"/posts/7955ce21/","series":[],"tags":["SSL","TSL"],"title":"SSL TLS的完整概述及其加密方式"},{"categories":["算法"],"content":"牛客算法必刷TOP101，包含：链表、二分查找/排序、二叉树、堆/栈/队列、哈希、递归/回溯、动态规划、字符串、双指针、贪心算法、模拟总共101道题。\n此部分是二分查找/排序专题。\n牛客网 (nowcoder.com)\n二分查找-I 描述 请实现无重复数字的升序数组的二分查找\n给定一个 元素升序的、无重复数字的整型数组 nums 和一个目标值 target ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标（下标从 0 开始），否则返回 -1\n数据范围：$0 \\le len(nums) \\le 2\\times10^5$ ， 数组中任意值满足 $|val| \\le 10^9$\n进阶：时间复杂度 O(\\log n)O(logn) ，空间复杂度 O(1)O(1)\n示例1 输入：\n1[-1,0,3,4,6,10,13,14],13 返回值：\n16 说明：\n113 出现在nums中并且下标为 6 示例2 输入：\n1[],3 返回值：\n1-1 说明：\n1nums为空，返回-1 示例3 输入：\n1[-1,0,3,4,6,10,13,14],2 返回值：\n1-1 说明：\n12 不存在nums中因此返回 -1 解析 解析1-二分查找 对于有序的列表要找某个元素，二分查找是最快的一个。如果是升序的，从中间开始，当前的元素（中间）的值\u0026gt;目标值，就说明当前的值大了，需要在小的一部分找。修改右边的指针为mid-1,如果当前的元素\u0026lt;目标值，那么就要修改左边指针为mid+1，如果相等，则返回当前下标。\n1 int search(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { 2 int left = 0; 3 int right = nums.size()-1; 4 while(left\u0026lt;=right){ 5 int mid = (left+right)\u0026gt;\u0026gt;1; 6 if(nums[mid]==target){ 7 return mid; 8 }else if(nums[mid]\u0026gt;target){ 9 right = mid-1; 10 }else{ 11 left = mid+1; 12 } 13 } 14 return -1; 15 } 二维数组中的查找 描述 在一个二维数组array中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n[\n[1,2,8,9], [2,4,9,12], [4,7,10,13], [6,8,11,15]\n]\n给定 target = 7，返回 true。\n给定 target = 3，返回 false。\n数据范围：矩阵的长宽满足$ 0 \\le n,m \\le 500$ ， 矩阵中的值满足 $0 \\le val \\le 10^9$ 进阶：空间复杂度 O(1) ，时间复杂度 O(n+m)\n示例1 输入：\n17,[[1,2,8,9],[2,4,9,12],[4,7,10,13],[6,8,11,15]] 返回值：\n1true 说明：\n1存在7，返回true 示例2 输入：\n11,[[2]] 返回值：\n1false 示例3 输入：\n13,[[1,2,8,9],[2,4,9,12],[4,7,10,13],[6,8,11,15]] 返回值：\n1false 说明：\n1不存在3，返回false 解析 解析1-从[0][0]开始二分查找 从[0][0]开始找目标值要处理这种情况，当前的值比目标值大，改后退还是如何前进。这样思考的情况太多，所以删除，\n解析2-从数组左下角开始查找。 从左下角开始找起可以避免当前的值比目标值大了之后处理麻烦的情况。当前的值比目标值小，列索引++，如果当前值比目标大，行\u0026ndash;。\n如果越界了都没找到，就是没有。\n1bool Find(int target, vector\u0026lt;vector\u0026lt;int\u0026gt; \u0026gt; array) { 2 int hang = array.size()-1; 3 int lies = array[0].size(); 4 int lie = 0; 5 while(lie\u0026lt;lies\u0026amp;\u0026amp;hang\u0026gt;-1){ 6 if(array[hang][lie]==target){ 7 return true; 8 }else if(array[hang][lie]\u0026gt;target){ 9 hang--; 10 }else{ 11 lie++; 12 } 13 } 14 return false; 15 } 寻找峰值 描述 给定一个长度为n的数组nums，请你找到峰值并返回其索引。数组可能包含多个峰值，在这种情况下，返回任何一个所在位置即可。\n1.峰值元素是指其值严格大于左右相邻值的元素。严格大于即不能有等于\n2.假设 nums[-1] = nums[n] = $-\\infty$\n3.对于所有有效的 i 都有 nums[i] != nums[i + 1]\n4.你可以使用O(logN)的时间复杂度实现此问题吗？\n数据范围：\n$1 \\le nums.length \\le 2\\times 10^5$\n$-2^{31}\u0026lt;= nums[i] \u0026lt;= 2^{31} - 1$\n如输入[2,4,1,2,7,8,4]时，会形成两个山峰，一个是索引为1，峰值为4的山峰，另一个是索引为5，峰值为8的山峰，如下图所示：\n示例1 输入：\n1[2,4,1,2,7,8,4] 返回值：\n11 说明：\n14和8都是峰值元素，返回4的索引1或者8的索引5都可以 示例2 输入：\n1[1,2,3,1] 返回值：\n12 说明：\n13 是峰值元素，返回其索引 2 解析 解析1-寻找最大值 由于是要找峰值，那么也就是极大值，只要找到最大值那么他一定是极大值。\n1int findPeakElement(vector\u0026lt;int\u0026gt;\u0026amp; nums) { 2 int index = 0; 3 for(int i = 1;i\u0026lt;nums.size();i++){ 4 if(nums[i]\u0026gt;nums[index]){ 5 index = i; 6 } 7 8 } 9 return index; 10 } 解析2-二分查找 由于题目给出的条件，两边(inde = -1,index = nums.size())都是最小值。只有当前序列是递增的时候才会出现山峰，如果当前序列是递减的，那么他可能就不会有山峰。\n1 int findPeakElement(vector\u0026lt;int\u0026gt;\u0026amp; nums) { 2 int left = 0; 3 int right = nums.size()-1; 4 while(left\u0026lt;right){ 5 int mid = (left+right)\u0026gt;\u0026gt;1; 6 if(nums[mid]\u0026gt;nums[mid+1]){ 7 right = mid; 8 }else{ 9 left = mid+1; 10 } 11 } 12 return right; 13 } 旋转数组的最小数字 描述 有一个长度为 n 的非降序数组，比如[1,2,3,4,5]，将它进行旋转，即把一个数组最开始的若干个元素搬到数组的末尾，变成一个旋转数组，比如变成了[3,4,5,1,2]，或者[4,5,1,2,3]这样的。请问，给定这样一个旋转数组，求数组中的最小值。\n数据范围：$1 \\le n \\le 10000$，数组中任意元素的值: $0 \\le val \\le 10000$\n要求：空间复杂度：O(1) ，时间复杂度：O(logn)\n示例1 输入：\n1[3,4,5,1,2] 返回值：\n11 示例2 输入：\n1[3,100,200,3] 返回值：\n13 解析 解析1-遍历 遍历一遍找到最小值就行。\n解析2-二分 查看比较中间的值和right的值\nmid的值大于right值，就说明截断的值在右边，下一次从mid+1到right搜索就好了 mid的值小于right的值，截断的值在左边，就从left到right搜索 当这两个值相等时候，不能判断在哪里，所以就要减少right进行搜索 1int minNumberInRotateArray(vector\u0026lt;int\u0026gt; rotateArray) { 2 if(rotateArray.size()==0){ 3 return 0; 4 } 5 int left = 0; 6 int right = rotateArray.size()-1; 7 while(left\u0026lt;right){ 8 int mid = (left+right)\u0026gt;\u0026gt;1; 9 if(rotateArray[mid]\u0026gt;rotateArray[right]){ 10 left = mid+1; 11 }else if(rotateArray[mid]\u0026lt;rotateArray[right]){ 12 right = mid; 13 }else{ 14 right--; 15 } 16 } 17 return rotateArray[left]; 18 } 数组中的逆序对 描述 在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P mod 1000000007\n数据范围： 对于 50% 的数据, $size\\leq 10^4$ 对于 100% 的数据, $size\\leq 10^5$\n数组中所有数字的值满足 $0 \\le val \\le 1000000$\n要求：空间复杂度 O(n)，时间复杂度 O(nlogn)\n输入描述： 题目保证输入的数组中没有的相同的数字\n示例1 输入：\n1[1,2,3,4,5,6,7,0] 返回值：\n17 示例2 输入：\n1[1,2,3] 返回值：\n10 解析 解析1-暴力求解 按照定义进行模拟就可以。时间复杂度O(n^2)\n解析2-归并排序 我们举个例子,对于序列1,2,3,4,5的逆序对数是0，但是对于5,4,3,2,1的逆序对数是4+3+2+1个，只要是部分有序的，我们就可以O(1)的时间复杂度求得逆序数。对于我们使用的归并排序，所有排序的数组是部分有序的，比如要归并2,4,6,8和1,3,5,7,1小，归并1，但是左边的序列都比1大，都可以组成逆序数，逆序数数量+4，\n左边 右边 归并数 逆序数 2,4,6,8 1,3,5,7 - 0 2,4,6,8 3,5,7 1 0+4，（1比左边的2小，就是和左边的所有数都可以组成逆序数） 4,6,8 3,5,7 1，2 0+4+0(3比左边的2大，也就是和左边的组成不了逆序数) 4,6,8 5,7 1，2，3 0+4+0+3，(3比4小，和左边的所有数都可以组成逆序数) \u0026hellip;. \u0026hellip; \u0026hellip; \u0026hellip; 这样就可以求得所有的逆序数对数了。\n1const int kmod = 1000000007; 2 int InversePairs(vector\u0026lt;int\u0026gt; data) { 3 int ret = 0; 4 vector\u0026lt;int\u0026gt; tmp(data.size()); 5 mergeSort(data, tmp, 0, data.size() - 1, ret); 6 return ret; 7 } 8 void mergeSort(vector\u0026lt;int\u0026gt;\u0026amp;array,vector\u0026lt;int\u0026gt;\u0026amp;temp,int left,int right,int \u0026amp;ret){ 9 if(left==right){ 10 return ; 11 } 12 int mid = left+((right-left)\u0026gt;\u0026gt;1); 13 mergeSort(array,temp,left, mid,ret); 14 mergeSort(array,temp,mid+1, right,ret); 15 merge(array,temp,left,mid,right,ret); 16 } 17 void merge(vector\u0026lt;int\u0026gt;\u0026amp;array,vector\u0026lt;int\u0026gt;\u0026amp;temp,int left,int mid,int right,int \u0026amp;ret){ 18 int k = 0; 19 int l = left,r = mid+1; 20 while(l\u0026lt;=mid\u0026amp;\u0026amp;r\u0026lt;=right){ 21 // 左边的比右边的大， 22 if(array[l]\u0026gt;array[r]){ 23 temp[k++] = array[r++]; 24 // 计算逆序对数了 25 ret+=(mid-l+1); 26 ret%=kmod; 27 }else{ 28 temp[k++] = array[l++]; 29 } 30 } 31 while(l\u0026lt;=mid){ 32 temp[k++] = array[l++]; 33 } 34 while(r\u0026lt;=right){ 35 temp[k++] = array[r++]; 36 } 37 for(k = 0,l=left;l\u0026lt;=right;l++,k++){ 38 array[l] = temp[k]; 39 } 40 } 比较版本号 描述 牛客项目发布项目版本时会有版本号，比如1.02.11，2.14.4等等\n现在给你2个版本号version1和version2，请你比较他们的大小\n版本号是由修订号组成，修订号与修订号之间由一个\u0026quot;.\u0026ldquo;连接。1个修订号可能有多位数字组成，修订号可能包含前导0，且是合法的。例如，1.02.11，0.1，0.2都是合法的版本号\n每个版本号至少包含1个修订号。\n修订号从左到右编号，下标从0开始，最左边的修订号下标为0，下一个修订号下标为1，以此类推。\n比较规则：\n一. 比较版本号时，请按从左到右的顺序依次比较它们的修订号。比较修订号时，只需比较忽略任何前导零后的整数值。比如\u0026quot;0.1\u0026quot;和\u0026quot;0.01\u0026quot;的版本号是相等的\n二. 如果版本号没有指定某个下标处的修订号，则该修订号视为0。例如，\u0026ldquo;1.1\u0026quot;的版本号小于\u0026quot;1.1.1\u0026rdquo;。因为\u0026quot;1.1\u0026quot;的版本号相当于\u0026quot;1.1.0\u0026rdquo;，第3位修订号的下标为0，小于1\n三. version1 \u0026gt; version2 返回1，如果 version1 \u0026lt; version2 返回-1，不然返回0.\n数据范围：\n1 \u0026lt;= version1.length, version2.length \u0026lt;= 1000\nversion1 和 version2 的修订号不会超过int的表达范围，即不超过 32 位整数 的范围 进阶： 时间复杂度 O(n)\n示例1 输入：\n1\u0026#34;1.1\u0026#34;,\u0026#34;2.1\u0026#34; 返回值：\n1-1 说明：\n1version1 中下标为 0 的修订号是 \u0026#34;1\u0026#34;，version2 中下标为 0 的修订号是 \u0026#34;2\u0026#34; 。1 \u0026lt; 2，所以 version1 \u0026lt; version2，返回-1 2 示例2 输入：\n1\u0026#34;1.1\u0026#34;,\u0026#34;1.01\u0026#34; 返回值：\n10 说明：\n1version2忽略前导0，为\u0026#34;1.1\u0026#34;，和version相同，返回0 示例3 输入：\n1\u0026#34;1.1\u0026#34;,\u0026#34;1.1.1\u0026#34; 返回值：\n1-1 说明：\n1\u0026#34;1.1\u0026#34;的版本号小于\u0026#34;1.1.1\u0026#34;。因为\u0026#34;1.1\u0026#34;的版本号相当于\u0026#34;1.1.0\u0026#34;，第3位修订号的下标为0，小于1，所以version1 \u0026lt; version2，返回-1 示例4 输入：\n1\u0026#34;2.0.1\u0026#34;,\u0026#34;2\u0026#34; 返回值：\n11 说明：\n1version1的下标2\u0026gt;version2的下标2，返回1 示例5 输入：\n1\u0026#34;0.226\u0026#34;,\u0026#34;0.36\u0026#34; 返回值：\n11 说明：\n1226\u0026gt;36，version1的下标2\u0026gt;version2的下标2，返回1 解析 解析1-模拟 由于版本号是以.分割的，可以将分割的结果进行对比，判断那个大。对于有前导0的数字的比较，可以将字符串转换为数字进行比较\n1int compare(string version1, string version2){ 2 int len1 = version1.size(); 3 int len2 = version2.size(); 4 int l1 = 0,l2 = 0; 5 while(l1\u0026lt;len1||l2\u0026lt;len2){ 6 long long num1 = 0; 7 // 用. 分割 8 while(l1\u0026lt;len1\u0026amp;\u0026amp;version1[l1]!=\u0026#39;.\u0026#39;){ 9 num1 = num1*10 +(version1[l1]-\u0026#39;0\u0026#39;); 10 l1++; 11 } 12 // 跳过. 13 l1++; 14 15 long long num2 = 0; 16 while(l2\u0026lt;len2\u0026amp;\u0026amp;version2[l2]!=\u0026#39;.\u0026#39;){ 17 num2 = num2*10 +(version2[l2]-\u0026#39;0\u0026#39;); 18 l2++; 19 } 20 l2++; 21 22 if(num1\u0026gt;num2){ 23 return 1; 24 } 25 if(num1\u0026lt;num2){ 26 return -1; 27 } 28 } 29 return 0; 30} 总结 刷题时间 时间 题目 4-29 二分查找-I 4-29 二维数组中的查找 4-30 寻找峰值 5-2 旋转数组的最小数字 5-3 数组中的逆序对 技巧总结 二分查找一定要清楚left和right的关系，他们两个能不能相等，相等代表的是 二维数组中的查找，虽然是知道二分查找，但是要记住从那开始 数组中的逆序对要多刷。理解这个思想。 ","date":"2022-04-30","img":"","permalink":"/posts/85d3feae/","series":["牛客TOP101"],"tags":["算法","牛客TOP101"],"title":"Newcoder Top 101 二分查找排序"},{"categories":["Go"],"content":"jimyag/singleflight 包主要是用来做并发控制，常见的比如防止缓存击穿 合并查询请求。\n特性 实用，可以大幅度提升合并查询请求的效率 简单 所有的代码仅有90行，逻辑简单 支持泛型，基于go1.18和go-zero实现的泛型SingleFlight 功能 防止缓存击穿 缓存击穿：缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。\n通过 SingleFlight 可以将对同一个 Key 的并发请求进行合并，只让其中一个请求到数据库进行查询，其他请求共享同一个结果，可以很大程度提升并发能力。\n查询缓存时，合并请求，提升服务性能。 假设有一个 IP 查询的服务，每次用户请求先在缓存中查询一个 IP 的归属地，如果缓存中有结果则直接返回，不存在则进行 IP 解析操作。\nn 个用户请求查询同一个 IP（8.8.8.8）就会对应 n 个 Redis 的查询，在高并发场景下，如果能将 n 个 Redis 查询合并成一个 Redis 查询，那么性能肯定会提升很多，而 SingleFlight 就是用来实现请求合并的。\n快速入手 Install 1go get github.com/jimyag/singleflight@latest Usage 启动10个携程同时对calls加1，最终的结果只加了一次\n1package main 2 3import ( 4\t\u0026#34;log\u0026#34; 5\t\u0026#34;sync\u0026#34; 6\t\u0026#34;sync/atomic\u0026#34; 7\t\u0026#34;time\u0026#34; 8 9\t\u0026#34;github.com/jimyag/singleflight\u0026#34; 10) 11 12func main() { 13\tg := singleflight.NewSingleFlight[string]() 14\tc := make(chan string) 15\tvar calls int32 16\t// 给 calls 加1 17\tfn := func() (string, error) { 18\tatomic.AddInt32(\u0026amp;calls, 1) 19\treturn \u0026lt;-c, nil 20\t} 21 22\tconst n = 10 23\tvar wg sync.WaitGroup 24\t// 同时加1 最终的结果只能是 1 25\tfor i := 0; i \u0026lt; n; i++ { 26\twg.Add(1) 27\tgo func() { 28\tv, err := g.Do(\u0026#34;key\u0026#34;, fn) 29\tif err != nil { 30\tlog.Fatalf(\u0026#34;Do error: %v\u0026#34;, err) 31\t} 32\tif v != \u0026#34;bar\u0026#34; { 33\tlog.Fatalf(\u0026#34;got %q; want %q\u0026#34;, v, \u0026#34;bar\u0026#34;) 34\t} 35\twg.Done() 36\t}() 37\t} 38\ttime.Sleep(100 * time.Millisecond) // let goroutines above block 39\tc \u0026lt;- \u0026#34;bar\u0026#34; 40\twg.Wait() 41\tif got := atomic.LoadInt32(\u0026amp;calls); got != 1 { 42\tlog.Fatalf(\u0026#34;number of calls = %d; want 1\u0026#34;, got) 43\t} 44\tlog.Printf(\u0026#34;done %v\u0026#34;, calls) 45} 12022/04/27 13:43:26 done 1 如何实现 万老师的文章中写的很详细，这边直接引用万老师的分析。\n先看代码结构：\n1type ( 2 3\t// SingleFlight 4\t// 可以将对同一个 Key 的并发请求进行合并，只让其中一个请求到数据库进行查询，其他请求共享同一个结果，可以很大程度提升并发能力 5\t// 定义 call 的结构 6\tcall[T any] struct { 7\twg sync.WaitGroup // 用于实现通过1个 call，其他 call 阻塞 8\tval T // 表示 call 操作的返回结果 9\terr error // 表示 call 操作发生的错误 10\t} 11 12\t// 总控结构，实现 SingleFlight 接口 13\tflightGroup[T any] struct { 14\tcalls map[string]*call[T] // 不同的 call 对应不同的 key 15\tlock sync.Mutex // 利用锁控制请求 16\t} 17) 然后看最核心的 Do方法做了什么事情：\n1func (g *flightGroup[T]) Do(key string, fn func() (T, error)) (T, error) { 2 // 对 key 发起 call 请求（其实就是做一件事情）， 3 // 如果此时已经有其他协程已经在发起 call 请求就阻塞住（done 为 true 的情况）， 4 // 等待拿到结果后直接返回 5 c, done := g.createCall(key) 6 if done { 7 return c.val, c.err 8 } 9 // 如果 done 是 false，说明当前协程是第一个发起 call 的协程， 10 // 那么就执行 g.makeCall(c, key, fn) 11 // 真正地发起 call 请求（此后的其他协程就阻塞在了 g.createCall(key)) 12 g.makeCall(c, key, fn) 13 return c.val, c.err 14} 从上图可知，其实关键就两步：\n判断是第一个请求的协程（利用 map） 阻塞住其他所有协程（利用 sync.WaitGroup） 来看下 g.createCall(key) 如何实现的：\n1func (g *flightGroup[T]) createCall(key string) (c *call[T], done bool) { 2 g.lock.Lock() 3 // 先看第一步：判断是第一个请求的协程（利用 map）此处判断 map 中的 key 是否存在， 4 // 如果已经存在，说明已经有其他协程在请求了， 5 // 当前这个协程只需要等待，等待是利用了 sync.WaitGroup 的 Wait() 方法实现的，此处还是很巧妙的 6 if c, ok := g.calls[key]; ok { 7 g.lock.Unlock() 8 c.wg.Wait() 9 return c, true 10 } 11 12 // 如果是第一个发起 call 的协程，所以需要 new 这个 call，然后将 wg.Add(1)， 13 // 这样就对应了上面的 wg.Wait()，阻塞剩下的协程。 14 // 随后将 new 的 call 放入 map 中。 15 // 注意此时只是完成了初始化，并没有真正去执行 call 请求， 16 // 真正的处理逻辑在 g.makeCall(c, key, fn) 中。 17 c = new(call[T]) 18 c.wg.Add(1) 19 g.calls[key] = c 20 g.lock.Unlock() 21 22 return c, false 23} 1func (g *flightGroup[T]) makeCall(c *call[T], key string, fn func() (T, error)) { 2 // 这个方法中做的事情很简单，就是执行了传递的匿名函数 fn()（也就是真正 call 请求要做的事情）。最后处理收尾的事情（通过 defer），也是分成两步： 3 // 4 //删除 map 中的 key，使得下次发起请求可以获取新的值。 5 //调用 wg.Done()，让之前阻塞的协程全部获得结果并返回。 6 defer func() { 7 g.lock.Lock() 8 delete(g.calls, key) 9 g.lock.Unlock() 10 c.wg.Done() 11 }() 12 13 c.val, c.err = fn() 14} 参考 singleflight包原理解析 | silenceper\n通过 SingleFlight 模式学习 Go 并发编程 | Go 技术论坛 (learnku.com)\n","date":"2022-04-27","img":"","permalink":"/posts/34618820/","series":[],"tags":["Go","SingleFlight"],"title":"减少下层服务的压力 SingleFlight"},{"categories":["Go"],"content":"本文是基于GoCN 2022年第八期泛型的讲座的笔记。\n泛型的简介 基本语法 支持接口、结构体、方法\n1type Set[T any] interface { 2\tPut(key T) error 3\tExist(key T) error 4\tGet(key T) (T, error) 5} 6 7type HashSet[T any]struct{ 8 val T 9} 10 11func Print[T any](t T){ 12 fmt.Printf(\u0026#34;%v\u0026#34;,t) 13} 约束 约束是泛型里面新引入的语法元素。约束简单来说就是，类型参数所要满足的条件。 约束具体来说可以分成：\n基本类型和内置类型 基本类型和内置 虽然也能作为约束，但是实际中可能并不常用。这样不具备任何意义\n1func PrintBool[T bool](v T) { 2\tfmt.Printf(\u0026#34;%v\u0026#34;, v) 3} 4 5func PrintSlice[T []int](v T) { 6\tfmt.Printf(\u0026#34;%v\u0026#34;, v) 7} 8 9func PrintArray[T [3]int](v T) { 10\tfmt.Printf(\u0026#34;%v\u0026#34;, v) 11} 12 13func PrintMap[T map[string]int](v T) { 14\tfmt.Printf(\u0026#34;%v\u0026#34;, v) 15} 16 17func PrintChan[T chan int](v T) { 18\tval := \u0026lt;-v 19\tfmt.Printf(\u0026#34;%v\u0026#34;, val) 20} 基本类型和内置虽然也能作为约束，但是实际中可能并不常用。 channel 这边类型推断看上去还 是不太智能的样子，还得自己手动转换\n1func PrintChan[T chan int](v T) { 2\tval := \u0026lt;-v 3\tfmt.Printf(\u0026#34;%v\u0026#34;, val) 4} 5 6func PrintOnlyReadChan[T \u0026lt;-chan int](v T) { 7\tval := \u0026lt;-v 8\tfmt.Printf(\u0026#34;%v\u0026#34;, val) 9} 10 11func main() { 12\tch := make(chan int, 2) 13\tch \u0026lt;- 1 14\tch \u0026lt;- 2 15\tPrintChan(ch) 16\t// han int does not implement \u0026lt;-chan int 17\t//PrintOnlyReadChan(ch) 18 // 必须将chan手动转换为\u0026lt;-chan go1.18 19\tvar ch1 \u0026lt;-chan int 20\tch1 = ch 21\tPrintOnlyReadChan(ch1) 22} 内置约束 any 和 comparable。前者代表任意的类型，后者代表的是可比较类型，也就是 Go 在没有泛型时候就有的可\n比较的概念。\n例如在和 map 结合使用的时候，Key 必须满足 comparable 的约束。 严格来说，any 和 comparable 也只不过 是内置类型。\ncomparable是golang新引入的预定义标识符，是一个接口，指代可以使用==或!=来进行比较的类型集合。\ncomparable仅能用于泛型中的类型限定（type constraint）。\n可直接作为类型限定使用，也可嵌入到类型限定中使用。\n1type HashSet[T comparable, V any] map[T]V 2 3func main() { 4\tset := HashSet[string, int]{} 5\tset[\u0026#34;a\u0026#34;] = 1 6} 普通接口 这种方法应该是最常用的，如果限制HashMap必须实现Hashable的接口，就可以保证，这个结构体一定有这个方法，也就能确定他的HashCode一定是int\n1type Hashable interface { 2\tHashCode() int 3} 4 5type HashMap[K Hashable, V comparable] struct { 6} 7 8func (h *HashMap[K, V]) HashCode() int { 9\treturn 1 10} 11 12func main() { 13\thash := HashMap[Hashable, int]{} 14\thash.HashCode() 15} 普通结构体 普通的结构体用作泛型约束，将无法调用任何方法，任何字段。也就是说，当成整体来用是可以的，但是不能访问字段或者方法。\n这里所报的错误，可以了解到go的泛型其实是以鸭子类型为设计理念，强调的是method不是字段。\n1type User struct { 2\tName string 3\tAge int 4} 5 6func (u *User) GetAge() int { 7\treturn u.Age 8} 9 10func PrintUser[T User](v T) { 11\t// ok 12\tfmt.Printf(\u0026#34;%v\u0026#34;, v) 13\t// v.GetAge undefined (type T has no field or method GetAge) 14\t//fmt.Printf(\u0026#34;%v\u0026#34;, v.GetAge()) 15 // v.Name undefined (type T has no field or method Name) 16\t//fmt.Printf(\u0026#34;%v\u0026#34;, v.Name 17} 18 19func main() { 20\tu := User{Name: \u0026#34;jimyag\u0026#34;, Age: 20} 21 PrintUser(u) 22} type X Y 定义的类型 如果Y是结构体，那么X就会受到结构体的约束。\n如果Y是一个接口，那么X就是使用\n1type Buyer User 2 3func (b *Buyer) GetName() string { 4\treturn b.Name 5} 6 7func PrintBuyer[T Buyer](v T) { 8\t// ok 9\tfmt.Printf(\u0026#34;%v\u0026#34;, v) 10\t// v.GetName undefined (type T has no field or method GetName) 11\t//fmt.Printf(\u0026#34;%v\u0026#34;, v.GetName()) 12} 13 14func main() { 15\tb := Buyer{Name: \u0026#34;jimyag\u0026#34;, Age: 20} 16\tPrintBuyer(b) 17} 约束接口 用符号 | 来组合类型，用符号 ~ 来表达 type X Y 这种形式的衍生类型。\n如果是衍生类型，那么像type Age int也可以被用作int\n1type Number interface { 2 int | int64 3} 4 5type Number2 interface { 6 ~int | ~int64 7} 8 9func NumberGet[n Number](v n) n { 10 fmt.Printf(\u0026#34;%v\u0026#34;, v) 11 return v 12} 13func NumberGet2[n Number2](v n) n { 14 fmt.Printf(\u0026#34;%v\u0026#34;, v) 15 return v 16} 17 18type Age int 19 20func main() { 21 foo := int(1) 22 NumberGet(foo) 23 NumberGet2(foo) 24 foo2 := Age(1) 25 // Age does not implement Number (possibly missing ~ for int in constraint Number) 26 //NumberGet(foo2) 27 NumberGet2(foo2) 28} 限制 无法限制必须组合某个结构体\n结构体可以作为泛型参数，但是无法访问任何字段和方法。由此带来的就是我们在 Go 内无法做到类似于别的语言用泛型表达类型必须继承某个抽象类的效果。\n换言之，我们无法限定类型必须要组合某个类型。\n1type User struct { 2\tName string 3\tAge int 4} 5 6func (u *User) GetAge() int { 7\treturn u.Age 8} 9 10func PrintUser[T User](v T) { 11\t// ok 12\tfmt.Printf(\u0026#34;%v\u0026#34;, v) 13\t// v.GetAge undefined (type T has no field or method GetAge) 14\t//fmt.Printf(\u0026#34;%v\u0026#34;, v.GetAge()) 15} 16 17type Gopher struct { 18\tUser 19\tLanguage string 20} 21 22func main() { 23\tg := Gopher{ 24\tUser: User{Name: \u0026#34;gopher\u0026#34;, Age: 1}, 25\tLanguage: \u0026#34;\u0026#34;, 26\t} 27\t// Gopher does not implement User 28\t// PrintUser(g) 29} 业务开发受限更多，尤其是希望在公司推行一些规范的时候，无法利用泛型来加强 检测。例如要求所有的数据库实体都必须组合一个 BaseEntity，BaseEntity 里面 有公司在数据库表创建方面的各种强制字段。类似与上面的User一样，就不行。\n约束类型只能用于泛型 约束类型无法被用作类型声明，只能用于泛型。 这导致我们无法表达：我只接收特定几种类型作为输入的语义。 假如说我现在想要实现一个求和的函数，能够将 int 类型和 float 类型进行相加。\n1type Number interface { 2\tint | int64 3} 4 5type Number2 interface { 6\t~int | ~int64 7} 8 9func Sum[T Number](a ...T) T { 10\tvar result T 11\tfor _, v := range a { 12\tresult += v 13\t} 14\treturn result 15} 16func main() { 17\tres := Sum[int](1, 2, 3, 4, 5) 18\tfmt.Printf(\u0026#34;%v\u0026#34;, res) 19} Number是一个泛型约束类型，所以无法 被用作普通的类型，它只能出现在泛型里面。所以下边的写法是错误的。 同样的，也无法声明一个 Number 变量\n1// 这是一个错误的声明 2func Sum2[T Number](a ...Number) T { 3\tvar result T 4\tfor _, v := range a { 5\tresult += v 6\t} 7\treturn result 8} 我们日常开发，或者说中间件开发的过程 中，经常会碰到某个接口只接收特定几种类型的情况，目前的做法都是将参数声明成 interface{} 并且结合 swich-case 来处理，在最后肯定是在 default 里面 进行错误输入处理。\n这种样板代码将会长期存在。\n1func Sum3(a ...interface{}) float64 { 2 var result float64 = 0 3 for _, v := range a { 4 switch va := v.(type) { 5 6 case float64: 7 result += va 8 9 case int: 10 result += float64(va) 11 12 default: 13 panic(\u0026#34;unsupported type\u0026#34;) 14 } 15 } 16 return result 17} 结构体和接口无法声明泛型方法 接口或者结构体都可以是泛型的，但是它们不能声明泛型方法。这是最强的限制，没有之一。 它几乎断绝了所有的客户端类型的中间件利用泛型的道路。\n1type Stream[T any] struct { 2\tvalues []T 3} 4 5// Filter 这个方法不是一个泛型方法，因为他没有泛型参数 虽然他的接收器是一个泛型 6func (s *Stream[T]) Filter(func(t T) bool) *Stream[T] { 7\treturn s 8} 9 10// Map syntax error: method must have no type parameters 11func (s *Stream[T]) Map[E any](func(t T) E) *Stream[E] { 12\treturn s 13} 下面的写法也全部无法通过编译\n1type Cache interface { 2 Get[K any](key string) (K, error) 3} 4 5type Orm interface { 6 Create[K any](k K) (K, error) 7} 8 9type Config interface { 10 Get[K any](key string) (K, error) 11} 12 13type HttpClient interface { 14 Get[K any](key string) (K, error) 15} interface method must have no type parameters undefined: K\n如果硬要使用泛型，就需要将泛型声明在类型定义上，而后在每次使用的时候都需要用具体类型来创建一\n个实例。\n1type CacheV1[T any] interface { 2\tGet(key string) (T, error) 3} 4 5var intCache CacheV1[int] 6 7var stringCache CacheV1[string] 8 9type OrmV1[T any] interface { 10\tCreate(t T) (T, error) 11} 12 13var userOrm OrmV1[User] 这种做法严重违背了单例设计原则。\n客户端类型的中间件和我们日常开发最贴近，但是因为泛型的这一个限制，不能太期望这一类的客户端中间件会带来大的变更。\nswitch 无法操作类型参数 虽然在大多数场景下，使用了泛型参数，内部还要 switch 是一个很奇怪的用法。 但是偶尔还是可能需要这么一个语法特性。\n目前来说，Go 泛型支持不是很好。 switch 类型参数这个特性还处于 proposal 戒断\n1func Get[T any](key string) (T, error) { 2\tvar t T 3\t// cannot use type switch on type parameter value t (variable of type T constrained by any) 4\tswitch t.(type) { 5 6\t// cannot use 10 (untyped int constant) as T value in assignment 7\tcase int: 8\tt = 10 9\treturn t, nil 10\t} 11\treturn t, nil 12} 13 14func GetV1[T any](key string) (T, error) { 15\t// 无法将类型作为 switch 对象 16\tswitch T { 17\tcase int: 18\treturn 10, nil 19\t} 20\treturn T, nil 21} 类似的需求还是只能通过指针来达成目标, 并且指针要赋值给一个 interface{} 类 型才能进一步进行 switch.\n1func GetV2[T any](key string) (T, error) { 2\tvar t T 3\tvar tp interface{} = \u0026amp;t 4\tswitch val := tp.(type) { 5\tcase *int: 6\t*val = 10 7\treturn t, nil 8\t} 9\treturn t, nil 10} 影响 数据结构与算法的类库 前述的这些限制对数据结构与算法的类库几乎没有影响。所以它们会迎来比较大的发展。\n数据结构：例如 Map，Set 等。目前来看默认的 map 的核心缺陷在于 key 必须是comparable 的，而在一些使用复杂结构体作为 key 的场景下，难以使用。以及 map 的变种，例如有序 map，追求高效率 的小 map。 又如树形结构\n池 池一类的也可以迎来一定的改进。\n比如典型的 sync.Pool 可以考虑使用泛型进行封装。 也可以设计通用的资源池。这一类的资源 池可以满足：\n资源一定时间不被使用就会被释放\n控制住空闲资源的数量\n连接池、对象池可以看做是这种通用资源池的特例\n1type Pool[T any] struct { 2\tpool sync.Pool 3} 4 5func NewPool[T any](factory func() T) *Pool[T] { 6\treturn \u0026amp;Pool[T]{ 7\tpool: sync.Pool{ 8\tNew: func() interface{} { 9\treturn factory() 10\t}, 11\t}, 12\t} 13} 14 15func (p *Pool[T]) Get() T { 16\treturn p.pool.Get().(T) 17} 缓存模式会有显著改进 缓存模式可以说将迎来显著地，用户体验 上的改进。\n核心在于早期我们设计缓存模式接口，如 ~write-through~, ~read-through~ 的时候， 要么直接使用 interface{}，用户则会陷 入类型断言中。 要么使用具体类型，或者复制粘贴代码， 或者使用代码生成策略。\n但是因为 T any 不能被看成是 interface{}，所以虽然代码看起来是装饰器，但是 ReadThroughCache 在 Go 里面并不被认为实现了 Cache 接口。至少在goland看来不是\n1type Cache interface { 2\tGet(key string) (interface{}, error) 3\tSet(key string, value interface{}) error 4} 5 6type ReadThroughCache[T any] struct { 7\tcache Cache 8\treadFunc func() (T, error) 9} 10 11func (c *ReadThroughCache[T]) Get(key string) (T, error) { 12\tvar t T 13\treturn t, nil 14} 15 16func (c *ReadThroughCache[T]) Set(key string, value T) error { 17\treturn nil 18} 19 20var a Cache = \u0026amp;ReadThroughCache[interface{}]{} 21 22func main() { 23\ta.Set(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;) 24\ta.Get(\u0026#34;\u0026#34;) 25} 参考 2022 开源说 第八期 泛型_哔哩哔哩_bilibili\n","date":"2022-04-26","img":"","permalink":"/posts/33cd41f9/","series":[],"tags":["Go","泛型"],"title":"Go泛型的限制和对中间件的影响"},{"categories":["踩坑"],"content":"在git中不小心上传了大文件，推送到GitHub时被拒绝。\nThe size of file ‘xxx‘ has exceeded the upper limited size (100 MB) in commit\n我们在git中上传文件时不小心上传了压缩之后的public.zip文件，文件大小有108MB，超过了GitHub单个文件记录，被拒绝了。\n如何删除呢？\n1git filter-branch --force --index-filter \u0026#34;git rm --cached --ignore-unmatch public.zip\u0026#34; --prune-empty --tag-name-filter cat -- --all 其中public.zip就是要删除的大文件名称\n运行结果如下\n1WARNING: git-filter-branch has a glut of gotchas generating mangled history 2 rewrites. Hit Ctrl-C before proceeding to abort, then use an 3 alternative filtering tool such as \u0026#39;git filter-repo\u0026#39; 4 (https://github.com/newren/git-filter-repo/) instead. See the 5 filter-branch manual page for more details; to squelch this warning, 6 set FILTER_BRANCH_SQUELCH_WARNING=1. 7Proceeding with filter-branch... 8 9Rewrite 7934e441f11564177dafeea762d2dddf0662ba6e (35/41) (24 seconds passed, remaining 4 predicted) rm \u0026#39;public.zip\u0026#39; 10Rewrite 8f0fca234e1d7deeabb26c93b35e2bf13aeb1542 (35/41) (24 seconds passed, remaining 4 predicted) rm \u0026#39;public.zip\u0026#39; 11Rewrite 7ed0cf806e6d4eb132addcc0c36b4660243df528 (37/41) (25 seconds passed, remaining 2 predicted) rm \u0026#39;public.zip\u0026#39; 12Rewrite 539b54782f23819f728f487b792abb3e47e68409 (37/41) (25 seconds passed, remaining 2 predicted) rm \u0026#39;public.zip\u0026#39; 13Rewrite b02dae8bb5c48dac8f528bd26aa97e83c955e09f (39/41) (27 seconds passed, remaining 1 predicted) rm \u0026#39;public.zip\u0026#39; 14Rewrite b2dd2b219d797742da52fa18c227cb7e9fcb5a23 (39/41) (27 seconds passed, remaining 1 predicted) rm \u0026#39;public.zip\u0026#39; 15Rewrite 04f754981ba819d3229b2aaef8b4d3be880a79d6 (41/41) (28 seconds passed, remaining 0 predicted) 16Ref \u0026#39;refs/heads/master\u0026#39; was rewritten 17WARNING: Ref \u0026#39;refs/remotes/origin/master\u0026#39; is unchanged 注意一定要时双引号，要不然会出现fatal: bad revision 'rm'的错误。\n(21条消息) git 操作问题清单 | 删除大文件，版本回退，pull合并\u0026hellip;._qyhyzard的博客-CSDN博客\n","date":"2022-04-25","img":"","permalink":"/posts/b983a6c5/","series":[],"tags":["踩坑","Git"],"title":"Git删除不小心上传的大文件"},{"categories":[],"content":"大数据技术及应用的复习资料。\n大数据概述 大数据概念 指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应海量、高增长率和多样化的信息资产。\n大数据特性 海量性 多样性 真实性 价值密度低 高速性 可变性 大数据的影响 数据的运行、计算速度越来越快\n数据存储成本下降\n实现信息对等解放脑力，机器拥有人的智慧\n大数据的关键技术 分布式系统基础架构Hadoop的出现，为大数据带来了新的曙光；\nHDFS为海量的数据提供了存储；\nMapReduce则为海量的数据提供了并行计算，从而大大提高了计算效率；\nSpark、Storm、Impala、Flink等各种各样的技术进入人们的视野。\n大数据与云计算物联网的关系 物联网、云计算和大数据三者互为基础。\n物联网产生大数据，大数据需要云计算。\n物联网在将物品和互联网连接起来，进行信息交换和通信，以实现智能化识别、定位、跟踪、监控和管理的过程中，产生的大量数据，云计算解决万物互联带来的巨大数据量，所以三者互为基础，又相互促进。如果不那么严格的说，它们三者可以看做一个整体，相互发展、相互促进。\n以下关于云计算、大数据和物联网之间的关系，论述错误的是： B\nA、物联网可以借助于大数据实现海量数据的分析\nB、云计算侧重于数据分析\nC、物联网可以借助于云计算实现海量数据的存储\nD、云计算、大数据和物联网三者紧密相关，相辅相成\nhadoop简介 Hadoop简介 hadoop是一个分布式系统基础架构，hadoop的框架最核心的设计是HDFS和MapReduce，HDFS为海量的数据提供了存储能力，MapReduce为海量数据提供了计算能力\nHadoop特性/优点 高可靠性 ：采用冗余数据存贮方式，即使一个副本发生故障，其他副本也可以保证对外工作的正常进行\n高扩展性 ：采用冗余数据存贮方式，即使一个副本发生故障，其他副本也可以保证对外工作的正常进行。\n高效性 ：作为并行分布式计算平台，hadoop采用分布式存贮和分布式处理两大核心技术，能够高效的处理PB级别的数据\n高容错性 ：采用冗余数据存贮方式，自动保存数据的多个副本，并且能够自动将失败的任务重新分配。\n经济性：hadoop采用廉价的计算机集群，普通的用户也可以pc机搭建环境\n运行在linux平台上，hadoop是基于java语言开发的，可以较好的运行在linux的平台上\n支持多种编程语言，如：C++等/\nHadoop缺点 在当前Hadoop的设计中，所有的metadata操作都要通过集中式的NameNode来进行，NameNode有可能是性能的瓶颈。\n当前Hadoop单一NameNode、单一Jobtracker的设计严重制约了整个Hadoop可扩展性和可靠性。\n首先，NameNode和JobTracker是整个系统中明显的单点故障源。再次，单一NameNode的内存容量有限，使得Hadoop集群的节点数量被限制到2000个左右，能支持的文件系统大小被限制在10-50PB，最多能支持的文件数量大约为1.5亿左右。实际上，有用户抱怨其集群的NameNode重启需要数小时，这大大降低了系统的可用性。\nHadoop项目结构 详细介绍\n1，core/common Hadoop Common原名为Hadoop Core,0.20版本之后改为common。自0.21版本之后，HDFS和MapReduce被分离出来作为单独的子项目，其余部分构成Hadoop Common。\nCommon是为Hadoop及其他子项目提供支持的常用工具，主要包括文件系统，RPC和串行化库，他们为在廉价的硬件上搭建云计算环境提供基本的服务，同时也为运行在该平台上的软件开发提供所需要的API。\n2，Avro Avro是Hadoop的一个子项目，也是Apache中的一个独立项目。\nAvro是一个用于数据序列化的系统，提供了丰富的数据结构类型，快速可压缩的二进制数据格式，存储持久性数据的文件集，远程调用的功能和简单的动态语言集成功能。\nAvro可以将数据结构或对象转化成便于存储和传输的格式，节约数据存储空间和网络传输带宽，Hadoop的其它子项目的客户端与服务端之间的数据传输都采用Avro。\n3，HDFS HDFS是Hadoop项目的两大核心之一，它是针对谷歌文件系统（GFS）的开源实现。\nHDFS具有处理超大数据，流式处理，可以运行在廉价商用服务器上等优点。\nHDFS在设计之初就是要运行在廉价的大型服务器集群上，因此，在设计上就把硬件故障作为一种常态来考虑，可以保证在部分硬件发生故障的情况下，仍能保证文件系统的整体的可用性和可靠性。\nHDFS放宽了一部分POSIX约束，从而实现以流的形式访问文件系统中的数据。\nHDFS在访问应用程序数据时候，可以具有很高的吞吐量，因此，对于超大数据集的应用程序而言，选择HDFS作为底层数据存储是较好的选择。\n4，HBase HBase是一个提供高可靠性，高性能，可伸缩，实时读写，分布式的列式数据库，一般采用HDFS作为其底层数据存储。\nHBase是针对谷歌的BigTable的开源实现，二者都采用了相同的数据模型，具有强大的非结构化数据存储能力。HBase与传统关系数据库的一个重要区别就是，前者是基于列的存储，而后者采用基于行的存储。HBase具有良好的横向扩展能力，可以通过不断增加廉价的商用服务器来增加存储能力。\n5，MapReduce Hadoop MapReduce是这对google 的MapReduce的实现。\nMapReduce是一种编程模型，用于大规模数据集的并行计算，它将复杂，运行于大规模集群上的并行计算过程高度的抽象到了两个函数——Map和Reduce，并允许用户在不了解分分布式系统底层细节的情况下开发并行应用程序，并将其运行于廉价计算机集群上，完成海量数据的处理。\n6，Zookeeper Zookeeper是针对谷歌Chubby的一个开源实现，是高效和可靠的协同工作系统，提供分布式锁之类的基本服务，用于构建分布式应用，减轻分布式应用程序锁承担的协调任务。\nZookeeper使用Java编写，很容易编程接入，它使用了一个和文件树结构相似的数据模型，可以使用Java或者C来进行编程接入。\n7，Hive Hive是一个基于Hadoop的数据仓库工具，可以用于对Hadoop文件中的数据集进行数据整理，特殊查询和分析存储。\nHive的学习门槛较低，因为，它提供了类似于关系数据SQL语言的特殊查询语言——Hive QL,可以通过Hive QL语句快速实现简单的MapReduce统计，Hive自身可以将Hive QL语句转换为MapReduce任务进行运行，而不必开发专门的MapReduce应用，因而十分适合数据仓库的统计分析。\n8，Pig Pig是一种数据流语言和运行环境，适合于使用Hadoop和MapReduce平台来查询大型半结构化数据集。\nPig的出现大大简化了Hadoop常见的工作任务，它在MapReduce的基础上创建了更简单的过程语言抽象，为Hadoop应用程序提供了一种更加接近结构化查询语言的接口。\nPig是一个相对简单的语言，它可以执行SQL语句，因此，当我们需要从大型数据集中搜索满足某个给定搜索条件的记录时，采用Pig要比MapReduce具有明显的优势，前者只需要编写一个简单的脚本在集群中自动并行处理与分发，而后者则需要编写一个单独的MapReduce应用程序。\n9，Sqoop Sqoop可以改进数据的互操作性，主要用来在Hadoop和关系数据库直接交换数据。\n通过Sqoop,我们可以方便的将关系数据库之中的数据导入Hadoop，或者将Hadoop中的数据导入关系数据库。Sqoop主要通过JDBC和关系数据库进行交互，理论上，支持JDBC的关系数据库都可以使Sqoop和Hadoop进行数据交互。\nSqoop是专门为大数据集设计的，支持增量更新，可以将新纪录添加到最近一次到处的数据源上，或者指定上次修改的时间戳。\n10，Chukwa Chukwa是一个开源的，用于监控大型分布式系统的数据收集系统，可以将各种类型的数据收集成合适的Hadoop处理的文件，并保存在HDFS中供Hadoop进行各种MapReduce操作。\nChukwa构建在Hadoop的HDFS和MapReduce框架之上，继承了Hadoop的可伸缩性和可扩展性。\nChukwa内置了一个强大而灵活的工具集，可用于展示，监控和分析已收集的数据。\nHadoop生态系统 详细介绍\n1.Hive 2.Hbase 3.Pig 4.Sqoop 5.Flume 6.Zookeeper 7.Spark 8.Storm 9.Avr\nHdfs HDFS( Hadoop Distributed File System)是一个易于扩展的分布式文件系统\nHdfs体系结构 HDFS 采用的是master/slaves主从结构模型来管理数据.\n这种结构模型主要由四个部分组成：\nClient(客户端)、Namenode(名称节点)、Datanode(数据节点)和SecondaryNamenode(第二名称节点，辅助Namenode)。\n一个真正的HDFS集群包括一个Namenode和若干数目的Datanode。\nNamenode是一个中心服务器，负责管理文件系统的命名空间 (Namespace )及客户端对文件的访问。\n集群中的Datanode一般是一个节点运行一个Datanode进程，负责管理客户端的读写请求，在Namenode的统一调度下进行数据块的创建、删除和复制等操作。\nClient的主要功能 在上传文件时将文件切分为Block，在文件下载时将文件合并； 上传与下载数据文件时，与NameNode交互，获取文件元数据； 上传与下载数据文件时，与DataNode交互，读取或写入数据。 NameNode介绍 主要功能提供名称查询服务，用来保存metadata信息 管理文件系统的命名空间；（它维护着文件系统树及整棵树内所有的文件和目录。这些信息以两个文件形式永久保存在本地磁盘上 管理元数据：文件的位置、所有者、权限、数据块block信息 管理Block副本策略：多少个副本，默认3个副本； 处理客户端读写请求，为DataNode分配任务。 DataNode介绍 主要功能保存Block。 Slave工作节点（可大规模扩展）； 存储Block和数据校验和执行客户端发送的读写操作； 通过心跳机制定期（默认3秒）向NameNode汇报运行状态和Block列表信息，如果NN10分钟没有收到DN的心跳，则认为其已经lost，并复制其上的block到其它DN； 集群启动时，DataNode向NameNode提供Block列表信息。（数据块的位置并不是由namenode维护的，而是以块列表的形式，存储在datanode中，在安全模式中，datanode会向namenode发送最新的块列表信息。） Bloack数据块 HDFS是HDFS的最小存储单元； 文件写入HDFS会被切分成若干个Block； Block大小固定，默认为128MB，可自定义； 若一个Block的大小小于设定值，物理上不会占用整个块空间； 默认情况下每个Block有3个副本。 Block和元数据分开存储：Block存储于DataNode，元数据存储于NameNode； 如何设置Block大小： 目标：最小化寻址开销，降到1%以下 默认大小：128M 块太小：寻址时间占比过高 块太大：Map任务数太少，作业执行速度变慢 Block多副本： 以DataNode节点为备份对象 机架感知：将副本存储到不同的机架上，实现数据的高容错 副本均匀分布：提高访问带宽和读取性能，实现负载均衡 元数据存储 元数据的两种存储形式： 内存元数据（NameNode） 文件元数据（edits + fsimage） Block副本放置机制 第一个副本：放置在上传文件的DN上，如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点上； 第二个副本：与第一个不同机架的节点上； 第三个副本：与第一个机架相同的其他节点上 节点选择：同等条件下优先选择空闲节点\nBlock大小和副本数由Client端上传文件到HDFS时设置，其中副本数可以变更，Block是不可以在上传后变更的。\n不一次性写三份，而是由一个dn写入另一个dn，目的是防止阻塞，防止并发量过大。\n安全模式 什么是安全模式 安全模式是HDFS的一种特殊状态，在这种状态下，HDFS只接收读数据请求，而不接收写入、删除、修改等变更请求； 安全模式是HDFS确保Block数据安全的一种保护机制； Active NameNode启动时，HDFS会进入安全模式，DataNode主动向NameNode汇报可用Block列表等信息，在系统达到安全标准前，HDFS一直处于“只读”状态。 何时正常离开安全模式 Block上报率：DataNode上报的可用Block个数 / NameNode元数据记录的Block个数； 当Block上报率 \u0026gt;= 阈值时，HDFS才能离开安全模式，默认阈值为0.999； 不建议手动强制退出安全模式。 触发安全模式的原因 NameNode重启 NameNode磁盘空间不足 Block上报率低于阈值 DataNode无法正常启动 日志中出现严重异常 用户操作不当，如：强制关机（特别注意！） HDFS文件的读取-重点 客户端向NameNode请求读取文件 NameNode查找目录树，查询块和NameNode的关系 按照NameNode与客户端的距离由近到远的顺序列表返回给客户端 客户端与最近的DataNode连接 DataNode返回相应Block的数据 客户端组装block成一个文件 HDFS文件的写入 客户端请求上传文件 NameNode检查目录中是否存在这个文件，并返回是否可以上传 客户端将文件切块 客户端向NamNode提出上传的各个block的列表 NameNode检查DataNode信息 NameNode返回可以上传的DataNode列表 客户端请求与DataNode建立传输Block的通道 上传到一个结点A之后，通过这个结点A复制到另一个结点B 再通过复制的结点B复制到新的结点C 客户端以Packet为单位发送数据 客户端通知NameNode成功写入Block Hdfs存储原理 HDFS采用master/slave架构。一个HDFS集群是由一个Namenode和一定数目的Datanodes组成。NameNode作为master服务，它负责管理文件系统的命名空间和客户端对文件的访问。DataNode作为slave服务，在集群中可以存在多个。通常每一个DataNode都对应于一个物理节点。DataNode负责管理节点上它们拥有的存储，它将存储划分为多个block块，管理block块信息，同时周期性的将其所有的block块信息发送给NameNode。\nHadoop1.0与2.0的区别 提出HDFS Federation，它让多个NameNode分管不同的目录进而实现访问隔离和横向扩展，同时彻底解决了NameNode单点故障问题 针对Hadoop1.0中的MapReduce在扩展性和多框架支持等方面的不足，它将JobTracker中的资源管理和作业控制分开，分别由ResourceManager（负责所有应用程序的资源分配）和ApplicationMaster（负责管理一个应用程序）实现，即引入了资源管理框架Yarn。通用的资源管理模块，可为各类应用程序进行资源管理和调度 HDFS的主要组件及功能 Block是HDFS最小存储单元，大小固定，1.X默认是64MB2.X默认为128MB，可自定义。默认情况下每个Block有（至少）三个副本，通过水平复制，达到数据冗余度的要求。\n单一master（NameNode）来协调存储元数据。\nnameNode DataNode 存储元数据 存储我呢见数据 元数据保存在内存中 文件保存在磁盘上 保存文件，Block，DataNode之间的映射关系 维护了block id 到datanode本地文件的映射关系 HDFS适用场景 超大文件 流式数据访问 一次写入、多次读取 传输时间和寻址时间 不适用 低延时 大量小文件 多用户写入、任意修改文件 Shell语法 ls：查看文件\n1hadoop fs -ls / 查看HDFS文件系统上的文件 2hadoop fs -ls -R / 查看HDFS文件系统多层文件夹 mkdir：创建文件夹\n1hadoop fs -mkdir /test/ 创建test文件夹 2hadoop fs -mkdir -p /a/b 创建多层文件夹 put：上传文件\n1hadoop fs -put 1.tar /test 把当前目录的1.tar上传到hdfs的test目录 cat/text ：查看文件内容\n1hadoop fs -cat 1.txt 2hadoop fs -text 1.txt get：下载文件\n1hadoop fs -get /test/1.tar test.tar 把hdfs的test目录下的1.tar下载到本地，命名为test.tar rm：删除文件\n1hadoop fs -rm /test/1.tar 删除HDFS系统上test目录下的1.tar文件 2hadoop fs rm -r /test/ 删除HDFS系统上test目录 3或者 4hadoop fs -rmr /test/ 删除HDFS系统上test目录 MapReduce 特点 无需管理master、slave和分布式，程序员只需关注业务本身。 计算跟着数据走 良好的扩展性：计算能力随着节点数增加，近似线性递增 高容错 状态监控 适合海量数据的离线批处理 降低了分布式编程的门槛 MapReduce框架采用了Master/Slave架构，包括一个Master和若干个Slave。 Master上运行JobTracker，负责作业管理、状态监控和任务调度等，Slave上运行TaskTracker，负责任务的执行和任务状态的汇报； 适用场景 数据统计，如：网站的PV（page view）、UV（user visit）统计，搜索引擎构建索引 海量数据查询、复杂数据分析算法实现 不适用场景 OLAP（On-Line Analytical Processing）联机分析处理\n要求毫秒或秒级返回结果\n流计算\n流计算的输入数据集是动态的，而MapReduce是静态的\n多步骤的复杂计算任务\nMapReduce体系结构 主要由四个部分组成，分别是Client、JobTracker、TaskTracker以及Task。\nClient 用户编写的MapReduce程序通过Client提交到JobTracker端； 用户可通过Client提供的一些接口查看作业运行状态。 JobTracker JobTracker负责资源监控和作业调度； JobTracker 监控所有TaskTracker与Job的健康状况，一旦发现失败，就将相应的任务转移到其他节点； JobTracker 会跟踪任务的执行进度、资源使用量等信息，并将这些信息告诉任务调度器（TaskScheduler），而调度器会在资源出现空闲时，选择合适的任务去使用这些资源。 TaskTracker TaskTracker 会周期性地通过“心跳”将本节点上资源的使用情况和任务的运行进度汇报给JobTracker，同时接收JobTracker 发送过来的命令并执行相应的操作（如启动新任务、杀死任务等）； TaskTracker 使用“slot”等量划分本节点上的资源量（CPU、内存等）。一个Task 获取到一个slot 后才有机会运行，而Hadoop调度器的作用就是将各个TaskTracker上的空闲slot分配给Task使用。slot 分为Map slot 和Reduce slot 两种，分别供MapTask 和Reduce Task 使用。 Task Task 分为Map Task 和Reduce Task 两种，均由TaskTracker 启动。 MapReduce工作流程 MapReduce 就是将输入进行分片，交给不同的 Map 任务进行处理，然后由 Reduce 任务合并成最终的解。\n对输入的数据进行分片格式化。 执行MapTask。每个切片分配一个map()任务，map()对其中的数据进行计算，对每个数据用键值对的形式记录。 对MapTask进行Shuffle，形成内部有序，整体无序的小文件 将小文件传到Reduce()中执行，，然后进行归并排序，最终输出 注意 不同的Map任务之间不会进行通信 不同的Reduce任务之间也不会发生任何信息交换 用户不能显式地从一台机器向另一台机器发送消息 所有的数据交换都是通过MapReduce框架自身去实现的 WordCount流程 我们将任务切为三份，所以启动三个map任务。 我们会启动四个reduce任务，所以数据被重构，重新分布成四份，每份对应一个reduce。 map将数据转换为键值对，reduce将键值对合并。 其中：spliting和Mapping是用户实现的，Shuffling是框架实现的，Reducing是用户实现\nJob \u0026 Task（作业与任务） 作业是客户端请求执行的一个工作单元，如整个wordcount计算作业； 包括输入数据、MapReduce程序、配置信息 任务是将作业分解后得到的细分工作单元，如其中的一个map任务。 分为Map任务和Reduce任务两类 Split（切片） 输入数据被划分成等长的小数据块，称为输入切片（Input Split），简称切片； 每个Split交给一个Map任务处理，Split的数量决定Map任务的数量； Split的划分方式由程序设定，按照HDFS block是其中的一种； Split越小，负载越均衡，但集群的开销越大； Shuffle阶段（洗牌） Map、Reduce阶段的中间环节，负责执行Partition（分区）、Sort（排序）、Spill（溢写）、Merge（合并）、抓取（Fetch）等工作； Partition决定了Map任务输出的每条数据放入哪个分区，交给哪个Reduce任务处理； Reduce任务的数量决定了Partition数量；（ reduce任务的数量并非由输入数据的大小决定，而是特别指定的。 ） Partition编号 = Reduce任务编号 =“hash（key） % reduce task number”； 避免和减少Shuffle是MapReduce程序调优的重点。 Mapper、Partition、Reducer数目的确定与关系？ Mapper：由客户端分片情况决定，客户端获取到输入路径的所有文件，依次对每个文件执行分片，分片大小通过最大分片大小、最小分片大小、hdfs的blocksize综合确定，分片结果写入job.split提交给yarn，对每个分片分配一个Mapper，即确定了数目。 Partition：由PartitionerClass中的逻辑确定，默认情况下使用的HashPartitioner中使用了hash值与reducerNum的余数，即由reducerNum决定，等于Reducer数目。如果自定义的PartitionerClass中有其他逻辑比如固定了，也可以与Reducer数目无关，但注意这种情况下，如果reducerNum小于分区数则会报错，如果大于则会产生无任务的reduecer但不会影响结果。但是如果reducerNum只有1个，则不会报错而是所有分区都交给唯一的reducer。 Reducer：通过job.setNumReduceTasks手动设置决定。 MapReduce shuffle过程 Map端的shuffle过程 每个Map任务分配一个缓存\nMapReduce默认100MB缓存\n设置溢写比例0.8\n分区默认采用哈希函数\n排序是默认的操作\n排序后可以合并（Combine）（自定义）\n合并不能改变最终结果\n在Map任务全部结束之前进行归并\n归并得到一个大的文件，放在本地磁盘\n文件归并时，如果溢写文件数量大于预定值（默认是3）则可以再次启动Combiner，少于3不需要\nJobTracker会一直监测Map任务的执行，并通知Reduce任务来领取数据\n合并（Combine）和归并（Merge）的区别：\n两个键值对\u0026lt;“a”,1\u0026gt;和\u0026lt;“a”,1\u0026gt;，如果合并，会得到\u0026lt;“a”,2\u0026gt;，如果归并，会得到\u0026lt;“a”,\u0026lt;1,1\u0026raquo;\nReduce端的Shuffle过程 Reduce任务通过RPC（远程过程调用）向JobTracker询问Map任务是否已经完成，若完成，则领取数据； Reduce领取数据先放入缓存，来自不同Map机器，先归并，再合并，写入磁盘； 多个溢写文件归并成一个或多个大文件，文件中的键值对是排序的； 当数据很少时，不需要溢写到磁盘，直接在缓存中归并，然后输出给Reduce。 Shuffle详解-及这个就行 Map端 Map任务将中间结果写入专用内存缓冲区Buffer（默认100M），同时进行Partition和Sort（先按“key hashcode % reduce task number”对数据进行分区，分区内再按key排序） 当Buffer的数据量达到阈值（默认80%）时，将数据溢写（Spill）到磁盘的一个临时文件中，文件内数据先分区后排序 Map任务结束前，将多个临时文件合并（Merge）为一个Map输出文件，文件内数据先分区后排序 所有Map任务完成后，Map阶段结束，一般每个Map任务都有输出 Reduce端 Reduce任务从多个Map输出文件中主动抓取（Fetch）属于自己的分区数据，先写入Buffer，数据量达到阈值后，溢写到磁盘的一个临时文件中 数据抓取完成后，将多个临时文件合并为一个Reduce输入文件，文件内数据按key排序 YARN模式（ Hadoop 2.X ） HBase HBase概念 HBase是一个高可靠、高性能、面向列、可伸缩的分布式数据库，主要用来存储非结构化和半结构化的松散数据。\nHBase与传统数据库的对比： 数据类型：传统数据库数据类型较丰富，Hbase数据类型更加简单。\n数据操作：传统数据库涉及多表连接，Hbase不存在。\n存储模式：关系数据库是基于行模式存储的。HBase是基于列存储的。\n数据索引：关系数据库可以针对不同列构建多个索引，HBase只有行键索引。\n数据维护：传统数据库更新会丢失版本旧的数据，Hbase更新会保留版本旧的数据。\n可伸缩性：关系数据库很难实现横向扩展，纵向扩展的空间也比较有限。Hbase相反。\nHBase适用场景 并发查询\n海量数据 高并发 简单条件查询 半结构化和非结构化数据存储\n10K~10M的结构化和非结构化数据 HBase数据模型 数据模型概述 HBase是一个稀疏、多维度、排序的映射表，这张表的索引是行键、列族、列限定符和时间戳\n数据模型相关概念 1. 表：HBase采用表组织数据，由行和列构成\n2. 行：由行键来标识\n3. 列族：基本的访问控制单元\n4. 列限定符：数据通过列限定符定位\n5. 单元格：通过行、列、列限定符确定一个单元格\n6. 时间戳：每个单元格都保存着同一份数据的不同版本，这些版本采用时间戳进行索引。\n四维模型 HBase中需要根据行键、列族、列限定符和时间戳来确定一个单元格，因此，可以视为一个“四维坐标”，即[行键, 列族, 列限定符, 时间戳]\nHbase实现原理 功能组件 库函数\n一个Master主服务器 : 负责管理和维护HBase表的分区信息，维护Region服务器列表，分配Region，负载均衡\n许多个Region服务器: 负责存储和维护分配给自己的Region，处理来自客户端的读写请求；客户端并不是直接从Master主服务器上读取数据，而是在获得Region的存储位置信息后，直接从Region服务器上读取数据\nRegion 分布式存储和负载的最小单元； 系统将表水平划分（按行）为多个Region，每个Region保存表的一段连续数据； 默认每张表开始只有一个Region，随着数据不断写入，Region不断增大，当Region大小超过阀值时，当前Region会分裂成两个子Region。 每个Region默认大小是100MB到200MB（2006年以前的硬件配置） 每个Region的最佳大小取决于单台服务器的有效处理能力 目前每个Region最佳大小建议1GB-2GB（2013年以后的硬件配置） 同一个Region不会被分拆到多个Region服务器 每个Region服务器存储10-1000个Region 表被切分成多个Regions,分布到多个RegionServers上 Hbase三层结构 一、Zookeeper文件：记录了-ROOT-表的位置信息\n二、ROOT-表：记录了.META.表的Region位置信息\n三、META.表：-记录了数据表的Region位置信息\n为了加快访问速度，.META.表的全部Region都会被保存在内存中\n客户端访问数据时的“三级寻址” 为了加速寻址，客户端会缓存位置信息，同时，需要解决缓存失效问题； 寻址过程客户端只需要询问Zookeeper服务器，不需要连接Master服务器。 HBase系统架构 客户端 客户端包含访问HBase的接口，同时在缓存中维护着已经访问过的Region位置信息，用来加快后续数据访问过程。\nZookeeper服务器 Zookeeper可以帮助选举出一个Master作为集群的总管，并保证在任何时刻总有唯一一个Master在运行，这就避免了Master的“单点失效”问题；\n监控RegionServer的上下线信息，并通知Master；存储元数据的寻址入口；存储所有Region的寻址入口。\nZookeeper是一个很好的集群管理工具，被大量用于分布式计算，提供配置维护、域名服务、分布式同步、组服务等。\nMaster 主服务器Master主要负责表和Region的管理工作： 管理用户对表的增加、删除、修改、查询等操作 实现不同Region服务器之间的负载均衡 在Region分裂或合并后，负责重新调整Region的分布 对发生故障失效的Region服务器上的Region进行迁移 不处理Client的数据读写请求 Region服务器（Slave） Region服务器是HBase中最核心的模块，负责维护分配给自己的Region，并响应用户的读写请求。 管理Region Split（分裂） 管理StoreFile Compaction（合并） Region服务器工作原理 Region按照列族，分为多个Store。（下图） 一个Region由多个Store组成，每个Store存储一个列族。Region是分布式存储的最小单元，而Store是存储落盘的最小单元。 Store由一个MemStore和若干StoreFile组成。 MemStore与StoreFile MemStore是Store的内存缓冲区，StoreFile是MemStore的磁盘溢写文件，在HDFS中被称为HFile。 数据读写都先访问MemStore。Client读取数据时，先找MemStore，再找StoreFile。写数据时，先写MemStore，当数据量超过阈值时，RegionServer会将MemStore中的数据溢写磁盘，每次溢写都生成一个独立的StoreFile（HFile）； 读数据时 client先找MemStore，再找StoreFile 写数据时 先再MemStore中写入， 数据量超过阈值时，RegionServer将MemStore中的数据溢写磁盘。每次溢写独立生成一个StoreFile 用户写入数据 用户写入数据时，被分配到相应Region服务器去执行 用户数据首先被写入到MemStore和Hlog中 只有当操作写入Hlog之后，commit()调用才会将其返回给客户端 向Hbase写入数据 访问ZK，获取meta表所在RegionServer和Region 读取meta表，获取所有Region在所有RegionServer上的分布，和每个Region中维护的表数据的范围。 根据主键和meta表，得出待写数据归属的Region和RegionServer，向特定RegionServer发送数据。 RegionServer接受数据 RegionServer收到数据。先将操作写入HLog，再将数据写入MemStore。当MemStore的数据量超过阈值时，将数据溢写磁盘，生成一个StoreFile文件。 当Store中StoreFile的数量超过阈值时，将若干小StoreFile合并。 当Region中最大Store的大小超过阈值时，Region分裂成两个子Region HLog 含义：以WAL（Write Ahead Log，预写日志）方式写数据时产生的日志文件 目的：RegionServer意外宕机时的数据恢复 先写HLog，再写MemStore，最后写StoreFile，每个RegionServer维护一个HLog 定期删除HLog过期数据 用户更新数据必须首先写入日志后，才能写入MemStore缓存，并且，直到MemStore缓存内容对应的日志已经写入磁盘，该缓存内容才能被刷写到磁盘。 Zookeeper会实时监测每个Region服务器的状态，当某个Region服务器发生故障时，Zookeeper会通知Master； Master首先会处理该故障Region服务器上面遗留的HLog文件，这个遗留的HLog文件中包含了来自多个Region对象的日志记录； 系统会根据每条日志记录所属的Region对象对HLog数据进行拆分，分别放到相应Region对象的目录下，然后，再将失效的Region重新分配到可用的Region服务器中，并把与该Region对象相关的HLog日志记录也发送给相应的Region服务器； Region服务器领取到分配给自己的Region对象以及与之相关的HLog日志记录以后，会重新做一遍日志记录中的各种操作，把日志记录中的数据写入到MemStore缓存中，然后，刷新到磁盘的StoreFile文件中，完成数据恢复； 共用日志优点：提高对表的写操作性能；缺点：恢复时需要分拆日志。 用户读数据 Client从Hbase读取数据\n访问ZK，获取meta表所在RegionServer和Region 读取meta表，获取所有Region在所有RegionServer上的分布，和每个Region中维护的表数据的范围。 缓存meta表位置和内容。根据表空间、表名、主键和meta表内容，得出待读数据归属的Region和RegionServer，从特定RegionServer读数据。 RegionServer先从MemStore读取数据，如未找到，再从StoreFile中读取。 Shell 查看当前namespace，\n1list_namespace 创建一个新的namespace “test”，\n1create_namespace \u0026#39;test\u0026#39; 并设置最大建表数为10\n1alter_namespace \u0026#39;test\u0026#39;, {METHOD =\u0026gt; \u0026#39;set\u0026#39;, \u0026#39;hbase.namespace.quota.maxtables\u0026#39; =\u0026gt; \u0026#39;10\u0026#39;} 创建一个表test01，有两个列族f1,f2，设置f1的最大版本数为5，设置表的预分区为3个\n1create \u0026#39;test:test01\u0026#39;, {NAME=\u0026gt;\u0026#39;f1\u0026#39;, VERSIONS=\u0026gt;5}, \u0026#39;f2\u0026#39;, SPLITS =\u0026gt; [\u0026#39;10\u0026#39;,\u0026#39;20\u0026#39;,\u0026#39;30\u0026#39;] 创建另一个表test02，有两个列族g1，g2\n1create \u0026#39;test:test02\u0026#39;,\u0026#39;g1\u0026#39;,\u0026#39;g2\u0026#39; 查看namespace test 中的表\n1list 删除表test02中的g2列\n1alter \u0026#39;test:test02, \u0026#39;delete\u0026#39;=\u0026gt;\u0026#39;g2\u0026#39; 修改表test02的的属性MAX_FILESIZE为256128256\n1alter \u0026#39;test:test02\u0026#39;, MAX_FILESIZE=\u0026#39;256128256\u0026#39; 为表test02增加一列s1，设置s1的最大版本数为5\n1alter \u0026#39;test:test02\u0026#39;, {NAME=\u0026gt;\u0026#39;s1\u0026#39;, VERSIONS=\u0026gt;\u0026#39;5\u0026#39;} 删除表test02\n1drop \u0026#39;test:test02\u0026#39; 为表test01添加数据\n1put \u0026#39;test:test01\u0026#39;, \u0026#39;r01\u0026#39;, \u0026#39;f1:name\u0026#39;, \u0026#39;zhang\u0026#39; 2put \u0026#39;test:test01\u0026#39;, \u0026#39;r01\u0026#39;, \u0026#39;f1:num\u0026#39;, \u0026#39;10\u0026#39; 3put \u0026#39;test:test01\u0026#39;, \u0026#39;r01\u0026#39;, \u0026#39;f1:addr\u0026#39;, \u0026#39;shanghai\u0026#39; 4put \u0026#39;test:test01\u0026#39;, \u0026#39;r02\u0026#39;, \u0026#39;f1:name\u0026#39;, \u0026#39;wang\u0026#39; 5put \u0026#39;test:test01\u0026#39;, \u0026#39;r02\u0026#39;, \u0026#39;f2:addr\u0026#39;, \u0026#39;hangzhou\u0026#39; 全表扫描数据\n1scan \u0026#39;test:test01\u0026#39; 查看r02行的name列数据\n1get \u0026#39;test:test01\u0026#39;, \u0026#39;r02\u0026#39;, \u0026#39;f1:name\u0026#39; 删除r02行f2列的数据\n1delete \u0026#39;test:test01\u0026#39;, \u0026#39;r02\u0026#39;, \u0026#39;f2\u0026#39; 清空表test01的数据\n1truncate_preserve \u0026#39;test:test01\u0026#39; 现有以下关系型数据库中的表和数据，要求将其转换为适合于HBase存储的表，绘出表格，然后插入数据，并查看数据。建议用列族的方式来创建。\n学号（S_No） 姓名（S_Name） 年龄（S_Age） 2018001 Lily 21 2018002 Jacky 22 2018003 Mouse 21 课程号（C_No） 课程名（C_Name） 123001 English 123002 Computer 学号（SC_Sno） 课程号（SC_Cno） 成绩（SC_Score） 2018001 123001 89 2018001 123002 78 2018002 123001 90 2018002 123002 69 2018003 123001 78 2018003 1230023 65 构造的HBase表格可以为（仅供参考）\n主键的列名是随机分配的，因此无需创建主键列。\n创建表：create 表名，字段名1 / 列族1，字段名2 / 列族2，……\n1create \u0026#39;scs\u0026#39;,\u0026#39;basic_info\u0026#39;,\u0026#39;score\u0026#39; 插入数据：put 表名，rowkey，字段名1，字段值1\n1put \u0026#39;scs\u0026#39;,\u0026#39;s001\u0026#39;,\u0026#39;basic_info:s_no\u0026#39;,\u0026#39;2018001\u0026#39; 2put \u0026#39;scs\u0026#39;,\u0026#39;s001\u0026#39;,\u0026#39;basic_info:s_name\u0026#39;,\u0026#39;Lily\u0026#39; 3put \u0026#39;scs\u0026#39;,\u0026#39;s001\u0026#39;,\u0026#39;basic_info:s_age\u0026#39;,\u0026#39;21\u0026#39; 4put \u0026#39;scs\u0026#39;,\u0026#39;s001\u0026#39;,\u0026#39;score:english\u0026#39;,\u0026#39;89\u0026#39; 5put \u0026#39;scs\u0026#39;,\u0026#39;s001\u0026#39;,\u0026#39;score:computer\u0026#39;,\u0026#39;78\u0026#39; 查看数据：scan 表名\n1scan \u0026#39;scs\u0026#39; 如果在学生表中为学生增加一项“联系电话（S_Tel）”，如何完成？插入数据后，查看数据。（提示：使用列族，添加列限定符）\n1put \u0026#39;scs\u0026#39;,\u0026#39;s001\u0026#39;,\u0026#39;basic_info:tel\u0026#39;,\u0026#39;185CCCCCCCC\u0026#39; 若查看rowkey为“s001”（值是示例，根据你自己设置的rowkey值进行查询）的所有课程成绩（SC表），如何完成？（提示：get 表名 key值）\n1get \u0026#39;scs\u0026#39;,\u0026#39;s001\u0026#39;,\u0026#39;score\u0026#39; Hive Hive概念 Hive是一个数据仓库基础工具在Hadoop中用来处理结构化数据。\nHive特点 Hive是一个构建于Hadoop顶层的数据仓库工具 支持大规模数据存储、分析，具有良好的可扩展性 某种程度上可以看作是用户编程接口，本身不存储和处理数据 依赖分布式文件系统HDFS存储数据 依赖分布式并行计算模型MapReduce处理数据 定义了简单的类似SQL 的查询语言——HiveQL 用户可以通过编写的HiveQL语句运行MapReduce任务 可以很容易把原来构建在关系数据库上的数据仓库应用程序移植到Hadoop平台上 是一个可以提供有效、合理、直观组织和使用数据的分析工具 Hive具有的特点非常适用于数据仓库 采用批处理方式处理海量数据\n提供适合数据仓库操作的工具\nHive缺点 延迟较高:默认MR为执行引擎,MR延迟较高。\n不支持物化视图 :Hive支持普通视图，不支持物化视图（数据转换成表）。Hive不能在视图上更新、插入、删除数据。\n不适用OLTP :暂不支持列级别的数据添加、更新、删除操作。\n暂不支持存储过程\nHive应用场景 数据挖掘\n非实时分析\n数据汇总\n数据仓库\nHive系统架构 由用户接口模块、驱动模块和元数据存储模块构成\n相关概念 Metastore，存储元数据的角色。Hive将元数据存储在传统的关系型数据库（mysql、derby）中。 Hive中的元数据包括：表的名字、表的数据所在的HDFS目录、数据在目录中的分布规则、以及其他表属性。 正如Oracle使用的SQL方言是PL/SQL，Hive所使用的SQL方言是HQL。 Hive将HQL语句转换成分布式的MapReduce计算任务。 Hive计算引擎可以是Apache MapReduce或者Apache Spark。 Hive数据存储模型 内部表与外部表 表（Table） 表是数据管理和存储的基本对象，由元数据和表数据组成 元数据保存在Metastore中 表的数据保存在存储引擎中，如 HDFS文件系统 Hive+HDFS 表数据保存在HDFS，每个表对应一个目录，表名=目录名。每个数据库对应一个目录，目录名=数据库名.db，表数据是目录内的文件。表目录在数据库目录下。在表目录下，数据还可以按照分区和分桶方式分布。 内部表（Table）/托管表 内部表与关系数据库中的Table在概念上类似； 每个Table在Hive中都有一个相应的目录存储数据； 所有的Table数据（不包括External Table）都保存在这个目录中； 内部表的创建过程和数据加载过程，可以分别独立完成，也可以在同一个语句中完成，在加载数据的过程中，数据会被移动到数据仓库目录中；之后对数据访问将会直接在数据仓库目录中完成。 删除表时，元数据与数据都会被删除。 外部表（ External Table ） 外部表指向已经在HDFS中存在的数据。 它和内部表在元数据的组织上是相同的，而实际数据的存储则有较大的差异。 外部表只有一个过程，创建表和加载数据同时完成（CREATE EXTERNAL TABLE …… LOCATION），实际数据是存储在LOCATION后面指定的HDFS路径中，并不会移动到数据仓库目录中。 删除表时，仅删除该链接，不删除数据。 注意 默认创建内部表/托管表，Hive会将数据移动到数据仓库目录。 创建外部表，这时Hive会到仓库目录以外的位置访问数据。 如果所有处理都由Hive完成，建议使用内部表/托管表。 如果要用Hive和其它工具来处理同一个数据集，建议使用外部表。 内部表 外部表 创建加载可以独立完成 数据移到仓库目录 数据位置不移动 创建加载同时完成 元数据和数据会被一起删除 只删除元数据 分区分桶 分区 通过特定条件将表的数据分发到分区目录中，或者将分区中的数据分发到子分区目录中。\n分区的作用：减少不必要的全表扫描，提升查询效率。 分桶 通过分桶键哈希取模的方式，将表或分区中的数据随机、均匀地分发到N个桶中，桶数N一般为质数，桶编号为0, 1, …, N-1\n分桶的作用：提高取样效率，提高Join查询效率，对应桶抽取数据就好 区别： 分区： 数据表可以按照某个字段的值划分分区。 每个分区是一个目录。 分区数量不固定。 分区下可再有分区或者桶。 分桶 数据可以根据桶的方式将不同数据放入不同的桶中。 每个桶是一个文件。 建表时指定桶个数，桶内可排序。 数据按照某个字段的值Hash后放入某个桶中。 文件格式 Text表 系统默认的表类型，无压缩，行存储，仅支持批量Insert 分析查询的性能较低，主要用于导入原始文本数据时建立过渡表 ORC表 优化的列式存储，轻量级索引，压缩比高，仅支持批量Insert Hive计算的主要表类型，主要用于数仓的离线分析，通常由Text表生成 用户向Hive输入一段命令或查询时，Hive需要与Hadoop交互工作来完成该操作 驱动模块接收该命令或查询编译器 对该命令或查询进行解析编译 由优化器对该命令或查询进行优化计算 该命令或查询通过执行器进行执行 Shell 首先通过show databases命令查看已存在的数据库。然后使用create命令创建一个新的数据库，在本实验中命名为“demo+学号后4位”\n1create database \u0026#39;demo0737\u0026#39;; 使用USE命令，将你创建的demo数据库设置为当前使用的数据库\n1use \u0026#39;demo0737\u0026#39;; 通过create table命令创建一个表，表名users，创建完成后，用describe 表名 命令查看建表结果，确保建表成功。表属性包含：\nid：int，记录编号，具有唯一性\nuid：string，用户id\nitem_id：string，商品id\nbehavior_type：int，包括浏览、收藏、加购物车、购买，分别为1、2、3、4\nitem_category：string，商品分类\nvisit_date：date，该记录产生时间\nprovince：string，用户所在省份\n1create external table users( 2​\tid int,uid string ,item_id string,behavior_type int ,item_category string, visit_date date,province string 3)row format delimited fields terminated by ‘\\t’; 按照给定的附件中表样式（users_table.txt，字段间隔为tab）自己编写更多的txt数据，然后使用load data local inpath +‘路径’命令，注意：local表示加载本地系统中文件的数据，而不是HDFS中的。\n1load data local inpath \u0026#39;./users_table.txt\u0026#39; into table users; 查询visit_date为“2019-11-11”的记录。（给定检索条件）\n1select * from demo0737 where visit_date=\u0026#39;2019-11-11\u0026#39;; 查询visit_date为“2019-11-11”的前5条用户购买商品的商品分类和用户所在省份。（给定检索条件，并限定检索数量，limit）\n1select item_category,province from demo0737 where visit_date=\u0026#39;2019-11-11\u0026#39; limit 5; 使用聚合函数count（）计算出表内有多少行数据\n1select count(*) from demo0737; 查询uid不重复的数据有多少条。（distinct）\n1select distinct uid from demo0737; Spark Spark特点 1.运行速度快\n2.容易使用\n3.通用性\n4.运行模式多样\n与Hadoop的关系 Spark在借鉴Hadoop MapReduce优点的同时，\nSpark编辑模型比Hadoop更灵活， spark提高了内存计算，对于迭代运算效率更高。 Spark基于DAG的任务调度执行机制优于Hadoop的迭代执行机制。 Spark生态系统 主要包含了Spark Core、Spark SQL、Spark Streaming、MLLib和GraphX 等组件。\nSpark生态系统组件应用场景 复杂的批量数据处理\n基于历史数据的交互式查询\n基于实时数据流的数据处理\n基于历史数据的数据挖掘\n图结构数据的处理\nSpark运行架构 集群资源管理器（Cluster Manager）\n运行作业任务的工作节点（Worker Node）\n每个应用的任务控制节点（Driver）\n每个工作节点上负责具体任务的执行进程（Executor）\n一个应用由一个任务控制节点Driver和若干个作业Job构成，一个作业由多个阶段Stage构成，一个阶段由多个没有Shuffle关系的任务Task组成。 当执行一个应用时，Driver会向集群管理器申请资源，启动Executor，并向Executor发送应用程序代码和文件，然后在Executor上执行任务，运行结束后，执行结果会返回给Driver，或者写到HDFS或者其他数据库中。 Spark运行基本流程 SparkContext对象代表了和一个集群的连接\n首先为应用构建起基本的运行环境，即由Driver创建一个SparkContext，进行资源的申请、任务的分配和监控； 资源管理器为Executor分配资源，并启动Executor进程； SparkContext根据RDD的依赖关系构建DAG图，DAG图提交给DAGScheduler解析成Stage，然后把一个个TaskSet提交给底层调度器TaskScheduler处理；Executor向SparkContext申请Task，Task Scheduler将Task发放给Executor运行，并提供应用程序代码； Task在Executor上运行，把执行结果反馈给TaskScheduler，然后反馈给DAGScheduler，运行完毕后写入数据并释放所有资源 。 RDD工作原理 RDD(弹性分布式数据集)概念 一个只读的分区记录集合。不能直接修改，只能基于稳定的物理存储中的数据集创建RDD，或者通过在其他RDD上执行确定的转换操作（如map、join和group by）而创建得到新的RDD。\nRDD执行过程 RDD读入外部数据源进行创建 RDD经过一系列的转换（Transformation）操作，每一次都会产生不同的RDD，供给下一个转换操作使用 最后一个RDD经过“动作”操作进行转换，并输出到外部数据源 这一系列处理称为一个Lineage（血缘关系），即DAG拓扑排序的结果。 优点：惰性调用、管道化、避免同步等待、不需要保存中间结果、每次操作变得简单。\nRDD特性 高效的容错性 中间结果持久化到内存 存放的数据可以是未序列化的Java 对象 宽依赖与窄依赖 窄依赖 一个父RDD的分区对应于一个子RDD的分区或多个父RDD的分区对应于一个子RDD的分区。多对一或一对一\n宽依赖 存在一个父RDD的一个分区对应一个子RDD的多个分区。多对多\nfork/join的优化原理 所以，如果连续的变换操作序列都是窄依赖，就可以把多个fork/join合并为一个，这个过程称为“流水线（pipeline）优化”。\n窄依赖可以实现“流水线”优化 宽依赖无法实现“流水线”优化（节点间需shuffle） 阶段划分 Spark通过分析各个RDD的依赖关系生成了DAG，再通过分析各个RDD中的分区之间的依赖关系来决定如何划分Stage，具体划分方法是：\n在DAG中进行反向解析，遇到宽依赖就断开 遇到窄依赖就把当前的RDD加入到Stage中 将窄依赖尽量划分在同一个Stage中，可以实现流水线计算 被分成三个Stage，在Stage2中，从map到union都是窄依赖，这两步操作可以形成一个流水线操作\nRDD运行原理 创建RDD对象； SparkContext负责计算RDD之间的依赖关系，构建DAG； DAGScheduler负责把DAG图分解成多个Stage，每个Stage中包含了多个Task，每个Task会被TaskScheduler分发给各个WorkerNode上的Executor去执行。 Spark SQL工作原理 将SQL转换成抽象语法树\n将抽象语法树转换成查询块\n将查询块转换成逻辑查询计划\n重写逻辑查询计划\n讲逻辑计划转成物理计划\n选择最佳优化查询策略\nSpark Mllib基本原理 MLlib是Spark的机器学习库，旨在简化机器学习的工程实践工作。Mllib常见机器学习问题：分类、回归、聚类、协同过滤。\nDataFrame 使用 SparkSQL 中的 DataFrame 作为数据集，可以容纳各种数据类型。较之 RDD，DataFrame 包含了 schema 信息，更加类似传统数据库中的二维表。\n它被 ML Pipeline 用来存储源数据。\nTransformer 转换器，是一种可以将一个 DataFrame 转换为另一个 DataFrame 的算法。如一个模型就是一个 Transformer。它可以把一个不包含预测标签的测试集的 DataFrame 打上标签，转化成另一个包含预测标签的 DataFrame。\n大致方法原型为 DataFrame Transformer.transform(DataFrame)\nEstimator 估计器或评估器，它是某种学习算法，或在训练数据上的训练方法的概念抽象。在 Pipeline 里通常是被用来操作 DataFrame 数据并生成一个 Transformer。\n从技术上将，估计器有一个抽象方法 fit () 需要被具体算法去实现，它接收一个 DataFrame 并产生一个转换器。\n大致方法原型如下 Transformer Estimator.fit(DataFrame)。\n即通过 Estimator 对某个数据集进行 fit 操作后得到 Transformer。\nParameter 参数，参数被用来设置 Transformer 或者 Estimator 的参数。现在所有转换器和估计器可共享用于指定参数的公共 API。\nPipeLine 流水线或管道，流水线将多个工作流阶段（转换器和估计器）连接在一起，形成机器学习的工作流，并获得结果输出。\n注意流水线本身也是一个 Estimator，在执行完 fit 操作后，产生一个 PipelineModel，它也是一个 Transformer。\n参考 Hadoop项目结构_weixin_33727510的博客-CSDN博客\n","date":"2022-04-24","img":"","permalink":"/posts/77d147b1/","series":[],"tags":["复习资料"],"title":"大数据技术及应用-复习资料"},{"categories":["算法"],"content":"牛客算法必刷TOP101，包含：链表、二分查找/排序、二叉树、堆/栈/队列、哈希、递归/回溯、动态规划、字符串、双指针、贪心算法、模拟总共101道题。\n此部分是链表专题。\n牛客网 (nowcoder.com)\n反转链表 描述 给定一个单链表的头结点pHead(该头节点是有值的，比如在下图，它的val是1)，长度为n，反转该链表后，返回新链表的表头。\n数据范围： 0≤n≤1000\n要求：空间复杂度 O*(1) ，时间复杂度 O*(*n) 。\n如当输入链表{1,2,3}时，\n经反转后，原链表变为{3,2,1}，所以对应的输出为{3,2,1}。\n以上转换过程如下图所示：\n示例1 输入：\n1{1,2,3} 返回值：\n1{3,2,1}\t示例2 输入：\n1{} 返回值：\n1{} 说明：\n1空链表则输出空 解法 原地置换 分别用三个指针pre,cur,next代表之前的结点，当前的结点，下一个结点。改变链表的指向关系就可以原地改变顺序。\n以下是模拟的过程\n代码如下：\n1class Solution { 2public: 3 ListNode* ReverseList(ListNode* pHead) { 4 ListNode*pre = nullptr; 5 ListNode*cur = pHead; 6 while(cur){ 7 ListNode*next = cur-\u0026gt;next; // 第四步 8 cur-\u0026gt;next = pre; //第一步 9 pre = cur; //第二步 10 cur = next; // 第三步 11 } 12 return pre; 13 } 14}; 链表内指定区间反转 描述 将一个节点数为 size 链表 m 位置到 n 位置之间的区间反转，要求时间复杂度 O(n)O(n)，空间复杂度 O(1)O(1)。 例如： 给出的链表为 1→2→3→4→5→NULL, m*=2,*n=4, 返回 1→4→3→2→5→NULL\n要求：时间复杂度 O(n)O(n) ，空间复杂度 O(n)O(n)\n进阶：时间复杂度 O(n)O(n)，空间复杂度 O(1)O(1)\n示例1 输入：\n1{1,2,3,4,5},2,4 返回值：\n1{1,4,3,2,5} 示例2 输入：\n1{5},1,1 返回值：\n1{5} 解析 解法一 对于这道题，我们可以参考反转链表的题，只需要直到指定的区间的链表，然后断开，将这个区间的链表进行反转。\n注意，由于在此过程中需要保存区间左边和右边的链表，所以需要加上一个新的头结点来处理边界问题。\n1// 反转当前链表 2ListNode *reverse(ListNode *head) { 3 ListNode *pre = nullptr; 4 ListNode *cur = head; 5 ListNode *next = nullptr; 6 while (cur) { 7 next = cur-\u0026gt;next; 8 cur-\u0026gt; 9 next = pre; 10 pre = cur; 11 cur = next; 12 } 13 return pre; 14} 15 16 17ListNode *reverseBetween(ListNode *head, int m, int n) { 18 if (head-\u0026gt;next == nullptr || head == nullptr || m == n) { 19 return 20 head; 21 } 22 // 防止出现pre的问题 23 auto *newHead = new ListNode(0); 24 newHead-\u0026gt;next = head; 25 ListNode *pre = newHead; 26 // 从哪里开始的 27 ListNode *begin = head; 28 // 结束的最后一个结点 29 ListNode *end = nullptr; 30 // 结束断开的下一个 31 ListNode *endEnd = nullptr; 32 // 找到从哪里开始断开 33 for (int i = 0; i \u0026lt; m - 1; i++) { 34 pre = begin; 35 begin = begin-\u0026gt;next; 36 } 37 // 断开左边的 38 pre-\u0026gt;next = nullptr; 39 40 // 从哪里结束 41 end = begin; 42 for (int i = m; i \u0026lt; n; i++) { 43 end = end-\u0026gt;next; 44 } 45 // 右边断开的 46 endEnd = end-\u0026gt;next; 47 // 断开 48 end-\u0026gt;next = nullptr; 49 // 反转区间的链表 50 end = reverse(begin); 51 // 反转之后接上， 区间头变成尾，尾巴变成了头 52 pre-\u0026gt;next = end; 53 begin-\u0026gt;next = endEnd; 54 return newHead-\u0026gt;next; 55} 解法二 利用头插法将新遍历的结点放到前面来。\n将cur的next指向next的next next的next指向pre的next pre的next指向next。 1ListNode *reverseBetween(ListNode *head, int m, int n) { 2 // 防止出现pre的问题 3 auto *newHead = new ListNode(0); 4 newHead-\u0026gt;next = head; 5 ListNode *pre = newHead;\t6 for(int i = 1;i\u0026lt;m;i++){ 7 pre = pre-\u0026gt;next; 8 } 9 cur = pre-\u0026gt;next; 10 for(int i = m;i\u0026lt;n;i++){ 11 ListNode*next = cur-\u0026gt;next; 12 cur-\u0026gt;next= next-\u0026gt;next; 13 next-\u0026gt;next= pre-\u0026gt;next; 14 pre-\u0026gt;next= next; 15 } 16 return newHead-\u0026gt;next; 17} 链表中的节点每k个一组翻转 描述 将给出的链表中的节点每 k 个一组翻转，返回翻转后的链表 如果链表中的节点数不是 k 的倍数，将最后剩下的节点保持原样 你不能更改节点中的值，只能更改节点本身。\n数据范围： 0≤n≤2000 ， 1≤k≤2000 ，链表中每个元素都满足 0≤val≤1000 要求空间复杂度 O(1)，时间复杂度 O(n)\n例如：\n给定的链表是 1→2→3→4→5\n对于 k=2 , 你应该返回 2→1→4→3→5\n对于 k=3 , 你应该返回 3→2→1→4→5\n示例1 输入：\n1{1,2,3,4,5},2 复制\n返回值：\n1{2,1,4,3,5} 复制\n示例2 输入：\n1{},1 复制\n返回值：\n1{} 解析 通过链表指定区间的反转我们知道了利用头插法进行转换链表，这个题也是类似。都反转，对每一组都是指定区间的反转。只需要将k个结点分为一组就行。\n1 ListNode* reverseKGroup(ListNode* head, int k) { 2 int len = 0; 3 ListNode*cur = head; 4 ListNode*newHead = new ListNode(0); 5 newHead-\u0026gt;next = head; 6 // 求出总共有多长 7 while(cur){ 8 len++; 9 cur = cur-\u0026gt;next; 10 } 11 ListNode *pre = newHead; 12 cur = head; 13 // 分成多少组 14 for(int i = 0;i\u0026lt;len/k;i++){ 15 // 组内进行区间反转 16 for(int j = 1;j\u0026lt;k;j++){ 17 ListNode*next = cur-\u0026gt;next; 18 cur-\u0026gt;next=next-\u0026gt;next; 19 next-\u0026gt;next= pre-\u0026gt;next; 20 pre-\u0026gt;next= next; 21 } 22 pre = cur; 23 cur = cur-\u0026gt;next; 24 } 25 return newHead-\u0026gt;next; 26 } 合并两个排序的链表 描述 输入两个递增的链表，单个链表的长度为n，合并这两个链表并使新链表中的节点仍然是递增排序的。\n如输入{1,3,5},{2,4,6}时，合并后的链表为{1,2,3,4,5,6}，所以对应的输出为{1,2,3,4,5,6}\n示例1 输入：\n1{1,3,5},{2,4,6} 返回值：\n1{1,2,3,4,5,6} 复制\n示例2 输入：\n1{},{} 返回值：\n1{} 示例3 输入：\n1{-1,2,4},{1,3,4} 返回值：\n1{-1,1,2,3,4,4} 解析 解法一 利用归并排序的思想，进行模拟即可。\n1ListNode* Merge(ListNode* pHead1, ListNode* pHead2) { 2 ListNode *res = new ListNode(0); 3 ListNode *cur = res; 4 while(pHead1\u0026amp;\u0026amp;pHead2){ 5 if(pHead1-\u0026gt;val\u0026lt;=pHead2-\u0026gt;val){ 6 cur-\u0026gt;next = pHead1; 7 pHead1 = pHead1-\u0026gt;next; 8 }else{ 9 cur-\u0026gt;next = pHead2; 10 pHead2 = pHead2-\u0026gt;next; 11 } 12 cur = cur-\u0026gt;next; 13 } 14 if(pHead1){ 15 cur-\u0026gt;next = pHead1; 16 } 17 if(pHead2){ 18 cur-\u0026gt;next = pHead2; 19 } 20 return res-\u0026gt;next; 21} 解法二 我们利用归并思想不断合并两个链表，每当我们添加完一个节点后，该节点指针后移，相当于这个链表剩余部分与另一个链表剩余部分合并，两个链表剩余部分合并就是原问题两个有序链表合并的子问题，因此也可以使用递归：\n终止条件： 当一个链表已经因为递归到了末尾，另一个链表剩余部分一定都大于前面的，因此我们可以将另一个链表剩余部分拼在结果后面，结束递归。 返回值： 每次返回拼接好的较大部分的子链表。 本级任务： 每级不断进入下一个较小的值后的链表部分与另一个链表剩余部分，再将本次的节点接在后面较大值拼好的结果前面。 具体做法：\nstep 1：每次比较两个链表当前节点的值，然后取较小值的链表指针往后，另一个不变，两段子链表作为新的链表送入递归中。 step 2：递归回来的结果我们要加在当前较小值的节点后面，相当于不断在较小值后面添加节点。 step 3：递归的终止是两个链表有一个为空。 1// 每次返回拼接好的较大部分的子链表 2ListNode* Merge(ListNode* pHead1, ListNode* pHead2) { 3 //一个已经为空了，返回另一个 4 if(pHead1==nullptr){ 5 return pHead2; 6 } 7 if(pHead2==nullptr){ 8 return pHead1; 9 } 10 11 if(pHead1-\u0026gt;val\u0026lt;=pHead2-\u0026gt;val){ 12 pHead1-\u0026gt;next = Merge(pHead1-\u0026gt;next, pHead2); 13 return pHead1; 14 }else{ 15 pHead2-\u0026gt;next = Merge(pHead1, pHead2-\u0026gt;next); 16 return pHead2; 17 } 18} 合并k个已排序的链表 描述 合并 k 个升序的链表并将结果作为一个升序的链表返回其头节点。\n数据范围：节点总数满足 0≤n≤105，链表个数满足 1≤k≤10^5 ，每个链表的长度满足 1≤len≤200 ，每个节点的值满足 |val| \u0026lt;= 1000\n要求：时间复杂度 O(nlogk)\n示例1 输入：\n1[{1,2,3},{4,5,6,7}] 返回值：\n1{1,2,3,4,5,6,7} 示例2 输入：\n1[{1,2},{1,4,5},{6}] 返回值：\n1{1,1,2,4,5,6} 解析 解析1-超时 上面已经完成了两个排序链表的合并,两个链表两两进行合并就行。但是时间复杂度是O(n*k)不满足时间要求。\n1 ListNode*merge(ListNode*list1,ListNode*list2){ 2 ListNode * res = new ListNode(0); 3 ListNode *cur = res; 4 while(list1\u0026amp;\u0026amp;list2){ 5 if(list1-\u0026gt;val\u0026lt;=list2-\u0026gt;val){ 6 cur-\u0026gt;next = list1; 7 list1 = list1-\u0026gt;next; 8 }else{ 9 cur-\u0026gt;next = list2; 10 list2 = list2-\u0026gt;next; 11 } 12 cur =cur-\u0026gt;next; 13 } 14 if(list1){ 15 cur-\u0026gt;next = list1; 16 } 17 if(list2){ 18 cur-\u0026gt;next = list2; 19 } 20 return res-\u0026gt;next; 21 } 22 ListNode *mergeKLists(vector\u0026lt;ListNode *\u0026gt; \u0026amp;lists) { 23 ListNode *res ; 24 for(int i = 0;i\u0026lt;lists.size();i++){ 25 res = merge(res, lists[i]); 26 } 27 return res; 28 } 解析2 上述中，我们是让合并好的再和新的进行合并，其实我们可以让新的链表两两合并，减少额外的合并次数。降低时间复杂度。\n1 ListNode*merge(ListNode*list1,ListNode*list2){ 2 ListNode * res = new ListNode(0); 3 ListNode *cur = res; 4 while(list1\u0026amp;\u0026amp;list2){ 5 if(list1-\u0026gt;val\u0026lt;=list2-\u0026gt;val){ 6 cur-\u0026gt;next = list1; 7 list1 = list1-\u0026gt;next; 8 }else{ 9 cur-\u0026gt;next = list2; 10 list2 = list2-\u0026gt;next; 11 } 12 cur =cur-\u0026gt;next; 13 } 14 if(list1){ 15 cur-\u0026gt;next = list1; 16 } 17 if(list2){ 18 cur-\u0026gt;next = list2; 19 } 20 return res-\u0026gt;next; 21 } 22 23 // 分组进行合并 24 ListNode* groupMerge(vector\u0026lt;ListNode *\u0026gt; \u0026amp;lists,int left,int right){ 25 // 中间只有一个的情况 26 if(left==right){ 27 return lists[left]; 28 } 29 if(left\u0026gt;right){ 30 return nullptr; 31 } 32 // 从中间分开两段，分开的部分进行合并 33 int mid = (left+right)\u0026gt;\u0026gt;1; 34 // 合并的两部分再进行合并 35 return merge(groupMerge(lists, left, mid), groupMerge(lists, mid+1, right)); 36 37 } 38 ListNode *mergeKLists(vector\u0026lt;ListNode *\u0026gt; \u0026amp;lists) { 39 return groupMerge(lists, 0, lists.size()-1); 40 } 判断链表中是否有环 描述 判断给定的链表中是否有环。如果有环则返回true，否则返回false。\n数据范围：链表长度 0≤n≤10000，链表中任意节点的值满足 |val| \u0026lt;= 100000\n要求：空间复杂度 O(1),时间复杂度 O(n)\n输入分为两部分，第一部分为链表，第二部分代表是否有环，然后将组成的head头结点传入到函数里面。-1代表无环，其它的数字代表有环，这些参数解释仅仅是为了方便读者自测调试。实际在编程时读入的是链表的头节点。\n例如输入{3,2,0,-4},1时，对应的链表结构如下图所示：\n可以看出环的入口结点为从头结点开始的第1个结点（注：头结点为第0个结点），所以输出true。\n示例1 输入：\n1{3,2,0,-4},1 返回值：\n1true 说明：\n1第一部分{3,2,0,-4}代表一个链表，第二部分的1表示，-4到位置1（注：头结点为位置0），即-4-\u0026gt;2存在一个链接，组成传入的head为一个带环的链表，返回true 示例2 输入：\n1{1},-1 返回值：\n1false 说明：\n1第一部分{1}代表一个链表，-1代表无环，组成传入head为一个无环的单链表，返回false 示例3 输入：\n1{-1,-7,7,-4,19,6,-9,-5,-2,-5},6 返回值：\n1true 解析 方法1-哈希表 将已经遍历过的结点保存在map中，如果map中已经有了，就说明有环，整个链表遍历完之后都没有，就说明没有环。\n1bool hasCycle(ListNode* head) { 2 map\u0026lt;ListNode*, bool\u0026gt; m; 3 while (head) { 4 auto a = m.find(head); 5 if (a != m.end()) { 6 return true; 7 } else { 8 m[head] = true; 9 } 10 head = head-\u0026gt;next; 11 } 12 return false; 13} 方法2-双指针 一个快指针走两步，一个慢指针走一步。当两个指针相遇的时候就说明，是有环的。证明过程如下：\n「代码随想录」你的疑惑，这里都讲清楚了！142. 环形链表 II - 环形链表 II - 力扣（LeetCode） (leetcode-cn.com)\n1bool hasCycle(ListNode* head) { 2 ListNode* fast = head; 3 ListNode* slow = head; 4 while (fast \u0026amp;\u0026amp; fast-\u0026gt;next) { 5 fast = fast-\u0026gt;next-\u0026gt;next; 6 slow = slow-\u0026gt;next; 7 if (fast == slow) { 8 return true; 9 } 10 } 11 return false; 12} 链表中环的入口结点 给一个长度为n链表，若其中包含环，请找出该链表的环的入口结点，否则，返回null。\n数据范围：n*≤10000，1\u0026lt;=结点值\u0026lt;=10000\n要求：空间复杂度 O(1)，时间复杂度 O(n)\n例如，输入{1,2},{3,4,5}时，对应的环形链表如下图所示：\n可以看到环的入口结点的结点值为3，所以返回结点值为3的结点。\n输入描述： 输入分为2段，第一段是入环前的链表部分，第二段是链表环的部分，后台会根据第二段是否为空将这两段组装成一个无环或者有环单链表\n返回值描述： 返回链表的环的入口结点即可，我们后台程序会打印这个结点对应的结点值；若没有，则返回对应编程语言的空结点即可。\n示例1 输入：\n1{1,2},{3,4,5} 返回值：\n13 说明：\n1返回环形链表入口结点，我们后台程序会打印该环形链表入口结点对应的结点值，即3 示例2 输入：\n1{1},{} 返回值：\n1\u0026#34;null\u0026#34; 说明：\n1没有环，返回对应编程语言的空结点，后台程序会打印\u0026#34;null\u0026#34; 示例3 输入：\n1{},{2} 返回值：\n12 说明：\n1环的部分只有一个结点，所以返回该环形链表入口结点，后台程序打印该结点对应的结点值，即2 解析 解析1-哈希表 和判断链表中是否有环是一样的，如果map中有就说明这个位置就是环，否则就是没有环。\n1ListNode* EntryNodeOfLoop(ListNode* head) { 2 map\u0026lt;ListNode*, bool\u0026gt; m; 3 while (head) { 4 auto a = m.find(head); 5 if (a != m.end()) { 6 return a.first; 7 } else { 8 m[head] = true; 9 } 10 head = head-\u0026gt;next; 11 } 12 return nullptr; 13} 解析2-双指针 一个快指针走两步，一个慢指针走一步。当两个指针相遇的时候就说明，是有环的。有环之后，让头指针和相遇的指针一起走，相遇之后就是环的入口：\n「代码随想录」你的疑惑，这里都讲清楚了！142. 环形链表 II - 环形链表 II - 力扣（LeetCode） (leetcode-cn.com)\n1ListNode* EntryNodeOfLoop(ListNode* pHead) { 2 ListNode* fast = pHead; 3 ListNode* slow = pHead; 4 while (fast \u0026amp;\u0026amp; fast-\u0026gt;next) { 5 fast = fast-\u0026gt;next-\u0026gt;next; 6 slow = slow-\u0026gt;next; 7 if (fast == slow) { 8 while(fast!=pHead){ 9 fast = fast-\u0026gt;next; 10 pHead = pHead-\u0026gt;next; 11 } 12 return fast; 13 } 14 } 15 return nullptr; 16 } 链表中倒数最后k个结点 描述 输入一个长度为 n 的链表，设链表中的元素的值为 ai ，返回该链表中倒数第k个节点。\n如果该链表长度小于k，请返回一个长度为 0 的链表。\n数据范围：$0 \\leq n \\leq 10^50≤n≤105$，$0 \\leq a_i \\leq 10^9$，$0 \\leq k \\leq 10^9$\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n进阶：空间复杂度 O(1)，时间复杂度 O(n)\n例如输入{1,2,3,4,5},2时，对应的链表结构如下图所示：\n其中蓝色部分为该链表的最后2个结点，所以返回倒数第2个结点（也即结点值为4的结点）即可，系统会打印后面所有的节点来比较。\n示例1 输入：\n1{1,2,3,4,5},2 返回值：\n1{4,5} 说明：\n1返回倒数第2个节点4，系统会打印后面所有的节点来比较。 示例2 输入：\n1{2},8 返回值：\n1{} 解析 解法1-数组 将链表的每一个结点按照顺序保存到数组中，按照要求求出当前倒数第几个结点。\n解法2-遍历两遍 第一遍求出链表的长度，第二遍遍历到倒数第k个结点。\n1ListNode* FindKthToTail(ListNode* pHead, int k) { 2 int len = 0; 3 ListNode* cur = pHead; 4 // 求长度 5 while (cur) { 6 len++; 7 cur = cur-\u0026gt;next; 8 } 9 // 指向头 10 cur = pHead; 11 // 如果超过长度了，返回空 12 if (k \u0026gt; len) { 13 return nullptr; 14 } 15 len -= k; 16 while (len \u0026gt; 0) { 17 cur = cur-\u0026gt;next; 18 len--; 19 } 20 return cur; 21 } 删除链表的倒数第n个节点 描述 给定一个链表，删除链表的倒数第 n 个节点并返回链表的头指针.\n例如，给出的链表为: $1\\to 2\\to 3\\to 4\\to 5$, n= 2,删除了链表的倒数第 n 个节点之后,链表变为$1\\to 2\\to 3\\to 5$。\n数据范围： 链表长度 $0\\le n \\le 1000$，链表中任意节点的值满足 $0 \\le val \\le 100$\n要求：空间复杂度 $O(1)$，时间复杂度 $O(n)$\n题目保证 $n$一定是有效的\n示例1 输入：\n1{1,2},2 返回值：\n1{2} 解析 解析1-求长度，找到倒数第n+1个结点 利用链表中倒数第k个结点可以找到倒数第n+1个结点，根据倒数第$n+1$个结点，使用$cur\\to next = cur\\to next\\to next$删除倒数第n个结点。\n1ListNode* removeNthFromEnd(ListNode* head, int n) { 2 ListNode *newHead = new ListNode(0); 3 newHead-\u0026gt;next = head; 4 // 找到倒数第n+1个元素 5 int len = 0; 6 ListNode *cur = newHead; 7 while(cur){ 8 len++; 9 cur = cur-\u0026gt;next; 10 } 11 cur = newHead; 12 // 这里的n+2是因为添加了一个新的头结点。 13 len-=n+2; 14 while(len\u0026gt;-1){ 15 cur = cur-\u0026gt;next; 16 len--; 17 } 18 19 cur-\u0026gt;next = cur-\u0026gt;next-\u0026gt;next; 20 return newHead-\u0026gt;next; 21} 解析2-双指针 快指针指向head,快指针先走n步。慢指针指向新的头结点，当快指针走完n步之后，慢指针跟着快指针走完全部的。这时候慢指针指向的是倒数第n+1个结点，然后利用$cur\\to next = cur\\to next\\to next$删除倒数第n个结点。\n重要！！！！\n快指针指向head,快指针先走n步 慢指针指向newHead,跟随快指针走，等到快指针走完，这时候，慢指针就在倒数第n+1个结点。 1ListNode* removeNthFromEnd(ListNode* head, int n) { 2 ListNode *newHead = new ListNode(0); 3 newHead-\u0026gt;next = head; 4 // 快指针指向head 5 ListNode*fast = head; 6 // 慢指针指向newHead 7 ListNode*slow = newHead; 8 // 快指针先走n步 9 while(n\u0026gt;0){ 10 n--; 11 fast = fast-\u0026gt;next; 12 } 13 // 快指针走完全部 14 while(fast){ 15 fast = fast-\u0026gt;next; 16 slow = slow-\u0026gt;next; 17 } 18 // 慢指针在倒数第n+1个结点 19 slow-\u0026gt;next = slow-\u0026gt;next-\u0026gt;next; 20 return newHead-\u0026gt;next; 21} 两个链表的第一个公共结点 描述 输入两个无环的单向链表，找出它们的第一个公共结点，如果没有公共节点则返回空。（注意因为传入数据是链表，所以错误测试数据的提示是用其他方式显示的，保证传入数据是正确的）\n数据范围： $n \\le 1000$ 要求：空间复杂度 O(1)O(1)，时间复杂度 $O(n)$\n例如，输入{1,2,3},{4,5},{6,7}时，两个无环的单向链表的结构如下图所示：\n可以看到它们的第一个公共结点的结点值为6，所以返回结点值为6的结点。\n输入描述： 输入分为是3段，第一段是第一个链表的非公共部分，第二段是第二个链表的非公共部分，第三段是第一个链表和第二个链表的公共部分。 后台会将这3个参数组装为两个链表，并将这两个链表对应的头节点传入到函数FindFirstCommonNode里面，用户得到的输入只有pHead1和pHead2。\n返回值描述： 返回传入的pHead1和pHead2的第一个公共结点，后台会打印以该节点为头节点的链表。\n示例1 输入：\n1{1,2,3},{4,5},{6,7} 返回值：\n1{6,7} 说明：\n1第一个参数{1,2,3}代表是第一个链表非公共部分，第二个参数{4,5}代表是第二个链表非公共部分，最后的{6,7}表示的是2个链表的公共部分 2这3个参数最后在后台会组装成为2个两个无环的单链表，且是有公共节点的 示例2 输入：\n1{1},{2,3},{} 返回值：\n1{} 说明：\n12个链表没有公共节点 ,返回null，后台打印{} 解析 解析1-求长度，从最短的进行比较。 求出两个链表的长度，找出最短的一个链表，较长的链表遍历到和较短的链表长度一样，进行比较链表。\n注意：\n比较的是链表指针，不是值。 1ListNode* FindFirstCommonNode( ListNode* pHead1, ListNode* pHead2) { 2 int len1 = 0; 3 int len2 = 0; 4 ListNode*cur = pHead1; 5 // 求链表1的长度 6 while(cur){ 7 len1++; 8 cur = cur-\u0026gt;next; 9 } 10 // 求链表二的长度 11 cur = pHead2; 12 while(cur){ 13 len2++; 14 cur=cur-\u0026gt;next; 15 } 16 // 找出长的一个，遍历到和短的一样。 17 if(len1\u0026gt;len2){ 18 len1-=len2; 19 while(len1\u0026gt;0){ 20 pHead1=pHead1-\u0026gt;next; 21 len1--; 22 } 23 }else{ 24 len2-=len1; 25 while(len2\u0026gt;0){ 26 pHead2 = pHead2-\u0026gt;next; 27 len2--; 28 } 29 } 30 // 两个进行比较 31 while(pHead1){ 32 if(pHead1==pHead2){ 33 return pHead1; 34 } 35 pHead1 = pHead1-\u0026gt;next; 36 pHead2 = pHead2-\u0026gt;next; 37 } 38 return nullptr; 39 } 解析2-遍历两次结点 使用两个指针N1,N2，一个从链表1的头节点开始遍历，我们记为N1，一个从链表2的头节点开始遍历，我们记为N2。\n让N1和N2一起遍历，当N1先走完链表1的尽头（为null）的时候，则从链表2的头节点继续遍历，同样，如果N2先走完了链表2的尽头，则从链表1的头节点继续遍历，也就是说，N1和N2都会遍历链表1和链表2。\n因为两个指针，同样的速度，走完同样长度（链表1+链表2），不管两条链表有无相同节点，都能够到达同时到达终点。\n（N1最后肯定能到达链表2的终点，N2肯定能到达链表1的终点）。\n所以，如何得到公共节点：\n有公共节点的时候，N1和N2必会相遇，因为长度一样嘛，速度也一定，必会走到相同的地方的，所以当两者相等的时候，则会第一个公共的节点 无公共节点的时候，此时N1和N2则都会走到终点，那么他们此时都是null，所以也算是相等了 题解 | #两个链表的第一个公共结点#_牛客博客 (nowcoder.net)\n1ListNode* FindFirstCommonNode( ListNode* pHead1, ListNode* pHead2) { 2 ListNode*n1 = pHead1; 3 ListNode*n2 = pHead2; 4 while(n1!=n2){ 5 if(!n1){ 6 n1 = pHead2; 7 }else{ 8 n1 = n1-\u0026gt;next; 9 } 10 11 if(!n2){ 12 n2 = pHead1; 13 }else{ 14 n2 = n2-\u0026gt;next; 15 } 16 } 17 return n1; 18 } 链表相加(二) 描述 假设链表中每一个节点的值都在 0 - 9 之间，那么链表整体就可以代表一个整数。\n给定两个这种链表，请生成代表两个整数相加值的结果链表。\n数据范围：$0 \\le n,m \\le 1000000$，链表任意值 要求：空间复杂度 $O(n)$，时间复杂度 $O(n)$\n例如：链表 1 为 9-\u0026gt;3-\u0026gt;7，链表 2 为 6-\u0026gt;3，最后生成新的结果链表为 1-\u0026gt;0-\u0026gt;0-\u0026gt;0。\n示例1 输入：\n1[9,3,7],[6,3] 返回值：\n1{1,0,0,0} 说明：\n1如题面解释 示例2 输入：\n1[0],[6,3] 返回值：\n1{6,3} 解析 解析1-链表反转求和 由于所给的链表的头结点是最高位，而我们运算是从最低位开始相加，在运算之前先将链表反转为从低位开始。\n对于求和可以正常的模拟加法求和就可以。\n注意\n逢十进一 如果有进位要相加 最后有进位要额外新建结点。 1ListNode*reverse(ListNode*list){ 2 ListNode*pre = nullptr; 3 ListNode*cur = list; 4 while(cur){ 5 ListNode*next = cur-\u0026gt;next; 6 cur-\u0026gt;next = pre; 7 pre = cur; 8 cur = next; 9 } 10 return pre; 11} 12ListNode* addInList(ListNode* head1, ListNode* head2){ 13 int add = 0; 14 head1 = reverse(head1); 15 head2 = reverse(head2); 16 ListNode *pre = nullptr; 17 while(add||head1||head2){ 18 int val = add; 19 if(head1){ 20 val+=head1-\u0026gt;val; 21 head1=head1-\u0026gt;next; 22 } 23 if(head2){ 24 val+=head2-\u0026gt;val; 25 head2 =head2-\u0026gt;next; 26 } 27 add = val/10; 28 val = val%10; 29 ListNode*cur = new ListNode(val); 30 cur-\u0026gt;next = pre; 31 pre = cur; 32 } 33 return pre; 34} 解析2-栈实现反转链表 与方法一相同，只不过反转链表的时候是用了栈。\n单链表的排序 描述 给定一个节点数为n的无序单链表，对其按升序排序。\n数据范围：$0 \u0026lt; n \\le 100000$\n要求：时间复杂度 $O(nlogn)$\n示例1 输入：\n1{1,3,2,4,5} 返回值：\n1{1,2,3,4,5} 解析 解析1-归并排序 1 //合并两段有序链表 2 ListNode* merge(ListNode* pHead1, ListNode* pHead2) { 3 if(pHead1 == NULL) 4 return pHead2; 5 if(pHead2 == NULL) 6 return pHead1; 7 ListNode* head = new ListNode(0); 8 ListNode* cur = head; 9 while(pHead1 \u0026amp;\u0026amp; pHead2){ 10 if(pHead1-\u0026gt;val \u0026lt;= pHead2-\u0026gt;val){ 11 cur-\u0026gt;next = pHead1; 12 pHead1 = pHead1-\u0026gt;next; 13 }else{ 14 cur-\u0026gt;next = pHead2; 15 pHead2 = pHead2-\u0026gt;next; 16 } 17 cur = cur-\u0026gt;next; 18 } 19 if(pHead1) 20 cur-\u0026gt;next = pHead1; 21 else 22 cur-\u0026gt;next = pHead2; 23 return head-\u0026gt;next; 24 } 25 26\t// 归并排序递归版 27 ListNode* sortInList(ListNode* head) { 28 if(head==nullptr||head-\u0026gt;next==nullptr){ 29 return head; 30 } 31 // 中间结点的前一个，整个链表要断开 32 ListNode*midPre = head; 33 ListNode*mid = head-\u0026gt;next; 34 ListNode*right = head-\u0026gt;next-\u0026gt;next; 35 while(right\u0026amp;\u0026amp;right-\u0026gt;next){ 36 midPre = midPre-\u0026gt;next; 37 mid = mid-\u0026gt;next; 38 right = right-\u0026gt;next-\u0026gt;next; 39 } 40 // 断开链表 41 midPre-\u0026gt;next = nullptr; 42 // 归并排序的左边和右边。 43 return merge(sortInList(head),sortInList(mid)); 44 45 } 判断一个链表是否为回文结构 描述 给定一个链表，请判断该链表是否为回文结构。\n回文是指该字符串正序逆序完全一致。\n数据范围： 链表节点数 0 \\le n \\le 10^50≤n≤105，链表中每个节点的值满足 |val| \\le 10^7∣val∣≤107\n示例1 输入：\n1{1} 返回值：\n1true 示例2 输入：\n1{2,1} 返回值：\n1false 说明：\n12-\u0026gt;1 示例3 输入：\n1{1,2,2,1} 返回值：\n1true 说明：\n11-\u0026gt;2-\u0026gt;2-\u0026gt;1 解析 解析1-反转链表进行比较 从中间将整个链表一分为二，对右边进行反转，反转过来的链表在与之前的链表进行比较。\n注意\n区分链表结点个数是奇数还是偶数，如果是奇数，应该把多的一部分的结点放在左边，例如是1-\u0026gt;2-\u0026gt;4-\u0026gt;2-\u0026gt;3,分开的链表应该是1-\u0026gt;2-\u0026gt;4和2-\u0026gt;3,然后将右边的进行反转。只要将结点少的进行反转就可以 1// 链表反转 2ListNode*reverse(ListNode*list){ 3 ListNode*pre = nullptr; 4 ListNode*cur = list; 5 ListNode*next = nullptr; 6 while(cur){ 7 next = cur-\u0026gt;next; 8 cur-\u0026gt;next = pre; 9 pre = cur; 10 cur = next; 11 } 12 return pre; 13 } 14 /** 15 * 16 * @param head ListNode类 the head 17 * @return bool布尔型 18 */ 19 bool isPail(ListNode* head) { 20 // 如果只有一个结点，肯定是回文的。 21 if(head-\u0026gt;next==nullptr){ 22 return true; 23 } 24 ListNode*midPre = head; 25 ListNode*mid = head-\u0026gt;next; 26 ListNode*right =mid-\u0026gt;next; 27 // 找到中间的结点 28 while(right\u0026amp;\u0026amp;right-\u0026gt;next){ 29 midPre = midPre-\u0026gt;next; 30 mid = mid-\u0026gt;next; 31 right = right-\u0026gt;next-\u0026gt;next; 32 } 33 // 断开中间的结点 34 midPre-\u0026gt;next = nullptr; 35 // 反转结点少的链表 36 mid = reverse(mid); 37 // 判断 38 while(head\u0026amp;\u0026amp;mid){ 39 if(head-\u0026gt;val!=mid-\u0026gt;val){ 40 return false; 41 } 42 head = head-\u0026gt;next; 43 mid = mid-\u0026gt;next; 44 } 45 return true; 46 } 删除有序链表中重复的元素-I 描述 删除给出链表中的重复元素（链表中元素从小到大有序），使链表中的所有元素都只出现一次 例如： 给出的链表为$1\\to1\\to2$,返回$1 \\to 2$. 给出的链表为$1\\to1\\to 2 \\to 3 \\to 3$,返回$1\\to 2 \\to 3$.\n数据范围：链表长度满足 $0 \\le n \\le 100$，链表中任意节点的值满足$ |val| \\le 100$\n进阶：空间复杂度 O(1)，时间复杂度 O(n)\n示例1 输入：\n1{1,1,2} 返回值：\n1{1,2} 示例2 输入：\n1{} 返回值：\n1{} 解析 解析1-模拟 比较当前结点的值和之前结点的值是否一样，如果一样当前结点的next指向cur-\u0026gt;next-\u0026gt;next。否则指向cur-\u0026gt;next。\n1ListNode* deleteDuplicates(ListNode* head) { 2 ListNode*cur = head; 3 while(cur\u0026amp;\u0026amp;cur-\u0026gt;next){ 4 if(cur-\u0026gt;val==cur-\u0026gt;next-\u0026gt;val){ 5 cur-\u0026gt;next = cur-\u0026gt;next-\u0026gt;next; 6 }else{ 7 cur = cur-\u0026gt;next; 8 } 9 } 10 return head; 11 } 链表的奇偶重排 给定一个单链表，请设定一个函数，将链表的奇数位节点和偶数位节点分别放在一起，重排后输出。\n注意是节点的编号而非节点的数值。\n数据范围：节点数量满足 $0 \\le n \\le 10^5$，节点中的值都满足 $0 \\le val \\le 1000$\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n示例1 输入：\n1{1,2,3,4,5,6} 返回值：\n1{1,3,5,2,4,6} 说明：\n11-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;5-\u0026gt;6-\u0026gt;NULL 2重排后为1-\u0026gt;3-\u0026gt;5-\u0026gt;2-\u0026gt;4-\u0026gt;6-\u0026gt;NULL 3 示例2 输入：\n1{1,4,6,3,7} 返回值：\n1{1,6,7,4,3} 说明：\n11-\u0026gt;4-\u0026gt;6-\u0026gt;3-\u0026gt;7-\u0026gt;NULL 2重排后为 31-\u0026gt;6-\u0026gt;7-\u0026gt;4-\u0026gt;3-\u0026gt;NULL 4奇数位节点有1,6,7，偶数位节点有4,3。重排后为1,6,7,4,3 解析 解析1-分别保存奇偶指针 分别保存奇偶指针，奇指针指向head，偶指针指向head-\u0026gt;next，奇偶指针每次向后移动两位就可以。\n1ListNode* oddEvenList(ListNode* head) { 2 // 如果只有一或两个结点，就返回head 3 if(head==nullptr||head-\u0026gt;next==nullptr){ 4 return head; 5 } 6 // 开始奇数指针指向头 7 ListNode*jishu = head; 8 // 偶数指针要记录偶数的头结点，后面要连起来 9 ListNode*oushuBegin = head-\u0026gt;next; 10 // 每次更新的偶数结点 11 ListNode*oushuCur = oushuBegin; 12 // 偶数结点有 13 while(oushuCur\u0026amp;\u0026amp;oushuCur-\u0026gt;next){ 14 // 更新奇数结点 15 jishu-\u0026gt;next = oushuCur-\u0026gt;next; 16 jishu = jishu-\u0026gt;next; 17 // 更新偶数结点，此时奇数结点指向的时上一个偶数结点的next 18 oushuCur-\u0026gt;next = jishu -\u0026gt; next; 19 oushuCur = oushuCur-\u0026gt;next; 20 } 21 // ji 22 jishu-\u0026gt;next = oushuBegin; 23 return head; 24} 删除有序链表中重复的元素-II 描述 给出一个升序排序的链表，删除链表中的所有重复出现的元素，只保留原链表中只出现一次的元素。 例如： 给出的链表为$1 \\to 2\\to 3\\to 3\\to 4\\to 4\\to5$, 返回$1\\to 2\\to5$. 给出的链表为$1\\to1 \\to 1\\to 2 \\to 3$, 返回$2\\to 3$.\n数据范围：链表长度 $0 \\le n \\le 10000$，链表中的值满足 $|val| \\le 1000$\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n进阶：空间复杂度 O(1)，时间复杂度 O(n)\n示例1 输入：\n1{1,2,2} 返回值：\n1{1} 示例2 输入：\n1{} 返回值：\n1{} 解析 解析一 一次判断两个结点，如果两个结点的值不一样，就向前探索。\n如果这两个结点的值一样，那么就一直往下探索到下一个值得结点。\n1ListNode* deleteDuplicates(ListNode* head) { 2 if(head==nullptr){ 3 return head; 4 } 5 ListNode *newHead = new ListNode(head-\u0026gt;val-1); 6 newHead-\u0026gt;next = head; 7 ListNode *cur = head; 8 ListNode *pre =newHead; 9 while(cur\u0026amp;\u0026amp;cur-\u0026gt;next){ 10 if(cur-\u0026gt;val==cur-\u0026gt;next-\u0026gt;val){ 11 int t = cur-\u0026gt;val; 12 while(cur\u0026amp;\u0026amp;cur-\u0026gt;val==t){ 13 cur = cur-\u0026gt;next; 14 } 15 pre-\u0026gt;next = cur; 16 }else{ 17 pre = cur; 18 cur=cur-\u0026gt;next; 19 } 20 } 21 return newHead-\u0026gt;next; 22} 总结 刷题时间 时间 题目 4-22 反转链表 4-22 链表指定区间反转 4-24 链表每k个结点反转 4-24 合并两个有序链表 4-25 合并k个有序链表 4-25 判断链表中有环 4-25 判断链表中环的入口 4-25 链表中倒数第k个结点 4-26 删除链表的倒数第n个结点 4-26 两个链表的第一个公共结点 4-26 链表相加 4-26 单链表排序 4-26 判断链表是否为回文链表 4-26 删除有序链表中的重复元素-Ⅰ 4-28 链表的奇偶重拍 4-28 删除有序链表中重复元素-Ⅱ 技巧总结 链表的题目首先要在纸上模拟好过程，对于结点的指向清楚之后写代码很清楚。 新的头结点很重要，可以帮助我们处理很多边界问题。 反转链表有两种高效的方法 利用头插法反转，每次探索到的新结点都以头插法的方式放到头部。 断开遍历的下一个结点 合并链表就是归并处理。 合并k个有序链表，链表两两进行合并，合并之后再合并。归并排序的思想 链表是否有环，如果有环，类似两个不同速度的人一起在环里跑步，一定会相遇。 判断环的入口，要涉及到数学证明 链表中的倒数第k个结点，最优的应该是快慢指针，让快指针先走k次，然后慢指针一起走完。同时删除也是类似。 链表相加，可以先将链表反转之后进行模拟 单链表排序，链表排序使用不了快排，只能用归并排序 判断是否是回文，反转后半部分链表与前半部分进行比较 重刷总结 // todo\n","date":"2022-04-22","img":"","permalink":"/posts/70f03d51/","series":["牛客TOP101"],"tags":["算法","牛客TOP101"],"title":"Newcoder Top 101 链表专题"},{"categories":["面试"],"content":"【第三届字节跳动青训营｜刷题打卡】记录\nday-one 【多选】Golang 通过plugin.(*Plugin).Lookup函数可以查找到插件里面定义的哪些东西？ A. 变量\tB. 函数 C. 类型\tD. 包\n自己答案 答案: ab 来源src/plugin/plugin.go:35\n1 // A symbol is any exported variable or function. 2 func (p *Plugin) Lookup(symName string) (Symbol, error) { 3 return lookup(p, symName) 4 } 官方解析 a和b都是能被赋值给interface{}类型的变量，但是c和d不能。因此Lookup方法返回的结果是一个interface{}类型（Symbol类型）的变量，因此c和d不能通过Lookup返回。\nGo进阶25:Go插件plugin教程 | 🐶❤️🦀 (mojotv.cn)这篇文章介绍了plugin。\n假如在抖音中发布视频时，可以选择带上位置信息，请设计一种数据结构或方案，用于存储检索位置信息（简化为平面坐标 x, y），以实现搜索附近视频的功能（如附近 3km） 自己答案 使用了Geohash原理。顺便了解一下Geohash的原理。\n大家可以看一下后面的参考文章，以下内容都是从参考文章中摘录出来，方便理解用的。\n介绍 首先，GeoHash用一个字符串表示X和Y两个坐标。某些情况下无法在两列上同时应用索引，利用GeoHash。只需要在一列上应用索引即可。\nGeoHash本质上是空间索引的一种方式，其基本原理是将地球理解为一个二维平面，将平面递归分解成更小的子块，每个子块在一定经纬度范围内拥有相同的编码。以GeoHash方式建立空间索引，可以提高对空间poi(POI数据介绍 - 知乎 (zhihu.com))数据进行经纬度检索的效率。\n经度范围是东经180到西经180，纬度范围是南纬90到北纬90，我们设定西经为负，南纬为负，所以地球上的经度范围就是[-180， 180]，纬度范围就是[-90，90]。如果以本初子午线、赤道为界，地球可以分成4个部分。\n如果纬度范围[-90°, 0°)用二进制0代表，（0°, 90°]用二进制1代表，经度范围[-180°, 0°)用二进制0代表，（0°, 180°]用二进制1代表，那么地球可以分成如下4个部分\n如果在小块范围内递归对半划分呢？\n可以看到，划分的区域更多了，也更精确了。geohash算法就是基于这种思想，划分的次数更多，区域更多，区域面积更小了。通过将经纬度编码，给地理位置分区。\n实现 Geohash算法一共有三步。\n首先将坐标变成二进制 这里为了简化文章中的经纬度的描述，改为平面直角坐标系的坐标为描述。此时x的范围是（-90，90），y的范围是（-180，180）\n比如这样一个点 （39.923201, 116.390705）。x的范围（-90，90），其中间值为0。对于纬度39.923201，在区间（0，90）中，因此得到一个1；（0，90）区间的中间值为45度，纬度39.923201小于45，因此得到一个0，依次计算下去，即可得到坐标x的二进制表示，如下表：\nx 0区间 1区间 39.923201 -90，90 -90，0 0，90 1 0，90 0，45 45，90 0 0，45 0，22.5 22.5，45 1 22.5，45 22.5，33.75 33.75，45 1 33.75，45 33.75，39.375 39.375，45 1 \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; 如果我们想要更精确的坐标可以一直分下去，直到满足自己的要求为止。10111000110001111001\n同理我们可以对y坐标也进行处理。\ny 0区间 1区间 116.390705 -180，180 180，0 0，180 1 0，180 0，90 90，180 1 90，180 90，135 135，180 0 90，135 90，112.5 112.5，135 1 112.5，135 112.5，123.75 123.75，135 0 \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; 得到11010010110001000100\n将二进制合并 X坐标占偶数位，Y占奇数位，注意，0也是偶数位。\n1 11100 11101 00100 01111 00000 01101 01011 00001 2复制代码 按照Base32进行编码 Base32编码表的其中一种如下，是用0-9、b-z（去掉a, i, l, o）这32个字母进行编码。具体操作是先将上一步得到的合并后二进制转换为10进制数据，然后对应生成Base32码。需要注意的是，将5个二进制位转换成一个base32码。上例最终得到的值为：wx4g0ec1\n十进制 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 base32 0 1 2 3 4 5 6 7 8 9 b c d e f g 十进制 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 base32 h j k m n p q r s t u v w x y z Geohash比直接用经纬度的高效很多，而且使用者可以发布地址编码，既能表明自己位于北海公园附近，又不至于暴露自己的精确坐标，有助于隐私保护。 GeoHash用一个字符串表示经度和纬度两个坐标。在数据库中可以实现在一列上应用索引（某些情况下无法在两列上同时应用索引） GeoHash表示的并不是一个点，而是一个矩形区域 GeoHash编码的前缀可以表示更大的区域。例如wx4g0ec1，它的前缀wx4g0e表示包含编码wx4g0ec1在内的更大范围。 这个特性可以用于附近地点搜索 编码越长，表示的范围越小，位置也越精确。因此我们就可以通过比较GeoHash匹配的位数来判断两个点之间的大概距离。\n问题 geohash算法有两个问题。\n边缘问题 如图，如果车在红点位置，区域内还有一个黄点。相邻区域内的绿点明显离红点更近。但因为黄点的编码和红点一样，最终找到的将是黄点。这就有问题了。\n要解决这个问题，很简单，只要再查找周边8个区域内的点，看哪个离自己更近即可。\n曲线突变 本文第2张图片比较好地解释了这个问题。其中0111和1000两个编码非常相近，但它们的实际距离确很远。所以编码相近的两个单位，并不一定真实距离很近，这需要实际计算两个点的距离才行。\n官方解析 坐标范围检索，有四叉树、geohash 等几种标准解法。这道题本质并不是考察对高阶算法的掌握，而是想发掘在学习教材 btree 等基础二分思想后，能否进一步思考解出更复杂的问题； 另外考察思维灵活程度，看是否能变通的解决问题，如距离并没有限定必须是欧式距离；位置可以不精确，可以容忍有误差等。\n方法 1，四叉树（QTree）：在二叉树左、右节点的思想下，加入上、下、前、后等更多的方向，演进为四叉树和八叉树。高阶树比较超纲，相关实现省略。四叉树找到周围的环绕的点应该是最快的。 方法 2，geohash：把二维问题降为一维 如坐标（示例非标准 geohash，只是演示了思想）： (12, 345) -\u0026gt; (012, 345) -\u0026gt; \u0026ldquo;031425\u0026rdquo; (13, 348) -\u0026gt; (013, 348) -\u0026gt; \u0026ldquo;031438\u0026rdquo; (2, 789) -\u0026gt; (002, 789) -\u0026gt; \u0026ldquo;070829\u0026rdquo; 最终做字符串前缀匹配，可得 \u0026ldquo;031425\u0026rdquo; 和 \u0026ldquo;031438\u0026rdquo; 匹配到的位数最多，二者距离最近。求 3km 内的坐标，只需提前算出需匹配前几位即可，如匹配前 4 位，按 sql 表达是 LIKE \u0026lsquo;0314%\u0026rsquo; 方法 3，变通距离为 方圆 3km（曼哈顿距离），即 deltaX = 1500, deltaY = 1500，通过数据库解决 Create table tb_name ( x int, y int ) 并添加索引。 假如原点是 (x0, y0)，sql 如下： WHERE (x \u0026gt; x0 - 1500) AND (x \u0026lt; x0 + 1500) AND (y \u0026gt; y0 - 1500) AND (y \u0026lt; y0 + 1500) day-two 【多选】下列关于Join 运算不正确的是： a. Nested Loop Join 不能使用索引做优化。 b. 如果左表太大，不能放入内存中，则不能使用 Hash Join。 c. 如果 Join 的一个输入表在 Join Key 上有序，则一定会使用 Sort Merge Join。 d. Broadcast Join 适用于一张表很小，另一张表很大的场景。\n自己解析 A:可以做 Nested Loop Join - 知乎 (zhihu.com)\nB: 可以使用，数据库多表连接方式介绍－HASH-JOIN - _雨 - 博客园 (cnblogs.com)\nC：不是的(21条消息) Merge join、Hash join、Nested loop join对比分析_KPLives的博客-CSDN博客\nD: 正确的\n给定一个正整数数组 arrs 和整数 K ，请找出该数组内乘积小于等于 k 的连续的子数组的个数，算法时间复杂度o(n) 解析 对于连续的子数组的问题想到了双指针的方法。第一版的代码如下。但是这个代码其实还是暴力搜索，每遇到一个arr[i]就从i开始枚举，满足要求的加入到res中，不满足就下一个。相当于时间复杂度为On^2\n1int subArr(vector\u0026lt;int\u0026gt; \u0026amp;arr, int target) { 2 int slow = 0, fast = 0; 3 int res = 0; 4 for (; slow \u0026lt; arr.size(); slow++) { 5 int temp = 1; 6 for (fast = slow; fast \u0026lt; arr.size(); fast++) { 7 temp *= arr[fast]; 8 if (temp \u0026lt;= target) { 9 res++; 10 } else { 11 break; 12 } 13 } 14 } 15 return res; 16} 我们知道，每次都是乘以正整数，每次相乘只会越来越大。我们要想办法用到越乘越大这个特性。\n定义一个慢指针slow，所求的个数res，当前的乘积mul。\n快指针fast快速向前计算连续数组的乘积，如果计算的乘积大于目标值target了，就移动slow指针，直到mul小于target。\n剩下一个最棘手的问题如何求res\n首先我们看下代码\n1int subArr(vector\u0026lt;int\u0026gt; \u0026amp;arr, int target) { 2 int slow = 0; 3 int res = 0; 4 int mul = 1; 5 for (int fast = 0; fast \u0026lt; arr.size(); fast++) { 6 // 计算当前的乘积 7 mul *= arr[fast]; 8 // 如果乘积超过了慢指针就要开始移动。 9 while (mul \u0026gt; target) { 10 // mul = mul/arr[slow]; 11 // slow ++; 的简写 12 mul /= arr[slow++]; 13 } 14 // 快指针每向有移动一次增加的符合条件的个数。 15 res += (fast - slow + 1); 16 17 } 18 return res; 19} 我们要维护一个滑窗。窗口不断向右滑动，窗口右边界(fast)为固定轴，左边界(slow)则是一个变动轴。\n此窗口代表的意义为：以窗口右边界为结束点的区间，其满足乘积小于target所能维持的最大窗口。 因此，本题最重要的是求窗口在每个位置时，窗口的最大长度。(最大长度是重点)\n最终的答案便是窗口在每个位置的最大长度的累计和。 为什么呢？这个就需要我们找规律了。因为针对上一位置的窗口，移动一次后相对增加出来的个数便是(fast - slow + 1)。\n举个例子:\n窗口左边界：l,窗口右边界：r\nk=100\n位置i： 0, 1, 2, 3\n数组nums： 10, 5, 2, 6\n窗口1(l=1,r=2)： l, r\n窗口2(l=1,r=3): l, r\n窗口1中符合的有[5],[2],[5,2]\n窗口2中符合的有[5],[2],[5,2],[6],[2,6],[5,2,6]\n​\t可以看出，窗口2对比窗口1多出来的数组都是由于窗口右滑一次所带来的，即多出来的那几个必然是包含新窗口的边界fast\n​\t因此可以得出，最终答案可以是每次窗口最大长度的累加。\n为了求出每次窗口的最大长度(或理解为宽度也许)，我们可能需要对变动轴左边界(l)进行调整。 即调整左边界，使之能达到求出窗口的最大长度 day-three 【多选】绝大多数硬盘可以提供哪些写入保证？ a. 单个sector原子写入 b. 单个page原子写入 c. 硬盘顺序执行文件系统发送的操作 d. 以上都不可以\n在随时可能断电的情况下，大多数硬件能提供单个sector的原子性写入；\n但是也有少数硬件连单个sector的写入都无法保证；\n如果一个page对应多个sector，则单个page的完整写入总是无法得到保障。更加详细的情况可以查看这个讨论：crash - Are disk sector writes atomic?。\n对于同时发给硬盘的多个操作（比如写多个不连续的sector），硬盘并不保证操作的顺序。结合其弱原子性，所以硬盘可能处在任何一个中间状态。这主要是由于机械硬盘的寻址优化策略和固态/机械硬盘的缓存策略导致的。\n判断一棵二叉树是否是平衡二叉树。（平衡二叉树要求：树中节点左右子树树高差不超过1。） 二叉树的定义\n1.左右子树的高度差不能超过1 2.左右子树也是平衡二叉树\n解法一 这样的话，如果是空树则是平衡二叉树，如果不是空树，我们就去判断左子树是不是平衡二叉树，判断的依据就是左右子树高度差不超过1，代码如下：\n1#include\u0026lt;iostream\u0026gt; 2#include\u0026lt;vector\u0026gt; 3 4using namespace std; 5 6struct Node { 7 int val; 8 Node *left; 9 Node *right; 10 11 Node(int x) : val(x), left(nullptr), right(nullptr) {} 12 13 Node(int x, Node *left, Node *right) : val(x), left(left), right(right) {} 14}; 15// 获得树的高度 16int getTreeHeight(Node *tree) { 17 if (tree == nullptr) { 18 return 0; 19 } 20 int left = getTreeHeight(tree-\u0026gt;left); 21 int right = getTreeHeight(tree-\u0026gt;right); 22 return left \u0026gt; right ? left + 1 : right + 1; 23} 24 25bool isBalance(Node *tree) { 26 if (tree == nullptr) { 27 return true; 28 } 29 // 拿到左子树的高度 30 int leftHeight = getTreeHeight(tree-\u0026gt;left); 31 // 拿到右子树的高度 32 int rightHeight = getTreeHeight(tree-\u0026gt;right); 33 // 是否满足要求 34 if (abs(leftHeight - rightHeight) \u0026gt; 1) { 35 return false; 36 } 37 // 判断左子树和右子树是否是二叉平衡树 38 return isBalance(tree-\u0026gt;right) \u0026amp;\u0026amp; isBalance(tree-\u0026gt;left); 39} 40 41int main() { 42 Node *node = new Node(1, 43 new Node(1, 44 new Node(3, 45 new Node(4), 46 nullptr), 47 new Node(1)), 48 new Node(1)); 49 cout \u0026lt;\u0026lt; isBalance(node) \u0026lt;\u0026lt; endl; 50 Node *node1 = new Node(1, 51 new Node(1), 52 new Node(1)); 53 cout \u0026lt;\u0026lt; isBalance(node1) \u0026lt;\u0026lt; endl; 54 return 0; 55} 这样做是有一个坏处就是结点的高度会被重复计算。\n我们首先判断根节点1是不是平衡的，此时我们需要调用getTreeHeight函数求根节点左子树的高度，需要遍历节点4、5、7。接下来需要判断以节点2为根节点的子树是不是平衡树的时候，分别求以节点2为根节点的左子树的高度和右子树的高度，这时又遍历了节点4、5、7。\n解法二 这时提出一个新的方法：\n采用后序遍历的方式遍历二叉树的每一个节点，在遍历到一个节点之前我们就已经遍历了它的左右子树。此时，记录每个节点为根节点的树的高度，就可以一边遍历一边判断每个节点是不是平衡的。\n1bool IsBalanced(Node *node, int *depth) { 2 // 为空高度为0 3 if (node == nullptr) { 4 *depth = 0; 5 return true; 6 } 7 8 int nLeftDepth, nRightDepth; 9 // 左子树 10 bool bLeft = IsBalanced(node-\u0026gt;left, \u0026amp;nLeftDepth); 11 // 右子树 12 bool bRight = IsBalanced(node-\u0026gt;right, \u0026amp;nRightDepth); 13 14 if (bLeft \u0026amp;\u0026amp; bRight) { 15 int diff = nRightDepth - nLeftDepth; 16 if (abs(diff) \u0026lt; 2) //左右字树高度差绝对值不超过1 17 { 18 *depth = 1 + (nLeftDepth \u0026gt; nRightDepth ? nLeftDepth : nRightDepth); 19 return true; 20 } 21 } 22 return false; 23} 24 25bool IsBalanced(Node *pRoot) { 26 int depth = 0; 27 28 return IsBalanced(pRoot, \u0026amp;depth); 29} 这里的bool值也可以优化掉。用-1来代替\n1int IsBalanced(Node *node) { 2 // 为空高度为0 3 if (node == nullptr) { 4 return 0; 5 } 6 7 // 左子树 8 int left = IsBalanced(node-\u0026gt;left); 9 if (left == -1) return -1; 10 int right = IsBalanced(node-\u0026gt;right); 11 if (right == -1) return -1; 12 // -1 表示不满足高度要求 13 return abs(left - right) \u0026lt; 2 ? max(left, right) + 1 : -1; 14 15} 16 17bool isBalanced(Node *pRoot) { 18 return IsBalanced(pRoot) != -1; 19} day-four 【单选】go test 默认是以什么顺序执行测试的？ a. 多个 module 并发执行，单 module 下多个测试并发执行 b. 多个 module 并发执行，单 module 下多个测试串行执行 c. 多个 module 串行执行，单 module 下多个测试并发执行 d. 多个 module 串行执行，单 module 下多个测试串行执行\n解析 b； 多个 modules 会并发编译，然后并发执行测试，除非添加了额外的参数-p=1。单个 modules 下多个测试会串行执行，除非在测试函数内执行t.Parallel()。\n只有测试源码文件的名称对了，测试函数的名称和签名也对了，当我们运行go test命令的时候，其中的测试代码才有可能被运行\ngo test命令在开始运行时，会先做一些准备工作，比如，确定内部需要用到的命令，检查我们指定的代码包或源码文件的有效性，以及判断我们给予的标记是否合法，等等\n在准备工作顺利完成之后，go test命令就会针对每个被测代码包，依次地进行构建、执行包中符合要求的测试函数，清理临时文件，打印测试结果 对于每个被测代码包，go test命令会串行地执行测试流程中的每个步骤\n但是，为了加快测试速度，它通常会并发地对多个被测代码包进行功能测试，只不过，在最后打印测试结果的时候，它会依照我们给定的顺序逐个进行，这会让我们感觉到它是在完全串行地执行测试流程。\n另一方面，由于并发的测试会让性能测试的结果存在偏差，所以性能测试一般都是串行进行的。更具体地说，只有在所有构建步骤都做完之后，go test命令才会真正地开始进行性能测试。并且，下一个代码包性能测试的进行，总会等到上一个代码包性能测试的结果打印完成才会开始，而且性能测试函数的执行也都会是串行的。\n【分布式文件处理，获取最多的 URL】如果有一个 20g 的日志文件，日志文件记录着用户访问过的 url，每一行为一个 url，给你一台 512M 的主机，找出出现次数最多的 10 个 url。 解析 Top K算法：使用堆排序算法。\n可以考虑采用“分而治之”的思想，按照 Hash(url)%100 进行分流，把海量 url 日志分别存储到 100 个小文件中。 对于每一个小文件，可以构建一个 url 为 key，出现次数为 value 的 Hash map，同时记录当前文件出现次数排名前10的url 可以得到 100个小文件中的出现次前1000的 url，再依据常规的排序算法得到总体上出现次数最多的 url； day-five 【单选】使用 SQL 语句进行分组检索时，为了去掉不满足条件的分组，应当: a. 使用 WHERE 子句 b. 在 GROUPBY 后面使用 HAVING 子句 c. 先使用 WHERE 子句，再使用 HAVING 子句 d. 先使用 HAVING 子句，再使用 WHERE 子句\n解析 先使用where筛选出基础数据，再使用group by进行分组，最后使用having挑选除分组中满足要求的数据。\n下面的是挑选在1650434852之后上架的，平均价格大于2500的商品。\n1SELECT product_type, AVG(sale_price) 2FROM Product 3where product_create_at \u0026gt;1650434852 4GROUP BY product_type 5HAVING AVG(sale_price) \u0026gt;= 2500;\t优先使用where能降低group by中的数据量。\n实现一个 key 为字符串，value 也是字符串的，而且并发安全的 map，拥有方法 set(key string, value string)、get(key string) string、del(key string)。 扩展要求1： 字典初始有64个桶，当有一半以上的队列有多个元素时，进行自动扩容，将桶的数量翻倍。 扩展要求2： 当一半以上的队列都为空或只有一个元素，并且这种情况持续1分钟，则自动缩容，最小缩容到64队列。\n满足基本要求 1package exp5 2 3import \u0026#34;sync\u0026#34; 4 5// 自己的map的数据结构 6type MyMap struct { 7\tdata map[string]string 8 // 加读写锁 9\tlock sync.RWMutex 10} 11 12func NewMyMap() *MyMap { 13\treturn \u0026amp;MyMap{ 14\tdata: make(map[string]string), 15\t} 16} 17 18func (myMap *MyMap) Set(key, value string) { 19\tif myMap.data == nil { 20\tmyMap.data = make(map[string]string) 21\t} 22 // 加锁 23\tmyMap.lock.Lock() 24\tdefer myMap.lock.Unlock() 25\tmyMap.data[key] = value 26 27} 28 29func (myMap *MyMap) Get(key string) string { 30\tif myMap.data == nil { 31\treturn \u0026#34;\u0026#34; 32\t} 33 // 加 读锁 34\tmyMap.lock.RLock() 35\tdefer myMap.lock.RUnlock() 36\treturn myMap.data[key] 37} 38 39func (myMap *MyMap) Del(key string) { 40\tif myMap.data == nil { 41\treturn 42\t} 43\tmyMap.lock.Lock() 44\tdelete(myMap.data, key) 45\tmyMap.lock.Unlock() 46} 测试 1func createMap(t *testing.T) *MyMap { 2\tm := NewMyMap() 3\trequire.NotNil(t, m) 4\treturn m 5} 6 7func TestMyMap(t *testing.T) { 8\tm := createMap(t) 9\tn := 10000 10\tfor i := 0; i \u0026lt; n; i++ { 11\tj := i 12\t// 开启 1000 个协程，每个协程都会调用 Get 方法 13\tfor k := 0; k \u0026lt; 1000; k++ { 14\tk := k 15\tgo func() { 16\tm.Set(strconv.Itoa(j), strconv.Itoa(j+k)) 17\t}() 18\t} 19\t} 20 21\tfor i := 0; i \u0026lt; n; i++ { 22\tj := i 23\t// 开启 1000 个协程，每个协程都会调用 Get 方法 24\tfor k := 0; k \u0026lt; 1000; k++ { 25\tgo func() { 26\t_ = m.Get(strconv.Itoa(j)) 27\t}() 28\t} 29 30\t} 31 32\tfor i := 0; i \u0026lt; n; i++ { 33\tj := i 34\t// 开启 1000 个协程，每个协程都会调用 Del 方法 35\tfor k := 0; k \u0026lt; 1000; k++ { 36\tgo func() { 37\tm.Del(strconv.Itoa(j)) 38\t}() 39\t} 40 41\t} 42} 如果是普通的map，开多个goroutinue会报fatal error: concurrent map read and map write的致命错误。加锁之后的MyMap是没有线程安全问题的。\n对于扩展要求，map的源码还没有看完先todo\nday-six 【单选】下列关于 Python 的说法错误的是? a. Python 是强类型语言 b. Python 中所有变量本质上都是指针 c. Python 运行时会根据类型提示(type hints)检查变量类型 d. CPython 不支持尾递归优化\n解析 A：正确 Python 如何与其它编程语言的比较的解释：\n静态类型语言\n一种在编译期间就确定数据类型的语言。大多数静态类型语言是通过要求在使用任一变量之前声明其数据类型来保证这一点的。Java 和 C 是静态类型语言。\n动态类型语言\n一种在运行期间才去确定数据类型的语言，与静态类型相反。VBScript 和 Python 是动态类型的，因为它们确定一个变量的类型是在您第一次给它赋值的时候。\n强类型语言\n一种总是强制类型定义的语言。Java 和 Python 是强制类型定义的。您有一个整数，如果不明确地进行转换 ，不能将把它当成一个字符串。\n弱类型语言\n一种类型可以被忽略的语言，与强类型相反。VBScript 是弱类型的。在 VBScript 中，您可以将字符串 '12' 和整数 3 进行连接得到字符串'123'，然后可以把它看成整数 123 ，所有这些都不需要任何的显示转换。\n所以说 Python 既是动态类型语言 (因为它不使用显示数据类型声明)，又是强类型语言 (因为只要一个变量获得了一个数据类型，它实际上就一直是这个类型了)。\nB：正确\n1\u0026gt;\u0026gt;\u0026gt; a = 5 2\u0026gt;\u0026gt;\u0026gt; id(5) 31844502817200 4\u0026gt;\u0026gt;\u0026gt; id(a) 51844502817200 6\u0026gt;\u0026gt;\u0026gt; a = \u0026#39;444\u0026#39; 7\u0026gt;\u0026gt;\u0026gt; id(a) 81844504907376 9\u0026gt;\u0026gt;\u0026gt; id(\u0026#39;444\u0026#39;) 101844504907376 声明一个变量，发现a和5的地址竟然一样，如果给a赋值为444发现，a的地址又变了，这说明在a = 444的时候原来的a的地址被回收，这里的a有重新指向新的字符串的地址了。python把一切数据，一切的一切都看作对象，在python中，没有变量，只有指针，要说变量，也是指针变量。\nC: 错误，python是一个动态类型语言，在运行期间才会确定数据类型。运行时解释器（CPython）不会尝试在运行时推断类型信息，或者验证基于此传递的参数。\nD: 正确\n有很多时候，使用递归的方式写代码要比迭代更直观一些，以下面的阶乘为例：\n1def factorial(n): 2 if n == 0: 3 return 1 4 return factorial(n - 1) * n 但是这个函数调用，如果展开，会变成如下的形式：\n1factorial(4) 2factorial(3) * 4 3factorial(2) * 3 * 4 4factorial(1) * 2 * 3 * 4 5factorial(0) * 1 * 2 * 3 * 4 61 * 1 * 2 * 3 * 4 71 * 2 * 3 * 4 82 * 3 * 4 96 * 4 1024 可以看出，在每次递归调用的时候，都会产生一个临时变量，导致进程内存占用量增大一些。这样执行一些递归层数比较深的代码时，除了无谓的内存浪费，还有可能导致著名的堆栈溢出错误。\n但是如果把上面的函数写成如下形式：\n1def factorial(n, acc=1): 2 if n == 0: 3 return acc 4 return factorial(n - 1, n * acc) 我们再脑内展开一下：\n1factorial(4, 1) 2factorial(3, 4) 3factorial(2, 12) 4factorial(1, 24) 5factorial(0, 24) 624 很直观的就可以看出，这次的 factorial 函数在递归调用的时候不会产生一系列逐渐增多的中间变量了，而是将状态保存在 acc 这个变量中。\n而这种形式的递归，就叫做尾递归。\n尾递归的定义顾名思义，函数调用中最后返回的结果是单纯的递归函数调用（或返回结果）就是尾递归。\n比如代码：\n1def foo(): 2 return foo() 就是尾递归。但是 return 的结果除了递归的函数调用，还包含另外的计算，就不能算作尾递归了，比如：\n1def foo(): 2 return foo() + 1 # return 1 + foo() 也一样 Python 与尾递归优化 (aisk.me)\n给定包含 N 个任务 task 的数组 tasks 和整数 K，和一个可并发调用的执行函数 execute，要求实现以下逻辑： execute并发调用次数不超过10 以最快速度执行完所有task 使用golang 1package main 2 3import \u0026#34;sync\u0026#34; 4 5//二、给定包含 N 个任务 task 的数组 tasks 和整数 K，和一个可并发调用的执行函数 execute，要求实现以下逻辑： 6//execute并发调用次数不超过10 7//以最快速度执行完所有task 8//使用golang的channel实现 9 10func foo(tasks []int, execute func(task int)) { 11 wg := \u0026amp;sync.WaitGroup{} 12 ch := make(chan struct{}, 10) 13 for _, task := range tasks { 14 ch \u0026lt;- struct{}{} 15 wg.Add(1) 16 task := task 17 go func() { 18 execute(task) 19 wg.Done() 20 \u0026lt;-ch 21 }() 22 23 } 24 wg.Wait() 25} 26 27func execute(task int) { 28 println(task) 29} 30func main() { 31 foo([]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}, execute) 32} 空结构体的宽度是0，占用了0字节的内存空间。\n1var s struct{} 2fmt.Println(unsafe.Sizeof(s)) // prints 0 由于空结构体占用0字节，那么空结构体也不需要填充字节。所以空结构体组成的组合数据类型也不会占用内存空间。\n1type S struct { 2 A struct{} 3 B struct{} 4} 5var s S 6fmt.Println(unsafe.Sizeof(s)) // prints 0 chan struct{}通过消息来共享数据是gol的一种设计哲学，channel则是这种哲理的体现。\ngolang中的空结构体 channel := make(chan struct{},10)\n特点\n省内存，尤其在事件通信的时候。 struct零值就是本身，读取close的channel返回零值 通常struct{}类型channel的用法是使用同步，一般不需要往channel里面写数据，只有读等待，而读等待会在channel被关闭的时候返回。\nday-seven 一、【多选】下面关于 HTTP1.x 的性能优化方式，正确的有： a. 对域名进行分片，使得客户端可以创建更多的 TCP 连接提高请求并发度 b. 设置 Connection: Keep-Alive Header 保持长连接，减少 TCP 连接握手的开销 c. 利用 ServerPush 将页面上的关键静态资源直接推送到客户端，无需等待客户端请求 d. 将小的静态资源直接嵌入到页面中，减少 HTTP 请求次数\na，b，d； ServerPush 为 HTTP2 协议才具备的能力，无法应用在 HTTP1.x 的优化中。\n二、时间复杂度 O(nlogn) 空间复杂度 O(1) (非递归) 的限制下从单链表中找出第 K 大的节点 。 排序-搜索-递归版 1ListNode *sort(ListNode *head) { 2 // 处理空和一个元素 3 if (head == nullptr || head-\u0026gt;next == nullptr) { 4 return head; 5 } 6 7 // 截断链表 8 ListNode *fast = head; 9 ListNode *slow = head; 10 ListNode *brk = nullptr; 11 while (fast != nullptr \u0026amp;\u0026amp; fast-\u0026gt;next != nullptr) { 12 fast = fast-\u0026gt;next-\u0026gt;next; 13 if (fast == nullptr || fast-\u0026gt;next == nullptr) { 14 brk = slow; 15 } 16 slow = slow-\u0026gt;next; 17 } 18 brk-\u0026gt;next = nullptr; 19 20 ListNode *headLeft = sort(head); 21 ListNode *headRight = sort(slow); 22 23 // 合并 24 25 ListNode dump(0); 26 ListNode *cur = \u0026amp;dump; 27 // 两个都不为空 28 while (headLeft != nullptr \u0026amp;\u0026amp; headRight != nullptr) { 29 // 降序排列 30 if (headLeft-\u0026gt;val \u0026gt;= headRight-\u0026gt;val) { 31 cur-\u0026gt;next = headLeft; 32 headLeft = headLeft-\u0026gt;next; 33 cur = cur-\u0026gt;next; 34 } else { 35 cur-\u0026gt;next = headRight; 36 headRight = headRight-\u0026gt;next; 37 cur = cur-\u0026gt;next; 38 } 39 } 40 if (headLeft != nullptr) { 41 cur-\u0026gt;next = headLeft; 42 } 43 if (headRight != nullptr) { 44 cur-\u0026gt;next = headRight; 45 } 46 return dump.next; 47} 48int findK(ListNode *head, int k) { 49 ListNode *cur = head; 50 while (k-- \u0026amp;\u0026amp; cur) { 51 cur = cur-\u0026gt;next; 52 } 53 return cur-\u0026gt;val; 54} 排序-搜索-非递归版 1ListNode *merge(ListNode *head1, ListNode *head2) { 2 auto *dummyHead = new ListNode(0); 3 ListNode *temp = dummyHead, *temp1 = head1, *temp2 = head2; 4 while (temp1 != nullptr \u0026amp;\u0026amp; temp2 != nullptr) { 5 if (temp1-\u0026gt;val \u0026lt;= temp2-\u0026gt;val) { 6 temp-\u0026gt;next = temp1; 7 temp1 = temp1-\u0026gt;next; 8 } else { 9 temp-\u0026gt;next = temp2; 10 temp2 = temp2-\u0026gt;next; 11 } 12 temp = temp-\u0026gt;next; 13 } 14 if (temp1 != nullptr) { 15 temp-\u0026gt;next = temp1; 16 } else if (temp2 != nullptr) { 17 temp-\u0026gt;next = temp2; 18 } 19 return dummyHead-\u0026gt;next; 20} 21 22ListNode *sortList(ListNode *head) { 23 if (head == nullptr) { 24 return head; 25 } 26 // 计算链表的长度 27 int length = 0; 28 ListNode *node = head; 29 while (node != nullptr) { 30 length++; 31 node = node-\u0026gt;next; 32 } 33 // 头节点 34 auto *dummyHead = new ListNode(0, head); 35// 每次将链表拆分成若干个长度为subLen的子链表 , 并按照每两个子链表一组进行合并 36 for (int subLength = 1; subLength \u0026lt; length; subLength \u0026lt;\u0026lt;= 1) { 37 // curr用于记录拆分链表的位置 38 ListNode *prev = dummyHead, *curr = dummyHead-\u0026gt;next; 39 // 如果链表没有被拆完 40 while (curr != nullptr) { 41 // 第一个链表的头 即 curr初始的位置 42 ListNode *head1 = curr; 43 // 拆分出长度为subLen的链表1 44 for (int i = 1; i \u0026lt; subLength \u0026amp;\u0026amp; curr-\u0026gt;next != nullptr; i++) { 45 curr = curr-\u0026gt;next; 46 } 47// 拆分subLen长度的链表2 48 49 50 51 ListNode *head2 = curr-\u0026gt;next; // 第二个链表的头 即 链表1尾部的下一个位置 52 curr-\u0026gt;next = nullptr; // 断开第一个链表和第二个链表的链接 53 curr = head2; // 第二个链表头 重新赋值给curr 54// / 再拆分出长度为subLen的链表2 55 for (int i = 1; i \u0026lt; subLength \u0026amp;\u0026amp; curr != nullptr \u0026amp;\u0026amp; curr-\u0026gt;next != nullptr; i++) { 56 curr = curr-\u0026gt;next; 57 } 58// 再次断开 第二个链表最后的next的链接 59 ListNode *next = nullptr; 60 if (curr != nullptr) { 61 next = curr-\u0026gt;next; // next用于记录 拆分完两个链表的结束位置 62 curr-\u0026gt;next = nullptr; 63 } 64 65// 合并两个subLen长度的有序链表 66 ListNode *merged = merge(head1, head2); 67 prev-\u0026gt;next = merged; 68 while (prev-\u0026gt;next != nullptr) { 69 prev = prev-\u0026gt;next; // 将prev移动到 subLen*2 的位置后去 70 } 71 curr = next; // next用于记录 拆分完两个链表的结束位置 72 } 73 } 74 return dummyHead-\u0026gt;next; 75} day-eight 一、【单选】以下描述正确的是： a. 表达式和运算符都是执行计划的组成部分。 b. 在火山模型中，执行计划子节点对应的运算符执行完成后，父节点对应的运算符才能开始执行。 c. 排序算法仅仅在 Sort 运算符中使用。 d. 当使用 Index Scan 的时候，任何情况下都需要再回表读取数据。\n二、某应用需要一个可靠的审核管道，为大量用户提供文章的审核入口，并对接了专业的文章审核团队，请为该管道设计一个数据结构。【实现一个并发安全的环形队列】 要求：\n因为审核团队的人力有限，管道要起到流量控制作用，满了之后文章无法提交审核 高峰期时，多篇文章同时送审的事情常有发生，审核团队的多位同学也可能同时审核文章 先提交送审的文章应先被审核 进入审核管道的文章不能遗失、重复 每天有大量的文章送审，要尽可能节省审核管道的开销 简单使用chan就可以完成，chan本来就是并发安全的，但是可能性能不是很好。 同时送审就像同时往里面push， 同时审核就是同时pop chan就是一个先进先出的队列，如果通道中的缓存已满，之后送来的都会被阻塞。\n但是目前的进入审核管道的内容不能重复，这个问题没有解决。\n1type Content struct { 2\tfoo string 3} 4 5type Queue struct { 6\tch chan Content 7} 8 9func NewQueue(bufSize int) *Queue { 10\treturn \u0026amp;Queue{ 11\tch: make(chan Content, bufSize), 12\t} 13} 14 15func (q *Queue) Push(c Content) { 16\tq.ch \u0026lt;- c 17} 18 19func (q *Queue) Pop() Content { 20\treturn \u0026lt;-q.ch 21} 1import ( 2\t\u0026#34;strconv\u0026#34; 3\t\u0026#34;testing\u0026#34; 4) 5 6func BenchmarkNewQueue(b *testing.B) { 7\tbufSize := 10 8\tq := NewQueue(bufSize) 9\tfor i := 0; i \u0026lt; b.N; i++ { 10\ti := i 11\tgo func() { 12\tq.Push(Content{foo: strconv.Itoa(i)}) 13\t}() 14\t} 15\tfor i := 0; i \u0026lt; b.N; i++ { 16\tgo func() { 17\tq.Pop() 18\t}() 19\t} 20} 手写实现一个线程安全的队列\n1package exp8 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;log\u0026#34; 6\t\u0026#34;sync\u0026#34; 7) 8 9type Content struct { 10\tfoo string 11} 12 13type Queue struct { 14\tch []Content // 处理的内容 15\tindex int // 下一个要放的的位置 16\ttail int // 当前队列的尾部 17\tmutex sync.Mutex // 互斥锁 18\tauditing map[string]struct{} // 已经处理过的内容 19\tsize int // 队列的大小 20} 21 22func NewQueue(bufSize int) *Queue { 23\treturn \u0026amp;Queue{ 24\tch: make([]Content, bufSize), 25\tauditing: make(map[string]struct{}, bufSize), 26\tsize: bufSize, 27\tindex: 0, 28\ttail: 0, 29\t} 30} 31 32func (q *Queue) Push(c Content) error { 33\tq.mutex.Lock() 34\tdefer q.mutex.Unlock() 35\t// 如果已经在队列中了，忽略 36\tif _, ok := q.auditing[c.foo]; ok { 37\treturn fmt.Errorf(\u0026#34;error: %s already in queue\u0026#34;, c.foo) 38\t} 39\t// 如果队列已满，忽略 40\tif (q.index+1)%q.size == q.tail { 41\treturn fmt.Errorf(\u0026#34;error: queue is full\u0026#34;) 42\t} 43\tq.ch[q.index] = c 44\tq.auditing[c.foo] = struct{}{} 45\tq.index = (q.index + 1) % q.size 46\tlog.Print(\u0026#34;push: \u0026#34;, c.foo, \u0026#34; index:\u0026#34;, q.index, \u0026#34; tail:\u0026#34;, q.tail, \u0026#34; content:\u0026#34;, q.ch) 47\treturn nil 48} 49 50func (q *Queue) Pop() (Content, error) { 51\tq.mutex.Lock() 52\tdefer q.mutex.Unlock() 53\t// 如果队列为空，忽略 54\tif q.tail == q.index { 55\treturn Content{}, fmt.Errorf(\u0026#34;error: queue is empty\u0026#34;) 56\t} 57\tc := q.ch[q.tail] 58\tq.ch[q.tail] = Content{} 59\tdelete(q.auditing, c.foo) 60 61\tq.tail = (q.tail + 1) % q.size 62\tlog.Print(\u0026#34;pop: \u0026#34;, c.foo, \u0026#34; index:\u0026#34;, q.index, \u0026#34; tail:\u0026#34;, q.tail) 63\treturn c, nil 64} 测试\n1package exp8 2 3import ( 4\t\u0026#34;strconv\u0026#34; 5\t\u0026#34;sync\u0026#34; 6\t\u0026#34;testing\u0026#34; 7) 8 9func BenchmarkNewQueue(b *testing.B) { 10\tbufSize := 10 11\tq := NewQueue(bufSize) 12\tb.Log(b.N) 13\tfor i := 0; i \u0026lt; b.N; i++ { 14\ti := i 15\tgo func() { 16\tq.Push(Content{foo: strconv.Itoa(i)}) 17\t}() 18\t} 19\tfor i := 0; i \u0026lt; b.N; i++ { 20\tgo func() { 21\tb.Log(q.Pop()) 22\t}() 23\t} 24} 25 26func TestNewQueue(t *testing.T) { 27\tq := NewQueue(10) 28\tn := 100 29\twg := \u0026amp;sync.WaitGroup{} 30\tfor i := 0; i \u0026lt; n; i++ { 31\ti := i 32\twg.Add(1) 33\tgo func() { 34\tc, err := q.Pop() 35\tif err != nil { 36\tt.Log(err) 37\t} else { 38\tt.Logf(\u0026#34;get %v\u0026#34;, c) 39\t} 40\twg.Done() 41\t}() 42\t// 消费者多于生产者，队列会为空等待 43\tif i%2 == 0 { 44\twg.Add(1) 45\tgo func() { 46\terr := q.Push(Content{foo: strconv.Itoa(i % 10)}) 47\tif err != nil { 48\tt.Log(err) 49\t} else { 50\tt.Logf(\u0026#34;push %d\u0026#34;, i%10) 51\t} 52\twg.Done() 53\t}() 54\t} 55 56\t} 57\twg.Wait() 58} 测试结果\n1=== RUN TestNewQueue 2 chan_test.go:36: error: queue is empty 3 chan_test.go:36: error: queue is empty 4 chan_test.go:36: error: queue is empty 5 chan_test.go:36: error: queue is empty 62022/04/21 14:19:51 push: 0 index:1 tail:0 content:[{0} {} {} {} {} {} {} {} {} {}] 7 chan_test.go:49: push 0 82022/04/21 14:19:51 pop: 0 index:1 tail:1 9 chan_test.go:38: get {0} 10 chan_test.go:36: error: queue is empty 112022/04/21 14:19:51 push: 4 index:2 tail:1 content:[{} {4} {} {} {} {} {} {} {} {}] 12 chan_test.go:49: push 4 132022/04/21 14:19:51 pop: 4 index:2 tail:2 14 chan_test.go:38: get {4} 15 chan_test.go:36: error: queue is empty 16... 参考 (21条消息) go test 基本知识理解_红鲤鱼与绿鲤鱼与驴__的博客-CSDN博客\n2.2. 函数声明 (woodpecker.org.cn)\n全面理解Python中的类型提示（Type Hints） - 交流_QQ_2240410488 - 博客园 (cnblogs.com)\n","date":"2022-04-19","img":"","permalink":"/posts/537fd5d3/","series":[],"tags":["面试","Go"],"title":"【第三届字节跳动青训营｜刷题打卡】"},{"categories":["微服务","gRPC"],"content":"这一段时间又重构了之前的代码，这时候代码和项目的结构发生了很大的变化。\n重构的原因 在使用多个go.mod管理不同项目的时候，所有的项目是在同一个仓库里面，这个是之后重构不下去了的目录\n1├─api 2│ └─user-api 3├─common 4│ ├─proto 5│ └─util 6├─docs 7│ └─service 8├─goods 9│ ├─api 10│ ├─common 11│ │ └─proto 12│ └─srv 13├─order 14│ ├─api 15│ ├─common 16│ │ └─proto 17│ └─srv 18├─service 19│ ├─inventory_srv 20│ ├─order_srv 21│ └─user_srv 22└─user 23 ├─api 24 └─rpc 在最开始的时候是每个服务是这样的的\n1shop 2├── api 3│ └── user-api\t// 用户服务的api 4│ └── goods-api\t// 商品的api 5... 6├── docs 7│ └── service 8└── service 9 └── user-srv 10 └── goods-srv 把api和rpc 服务分开，每一个api和rpc服务都有一个go.mod但是在遇到rpc服务之间相互调用的时候就会出现循环引用的问题。这时候出现了第一次重构。\n第一次重构 将每个服务单独分开分为rpc-common-api，目录结构如下\n1├─goods 2│ ├─api 3│ ├─common 4│ │ └─proto 5│ └─srv 6├─order 7│ ├─api 8│ ├─common 9│ │ └─proto 10│ └─srv 这次使用了workspace的新特性，管理起来确实很方便，但是还是存在上述的循环引用的问题，并且当时的golond还没有完美适配1.18的新特性，只能使用beta版。之前了解过go-zero微服务的框架，看到他们有一个go-zero-looklook的项目，看到了里面的目录结构，在与go-zero-looklook的作者聊了之后发现微服务在使用多个仓库和一个仓库的优点和缺点，最后还是选择使用一个仓库一个go.mod进行管理，这样虽然又与平常的单体项目看起来差不多了，但是他其实还是微服务项目。\n第二次重构 1├─app 2│ ├─goods 3│ │ ├─api 4│ │ └─rpc 5│ ├─inventory 6│ │ └─rpc 7│ ├─order 8│ │ ├─api 9│ │ └─rpc 10│ └─user 11│ ├─api 12│ └─rpc 13├─common 14│ ├─model 15│ ├─proto 16│ └─utils 17├─deploy 18└─docs 以下的项目结构对于个人开发一个微服务来说很友好，\n方便管理，只有一个go.mod一个仓库，不用一直拉新的仓库之类的 不会出现循环引用的问题，所有的proto都放在了common中，如果要想修改proto，在common中修改之后所有用到的服务都会知道， rpc服务之间互相调用的时候要用到别的proto文件，这样只需要从公共中引用就行，在之前要不就复制一份到要用的服务中，但是这会产生proto的更新不及时的问题， 之前所有的公共的方法都是在每一个服务中，如果这个公共的方法更新之后，所有地方都要进行修改。将公共的方法等放在一起就不会出现这种问题，而且这样也能减少代码行数，之前的代码有3.1w行，而现在的代码只有1.4w行 项目的服务介绍 用户服务 用户服务主要是用来做登录鉴权。这里没有什么难点主要是使用了PASETO鉴权没有使用平常的JWT的token验证。\n1CREATE TABLE \u0026#34;user\u0026#34; 2( 3 \u0026#34;id\u0026#34; bigserial PRIMARY KEY, 4 \u0026#34;created_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 5 \u0026#34;updated_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 6 \u0026#34;deleted_at\u0026#34; timestamptz DEFAULT null, 7 \u0026#34;email\u0026#34; varchar UNIQUE NOT NULL, 8 \u0026#34;password\u0026#34; varchar NOT NULL, 9 \u0026#34;nickname\u0026#34; varchar NOT NULL, 10 \u0026#34;gender\u0026#34; varchar(6) NOT NULL DEFAULT \u0026#39;male\u0026#39;, 11 \u0026#34;role\u0026#34; int8 NOT NULL DEFAULT 1 12); 商品服务 商品服务提供了商品的信息的增删改查。数据表设计的也很简单\n1CREATE TABLE \u0026#34;goods\u0026#34; 2( 3 \u0026#34;id\u0026#34; bigserial PRIMARY KEY, 4 \u0026#34;created_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 5 \u0026#34;updated_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 6 \u0026#34;deleted_at\u0026#34; timestamptz DEFAULT null, 7 \u0026#34;name\u0026#34; varchar NOT NULL, 8 \u0026#34;price\u0026#34; float NOT NULL 9); 10 11CREATE INDEX ON \u0026#34;goods\u0026#34; (\u0026#34;name\u0026#34;); 同时它也提供如下服务。\n1service goods{ 2 // 商品 3 rpc CreateGoods(CreateGoodRequest)returns(GoodsInfo); // 创建商品 4 rpc UpdateGoods(GoodsInfo)returns(GoodsInfo); // 更新商品信息 5 rpc GetGoods(GoodID)returns(GoodsInfo); // 获得商品信息 6 rpc DeleteGoods(GoodsInfo)returns(Empty);// 删除good信息 7 rpc GetGoodsBatchInfo(ManyGoodsID)returns(ManyGoodsInfos);//批量获得商品信息 8} 库存服务 对于淘宝和京东这样的大型商城而言，对于一个商品可能在不同的地方都有库存，我们下单之后会选择就近的一个发货。同样的，这里的库存服务也是这样的，\n此项目做了简化只包含了关键的商品的id和数量，后面的商品出售的细节是在创建订单相关的服务中起作用的。这里先不做介绍。\n1CREATE TABLE \u0026#34;inventory\u0026#34; 2( 3 \u0026#34;id\u0026#34; bigserial PRIMARY KEY, 4 \u0026#34;created_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 5 \u0026#34;updated_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 6 \u0026#34;deleted_at\u0026#34; timestamptz DEFAULT null, 7 \u0026#34;goods_id\u0026#34; integer NOT NULL, 8 \u0026#34;sticks\u0026#34; integer NOT NULL, 9 \u0026#34;version\u0026#34; integer NOT NULL 10); 11 12CREATE INDEX ON \u0026#34;inventory\u0026#34; (\u0026#34;goods_id\u0026#34;); 13 14create type GoodsDetail as 15( 16 goods_id integer, 17 nums integer 18); 19 20 21create table stock_sell_detail 22( 23 \u0026#34;order_id\u0026#34; int8 not null primary key, 24 \u0026#34;status\u0026#34; int2 not null, 25 \u0026#34;detail\u0026#34; GoodsDetail[] not null 26); 27 28CREATE UNIQUE INDEX ON \u0026#34;stock_sell_detail\u0026#34; (\u0026#34;order_id\u0026#34;); 库存服务提供的服务\n1service inventory{ 2 rpc SetInv(GoodInvInfo) returns(Empty);// 设置库存 3 rpc InvDetail(GoodInvInfo) returns(GoodInvInfo);// 获取库存信息 4 rpc Sell(SellInfo)returns(Empty) ; // 库存扣减 5 rpc Rollback(SellInfo) returns(Empty);// 归还库存 6} 注意事项 设置库存的时候一定要确保该商品以及存在了 库存扣减的时候一定要确保所有的商品都可以购买成功，如果有一个不能购买成功的都要退回失败。 归还库存的时候一定要确保不能归还这也是第二张表的作用，确保不会重复归还。 订单服务 订单服务是此项目中最重要也是最复杂的一个服务。\n1CREATE TABLE \u0026#34;shopping_cart\u0026#34; 2( 3 \u0026#34;id\u0026#34; bigserial PRIMARY KEY, 4 \u0026#34;created_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 5 \u0026#34;updated_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 6 \u0026#34;deleted_at\u0026#34; timestamptz DEFAULT null, 7 \u0026#34;user_id\u0026#34; integer NOT NULL, 8 \u0026#34;goods_id\u0026#34; integer NOT NULL, 9 \u0026#34;nums\u0026#34; integer NOT NULL, 10 \u0026#34;checked\u0026#34; boolean NOT NULL 11); 12 13CREATE TABLE \u0026#34;order_info\u0026#34; 14( 15 \u0026#34;id\u0026#34; bigserial PRIMARY KEY, 16 \u0026#34;created_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 17 \u0026#34;updated_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 18 \u0026#34;deleted_at\u0026#34; timestamptz DEFAULT null, 19 \u0026#34;user_id\u0026#34; integer NOT NULL, 20 \u0026#34;order_id\u0026#34; int8 UNIQUE NOT NULL, 21 \u0026#34;pay_type\u0026#34; varchar, 22 \u0026#34;status\u0026#34; int2 NOT NULL, -- 1 待支付 2 成功 3 超时关闭 23 \u0026#34;trade_id\u0026#34; varchar, --支付编号 24 \u0026#34;order_mount\u0026#34; float, -- 订单金额 25 \u0026#34;pay_time\u0026#34; timestamptz, 26 \u0026#34;address\u0026#34; varchar NOT NULL, 27 \u0026#34;signer_name\u0026#34; varchar(40) NOT NULL, 28 \u0026#34;signer_mobile\u0026#34; varchar(20) NOT NULL, 29 \u0026#34;post\u0026#34; varchar NOT NULL 30); 31 32CREATE TABLE \u0026#34;order_goods\u0026#34; 33( 34 \u0026#34;id\u0026#34; bigserial PRIMARY KEY, 35 \u0026#34;created_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 36 \u0026#34;updated_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 37 \u0026#34;deleted_at\u0026#34; timestamptz DEFAULT null, 38 \u0026#34;order_id\u0026#34; int8 NOT NULL, 39 \u0026#34;goods_id\u0026#34; integer NOT NULL, 40 \u0026#34;goods_name\u0026#34; varchar NOT NULL, 41 \u0026#34;goods_price\u0026#34; float NOT NULL, 42 \u0026#34;nums\u0026#34; integer NOT NULL 43); 44CREATE INDEX ON \u0026#34;shopping_cart\u0026#34; (\u0026#34;user_id\u0026#34;); 45CREATE INDEX ON \u0026#34;shopping_cart\u0026#34; (\u0026#34;goods_id\u0026#34;); 46CREATE INDEX ON \u0026#34;order_info\u0026#34; (\u0026#34;user_id\u0026#34;); 47CREATE INDEX ON \u0026#34;order_info\u0026#34; (\u0026#34;order_id\u0026#34;); 48CREATE INDEX ON \u0026#34;order_goods\u0026#34; (\u0026#34;order_id\u0026#34;); 49CREATE INDEX ON \u0026#34;order_goods\u0026#34; (\u0026#34;goods_id\u0026#34;); 50CREATE INDEX ON \u0026#34;order_goods\u0026#34; (\u0026#34;goods_name\u0026#34;); 其中包括订单的信息、购物车的信息、订单中商品的信息。\n购物车的就是简单的增删改查，只要注意一下保证有就行。\n除了创建订单也没有什么要注意的。\n创建订单 首先发送一个要归还库存的半消息\n创建订单的方法中\n1orderlistener := NewOrderListener(server, ctx) 2\tp, err := rocketmq.NewTransactionProducer( 3\torderlistener, 4\tproducer.WithNameServer([]string{\u0026#34;192.168.0.2:9876\u0026#34;}), 5\t) 6// 处理错误 7\tif err != nil { 8\tglobal.Logger.Error(\u0026#34;创建生产者失败\u0026#34;, zap.Error(err)) 9\treturn \u0026amp;proto.OrderInfo{}, status.Error(codes.Internal, \u0026#34;创建生产者失败\u0026#34;) 10\t} 11\terr = p.Start() 12// 启动 13\tif err != nil { 14\tglobal.Logger.Error(\u0026#34;启动生产者失败\u0026#34;, zap.Error(err)) 15\treturn \u0026amp;proto.OrderInfo{}, status.Error(codes.Internal, \u0026#34;启动生产者失败\u0026#34;) 16\t} 17\ttopic := \u0026#34;order_reback\u0026#34; 18 19\t// 一定要在这边生成订单号 20\tcreateOrderParams := model.CreateOrderParams{ 21\tUserID: req.UserID, 22\tOrderID: generate.GenerateOrderID(req.UserID), 23\tStatus: 1, // 1 待支付 2 成功 3 超时关闭 24\tAddress: req.Address, 25\tSignerName: req.Name, 26\tSignerMobile: req.Mobile, 27\tPost: req.Post, 28\t} 29// struct 序列化为[]byte 30\tjsonString, err := json.Marshal(createOrderParams) 31\tif err != nil { 32\tglobal.Logger.Error(\u0026#34;序列化失败\u0026#34;, zap.Error(err)) 33\treturn \u0026amp;proto.OrderInfo{}, status.Error(codes.Internal, \u0026#34;序列化失败\u0026#34;) 34\t} 35\tres, err := p.SendMessageInTransaction( 36\tctx, 37\tprimitive.NewMessage( 38\ttopic, 39\tjsonString, 40\t), 41\t) 执行本地的事务\n1// 本地事务的监听 2type OrderListener struct { 3\tCode codes.Code 4\tDetail string 5\tOrderID int64 6\tOrderAmount float32 7\tserver *OrderServer 8\tctx context.Context 9} 10 11func NewOrderListener(server *OrderServer, ctx context.Context) *OrderListener { 12\treturn \u0026amp;OrderListener{ 13\tserver: server, 14\tctx: ctx, 15\t} 16} 17func (dl *OrderListener) ExecuteLocalTransaction(msg *primitive.Message) primitive.LocalTransactionState { 18\t// 4. 从购物车中拿到选中的商品 19\t// 1. 商品的金额自己查询 商品服务 20\t// 2. 库存的扣减 库存服务 21\t// 3. 订单的基本信息表 22\t// 23\t// 5. 从购物车中删除已购买的记录 24\t// 从购物车中拿到选中的商品 25\tcreateOrderParams := model.CreateOrderParams{} 26\terr := json.Unmarshal(msg.Body, \u0026amp;createOrderParams) 27\tif err != nil { 28\tglobal.Logger.Error(\u0026#34;解析消息失败\u0026#34;, zap.Error(err)) 29\treturn primitive.RollbackMessageState 30\t} 31 32\tgetCheckedCart := model.GetCartListCheckedParams{ 33\tUserID: createOrderParams.UserID, 34\tChecked: true, 35\t} 36\tgoodsIDS := make([]*proto.GoodID, 0) 37\tshoppingCart, err := dl.server.Store.GetCartListChecked(dl.ctx, getCheckedCart) 38\tif shoppingCart == nil { 39\tdl.Code = codes.InvalidArgument 40\tdl.Detail = \u0026#34;购物车为空\u0026#34; 41\treturn primitive.RollbackMessageState 42\t} else if err != nil { 43\tdl.Code = codes.Internal 44\tdl.Detail = \u0026#34;获取购物车失败\u0026#34; 45\treturn primitive.RollbackMessageState 46\t} 47 48\t// 保存 商品的数量 49\tgoodsNumMap := make(map[int32]int32) 50\tfor _, cart := range shoppingCart { 51\tgoodsIDS = append(goodsIDS, \u0026amp;proto.GoodID{Id: cart.GoodsID}) 52\tgoodsNumMap[cart.GoodsID] = cart.Nums 53\t} 54\tgoodsInfos, err := global.GoodsClient.GetGoodsBatchInfo(dl.ctx, \u0026amp;proto.ManyGoodsID{GoodsIDs: goodsIDS}) 55\tif err != nil { 56\tdl.Code = codes.Internal 57\tdl.Detail = \u0026#34;获取商品信息失败\u0026#34; 58\treturn primitive.RollbackMessageState 59\t} 60 61\t// 订单的总金额 62\tvar orderAmount float32 63\t// 订单中商品的参数 64\tcreateOrderGoodsParams := make([]*model.CreateOrderGoodsParams, 0) 65\t// 扣减库存 的参数 66\tsellInfo := proto.SellInfo{GoodsInfo: make([]*proto.GoodInvInfo, 0)} 67\tfor _, datum := range goodsInfos.Data { 68\t// 求总金额 69\torderAmount += datum.Price * float32(goodsNumMap[datum.Id]) 70\t// 订单中的参数 71\tcreateOrderGoodsParams = append(createOrderGoodsParams, \u0026amp;model.CreateOrderGoodsParams{ 72\tGoodsID: datum.Id, 73\tGoodsName: datum.Name, 74\tGoodsPrice: float64(datum.Price), 75\tNums: goodsNumMap[datum.Id], 76\t}) 77\t// 扣减库存的参数 78\tsellInfo.GoodsInfo = append(sellInfo.GoodsInfo, \u0026amp;proto.GoodInvInfo{ 79\tGoodsId: datum.Id, 80\tNum: goodsNumMap[datum.Id], 81\t}) 82\t} 83 84\t// 跨服务调用 扣减库存 85 86\t_, err = global.InventoryClient.Sell(dl.ctx, \u0026amp;sellInfo) 87\tif err != nil { 88\t// todo 89\t// 如果是因为网络问题，这种如何避免 90\t// sell 的返回逻辑 返回的状态码是否sell返回的状态码 如果是才进行rollback 91\tdl.Code = codes.ResourceExhausted 92\tdl.Detail = \u0026#34;扣减库存失败\u0026#34; 93\treturn primitive.RollbackMessageState 94\t} 95 96\t// 本地服务的事务 97\terr = dl.server.Store.ExecTx(dl.ctx, func(queries *model.Queries) error { 98\tcreateOrderParams.OrderMount = sql.NullFloat64{ 99\tFloat64: float64(orderAmount), 100\tValid: true, 101\t} 102\t// 保存order 103\t_, err = dl.server.Store.CreateOrder(dl.ctx, createOrderParams) 104\tif err != nil { 105\tdl.Code = codes.Internal 106\tdl.Detail = \u0026#34;保存订单失败\u0026#34; 107\treturn err 108\t} 109\tdl.OrderAmount = orderAmount 110 111\t// 将订单id更新 112\tfor _, good := range createOrderGoodsParams { 113\tgood.OrderID = createOrderParams.OrderID 114\t} 115\t// 批量插入订单中的商品 116\terr = dl.server.Store.ExecTx(dl.ctx, func(queries *model.Queries) error { 117\tfor _, good := range createOrderGoodsParams { 118\t_, err = queries.CreateOrderGoods(dl.ctx, *good) 119\tif err != nil { 120\tdl.Code = codes.Internal 121\tdl.Detail = \u0026#34;保存订单商品失败\u0026#34; 122\treturn err 123\t} 124\t} 125\treturn nil 126\t}) 127\tif err != nil { 128\treturn err 129\t} 130 131\t// 批量删除购物车中记录 132\terr = dl.server.Store.ExecTx(dl.ctx, func(queries *model.Queries) error { 133\tfor _, cart := range shoppingCart { 134\t_, err = queries.DeleteCartItem(dl.ctx, model.DeleteCartItemParams{ 135\tDeletedAt: sql.NullTime{Time: time.Now(), Valid: true}, 136\tUserID: cart.UserID, 137\tGoodsID: cart.GoodsID, 138\t}) 139\tif err != nil { 140\tdl.Code = codes.Internal 141\tdl.Detail = \u0026#34;删除购物车中商品失败\u0026#34; 142\treturn err 143\t} 144\t} 145\treturn nil 146\t}) 147\tif err != nil { 148\treturn err 149\t} 150\treturn nil 151\t}) 152\t// 如果有错就要把库存归还 153\tif err != nil { 154\treturn primitive.CommitMessageState 155\t} 156\treturn primitive.RollbackMessageState 157} 从购物车中拿到已经选中的商品 购物车中没有商品就说明这个消息是没有作用的可以抛弃 获取购物车失败就重试 批量处理获得的购物车的商品的信息 获取失败就重试 计算订单需要多钱 生成扣减库存的参数 扣减库存 因为网络问题的扣减失败，生成的错误码肯定不是在库存服务中sell接口中的错误参数，只要判断不是sell接口中的参数就可以判断是网络或者宕机造成的。如果是了就可以让他重试 由于某个商品扣减失败了而造成错误，那么所有的都应该回滚。目前系统设计的是这样的。 开始执行本地事务了。 保存订单信息 保存失败，归还库存 保存订单中的商品信息 保存失败，归还库存， 如果所有的都成了，就撤销归还库存的消息。 本地消息的回查\n1func (dl *OrderListener) CheckLocalTransaction(msg *primitive.MessageExt) primitive.LocalTransactionState { 2\tcreateOrderParams := model.CreateOrderParams{} 3\terr := json.Unmarshal(msg.Body, \u0026amp;createOrderParams) 4\tif err != nil { 5\tglobal.Logger.Error(\u0026#34;解析消息失败\u0026#34;, zap.Error(err)) 6\treturn primitive.RollbackMessageState 7\t} 8 9\t_, err = dl.server.GetOrderDetail(dl.ctx, \u0026amp;proto.GetOrderDetailRequest{OrderID: createOrderParams.OrderID}) 10\tif err != nil { 11\t// 没有扣减的库存不能被归还 12\treturn primitive.CommitMessageState 13\t} 14\treturn primitive.RollbackMessageState 15} 判断订单是否被创建成功了，如果创建成功了，就说明不用归还库存了。\n如果没有创建成功，就说明要归还原有的库存。\n库存服务监听reback的消息\n库存的main方法\n1// 监听库存归还的topic 2\tc, _ := rocketmq.NewPushConsumer( 3\tconsumer.WithNameServer([]string{\u0026#34;192.168.0.2:9876\u0026#34;}), 4\tconsumer.WithGroupName(\u0026#34;inventory-group\u0026#34;)) 5 6\tif err = c.Subscribe(\u0026#34;order_reback\u0026#34;, consumer.MessageSelector{},handler.AutoRollBack); err != nil { 7\tglobal.Logger.Error(\u0026#34;订阅库存归还消息失败\u0026#34;, zap.Error(err)) 8\t} 回调函数的实现\n1func AutoRollBack(ctx context.Context, msgs ...*primitive.MessageExt) (consumer.ConsumeResult, error) { 2 type OrderInfo struct { 3 OrderID int64 `json:\u0026#34;order_id\u0026#34;` 4 } 5 for _, msg := range msgs { 6 // 既然要归还库存，就应该直到每件商品应该归还多少， 这时候出现 重复归还的问题 7 // 这个接口应该保证幂等性，不能因为消息的重复发送而导致一个订单的库存归还多次，没有扣减的库存不能归还。 8 // 新建一张表，记录了详细的订单扣减细节，以及归还的情况 9 var orderInfo OrderInfo 10 err := json.Unmarshal(msg.Body, \u0026amp;orderInfo) 11 if err != nil { 12 global.Logger.Error(\u0026#34;JSON 解析失败\u0026#34;, zap.Error(err)) 13 // 根据业务来，如果赶紧时自己代码问题就用 14 //return consumer.ConsumeRetryLater,nil 15 // 否则就直接忽略这个消息 16 return consumer.ConsumeSuccess, nil 17 } 18 // 将inv的库存加回去，同时将sell status 变为2 19 // todo 20 _, err = global.DB.Begin() 21 if err != nil { 22 global.Logger.Error(\u0026#34;获得事务失败\u0026#34;, zap.Error(err)) 23 return consumer.ConsumeRetryLater, nil 24 } 25 26 // 将状态变为2 27 } 28 return consumer.ConsumeSuccess, nil 29} 拿到消息，这里拿到的消息都是要被归还的 解析消息，拿到订单号 将所有的库存全加回去 加失败了就重试 将状态变为2表示已归还，这里应该保证幂等性，已经归还的不能再此被归还，也就是状态为1的才可以继续被归还。 确定消费成功。 其他\n对于inventory中的sell接口，在sell时一定要保证创建一条stock_sell_detail记录来保证之后归还的时候可以使用。\n踩坑 先考虑能不能跑通再考虑效率的问题。用orm没有错的，首先是解决了问题，其次是效率。 ","date":"2022-04-18","img":"","permalink":"/posts/038c7636/","series":["从0到1实现完整的微服务框架"],"tags":["微服务","gRPC"],"title":"从0到1实现完整的微服务框架 总结"},{"categories":["踩坑","教程"],"content":"Win10端口没被却占用提示An attempt was made to access a socket in a way forbidden by its access permissions,我不理解\n搜索发现是hyper-v的问题\n查看动态端口范围 1netsh int ipv4 show dynamicport tcp 2 3C:\\Users\\jimyag\u0026gt;netsh int ipv4 show dynamicport tcp 4 5协议 tcp 动态端口范围 6 7启动端口 : 1024 8端口数 : 13977 我们可以看到Windows系统默认的 TCP 动态端口范围为：1024~13977。当我们开启Hyper-V后，系统默认会分配给一些保留端口供Hyper-V 使用\n1netsh interface ipv4 show excludedportrange protocol=tcp 2C:\\Users\\jimyag\u0026gt;netsh interface ipv4 show excludedportrange protocol=tcp 3 4协议 tcp 端口排除范围 5 6开始端口 结束端口 7 81026 1125 91226 1325 101326 1425 111426 1525 121526 1625 132180 2279 14... ... 解决方案 修改动态端口的起始\n使用管理员身份运行cmd\n1C:\\WINDOWS\\system32\u0026gt;netsh int ipv4 set dynamicport tcp start=49152 num=16383 2确定。 3 4 5C:\\WINDOWS\\system32\u0026gt;netsh int ipv4 set dynamicport udp start=49152 num=16383 6确定。 然后检查结果\n1C:\\Users\\jimyag\u0026gt;netsh int ipv4 show dynamicport tcp 2 3协议 tcp 动态端口范围 4--------------------------------- 5启动端口 : 49152 6端口数 : 16383 参考 修改Hyper-V动态端口范围以解决Windows 10下Docker等应用端口占用问题\n","date":"2022-04-12","img":"","permalink":"/posts/bf108eb3/","series":[],"tags":["踩坑","教程"],"title":"解决win端口没被占用提示access Permissions"},{"categories":["教程"],"content":"新购买的服务器的环境配置\n修改主机名 1[root@VM-0-16-centos ~]# hostnamectl set-hostname jimyag 2[root@VM-0-16-centos ~]# vim /etc/hosts 3127.0.0.1 jimyag 4127.0.0.1 localhost.localdomain localhost 5127.0.0.1 localhost4.localdomain4 localhost4 6 7::1 jimyag jimyag 8::1 localhost.localdomain localhost 9::1 localhost6.localdomain6 localhost6 10[root@VM-0-16-centos ~]# reboot 更新源 1yum update 安装docker 1yum install -y yum-utils \\ 2 device-mapper-persistent-data \\ 3 lvm2 1sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 2sudo yum makecache fast 1yum install -y docker-ce 1systemctl start docker.service 1systemctl enable docker.service 1curl -L https://get.daocloud.io/docker/compose/releases/download/1.25.4/docker-compose-`uname -s`-`uname -m` \u0026gt; /usr/local/bin/docker-compose 1chmod +x /usr/local/bin/docker-compose go环境安装 在Linux安装Go环境 | 步履不停 (jimyag.cn)\ngit配置.配置一个用于提交代码的用户，输入指令： git config \u0026ndash;global user.name \u0026ldquo;Your Name\u0026rdquo; 同时配置一个用户的邮箱，输入命令：\n1git config --global user.email \u0026#34;email@example.com\u0026#34; 生成公钥和私钥（用于github）\n1ssh-keygen -t rsa -C \u0026#34;youremail@example.com\u0026#34; 参考 DaoCloud | Docker 极速下载\n","date":"2022-04-11","img":"","permalink":"/posts/173a3c06/","series":[],"tags":["教程"],"title":"服务器环境的配置"},{"categories":["Hexo","Hugo","教程"],"content":"由于之前Hexo的NexT主题加载实在太慢，关闭加载动画之后还是很慢。索性换一个新的博客框架。\n安装Hugo 到 Hugo Releases 下载适合你的操作系统的版本。\n把 hugo （或者是 Windows 的 hugo.exe） 放到你的 环境变量 PATH 所在的目录，因为下一步我们将会用到它。\n更加完整的安装指南请参考： Installing Hugo。\n配置主题 1hugo new site hugo-blog 2cd hugo-blog 3git init 4git submodule add https://github.com/razonyang/hugo-theme-bootstrap themes/hugo-theme-bootstrap 5cp -a themes/hugo-theme-bootstrap/exampleSite/* . 6hugo mod npm pack 7npm install 8hugo server 配置作者信息 1name = \u0026#34;jimyag\u0026#34; 2avatar = \u0026#34;images/spider-man.jpg\u0026#34; # static/images/spider-man.jpg 3bio = \u0026#34;Gopher\u0026#34; 4location = \u0026#34;Shanghai\u0026#34; 5 6[params] 7 #layout = \u0026#34;compact\u0026#34; 8 9[social] 10 email = \u0026#34;jimyag@126.com\u0026#34; 11 github = \u0026#34;jimyag\u0026#34; 配置全站信息 这里也顺便配置备案信息\n1baseURL = \u0026#34;https://jimyag.cn\u0026#34; 2title = \u0026#34;步履不停\u0026#34; 3theme = \u0026#34;hugo-theme-bootstrap\u0026#34; # install via git submodule 4copyright = \u0026#34;Copyright © 2019-{year} jimyag. All Rights Reserved. 陕ICP备2020018182号-1\u0026#34; # 备案信息 5 6# Multilingual mode 7defaultContentLanguage = \u0026#34;zh-cn\u0026#34; 8defaultContentLanguageInSubdir = false # If you use only one language comment this option 9 10# Pagination 11paginate = 10 12 13enableRobotsTXT = true 14 15enableEmoji = true 16 17pygmentsUseClasses = true 18 19[blackfriday] 20 hrefTargetBlank = true 21 22[mediaTypes] 23 [mediaTypes.\u0026#34;application/manifest+json\u0026#34;] 24 suffixes = [\u0026#34;json\u0026#34;] 25 26[outputFormats] 27 [outputFormats.MANIFEST] 28 name = \u0026#34;manifest\u0026#34; 29 baseName = \u0026#34;manifest\u0026#34; 30 mediaType = \u0026#34;application/manifest+json\u0026#34; 31 32[outputs] 33 home = [\u0026#34;HTML\u0026#34;, \u0026#34;RSS\u0026#34;, \u0026#34;JSON\u0026#34;, \u0026#34;MANIFEST\u0026#34;] 34 35[taxonomies] 36 category = \u0026#34;categories\u0026#34; 37 series = \u0026#34;series\u0026#34; 38 tag = \u0026#34;tags\u0026#34; 39 40[build] 41 writeStats = true 配置友情连接 自定义一个友情链接的菜单，\n属性 类型 描述 name String 菜单名称。 identifier String 菜单 ID。 weight Number 菜单的权重，用于升序排序。 parent String 上级菜单的 identifier。 url String 菜单的 URL。 pre String 菜单名称的前置字符串。 post String 菜单名称的拖尾字符串。 params Object 菜单参数。 params.divider Boolean true 表示分隔符。 1[[main]] 2 name = \u0026#34;友情链接\u0026#34; 3 identifier = \u0026#34;friends\u0026#34; 4 weight = 40 5 pre = \u0026#39;\u0026lt;i class=\u0026#34;fas fa-fw fa-chevron-circle-down\u0026#34;\u0026gt;\u0026lt;/i\u0026gt;\u0026#39; 6[[main]] 7 name = \u0026#34;xieash\u0026#34; 8 identifier = \u0026#34;xieash\u0026#34; 9 parent = \u0026#34;friends\u0026#34; 10 url = \u0026#34;https://xieash.work/\u0026#34; 11 weight = 1 12[[main]] 13 name = \u0026#34;sunnysab\u0026#34; 14 identifier = \u0026#34;sunnysab\u0026#34; 15 parent = \u0026#34;friends\u0026#34; 16 url = \u0026#34;https://sunnysab.cn/\u0026#34; 17 weight = 2 18[[main]] 19 name = \u0026#34;wanfengcxz\u0026#34; 20 identifier = \u0026#34;wanfengcxz\u0026#34; 21 parent = \u0026#34;friends\u0026#34; 22 url = \u0026#34;https://wanfengcxz.cn/\u0026#34; 23 weight = 3 24[[main]] 25 name = \u0026#34;zhangzqs\u0026#34; 26 identifier = \u0026#34;zhangzqs\u0026#34; 27 parent = \u0026#34;friends\u0026#34; 28 url = \u0026#34;https://zhangzqs.cn/\u0026#34; 29 weight = 4 配置社交连接 1email = \u0026#34;jimyag@126.com\u0026#34; 2# facebook = \u0026#34;yourfacebookusername\u0026#34; 3github = \u0026#34;jimyag\u0026#34; 迁移hexo的博客内容 hexo的永久连接的字段是addlink,但是hugo是不支持这个字段的。\n大佬的永久链接生成方案是直接对时间 + 文章名生成字符串做一下 md5 然后取任意 4-12 位。想了一下，这样的 hash 冲撞概率还是挺小的，我觉得可以！\n那么接下来说说怎么把这个方案应用到 Hugo 中\nHugo 在永久链接中支持一个参数：slug。简单来说，我们可以针对每一篇文章指定一个 slug，然后在 config.toml 中配置permalinks包含slug参数，就可以生成唯一的永久链接。我们的目的就是对每篇文章自动生成一个 slug。\n修改archetypes/default.md添加如下一行：\n1--- 2#... 3slug: {{ substr (md5 (printf \u0026#34;%s%s\u0026#34; .Date (replace .TranslationBaseName \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title))) 4 8 }} 4#... 5--- 这个其实就是hugo的博客的模板，可以在里面添加自己预设的内容。\n这样在每次使用hugo new的时候就会自动填写一个永久链接了。\n之后修改config.toml添加如下行：\n1[permalinks] 2 posts = \u0026#34;/post/:slug\u0026#34; 支持letex公式 Hugo原生是不支持数学公式的这时候需要手动引入数学公式的库，\n在/themes/theme-name/layouts/partials中添加mathjax.html文件，\n1\u0026lt;script type=\u0026#34;text/javascript\u0026#34; 2 async 3 src=\u0026#34;https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML\u0026#34;\u0026gt; 4MathJax.Hub.Config({ 5 tex2jax: { 6 inlineMath: [[\u0026#39;$\u0026#39;,\u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;,\u0026#39;\\\\)\u0026#39;]], 7 displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\[\\[\u0026#39;,\u0026#39;\\]\\]\u0026#39;]], 8 processEscapes: true, 9 processEnvironments: true, 10 skipTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;], 11 TeX: { equationNumbers: { autoNumber: \u0026#34;AMS\u0026#34; }, 12 extensions: [\u0026#34;AMSmath.js\u0026#34;, \u0026#34;AMSsymbols.js\u0026#34;] } 13 } 14}); 15 16MathJax.Hub.Queue(function() { 17 // Fix \u0026lt;code\u0026gt; tags after MathJax finishes running. This is a 18 // hack to overcome a shortcoming of Markdown. Discussion at 19 // https://github.com/mojombo/jekyll/issues/199 20 var all = MathJax.Hub.getAllJax(), i; 21 for(i = 0; i \u0026lt; all.length; i += 1) { 22 all[i].SourceElement().parentNode.className += \u0026#39; has-jax\u0026#39;; 23 } 24}); 25\u0026lt;/script\u0026gt; 26 27\u0026lt;style\u0026gt; 28code.has-jax { 29 font: inherit; 30 font-size: 100%; 31 background: inherit; 32 border: inherit; 33 color: #515151; 34} 35\u0026lt;/style\u0026gt; 然后在head.html中加入如下语句\n1{{ partial \u0026#34;mathjax.html\u0026#34; . }} 重新安装依赖\n1hugo mod npm pack 2npm install 3hugo server 部署博客 Github Actions 起初想通过GitHub actions进行部署，使用rsync进行同步下面是action的配置文件\n1name: deploy 2 3on: 4 # push事件 5 push: 6 # 忽略某些文件和目录，自行定义 7 paths-ignore: 8 - \u0026#39;.gitignore\u0026#39; 9 - \u0026#39;.gitmodules\u0026#39; 10 - \u0026#39;README.md\u0026#39; 11 branches: [ master ] 12 13 # pull_request事件 14 pull_request: 15 # 忽略某些文件和目录，自行定义 16 paths-ignore: 17 - \u0026#39;.gitignore\u0026#39; 18 - \u0026#39;.gitmodules\u0026#39; 19 - \u0026#39;README.md\u0026#39; 20 branches: [ master ] 21 22 # 支持手动运行 23 workflow_dispatch: 24 25jobs: 26 # job名称为deploy 27 deploy: 28 # 使用GitHub提供的runner 29 runs-on: ubuntu-20.04 30 31 steps: 32 # 检出代码，包括submodules，保证主题文件正常 33 - name: Checkout source 34 uses: actions/checkout@v2 35 with: 36 ref: master 37 submodules: true # Fetch Hugo themes (true OR recursive) 38 fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod 39 40 # 准备 mode 41 - name: Setup Node.js 42 uses: actions/setup-node@v2 43 with: 44 node-version: 14 45 46 # 准备Hugo环境 47 - name: Setup Hugo 48 uses: peaceiris/actions-hugo@v2 49 with: 50 hugo-version: \u0026#39;latest\u0026#39; 51 # extended: true 52 53 # Hugo构建静态站点，默认输出到public目录下 54 - name: Build1 55 run: hugo mod npm pack 56 57 58 59 - name: Build2 60 run: npm install 61 62 - name: Build3 63 run: 64 hugo -D 65 # 将public目录下的所有内容同步到远程服务器的nginx站点路径，注意path参数的写法，\u0026#39;public\u0026#39;和\u0026#39;public/\u0026#39;是不同的 66 - name: Deploy 67 uses: burnett01/rsync-deployments@5.1 68 with: 69 switches: -avzr --delete 70 path: ./public/ 71 remote_host: ${{ secrets.REMOTE_HOST }} 72 remote_port: ${{ secrets.REMOTE_PORT }} 73 remote_path: ${{ secrets.REMOTE_PATH }} 74 remote_user: ${{ secrets.REMOTE_USER }} 75 remote_key: ${{ secrets.REMOTE_KEY }} 其中的secrets.REMOTE_HOST等五个参数需要在setting/secrets/actions中添加，可以自行添加。这有一个好处就是它是增量更新的，只有在第一次同步的时候是全部更新，之后只更新改变的或增加的。坏处就是腾讯云一直提醒服务器在国外被登录,每一个同步都要发邮件提醒，很烦。\nSCP scp命令使用很简单\n1scp -r 本地文件路径 username@ip:/远程文件路径 例如\n1scp -r public/* username@ip:/public/jimyag.cn/ 将当前文件中的public目录中所有的文件拷到远程主机的/public/jimyag.cn/文件夹中。\n配置https 以下均在服务器中执行。\n安装nginx\n1yum install nginx -y 启动nginx\n1systemctl start nginx 设置开机自启\n1systemctl enable nginx 修改默认配置文件，注释掉所有的\n1user root; #修改用户 2worker_processes auto; 3error_log /var/log/nginx/error.log; 4pid /run/nginx.pid; 5 6# Load dynamic modules. See /usr/share/doc/nginx/README.dynamic. 7include /usr/share/nginx/modules/*.conf; 8 9events { 10 worker_connections 1024; 11} 12 13http { 14 log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; 15 \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; 16 \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; 17 18 access_log /var/log/nginx/access.log main; 19 20 sendfile on; 21 tcp_nopush on; 22 tcp_nodelay on; 23 keepalive_timeout 65; 24 types_hash_max_size 4096; 25 26 include /etc/nginx/mime.types; 27 default_type application/octet-stream; 28 29 # Load modular configuration files from the /etc/nginx/conf.d directory. 30 # See http://nginx.org/en/docs/ngx_core_module.html#include 31 # for more information. 32 include /etc/nginx/conf.d/*.conf; 33 # 删除多余的内容 34} 在/etc/nginx/conf.d中新建文件jimyag_cn_http2https.conf,将所有的http请求rewrite到https\n1server { 2 listen 80 default_server; 3 listen [::]:80 default_server; 4 server_name jimyag.cn; 5 rewrite ^(.*) https://$server_name$1 permanent; 6} 在/etc/nginx/conf.d中新建文件jimyag_cn.conf,监听443端口\n1server { 2 listen 443 ssl http2; 3 listen [::]:443 ssl http2; 4 server_name jimyag.cn; 5 6 7 ssl_certificate /etc/ssl/certs/jimyag_cn/jimyag.cn_bundle.crt; # 证书所在文件 8 ssl_certificate_key /etc/ssl/certs/jimyag_cn/jimyag.cn.key; # 证书所在文件 9 ssl_session_cache shared:SSL:1m; 10 ssl_session_timeout 10m; 11 location /{ 12 root /public/jimyag.cn/; #博客文件所在 13 index index.html; 14 } 15} 证书需要在云服务器商中申请，申请成功后下载nginx版本就可以了，将其中的.crt和.key文件拷到证书所在位置即可。\n参考 快速入门 - Hugo Bootstrap (razonyang.com)\nHexo 迁移到 Hugo 记录 - Reborn\u0026rsquo;s Blog (mallotec.com)\nHUGO迁移 :: shaosy\u0026rsquo;s blog (siyangshao.github.io)\n","date":"2022-04-11","img":"","permalink":"/posts/642ecc47/","series":[],"tags":["Hexo","Hugo","教程"],"title":"从hexo迁移到Hugo"},{"categories":[["微服务"],["gRPC"]],"content":"新建订单的接口对数据的一致性要求很高，尤其是涉及到支付、金钱相关的事情。\n新建订单中的问题 对于新建订单失败之后，库存应该被归还回去，我们不应该出现以下情况。\n本地订单新建失败，库存扣减成功 本地订单新建成功，库存扣减失败 以下两种情况我们都能接受\n本地订单新建成功，库存扣减成功 本地订单失败，库存扣减失败 由于订单服务是通过网络调用库存服务的，在此过程中，有各种因素的影响。\n库存扣减成功 本地执行失败，调用库存归还接口，但是此时归还接口出问题了（磁盘满了），网络问题可以通过重试来避免。 重试 -网络抖动或者拥塞，之前调用的过一段时间才能被接收到，会不会导致重复归还\u0026ndash;幂等性问题 本地代码异常，不知道本地执行情况，无法调用库存归还接口。 库存扣减失败 本地事务不执行就行。\n先扣库存还是后扣库存 上面我们介绍的是先扣减库存再新建订单，这次我们后扣库存。\n我们将扣减库存的加入本地调用中，先执行新建订单、新建订单商品、删除购物车记录、扣减库存。只有扣减库存成功才会commit。\n扣减库存发送出去了，但是网络拥塞了，就会重试N次，重试结束后还没收到扣减的响应，这时候本地事务认为扣减失败了，就rollback了，但其实扣减成功了。 调用扣减库存没有问题，当把网络请求发送出去之后，宕机了。这时候库存还是被扣减了，订单就会被rollback。 TCC解决库存扣减问题 TCC事务管理器中内部事务开始之前都会写日志，下次启动的时候可以读取日志，继续没有执行的逻辑。\n基于可靠消息最终一致性方案 订单服务发送一个half消息，开始执行本地事务，如果成功就commit，失败就rollback。库存服务一直在监听是否又库存扣减的消息，进行扣减库存。\n本质上解决了可靠消息，消费者应该保证消息一定会被消费。这就要求我们的库存服务一定要可靠，一定要执行成功。这个服务一般可以保证可靠。\n但是由于是库存服务，如果没有库存了，扣减失败怎么办？\n在本地消息执行之前发送归还的half消息 调用库存服务，如果失败就不往下执行。如果成功。 开始执行本地事务， 成功之后rollback归还 失败就commit归还 发送订单超时的延时消息，库存服务一直监听延迟消息。 回查订单本地有没有订单信息，如果有就rollback，没有就commit 实现 生产者 1type OrderListener struct{ 2 Code codes.Code 3 Detail string 4 ID int32 5 OrderAmount float32 6} 7 8func NewOrderListener() *OrderListener { 9 return \u0026amp;OrderListener{} 10} 11 12func (dl *OrderListener) ExecuteLocalTransaction(msg *primitive.Message) primitive.LocalTransactionState { 13 var orderInfo model.OrderInfo 14 err:=json.Unmarshal(msg.Body,\u0026amp;orderInfo) 15 if err!=nil{ 16 // 由于还没有执行，所以应该将之前的回宫 17 return primitive.RollbackMessageState 18 } 19 // 没有选中商品 20 if xxxx{ 21 dl.Code = code.InvalidArgument 22 dl.Detail = \u0026#34;没有选中的商品\u0026#34; 23 // 没有执行sell之前都要回滚 24 return primitive.RollbackMessageState 25 } 26 27 // 跨服务调用商品微服务 28 if xxx{ 29 dl.Code = code.Internal 30 dl.Detail = \u0026#34;批量查询商品信息是啊比\u0026#34; 31 // 没有执行sell之前都要回滚 32 return primitive.RollbackMessageState 33 } 34 35 //跨微服务调用库存微服务， 36 if xxx{ 37 // 如果因为网络问题，如何避免误判 38 // sell 返回的状态码 是不是sell中列举出来的状态码就是网络的问题 39 // todo 40 dl.Code = code.Internal 41 dl.Detail = \u0026#34;库存扣减失败\u0026#34; 42 // 没有执行sell之前都要回滚 43 return primitive.RollbackMessageState 44 } 45 // 生成订单表 46 if xxx{ 47 dl.Code = code.Internal 48 dl.Detail = \u0026#34;库存扣减失败\u0026#34; 49 // 订单创建失败就要归还库存 50 return primitive.CommitMessageState 51 } 52 // 批量插入订单物品的信息 53 if xxx{ 54 dl.Code = code.Internal 55 dl.Detail = \u0026#34;插入订单信息失败\u0026#34; 56 // 就要归还了、 57 // 订单创建失败就要归还库存 58 return primitive.CommitMessageState 59 } 60 // 发送延时消息 61 p, _ := rocketmq.NewProducer( 62\tproducer.WithNsResolver(primitive.NewPassthroughResolver([]string{\u0026#34;127.0.0.1:9876\u0026#34;})), 63\tproducer.WithRetry(2), 64\t) 65\terr := p.Start() 66\tif err != nil { 67\tfmt.Printf(\u0026#34;start producer error: %s\u0026#34;, err.Error()) 68\tos.Exit(1) 69\t} 70\tmsg := primitive.NewMessage(\u0026#34;order_timeout\u0026#34;, msg.Body) 71\tmsg.WithDelayTimeLevel(5) // 设置延迟的级别 72\tres, err := p.SendSync(context.Background(), msg) 73 74\tif err != nil { 75\tfmt.Printf(\u0026#34;send message error: %s\\n\u0026#34;, err) 76 // rollback 77 dl.Code = code.Internal 78 dl.Detail = \u0026#34;发送延时消息失败\u0026#34; 79 return primitive.RollbackMessageState 80\t} 81\t82\terr = p.Shutdown() 83\tif err != nil { 84\tfmt.Printf(\u0026#34;shutdown producer error: %s\u0026#34;, err.Error()) 85\t} 86 87 88 // 本地事务提交 commit 89 dl.Code = code.OK 90 return primitive.RollbackMessageState 91} 92 93func (dl *OrderListener) CheckLocalTransaction(msg *primitive.MessageExt) primitive.LocalTransactionState { 94\tfmt.Println(\u0026#34;rocketMQ 的消息回查\u0026#34;) 95 var orderInfo model.OrderInfo 96 err:=json.Unmarshal(msg.Body,\u0026amp;orderInfo) 97 if err!=nil{ 98 // 由于还没有执行，所以应该将之前的回宫 99 return primitive.RollbackMessageState 100 } 101 // 查询订单是否存在 102 if xxx{ 103 // 如果订单找不到 104 // 本地事务执行失败了，就要归还库存 105 return primitive.CommitMessageState 106 } 107 time.Sleep(time.Second * 4) 108 return primitive.RollbackMessageState 109} 110.... 111 112func (o *OrderServer)CreateOrder(ctx context.context req *proto.OrderRequest)(*proto.OrderInfoResponse ,error){ 113 orderListener：=NewOrderListener() 114 // 运行完就能拿到orderListener中的信息 115 p, err := rocketmq.NewTransactionProducer( 116\torderListener, 117 // 先写死 118\tproducer.WithNsResolver(primitive.NewPassthroughResolver([]string{\u0026#34;192.168.0.2:9876\u0026#34;})), 119\tproducer.WithRetry(1), 120\t) 121 if err != nil { 122\tglobal.Logger.Errorf(\u0026#34;生成producer失败: %s\\n\u0026#34;, err.Error()) 123 return nil,err 124\t} 125\terr = p.Start() 126\tif err != nil { 127\tglobal.Logger.Errorf(\u0026#34;启动 producer 失败: %s\\n\u0026#34;, err.Error()) 128 return nil,err 129\t} 130 order:=model.OrderInfo{ 131 OrderID:GenerateOrderID(req,UserID) 132 Address:... 133 .... 134 } 135 136 jsonString,err:= json.Marshal(order) 137 if err != nil { 138\tglobal.Logger.Errorf(\u0026#34;序列化失败: %s\\n\u0026#34;, err.Error()) 139 return nil,err 140\t} 141\tres, err := p.SendMessageInTransaction( 142 context.Background(), 143\tprimitive.NewMessage(\u0026#34;order_reback\u0026#34;, jsonString) 144\t) 145 146\tif err != nil { 147\tglobal.Logger.Errorf(\u0026#34;序列化失败: %s\\n\u0026#34;, err.Error()) 148 return nil,status.Error(codes.Internal,\u0026#34;消息发送失败\u0026#34;) 149\t} 150 if orderListener.Code!=codes.OK{ 151 return nil,status.Error(orderListener.Code,\u0026#34;新建订单失败\u0026#34;) 152 } 153 return \u0026amp;proto.OrderInfoResponse{...},ni; 154\t// 回查 155\ttime.Sleep(5 * time.Minute) 156\terr = p.Shutdown() 157\tif err != nil { 158\tfmt.Printf(\u0026#34;shutdown producer error: %s\u0026#34;, err.Error()) 159\t} 160} order_srv/main.go\n1func main(){ 2 ... 3 // 监听订单超时的topic 4 c, _ := rocketmq.NewPushConsumer( 5\t// GroupName 多个实例负载均衡 6\tconsumer.WithGroupName(\u0026#34;testGroup\u0026#34;), 7\tconsumer.WithNsResolver(primitive.NewPassthroughResolver([]string{\u0026#34;192.168.0.2:9876\u0026#34;})), 8\t) 9\terr := c.Subscribe(\u0026#34;order_timeout\u0026#34;, consumer.MessageSelector{},OrderTimeout ) 10\tif err != nil { 11\tfmt.Println(err.Error()) 12\t} 13\t// Note: start after subscribe 14\terr = c.Start() 15\tif err != nil { 16\tfmt.Println(err.Error()) 17\tos.Exit(-1) 18\t} 19 ... 20} 21 22 23func OrderTimeout(ctx context.Context, 24\tmsgs ...*primitive.MessageExt, 25) (consumer.ConsumeResult, error) { 26\tfor i := range msgs { 27\t// 查询支付状态，如果是未支付，就要归还换库存 28 // 归还库存我们不能直接又调用库存服务，但是我们可以模仿order发送一个消息到order_reback中去 29 // 发送失败 return RetryLater 30\t} 31 32\treturn consumer.ConsumeSuccess, nil 33\t} 消费者 在库存服务中，启动本地服务之后 监听归还topic\norder_srv/main.go\n1 2func main(){ 3..... 4// 服务器有数据会推给回调 5\tc, _ := rocketmq.NewPushConsumer( 6\t// GroupName 多个实例负载均衡 7\tconsumer.WithGroupName(\u0026#34;inventory\u0026#34;), 8\tconsumer.WithNsResolver(primitive.NewPassthroughResolver([]string{\u0026#34;192.168.0.2:9876\u0026#34;})), 9\t) 10\terr := c.Subscribe(\u0026#34;order_reback\u0026#34;, consumer.MessageSelector{}, AutoReback()) 11\tif err != nil { 12\tfmt.Println(err.Error()) 13\t} 14\t// Note: start after subscribe 15\terr = c.Start() 16\tif err != nil { 17\tfmt.Println(err.Error()) 18\tos.Exit(-1) 19\t} 20\ttime.Sleep(time.Hour) 21\terr = c.Shutdown() 22\tif err != nil { 23\tfmt.Printf(\u0026#34;shutdown Consumer error: %s\u0026#34;, err.Error()) 24\t} 25 .... 26} 27 28 29func AutoReback( 30 ctx context.Context, 31\tmsgs ...*primitive.MessageExt, 32) (consumer.ConsumeResult, error) { 33 for msg:=rang msgs{ 34 //既然要归还库存，就应该知道每件商品归还多少,但是有一个问题？重复归还 35 // 这个接口应该保证幂等性，不能因为消息的重复发送倒是一个订单的库存归还多次，没有扣减的库存你别归还 36 // 如何确保这些都没有问题，新建一张表，记录详细的订单扣减的细节，以及归还细节 37 var orderInfo OrderInfo 38 err:=json.Unmarshal(msgs[msg].Body,\u0026amp;orderInfo) 39 if err!=nil{ 40 global.Logger.Errof(\u0026#34;解析json失败\u0026#34;) 41 return consumer.ConsumeSuccess,nil 42 } 43 // 去将inv的库存加回去，将selldetail的状态设为2，在事务中执行 44 if xxx{ 45 return consumer.ConsumeSuccess,nil 46 } 47 // 逐个归还 48 ... 49 其中要是有问题 50 return consumer.ConsumeRetryLater,nil 51 // 52 } 53\treturn consumer.ConsumeSuccess, nil 54\t} ","date":"2022-04-05","img":"","permalink":"/posts/6f5f2fac/","series":["从0到1实现完整的微服务框架"],"tags":["微服务","gRPC"],"title":"从0到1实现完整的微服务框架-新建订单接口的实现"},{"categories":[["微服务"],["分布式"],["MQ"],["RocketMQ"]],"content":"在介绍分布式事务的时候我们介绍过MQ(消息队列),只是简单的提了一下，这篇文章会从mQ的基本概念、RocketMQ的概念，使用RocketMQ等几个方面介绍RocketMQ。\nMQ使用场景 什么是MQ 消息队列是一种先进先出的数据结构\n应用场景 其应用场景主要包含以下三个方面\n应用解耦 系统的耦合性越高，容错性就越低。\n以电商应用为例，用户创建订单后,如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障或者因为升级等原因暂时不可用，都会造成下单操作异常，影响用户使用体验。\n使用消息队列解耦合，系统的耦合性就会提高了。比如物流系统发生故障，需要几分钟才能来修复,在这段时间内,物流系统要处理的数据被缓存到消息队列中，用户的下单操作正常完成。当物流系统回复后，补充处理存在消息队列中的订单消息即可，终端系统感知不到物流系统发生过几分钟故障。\n流量削峰 应用系统如果遇到系统请求流量的瞬间猛增，有可能会将系统压垮。有了消息队列可以将大量请求缓存起来，分散到很长一段时间处理，这样可以大大提到系统的稳定性和用户体验。\n一般情况，为了保证系统的稳定性，如果系统负载超过阈值，就会阻止用户请求，这会影响用户体验,而如果使用消息队列将请求缓存起来，等待系统处理完毕后通知用户下单完毕，这样总不能下单体验要好。\n出于经济考量目的:业务系统正常时段的QPS如果是1000,流量最高峰是10000，为了应对流量高峰配置高性能的服务器显然不划算,这时可以使用消息队列对峰值流量削峰。\n数据分发 对与A系统，其他系统都要A系统的服务，在不使用MQ时，如果要新增一个系统来拿到A系统的信息，这时候就要改A系统的代码，让他能和E系统通信。如果其中的一个系统不想要A系统了，这时候还要删除与它相关的代码。\n而引入MQ之后，A系统将自己的产生的数据发送到MQ中，新系统想要数据就直接从MQ中消费，原来的系统如果不需要这些数据了，就可以不接受。\n缺点 缺点包含以下几点:\n系统可用性降低 系统引入的外部依赖越多，系统稳定性越差。一旦MQ宕机，就会对业务造成影响。 如何保证MQ的高可用? 系统复杂度提高 MQ的加入大大增加了系统的复杂度，以前系统间是同步的远程调用，现在是通过MQ进行异步调用。 如何保证消息没有被重复消费?怎么处理消息丢失情况?那么保证消息传递的顺序性? 一致性问题 A系统处理完业务，通过MQ给B、C、 D三个系统发消息数据，如果B系统、C系统处理成功，D系统处理失败。 如何保证消息数据处理的一致性? RocketMQ的安装 新建配置文件 ./data/brokerconf/broker.conf写入以下内容\n1# 所属集群名字 2brokerClusterName=DefaultCluster 3 4# broker 名字，注意此处不同的配置文件填写的不一样，如果在 broker-a.properties 使用: broker-a, 5# 在 broker-b.properties 使用: broker-b 6brokerName=broker-a 7 8# 0 表示 Master，\u0026gt; 0 表示 Slave 9brokerId=0 10 11# nameServer地址，分号分割 12# namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876 13 14# 启动IP,如果 docker 报 com.alibaba.rocketmq.remoting.exception.RemotingConnectException: connect to \u0026lt;192.168.0.120:10909\u0026gt; failed 15# 解决方式1 加上一句 producer.setVipChannelEnabled(false);，解决方式2 brokerIP1 设置宿主机IP，不要使用docker 内部IP 16brokerIP1=192.168.0.2 #如果没有报错就不用管 17 18# 在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 19defaultTopicQueueNums=4 20 21# 是否允许 Broker 自动创建 Topic，建议线下开启，线上关闭 ！！！这里仔细看是 false，false，false 22autoCreateTopicEnable=true 23 24# 是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭 25autoCreateSubscriptionGroup=true 26 27# Broker 对外服务的监听端口 28listenPort=10911 29 30# 删除文件时间点，默认凌晨4点 31deleteWhen=04 32 33# 文件保留时间，默认48小时 34fileReservedTime=120 35 36# commitLog 每个文件的大小默认1G 37mapedFileSizeCommitLog=1073741824 38 39# ConsumeQueue 每个文件默认存 30W 条，根据业务情况调整 40mapedFileSizeConsumeQueue=300000 41 42# destroyMapedFileIntervalForcibly=120000 43# redeleteHangedFileInterval=120000 44# 检测物理文件磁盘空间 45diskMaxUsedSpaceRatio=88 46# 存储路径 47# storePathRootDir=/home/ztztdata/rocketmq-all-4.1.0-incubating/store 48# commitLog 存储路径 49# storePathCommitLog=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/commitlog 50# 消费队列存储 51# storePathConsumeQueue=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/consumequeue 52# 消息索引存储路径 53# storePathIndex=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/index 54# checkpoint 文件存储路径 55# storeCheckpoint=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/checkpoint 56# abort 文件存储路径 57# abortFile=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/abort 58# 限制的消息大小 59maxMessageSize=65536 60 61# flushCommitLogLeastPages=4 62# flushConsumeQueueLeastPages=2 63# flushCommitLogThoroughInterval=10000 64# flushConsumeQueueThoroughInterval=60000 65 66# Broker 的角色 67# - ASYNC_MASTER 异步复制Master 68# - SYNC_MASTER 同步双写Master 69# - SLAVE 70brokerRole=ASYNC_MASTER 71 72# 刷盘方式 73# - ASYNC_FLUSH 异步刷盘 74# - SYNC_FLUSH 同步刷盘 75flushDiskType=ASYNC_FLUSH 76 77# 发消息线程池数量 78# sendMessageThreadPoolNums=128 79# 拉消息线程池数量 80# pullMessageThreadPoolNums=128 brokerIP1是本机ip\n新建docker-compost.yml 1version: \u0026#39;3.5\u0026#39; 2services: 3 rmqnamesrv: 4 image: foxiswho/rocketmq:server 5 container_name: rmqnamesrv 6 ports: 7 - 9876:9876 8 volumes: 9 - ./data/logs:/opt/logs 10 - ./data/store:/opt/store 11 networks: 12 rmq: 13 aliases: 14 - rmqnamesrv 15 16 rmqbroker: 17 image: foxiswho/rocketmq:broker 18 container_name: rmqbroker 19 ports: 20 - 10909:10909 21 - 10911:10911 22 volumes: 23 - ./data/logs:/opt/logs 24 - ./data/store:/opt/store 25 - ./data/brokerconf/broker.conf:/etc/rocketmq/broker.conf 26 environment: 27 NAMESRV_ADDR: \u0026#34;rmqnamesrv:9876\u0026#34; 28 JAVA_OPTS: \u0026#34; -Duser.home=/opt\u0026#34; 29 JAVA_OPT_EXT: \u0026#34;-server -Xms128m -Xmx128m -Xmn128m\u0026#34; 30 command: mqbroker -c /etc/rocketmq/broker.conf 31 depends_on: 32 - rmqnamesrv 33 networks: 34 rmq: 35 aliases: 36 - rmqbroker 37 38 rmqconsole: 39 image: styletang/rocketmq-console-ng 40 container_name: rmqconsole 41 ports: 42 - 8080:8080 43 environment: 44 JAVA_OPTS: \u0026#34;-Drocketmq.namesrv.addr=rmqnamesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false\u0026#34; 45 depends_on: 46 - rmqnamesrv 47 networks: 48 rmq: 49 aliases: 50 - rmqconsole 51 52networks: 53 rmq: 54 name: rmq 55 driver: bridge 启动rocketmq 1docker-compose up 测试 在rocket-consle中发送消息。\n浏览器中输入http://localhost:8080\n选择Topic-\u0026gt;ADD/UPDATE-\u0026gt;选择默认的Cluster和BrokerName，输入自己的topic name\u0026ndash;test-\u0026gt;commit。右上角出现Success就是topic已经建立成功。\n找到自己新建的topic名称，-\u0026gt;SEND MAGGAGE-\u0026gt;设置tag、key和内容-\u0026gt;commit\n在Message中通过topic筛选消息，可以看到已经发布的消息了。\nRocketMQ的基本概念 Producer：消息的发送者，消息的生产者。举例发信人 Consumer: 消息接收者，消息的消费者。举例:收信者 Broker: 暂存和传输消息。如果要拿具体的信息首先要从nameserver中拿具体的broker信息，再到具体的broker中获取信息;举例:邮局 NameServer: 管理Broker，类似于注册中心，同步存数据的各个结点，但是这个集群不用做数据同步。原因：？？; 举例:各个邮局的管理机构 Topic: 区分消息的种类;一个发送者可以发送消息给一 个或者多个Topic;一-个消息的接收者可以订阅一个或者多个Topic消息。类似你可以把你写的文章放到不同的平台，看文章的人可以从多个平台看文章 Message Queue:相当于是Topic的分区;用于并行发送和接收消息\nRocketMQ的消息类型 按照发送的特点分 同步发送 a.同步发送，线程阻塞，投递completes阻塞结束I b.如果发送失败，会在默认的超时时间3秒内进行重试，最多重试2次 c.投递completes不代表投递成功，要check SendResult.sendStatus来判断是否投递成功 d. SendResult里面有发送状态的枚举: SendStatus, 同步的消息投递有一个状态返回值的\n1public enum SendStatus { 2\tSEND_ OK; // 成功 3\tFLUSH_ DISK_ TIMEOUT; 4 FLUSH_ SLAVE TIMEOUT; 5\tSLAVE_ NOT_ AVAILABLE; 6} e. retry的实现原理:只有ack的SendStatus=SEND_ OK才会停止retry 注意事项:发送同步消息且Ack为SEND. OK,只代表该消息成功的写入了MQ当中，并不代表该消息成功的被Consumer消费了。\n异步发送 a.异步调用的话，当前线程一定要等待异步线程回调结束再关闭producer啊，因为是异步的，不会阻塞提前关闭producer会导致未回调链接就断开了。 b.异步消息不retry,投递失败回调onException()方法，只有同步消息才会retry。 C.异步发送一般用于链路耗时较长，对RT响应时间较为敏感的业务场景,例如用户视频上传后通知启动转码服务，转码完成后通知推送转码结果等。\n单向发送 a.消息不可靠，性能高，只负责往服务器发送一条消息， 不会重试也不关心是否发送成功 b.此方式发送消息的过程耗时非常短, 一般在微秒级别\n下表概括了三者的特点和主要区别\n发送方式 发送TPS(性能测试指标) 发送结果反馈 可靠性 同步发送 快 有 不丢失 异步发送 快 有 不丢失 单向发送 最快 没有 可能会丢失 按照使用功能特点分 普通消息(订阅) 普通消息是我们在业务开发中用到的最多的消息类型，生产者需要关注消息发送成功即可，消费者消费到消息即可，不需要保证消息的顺序，所以消息可以大规模并发地发送和消费,吞吐量很高，适合大部分场景。不能够保证顺序。\n顺序消息 顺序消息分为分区顺序消息和全局顺序消息。\n全局顺序消息比较容易理解，也就是哪条消息先进入，哪条消息就会先被消费,符合我们的FIFO。\n很多时候全局消息的实现代价很大，所以就出现了分区顺序消息。\n我们通过对消息的key,进行hash,相同hash的消息会被分配到同一个分区里面，当然如果要做全局顺序消息，我们的分区只需要-一个即可，所以全局顺序消息的代价是比较大的。\n延时消息 主要用来订单超时库存归还。\n延迟的机制是在服务端实现的，也就是Broker收到了消息，但是经过一段时间以后才发送服务器按照1-N定义了如下级别:“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”。\n若要发送定时消息，在应用层初始化Message消息对象之后，调用Message.setDelayTimeLevel(int level)方法来设置延迟级别，按照序列取相应的延迟级别，例如level=2,则延迟为5s。\n1msg.setDelayLevel(2); 2SendResult sendResult = producer.send(msg) 实现原理: a.发送消息的时候如果消息设置了DelayTimeLevel,那么该消息会被丢到ScheduleMessageService.SCHEDULE_ TOPIC这个Topic里面 b.根据DelayTimeLevel选择对应的queue C.再把真实的topic和queue信息封装起来, set到msg里面 d.然后每个SCHEDULE TOPIC_ XXX的每个DelayTimeLevelQueue,有定时任务去刷新，是否有待投递的消息 e.每10s定时持久化发送进度\n事务消息 消息队列RocketMQ版提供的分布式事务消息适用于所有对数据最终一致性有 强需求的场景。\n概念介绍 事务消息:消息队列RocketMQ版提供类似X或Open XA的分布式事务功能，通过消息队列RocketMQ版事务消息能达到分布式事务的最终一致。\n半事务消息:暂不能投递的消息，发送方已经成功地将消息发送到了消息队列RocketMQ版服务端，但是服务端未收到生产者对该消息的二次确认，此时该消息被标记成“暂不能投递”状态，处于该种状态下的消息即半事务消息。\n消息回查:由于网络闪断、生产者应用重启等原因，导致某条事务消息的二次确认丢失,消息队列RocketMQ版服务端通过扫描发现某条消息长期处于“半事务消息”时，需要主动向消息生产者询问该消息的最终状态(Commit或是Rollback)，该询问过程即消息回查。\n分布式事务消息的优势 消息队列RocketMQ版分布式事务消息不仅可以实现应用之间的解耦，又能保证数据的最终一致性。 同时，传统的大事务可以被拆分为小事务,不仅能提升效率，还不会因为某一个关联应用的不可用导致整体回滚,从而最大限度保证核心系统的可用性。在极端情况下，如果关联的某一个应用始终无法处理成功，也只需对当前应用进行补偿或数据订正处理，而无需对整体业务进行回滚。\nGo操作RocketMQ RocketMQ发送普通消息 1package main 2 3import ( 4\t\u0026#34;context\u0026#34; 5\t\u0026#34;fmt\u0026#34; 6\t\u0026#34;os\u0026#34; 7\t\u0026#34;strconv\u0026#34; 8 9\t\u0026#34;github.com/apache/rocketmq-client-go/v2\u0026#34; 10\t\u0026#34;github.com/apache/rocketmq-client-go/v2/primitive\u0026#34; 11\t\u0026#34;github.com/apache/rocketmq-client-go/v2/producer\u0026#34; 12) 13 14// Package main implements a simple producer to send message. 15func main() { 16\tp, err := rocketmq.NewProducer( 17\tproducer.WithNsResolver(primitive.NewPassthroughResolver([]string{\u0026#34;192.168.0.2:9876\u0026#34;})), 18\tproducer.WithRetry(2), 19\t) 20 21\tif err != nil { 22\tfmt.Printf(\u0026#34;new producer error: %s\u0026#34;, err.Error()) 23\tos.Exit(1) 24\t} 25\terr = p.Start() 26\tif err != nil { 27\tfmt.Printf(\u0026#34;start producer error: %s\u0026#34;, err.Error()) 28\tos.Exit(1) 29\t} 30\ttopic := \u0026#34;hellomq\u0026#34; 31 32\tfor i := 0; i \u0026lt; 10; i++ { 33\tmsg := \u0026amp;primitive.Message{ 34\tTopic: topic, 35\tBody: []byte(\u0026#34;Hello RocketMQ Go Client! \u0026#34; + strconv.Itoa(i)), 36\t} 37\tres, err := p.SendSync(context.Background(), msg) 38 39\tif err != nil { 40\tfmt.Printf(\u0026#34;send message error: %s\\n\u0026#34;, err) 41\t} else { 42\tfmt.Printf(\u0026#34;send message success: result=%s\\n\u0026#34;, res.String()) 43\t} 44\t} 45\terr = p.Shutdown() 46\tif err != nil { 47\tfmt.Printf(\u0026#34;shutdown producer error: %s\u0026#34;, err.Error()) 48\t} 49} RocketMQ消费消息 1package main 2 3import ( 4\t\u0026#34;context\u0026#34; 5\t\u0026#34;fmt\u0026#34; 6\t\u0026#34;os\u0026#34; 7\t\u0026#34;time\u0026#34; 8 9\t\u0026#34;github.com/apache/rocketmq-client-go/v2\u0026#34; 10\t\u0026#34;github.com/apache/rocketmq-client-go/v2/consumer\u0026#34; 11\t\u0026#34;github.com/apache/rocketmq-client-go/v2/primitive\u0026#34; 12) 13 14func main() { 15\t// 服务器有数据会推给回调 16\tc, _ := rocketmq.NewPushConsumer( 17\t// GroupName 多个实例负载均衡 18\tconsumer.WithGroupName(\u0026#34;testGroup\u0026#34;), 19\tconsumer.WithNsResolver(primitive.NewPassthroughResolver([]string{\u0026#34;192.168.0.2:9876\u0026#34;})), 20\t) 21\terr := c.Subscribe(\u0026#34;hellomq\u0026#34;, consumer.MessageSelector{}, func(ctx context.Context, 22\tmsgs ...*primitive.MessageExt) (consumer.ConsumeResult, error) { 23\tfor i := range msgs { 24\tfmt.Printf(\u0026#34;subscribe callback: %v \\n\u0026#34;, msgs[i]) 25\t} 26 27\treturn consumer.ConsumeSuccess, nil 28\t}) 29\tif err != nil { 30\tfmt.Println(err.Error()) 31\t} 32\t// Note: start after subscribe 33\terr = c.Start() 34\tif err != nil { 35\tfmt.Println(err.Error()) 36\tos.Exit(-1) 37\t} 38\ttime.Sleep(time.Hour) 39\terr = c.Shutdown() 40\tif err != nil { 41\tfmt.Printf(\u0026#34;shutdown Consumer error: %s\u0026#34;, err.Error()) 42\t} 43} RocketMQ发送延迟消息 1package main 2 3import ( 4\t\u0026#34;context\u0026#34; 5\t\u0026#34;fmt\u0026#34; 6\t\u0026#34;os\u0026#34; 7 8\t\u0026#34;github.com/apache/rocketmq-client-go/v2\u0026#34; 9\t\u0026#34;github.com/apache/rocketmq-client-go/v2/primitive\u0026#34; 10\t\u0026#34;github.com/apache/rocketmq-client-go/v2/producer\u0026#34; 11) 12 13func main() { 14\tp, _ := rocketmq.NewProducer( 15\tproducer.WithNsResolver(primitive.NewPassthroughResolver([]string{\u0026#34;127.0.0.1:9876\u0026#34;})), 16\tproducer.WithRetry(2), 17\t) 18\terr := p.Start() 19\tif err != nil { 20\tfmt.Printf(\u0026#34;start producer error: %s\u0026#34;, err.Error()) 21\tos.Exit(1) 22\t} 23\tfor i := 0; i \u0026lt; 10; i++ { 24\tmsg := primitive.NewMessage(\u0026#34;hellomq\u0026#34;, []byte(\u0026#34;Hello RocketMQ Go Client!\u0026#34;)) 25\tmsg.WithDelayTimeLevel(2) // 设置延迟的级别 26\tres, err := p.SendSync(context.Background(), msg) 27 28\tif err != nil { 29\tfmt.Printf(\u0026#34;send message error: %s\\n\u0026#34;, err) 30\t} else { 31\tfmt.Printf(\u0026#34;send message success: result=%s\\n\u0026#34;, res.String()) 32\t} 33\t} 34\terr = p.Shutdown() 35\tif err != nil { 36\tfmt.Printf(\u0026#34;shutdown producer error: %s\u0026#34;, err.Error()) 37\t} 38 39} 我们在下单之后，超时就要取消库存 定时执行逻辑 轮询的问题是多久执行一次，这里我们假设超时的时间是半个小时。 程序在12:00执行了一次，我在12.01下单了，12:30又执行，下次执行就是13：00,本来12：31就超时了，该回收了，但却等到了13：00才超时，在这29分钟内这是库存就不能被别人买。 如果一分钟轮询一次，无用功太多了。 我们使用延迟消息时间一到就执行，消息中包含了订单编号，只用查询这种编号就行了，不用轮询也减少数据库的压力。\nRocketMQ事务消息 1package main 2 3import ( 4 \u0026#34;context\u0026#34; 5 \u0026#34;fmt\u0026#34; 6 \u0026#34;os\u0026#34; 7 \u0026#34;strconv\u0026#34; 8 \u0026#34;time\u0026#34; 9 10 \u0026#34;github.com/apache/rocketmq-client-go/v2\u0026#34; 11 \u0026#34;github.com/apache/rocketmq-client-go/v2/primitive\u0026#34; 12 \u0026#34;github.com/apache/rocketmq-client-go/v2/producer\u0026#34; 13) 14 15type DemoListener struct { 16} 17 18func NewDemoListener() *DemoListener { 19 return \u0026amp;DemoListener{} 20} 21 22func (dl *DemoListener) ExecuteLocalTransaction(msg *primitive.Message) primitive.LocalTransactionState { 23 fmt.Println(\u0026#34;开始执行本地逻辑\u0026#34;) 24 time.Sleep(time.Second * 3) 25 fmt.Println(\u0026#34;执行本地逻辑成功\u0026#34;) 26 //return primitive.CommitMessageState 27 //return primitive.RollbackMessageState 28 // 本地执行逻辑无缘无故失败 代码异常、宕机 29 return primitive.UnknowState 30} 31 32func (dl *DemoListener) CheckLocalTransaction(msg *primitive.MessageExt) primitive.LocalTransactionState { 33 fmt.Println(\u0026#34;rocketMQ 的消息回查\u0026#34;) 34 time.Sleep(time.Second * 4) 35 return primitive.CommitMessageState 36} 37 38func main() { 39 p, _ := rocketmq.NewTransactionProducer( 40 NewDemoListener(), 41 producer.WithNsResolver(primitive.NewPassthroughResolver([]string{\u0026#34;192.168.0.2:9876\u0026#34;})), 42 producer.WithRetry(1), 43 ) 44 err := p.Start() 45 if err != nil { 46 fmt.Printf(\u0026#34;start producer error: %s\\n\u0026#34;, err.Error()) 47 os.Exit(1) 48 } 49 50 for i := 0; i \u0026lt; 1; i++ { 51 res, err := p.SendMessageInTransaction(context.Background(), 52 primitive.NewMessage(\u0026#34;transaction\u0026#34;, []byte(\u0026#34;Hello RocketMQ again \u0026#34;+strconv.Itoa(i)))) 53 54 if err != nil { 55 fmt.Printf(\u0026#34;send message error: %s\\n\u0026#34;, err) 56 } else { 57 fmt.Printf(\u0026#34;send message success: result=%s\\n\u0026#34;, res.String()) 58 } 59 } 60 // 回查 61 time.Sleep(5 * time.Minute) 62 err = p.Shutdown() 63 if err != nil { 64 fmt.Printf(\u0026#34;shutdown producer error: %s\u0026#34;, err.Error()) 65 } 66} 参考 docker-compose安装RocketMQ\nrocketmq-client-go/examples at master · apache/rocketmq-client-go (github.com)\n","date":"2022-04-04","img":"","permalink":"/posts/897c83b3/","series":["从0到1实现完整的微服务框架"],"tags":["微服务","分布式","MQ","RocketMQ"],"title":"从0到1实现完整的微服务框架-RocketMQ"},{"categories":[["微服务"],["分布式"],["BASE理论"],["CAP理论"]],"content":"在微服务的开发中，新建订单的接口是需要跨微服务调用，在此过程中由于是处于不同的系统之间，想要保证出错之后全部回滚，这在本地事务中是无法做到的，下面介绍数据不一致产生的原因和分布式事务的相关理论。这个好枯燥。。\n数据不一致 事务性问题(代码问题) 先扣库存还是后扣库存 先扣库存 扣完库存之后，新建订单出错了，而库存的事务以及提交了。库存就拜拜扣了\n后扣库存 先建订单成功了，之后调用库存服务失败了\n库存服务挂了：直接回滚就行 网络出现问题了：已经扣减了，但是扣减库存的响应的时候挂了。这时候订单服务那边收到超时了，自己回滚了，但是库存已经扣除了。 业务问题-用户下单之后没有支付 库存已经被扣减了，但是用户一直没有支付。\n解决 对于事务性问题，采用分布式的事务解决。\n对于业务下单不支付，采用超时机制进行，超时之后将库存归还。\n事务和分布式事务 事务概念: 一组sq|语句操作单元，组内所有SQL语句完成一个业务, 如果整组成功:意味着全部SQL都实现;如 果其中任何一个失败,意味着整个操作都失败。失败,意味着整个过程都是没有意义的。应该是数据库回 到操作前的初始状态。这种特性，就叫“事务”。\n为什么要存在事务? 1)失败后，可以回到开始位置 2)没都成功之前，别的用户(进程，会话)是不能看到操作内的数据修改的\n事务4大特征ACID: 原子性[atomicity]\n功能不可再分，要么全部成功，要么全部失败\n一致性[consistency] 一致性是指数据处于一种语义上的有意义且正确的状态。一致性是对数据可见性的约束，保证在一个事务中的多次操作的数据中间状态对其他事务不可见的。因为这些中间状态，是一个过渡状态，与事务的开始状态和事务的结束状态是不一致的。 举个例子，张三给李四转账100元。事务要做的是从张三账户上减掉100元，李四账户上加上100元。一致性的含义是其他事务要么看到张三还没有给李四转账的状态，要么张三已经成功转账给李四的状态，而对于张三少了100元，李四还没加上100元这个中间状态是不可见的。 我们来看一下转账过程中可能存在的状态:\n张三未扣减、李四未收到 张三已扣减、李四未收到 张三已扣减，李四已收到 上述过程中: 1. 是初始状态、2是中间状态、3是最终状态，1和3是我们期待的状态，但是2这种状态却不是我们期待出现的状态。\n那么反驳的声音来了:\n要么转账操作全部成功，要么全部失败,这是原子性。从例子上看全部成功，那么一致性就是原子性的一部分咯,为什么还要单独说一致性和原子性? 你说的不对。在未提交读的隔离级别下是事务内部操作是可见的，明显违背了一致性,怎么解释? 好吧，需要注意的是: 原子性和一致性的的侧重点不同:原子性关注状态，要么全部成功，要么全部失败，不存在部分成功的状态。而一致性关注数据的可见性,中间状态的数据对外部不可见，只有最初状态和最终状态的数据对外可见。\n隔离性[isolation] 事务的隔离性是指多个事务并发访问数据库时，一个用户的事务不能被其它用户的事务所干扰,多个并发事务之间数据要相互隔离。 隔离性是多个事务的时候,相互不能干扰，\n一致性是要保证操作前和操作后数据或者数据结构的一致性，而我提到的事务的一致性是关注数据的中间状态,也就是一致性需要监视中间状态的数据， 如果有变化，即刻回滚。\n如果不考虑隔离性，事务存在3种并发访问数据问题,也就是事务里面的脏读、不可重复读、虚 度/幻读\n持久性[durability] 是事务的保证，事务终结的标志(内存的数据持久到硬盘文件中)\n分布式事务 分布式事务顾名思义就是要在分布式系统中实现事务,它其实是由多个本地事务组合而成。\n对于分布式事务而言几乎满足不了ACID,其实对于单机事务而言大部分情况下也没有满足ACID,不然怎么会有mysql四种隔离级别呢?所以更别说分布在不同数据库或者不同应用上的分布式事务了。\n造成数据不一致的原因 网络问题 硬件故障 网卡 路由器 网线 网络抖动 跨服务调用， 网络拥塞 收不到回复的消息。 没有发送出去？\n发送了，没有收到，导致以为出错了\n程序出错 代码异常 宕机 断电 系统问题 磁盘满了 电脑坏了 分布式事务的理论 CAP理论 cap理论是分布式系统的理论基石\nConsistency (一致性): “all nodes see the same data at the same time ”,即更新操作成功并返回客户端后，所有节点在同一时间的数据 完全一致，这就是分布式的一致性。\n一致性的问题在并发系统中不可避免， 对于客户端来说，一致性指的是并发访问时更新过的数据如何获取的问题。从服务端来看,则是更新如何复制分布到整个系统，以保证数据最终一致。\n主从复制 一个是写数据库一个是读数据库\n一个服务将记录写入到写数据库,另一个服务从读数据库来读取刚刚的记录，这要保证，我只要写入进去了就一定可以读到。这里可以采用我写到数据库中，之后同步完成了，再响应给写的服务，这样可以保证我的读数据库中已经包含了之前写的数据了。\nAvailability (可用性): 可用性指“Reads and writes always succeed\u0026quot;，即服务一直可用， 而且是正常响应时间。\n好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。\n在前面的一致性中，我们要等到同步完成之后才响应，但是如果响应的时间很长(几秒),这时候，我要求必须要我写入了就可以从读数据库中获得。\n这时候会出现一个问题就是，我在同步的过程中肯定要对这条数据枷锁，但是如果加锁了，就不能保证数据的一致性，你就访问不到了，这就与一致性相违背了。\n一致性和可用性是互斥的。\nPartition Tolerance (分区容错性) 即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。\n分区容错性要求能够使应用虽然是一个分布式系统， 而看上去却好像是在一个可以运转正常的整体。\n比如现在的分布式系统中有某一个或者几个机器宕掉了,其他剩下的机器还能够正常运转满足系统需求,对于用户而言并没有什么体验上的影响。\n如果是一个分布式系统，一定要满足：分区容错性。\n取舍策略 CAP三个特性只能满足其中两个，那么取舍的策略就共有三种:\nCA：单机的数据库\nCP：要保证一致性和分区容错性，这要等同步完成之后才能使用，在网络等有问题的时候不对外提供服务就行。NoSQL数据库，MongoDB、HBase、Redis\nAP：保证可用性。CoachDB、Cassandra、DynamoDB\nBASE理论 BASE是Basically Available (基本可用)、Soft state (软状态)和Eventually consistent (最终一致性) 三个短语的缩写。\nBASE理论是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于CAP定理逐步演化而来的。\nBASE理论的核心思想是：即使无法做到强一致性, 但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。\n接下来看一下BASE中的三要素:\n基本可用 基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性一注意， 这绝不等价于系统不可用。比如:\n响应时间上的损失。正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加了1~2秒，这是可以接受的 系统功能上的损失:正常情况下，在一个电子商务网站上进行购物的时候,消费者几乎能够顺利完成每一笔订单，但是在一些节日大促购物高峰的时候,由于消费者的购物行为激增，为了保护购物系统的稳定性,部分消费者可能会被引导到一个降级页面 软状态 软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性。即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。\n最终一致性 最终一致性强调的是所有的数据副本，在经过一段时间的同步之后,最终都能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致,而不需要实时保证系统数据的强一致性。\n总结 总的来说，BASE理论面向的是大型高可用可扩展的分布式系统和传统的事物ACID特性是相反的，它完全不同于ACID的强一致性模型。而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的,但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中,ACID特性和BASE理论往往又会结合在一起。\n一句话: CAP就是告诉你:想要满足C、A、P就是做梦, BASE才是你最终的归宿\n两/三阶段提交 常见分布式事务解决方案 两阶段提交(2PC, Two-phase Commit) TCC补偿模式 基于本地消息表实现最终一致性 最大努力通知 基于可靠消息最终一致性方案 两阶段提交(2PC) 两阶段提交又称2PC,2PC是一个非常经典的中心化的原子提交协议。\n这里所说的中心化是指协议中有两类节点: 一个是中心化协调者节点(coordinator) 和N个参与者节点(partcipant)。\n两个阶段:第一阶段:投票阶段和第二阶段:提交/执行阶段。\n举例订单服务A,需要调用支付服务B去支付，支付成功则处理购物订单为待发货状态，否则就需要将购物订单处 理为失败状态。\n对于订单服务来说，首先是要调用库存服务、开始执行扣减库存的事务，调用通知服务、通知服务将信息写入数据库、之后在订单服务本地执行新建订单、插入商品等一系列操作。如果在此之前包括现在没有出问题，那么久确认扣减库存commit、确认发送消息，业务结束。如果在此之前出现了问题，那么就要通知之前的服务进行rollback。业务结束。\n这里通知服务只是一个通知卖家或买家的服务，通知货物是否买/卖了。\n2pc的缺陷 性能问题γ 无论是在第一阶段的过程中，还是在第二阶段,所有的参与者(通知服务、库存服务)资源和协调者(订单服务)资源都是被锁住的,只有当所有节点准备完 毕，事务协调者才会通知进行全局提交。 参与者进行本地事务提交后才会释放资源。这样的过程会比较漫长，对性能影响比较大。\n如果是通知服务挂了或者超时了，那么就会导致库存服务的资源库存被锁住，只有在通知服务rollback之后库存服务才能释放资源。\n单节点故障 由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。 尤其在第二阶段,协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。(虽然协调者挂掉, 可以重新选举一个协调者,但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题)。\nTCC(try confirm/cancel) 一个订单支付之后，我们需要一下的步骤：\n更改订单的状态为已支付 扣减商品库存（这里只是一个假设，在支付之前和在支付之后扣减库存都有许多问题） 给会员增加积分 创建销售出库单通知仓库发货。 好，业务场景有了，现在我们要更进一步，实现一个TCC分布式事务的效果。上述这几个步骤，要么一起成功， 要么一起失败,必须是一个整体性的事务。\n举个例子，现在订单的状态都修改为“已支付”了,结果库存服务扣减库存失败。那个商品的库存原来是100件，现在卖掉了2件，本来应该是98件了。结果呢? 由于库存服务操作数据库异常,导致库存数量还是100。这不是在坑人么，当然不能允许这种情况发生了!\n对于所有的我们都应该加一个中间状态，判断是否确认还是取消。\n代码演示 1type orderService struct{ 2\tCreditSrvClient proto.CreditClient // 用户积分 3\tWmsSrvClient proto.WmsClient // 记录仓库的变动 4\tInventorySrvClient proto.InventoryClient //库存确认扣减 5} 6 7func NewOrderService() *OrderService { 8 return \u0026amp;OrderService{ 9\tCreditSrvClient: proto. CreditClient{}, 10\tWmsSrvClient: proto. WmsClient{}, 11\tInventorySrvClient: proto . InventoryClient{}, 12\t} 13} 14 15func(o OrderService) UpdateOrderStatus() error { 16\treturn nil 17} 18 19func (o OrderService) Notify() error{ 20\to.UpdateOrderStatus() // 更新订单的状态 21\to.CreditSrvClient.AddCredit() // 增加积分 22\to.InventorySrvClient.ReduceStock() // 库存确认扣减 23\to.WmsClient.SaleDelivery() //记录仓库变更记录 24\treturn nil 25} 以出售接口为例：在model中加一个freeze冻结字段，表示有多少库存的东西被冻结了，那么在获取库存详细的时候就应该是获得的数量-冻结的数量。\n在出售时应该就变为了try sell，不在是直接减库存了，给冻结库存加上出售的数量。\n另外还需要confirm sell,给他确认扣减，这时候吧冻结的减掉，然后把真正的库存数量减冻结数量。\n还有一个cancel sell ，出现问题之后我要取消冻结的库存，那么回滚冻结的数量freeze-=sellNum.\n跨服务调用库存微服务进行库存扣减\n调用库存服务的trysell 调用仓库服务的trysell 调用积分 服务的tryAdd 任何一个服务出现了异常,那么你得调用对应的所有的微服务的cancel接口 如果所有的微服务都正常,那么你得调用所有的微服务的confirm TCC 底层的实各个服务实现比较简单，在业务逻辑中的confirm和cancel是很复杂的。在什么情况下进行confirm，cancel都是问题。\nTCC可能出现的问题 总结一下， 你要玩TCC分布式事务的话: .\n首先需要选择某种TCC分布式事务框架，各个服务里就会有这个TCC分布式事务框架在运行。\n然后你原本的一个接口，要改造为3个逻辑，Try-Confirm-Cancel。\n先是服务调用链路依次执行Try逻辑\n如果都正常的话，TCC分布式事务框架推进执行Confirm逻辑，完成整个事务\n如果某个服务的Try逻辑有问题，TCC分布式事务框架感知到之后就会推进执行各个服务的Cancel逻辑， 撤销之前执行的各种操作。\n这就是所谓的TCC分布式事务。\nTCC分布式事务的核心思想，说白了，就是当遇到下面这些情况时,\n某个服务的数据库宕机了 某个服务自己挂了 那个服务的redis、elasticsearch、 MQ等基础设施故障了 某些资源不足了，比如说库存不够这些 先来Try一下,不要把业务逻辑完成，先试试看，看各个服务能不能基本正常运转，能不能先冻结我需要的资源。 如果Try都ok，也就是说，底层的数据库、redis、 elasticsearch、 MQ都是可以写入数据的，并且你保留好了需要使用的一些资源(比如冻结了-部分库存)。 接着,再执行各个服务的Confirm逻辑，基本上Confirm就可以很大概率保证一个分布式事务的完成了。 那如果Try阶段某个服务就失败了，比如说底层的数据库挂了，或者redis挂了，等等。 此时就自动执行各个服务的Cancel逻辑，把之前的Try逻辑都回滚，所有服务都不要执行任何设计的业务逻辑。保证大家要么一起成功，要么一起失败。 终极大招 如果有一些意外的情况发生了，比如说订单服务突然挂了，然后再次重启，TCC分布式事务框架是如何保证之前没执行完的分布式事务继续执行的呢? . TCC事务框架都是要记录一些分布式事务的活动日志的，可以在磁盘上的日志文件里记录,也可以在数据库里记录。保存下来分布式事务运行的各个阶段和状态。 万一某个服务的Cancel或者Confirm逻辑执行一直失败怎么办呢?那也很简单，TCC事务框架会通过活动日志记录各个服务的状态。举个例子，比如发现某个服务的Cancel或者Confirm-直没成功，会不停的重试调用他的Cancel或者Confirm逻辑，务必要他成功! 当然了，如果你的代码没有写什么bug，有充足的测试，而且Try阶段都基本尝试了一下，那么其实一般Confirm、Cancel都是可以成功的! 如果实在解决不了，那么这个一定是很小概率的事件，这个时候发邮件通知人工处理 TCC优缺点 优点 解决了跨服务的业务操作原子性问题，例如组合支付，订单减库存等场景非常实用 TCC的本质原理是把数据库的二阶段提交上升到微服务来实现，从而避免了数据库2阶段中锁冲突的长事务低性能风险。 TCC异步高性能，它采用了try先检查,然后异步实现confirm,真正提交的是在confirm方法中。（依旧要用锁） 缺点 对微服务的侵入性强，微服务的每个事务都必须实现try, confirm, cance等3个方法，开发成本高，今后维护改造的成本也高。\n为了达到事务的一致性要求，try, confirm、cance接口必须实现等幂性操作。(定时器+重试)\n由于事务管理器要记录事务日志，必定会损耗一定的性能，并使得整个TCC事务时间拉长，建议采用redis的方式来记录事务日志。\ntcc需要通过锁来确保数据的一致性，会加锁导致性能不高\n基于本地消息的最终一致性方案 本地消息表这个方案最初是eBay提出的，此方案的核心是通过本地事务保证数据业务操作和消息的一致性,然后通过定时任务将消息发送至消息中间件，待确认消息发送给消费方成功再将消息删除。\n订单服务将自己的业务完成之后，将信息发送到消息队列中去，库存服务和通知服务从队列中拿任务完成，如果消息消费完成了就确认删除，如果没有就重试。只要不确认都会在消息队列中。\n虽然当前数据没有一致，但最终一定会一致。\n隐患：\n先记录再发送消息，发送失败了\n发送了但是消息队列宕机了，我们可以等待恢复重新发送。 发送消息了，消息队列在发送已经接收到订单消息时网络出问题超时了，这时候订单服务就会收到超时，订单就会回滚，但是库存和通知服务已经开始执行了。 这时候要增加一个本地消息表来记录消息的生产和消费，这样才能保证消息不会丢失。\n这种情况下，本地数据库操作与存储消息日志处于同一事务中，本地数据库操作与记录消息日志操作具备原子性。\n定时任务扫描日志 如何保证将消息发送给消息队列呢? 经过第一步消息已经写到消息日志表中，可以启动独立的线程，定时对消息日志表中的消息进行扫描并发送至消息中间件，在消息中间件反馈发送成功后删除该消息日志，否则等待定时任务下一周期重试。\n消费消息 如何保证消费者一-定能消费 到消息呢? 这里可以使用MQ的ack (即消息确认)机制，消费者监听MQ,如果消费者接收到消息并且业务处理完成后向MQ发送ack (即消息确认)，此时说明消费者正常消费消息完成，MQ将不再向消费者推送消息，否则消费者会不断重试向消费者来发送消息。 通知服务接收到“通知给用户”消息,开始通知用户，通知用户成功后消息中间件回应ack,否则消息中间件将重复投递此消息。\n由于消息会重复投递，积分服务的“增加积分”功能需要实现幂等性。\n基于可靠消息的最终一致性方案-常用 通过使用基于RocketMQ的可靠消息实现最终一致性的分布式方案。\n调用的过程如下图所示：\n备注\nhalf消息不能被消费。\n这里使用MQ来保证订阅方收到的消息一定是可靠的。\nMQ的回查是在一段时间后没有进行这个事务没有进行commit/rollback就会查询事务的消息状态。\n最大努力通知 最大努力通知型( Best-effort delivery)是最简单的一种柔性事务，适用于一些最终一致性时间敏感度低的业务，且被动方处理结果不影响主动方的处理结果。典型的使用场景：如银行通知、商户通知等。最大努力通知型的实现方案，一般符合以下特点：\n不可靠消息：业务活动主动方，在完成业务处理之后，向业务活动的被动方发送消息，直到通知N次后不再通知，允许消息丢失(不可靠消息)。 定期校对：业务活动的被动方，根据定时策略，向业务活动主动方查询(主动方提供查询接口)，恢复丢失的业务消息。\n以下这个例子，用户在支付之后，支付宝要尽自己最大的努力来通知到商家某某人已经支付成功了，但是对方的服务可能会挂掉或者这个对方这个接口不存在，这个时候，就要努力尝试通知商城。对于通知的时间也是有讲究的，不能每一次都是1秒中通知一次，可以刚开始1秒钟尝试通知一次，之后2秒、5秒\u0026hellip;但是也不能一直尝试通知，要有一定的上限。\n商城不能直接从支付宝系统MQ中直接拿消息，而是要通过支付宝提供的服务来拿到消息。\n","date":"2022-04-03","img":"","permalink":"/posts/252f6a9e/","series":["从0到1实现完整的微服务框架"],"tags":["微服务","分布式","BASE理论","CAP理论"],"title":"从0到1实现完整的微服务框架-分布式理论基础、分布式事务"},{"categories":[["微服务"],["gRPC"]],"content":"在分布式系统中，数据一致性是非常重要。在此项目中库存的增减也有同样的问题。\n快速启动库存服务 复制之前的用户服务的代码，\n生成表结构 1$migrate create -ext sql -dir migration -seq init_schema_inventory 2D:\\repository\\shop\\service\\inventory_srv\\db\\migration\\000001_init_schema_inventory.up.sql 3D:\\repository\\shop\\service\\inventory_srv\\db\\migration\\000001_init_schema_inventory.down.sql 复制生成的表结构到up文件中\n1CREATE TABLE \u0026#34;inventory\u0026#34; 2( 3 \u0026#34;id\u0026#34; bigserial PRIMARY KEY, 4 \u0026#34;created_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 5 \u0026#34;updated_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), 6 \u0026#34;deleted_at\u0026#34; timestamptz DEFAULT null, 7 \u0026#34;goods\u0026#34; integer NOT NULL, 8 \u0026#34;sticks\u0026#34; integer NOT NULL, 9 \u0026#34;version\u0026#34; integer NOT NULL 10); 11 12CREATE INDEX ON \u0026#34;inventory\u0026#34; (\u0026#34;goods\u0026#34;); down\n1DROP TABLE IF EXISTS \u0026#34;inventory\u0026#34;; 创建inventory数据库 1docker run --name shop-inventory -p 35433:5432 -e POSTGRES_PASSWORD=postgres -e TZ=PRC -d postgres:14-alpine 23536ecfbb483a64fadaa9e3e253c50b1082dbd71b290f7b36ebd2276c8a74dce 创建数据库 1docker exec -it shop-inventory createdb --username=postgres --owner=postgres shop 删除数据库 1docker exec -it shop-inventory dropdb --username=postgres shop 数据库迁移 1migrate -path db/migration -database \u0026#34;postgresql://postgres:postgres@localhost:35433/shop?sslmode=disable\u0026#34; -verbose up 22022/03/30 22:27:06 Start buffering 1/u init_schema_inventory 32022/03/30 22:27:06 Read and execute 1/u init_schema_inventory 42022/03/30 22:27:06 Finished 1/u init_schema_inventory (read 15.2808ms, ran 22.4171ms) 52022/03/30 22:27:06 Finished after 61.9324ms 62022/03/30 22:27:06 Closing source and database 1migrate -path db/migration -database \u0026#34;postgresql://postgres:postgres@localhost:35433/shop?sslmode=disable\u0026#34; -verbose down 22022/03/30 22:26:59 Are you sure you want to apply all down migrations? [y/N] 3y 42022/03/30 22:27:01 Applying all down migrations 52022/03/30 22:27:01 Start buffering 1/d init_schema_inventory 62022/03/30 22:27:01 Read and execute 1/d init_schema_inventory 72022/03/30 22:27:01 Finished 1/d init_schema_inventory (read 9.3861ms, ran 15.3116ms) 82022/03/30 22:27:01 Finished after 1.9435943s 92022/03/30 22:27:01 Closing source and database 生成curd代码 在wsl中 初始化\n1root@Jimyag:/mnt/c/Users/jimyag# docker run --rm -v /mnt/d/repository/shop/service/inventory_srv:/src -w /src kjconroy/sqlc init 写入如下\n1version: 1 2packages: 3 - path: \u0026#34;./model\u0026#34; # 生成go 代码的位置 4 name: \u0026#34;model\u0026#34; # 生成 go package 的名字 5 engine: \u0026#34;postgresql\u0026#34; # 使用的数据库引擎 6 schema: \u0026#34;./db/migration/\u0026#34; # 迁移表的sql语句 我们使用migrate中的up文件 7 queries: \u0026#34;./db/query\u0026#34; # CRUD的sql 8 emit_json_tags: true # 添加json在生成的struct中 9 emit_prepared_queries: false 10 emit_interface: true # 生成接口 11 emit_exact_table_names: false # 表名是否带s 在./db/query中写入\n1-- name: CreateInventory :one 2INSERT INTO \u0026#34;inventory\u0026#34;(goods, 3 sticks, 4 version) 5VALUES ($1, $2, $3) 6returning *; 7 8-- name: GetInventoryByGoodsID :one 9SELECT * 10FROM \u0026#34;inventory\u0026#34; 11WHERE goods = $1 12LIMIT 1; 13 14 15-- name: UpdateInventory :one 16update \u0026#34;inventory\u0026#34; 17set updated_at = $1, 18 sticks = sticks + sqlc.arg(counts) 19where goods = $2 20returning *; 生成curd代码\n1docker run --rm -v /mnt/d/repository/shop/service/inventory_srv:/src -w /src kjconroy/sqlc generate protoc生成go代码 1syntax = \u0026#34;proto3\u0026#34;; 2option go_package = \u0026#34;.;proto\u0026#34;; 3 4service inventory{ 5 rpc SetInv(GoodInvInfo) returns(Empty);// 设置库存 6 rpc InvDetail(GoodInvInfo) returns(GoodInvInfo);// 获取库存信息 7 rpc Sell(SellInfo)returns(Empty) ; // 库存扣减 8 rpc Rollback(SellInfo) returns(Empty);// 归还库存 9} 10message SellInfo{ 11 repeated GoodInvInfo goodsInfo = 1; 12} 13message GoodInvInfo{ 14 int32 goodsId = 1; 15 int32 num = 2; 16} 17message Empty {} cd到.proto文件\n1protoc -I . inventory.proto --go_out=plugins=grpc:. 封装数据库curd shop\\service\\inventory_srv\\model\\store.go\n1package model 2 3import ( 4\t\u0026#34;context\u0026#34; 5\t\u0026#34;database/sql\u0026#34; 6\t\u0026#34;fmt\u0026#34; 7\t\u0026#34;time\u0026#34; 8 9\t\u0026#34;go.uber.org/zap\u0026#34; 10\t\u0026#34;google.golang.org/grpc/codes\u0026#34; 11\t\u0026#34;google.golang.org/grpc/status\u0026#34; 12 13\t\u0026#34;github.com/jimyag/shop/service/inventory/global\u0026#34; 14\t\u0026#34;github.com/jimyag/shop/service/inventory/proto\u0026#34; 15) 16 17type Store interface { 18\tSetInvTx(ctx context.Context, arg CreateInventoryParams) (Inventory, error) 19\tSellTx(ctx context.Context, arg *proto.SellInfo) error 20\tRollBackTx(ctx context.Context, arg *proto.SellInfo) error 21\tQuerier 22} 23 24type SqlStore struct { 25\t*Queries 26\tdb *sql.DB 27} 28 29func NewSqlStore(db *sql.DB) Store { 30\treturn \u0026amp;SqlStore{ 31\tQueries: New(db), 32\tdb: db, 33\t} 34} 35 36func (store *SqlStore) execTx(ctx context.Context, fn func(queries *Queries) error) error { 37\ttx, err := store.db.BeginTx(ctx, nil) 38\tif err != nil { 39\treturn err 40\t} 41 42\tq := New(tx) 43\terr = fn(q) 44\tif err != nil { 45\tif rbErr := tx.Rollback(); rbErr != nil { 46\treturn fmt.Errorf(\u0026#34;tx err: %v, rb err: %v\u0026#34;, err, rbErr) 47\t} 48\treturn err 49\t} 50 51\treturn tx.Commit() 52} 53 54func (store *SqlStore) SetInvTx(ctx context.Context, arg CreateInventoryParams) (Inventory, error) { 55\tvar inventory Inventory 56\tvar err error 57\terr = store.execTx(ctx, func(queries *Queries) error { 58\tinventory, err = queries.GetInventoryByGoodsID(ctx, arg.Goods) 59\tif err != nil { 60\tif err == sql.ErrNoRows { 61\t// 没有找到 62\tinventory, err = queries.CreateInventory(ctx, arg) 63\treturn nil 64\t} else { 65\tglobal.Logger.Error(\u0026#34;\u0026#34;, zap.Error(err)) 66\treturn status.Error(codes.Internal, \u0026#34;内部错误\u0026#34;) 67\t} 68\t} 69\tglobal.Logger.Info(\u0026#34;\u0026#34;, zap.Any(\u0026#34;\u0026#34;, inventory)) 70\t// 找到了 71 72\tupdateArg := UpdateInventoryParams{ 73\tUpdatedAt: time.Now(), 74\tGoods: inventory.Goods, 75\tCounts: arg.Sticks, 76\t} 77\tinventory, err = queries.UpdateInventory(ctx, updateArg) 78\treturn err 79\t}) 80 81\treturn inventory, err 82} 83 84func (store *SqlStore) SellTx(ctx context.Context, arg *proto.SellInfo) error { 85\t// 本地事务 要不都卖，要不都不卖 86\t// 拿到所有的商品， 87\t// 判断是否有库存 88\t// 判断库存是否够 89\t// 扣减库存 - 库存 会出现数据不一致的问题 90\terr := store.execTx(ctx, func(queries *Queries) error { 91\tvar inventory Inventory 92\tvar err error 93\tfor _, info := range arg.GetGoodsInfo() { 94\tinventory, err = queries.GetInventoryByGoodsID(ctx, info.GoodsId) 95\tif err != nil { 96\tif err == sql.ErrNoRows { 97\treturn status.Error(codes.NotFound, \u0026#34;没有该货物\u0026#34;) 98\t} else { 99\treturn status.Error(codes.Internal, \u0026#34;内部错误\u0026#34;) 100\t} 101\t} 102\tif inventory.Sticks \u0026lt; info.Num { 103\treturn status.Error(codes.InvalidArgument, \u0026#34;货物不够\u0026#34;) 104\t} 105\tupdateArg := UpdateInventoryParams{} 106\tupdateArg.Goods = info.GoodsId 107\tupdateArg.Counts = -info.Num // 这边应该时负数 108\tupdateArg.UpdatedAt = time.Now() 109\tinventory, err = queries.UpdateInventory(ctx, updateArg) 110\tif err != nil { 111\treturn err 112\t} 113\t} 114\treturn nil 115\t}) 116\treturn err 117} 118 119func (store *SqlStore) RollBackTx(ctx context.Context, arg *proto.SellInfo) error { 120\terr := store.execTx(ctx, func(queries *Queries) error { 121\tvar err error 122\tfor _, info := range arg.GetGoodsInfo() { 123\t_, err = queries.GetInventoryByGoodsID(ctx, info.GoodsId) 124\tif err != nil { 125\tif err == sql.ErrNoRows { 126\treturn status.Error(codes.NotFound, \u0026#34;没有该货物\u0026#34;) 127\t} else { 128\treturn status.Error(codes.Internal, \u0026#34;内部错误\u0026#34;) 129\t} 130\t} 131\tupdateArg := UpdateInventoryParams{} 132\tupdateArg.Goods = info.GoodsId 133\tupdateArg.Counts = info.Num // 这边应该时正数 134\tupdateArg.UpdatedAt = time.Now() 135\t_, err = queries.UpdateInventory(ctx, updateArg) 136\tif err != nil { 137\treturn err 138\t} 139\t} 140\treturn nil 141\t}) 142\treturn err 143} 测试 shop\\service\\inventory_srv\\handler\\inventory_test.go\n1package handler 2 3import ( 4\t\u0026#34;context\u0026#34; 5\t\u0026#34;testing\u0026#34; 6 7\t\u0026#34;github.com/stretchr/testify/require\u0026#34; 8 9\t\u0026#34;github.com/jimyag/shop/service/inventory/proto\u0026#34; 10) 11 12func TestSetInv(t *testing.T) { 13\tin := proto.GoodInvInfo{ 14\tGoodsId: 1, 15\tNum: 10, 16\t} 17\tinventory, err := inventoryClient.SetInv(context.Background(), \u0026amp;in) 18\trequire.NoError(t, err) 19\trequire.NotNil(t, inventory) 20} 21 22func TestInvDetail(t *testing.T) { 23\tin := proto.GoodInvInfo{ 24\tGoodsId: 1, 25\tNum: 10, 26\t} 27\tinventory, err := inventoryClient.InvDetail(context.Background(), \u0026amp;in) 28\trequire.NoError(t, err) 29\trequire.NotNil(t, inventory) 30\trequire.Equal(t, in.Num, inventory.Num) 31\trequire.Equal(t, in.GoodsId, inventory.GoodsId) 32} 33 34func TestSell(t *testing.T) { 35\tin := proto.GoodInvInfo{ 36\tGoodsId: 5, 37\tNum: 1, 38\t} 39\tinventory, err := inventoryClient.SetInv(context.Background(), \u0026amp;in) 40\trequire.NoError(t, err) 41\trequire.NotNil(t, inventory) 42 43\tins := proto.SellInfo{ 44\tGoodsInfo: []*proto.GoodInvInfo{ 45\t{ 46\tGoodsId: 1, 47\tNum: 10, 48\t}, 49\t{ 50\tGoodsId: 4, 51\tNum: 100, 52\t}, 53\t}, 54\t} 55\tinventory, err = inventoryClient.Sell(context.Background(), \u0026amp;ins) 56\trequire.Error(t, err) 57\trequire.Nil(t, inventory) 58 59} 60 61func TestRollBack(t *testing.T) { 62\tin := proto.SellInfo{ 63\tGoodsInfo: []*proto.GoodInvInfo{ 64\t{ 65\tGoodsId: 1, 66\tNum: 10, 67\t}, 68\t}, 69\t} 70\tinventory, err := inventoryClient.Rollback(context.Background(), \u0026amp;in) 71\trequire.NoError(t, err) 72\trequire.NotNil(t, inventory) 73 74\tin = proto.SellInfo{ 75\tGoodsInfo: []*proto.GoodInvInfo{ 76\t{ 77\tGoodsId: 1, 78\tNum: 10, 79\t}, 80\t{ 81\tGoodsId: 10000, 82\tNum: 1, 83\t}, 84\t}, 85\t} 86\tinventory, err = inventoryClient.Rollback(context.Background(), \u0026amp;in) 87\trequire.Error(t, err) 88\trequire.Nil(t, inventory) 89} 库存服务的锁问题 对于减少库存也就是出售商品，多个携程同时对数据库进行修改，虽然我们使用了事务，但是这也不能避免。\n1graph TB 2\tsubgraph g1 3\tgoroutinue1 --\u0026gt; 查询服务1 --\u0026gt; 判断逻辑1 --\u0026gt; 业务逻辑1 --\u0026gt; 更新数据1 4\tend 5 6\tsubgraph g2 7\tgoroutinue2 --\u0026gt; 查询服务 --\u0026gt; 判断逻辑 --\u0026gt; 业务逻辑 --\u0026gt; 更新数据 8\tend 9\t两个goroutine同时对数据库进行curd，在开始我们执行事务，这是g1拿到查询的值为100，g2拿到查询的值为100，g1进行更新数据更新为99，g2更新为99，两个事务提交。这时候发现数据已经不一致了。这时候我们给这个事务加锁，是可以解决这个问题的。但是这样的性能太低了，如果我只修改某一个商品的库存，那么所有的库存都要被加锁，以及我们如果有多个服务，一个系统锁只能管住一个服务实例，有多个实例即一个分布式系统时，我们就需要分布式锁。\n基于mysql的悲观锁，乐观锁 悲观锁 悲观锁是一种思想，一种互斥锁，串行化了\nmysql 的 for update\n@@autocommit\n要关闭auto commit\n1select * form test where goods=12 for update 2-- 只会锁住满足条件的数据 只有 goods 是索引的话才会这样 如果where的条件没有索引，行锁会升级成表锁 3-- 只锁更新的语句 4-- 如果没有满足条件的结果，不会缩表， where 字段为索引 5-- 如果不满足条件不是索引还是会缩表 乐观锁 用到version\n查询数据的时候查询版本号，\n1update inv set stocks = stocks-2 version = version +1 where goods =421 and version =version 同时过来只有一个可以成功，但是其余的都要重试\n基于redis的分布式锁 实现原理 实现原理 判断某个key是否存在且为1，不存在 设置key为1 判断421是否为1 如果没有，设置为1 如果有，就轮询等待 业务逻辑做完，就删除这个key 1和2应该是一起的是一个原子操作，redis实现了一个命令setnx如果key不存在，设置指定的值，上述过程就变为 setnx(421,1) 业务逻辑 删除这个key 如果服务挂掉了？业务逻辑挂了，没有完成，就不会删除这个key，其他的都一直在等待这个。 解决方案：\n设置过期时间(过期之后自动删除) 如果设置了过期时间，比如是8秒，我的业务需要10秒中才能完成，怎么办？\n在过期之前刷新一下过期时间 但是需要自己启动一个携程刷新 延时的接口可能会带来负面影响\u0026ndash;。如果某一个服务hung住了，本来是2s就能执行完，但是你hung住（由于各种原因，比如硬件问题）就会一直申请延长锁，导致别人永远获取不到锁， 分布式锁解决的问题 \u0026ndash;基于lua脚本去做 互斥性 -setnx 死锁 安全性 锁只能被持有该锁的用户删除，不能被其他用户删除， 设置的value是多少，只有当是的gor才能直到， 在删除的时候取出redis中的值和当前自己保存下来的值对比，如果一样删除 多节点redis实现的分布式锁算法(RedLock):有效防止单点故障 在一个系统中，我们有多个redis的实例，有一个是redis的master节点，其余的都是redis的slaver节点当一个服务向redis的某个节点拿到锁之后，reids的集群会自动同步所有的锁的状况，这里的同步我们先不做关心。\n在这个时候，master宕机了，他们之间的同步服务用不了了？？，这时候应该怎么办？\n红锁的原理： 有5台redis的实例，在获取锁(setnx)的时候应该在5台实例上都获得锁,这五台都是相同级别的，\n在获得锁的时候，如果两个服务同时获得锁，一个获得了一部分，一个获得了另一部分，如果要求全部设置上的话，就都会失败，那么重试的话，就不会成功。这时应该拿到多数的台数就算成功。5台的话谁先拿到3台就成功，如果有三个服务分别拿了221，那么就重试，直到有人拿到一半以上。这里拿锁是同时去拿，同时开gor去拿锁，如果某个服务没有拿到多数的锁就应该释放当前的锁。\n别人总结的 假设有5个完全独立的redis主服务器\n获取当前时间戳 client尝试按照顺序使用相同的key,value获取所有redis服务的锁，在获取锁的过程中的获取时间比锁过期时间短 很多，这是为了不要过长时间等待已经关闭的redis服务。且试着获取下一个redis实例。 比如: TTL为5s,设置获取锁最多用1s,所以如果一秒内无法获取锁， 就放弃获取这个锁，从而尝试获取下个锁 client通过获取所有能获取的锁后的时间减去第一步的时间， 这个时间差要小于TTL时间并且至少有3个redis实例 成功获取锁,才算真正的获取锁成功 如果成功获取锁，则锁的真正有效时间是TTL减去第三步的时间差的时间;比如: TTL是5s,获取所有锁用了2s, 则真正锁有效时间为3s(其实应该再减去时钟漂移); 如果客户端由于某些原因获取锁失败,便会开始解锁所有redis实例;因为可能已经获取了小于3个锁，必须释 放，否则影响其他client获取锁 什么是时钟漂移 如果redis服务器的机器时钟发生了向前跳跃,就会导致这个key过早超时失效，比如说客户端1拿到锁后，key的过 期时间是12:02分，但redis服务器本身的时钟比客户端快了2分钟，导致key在12:00的时候就失效了，这时候,如 果客户端1还没有释放锁的话，就可能导致多个客户端同时持有同-把锁的问题。\nRedLock算法是否是异步算法? ? 可以看成是同步算法;因为即使进程间(多个电脑间)没有同步时钟，但是每个进程时间流速大致相同;并且时 钟漂移相对于TTL叫小，可以忽略,所以可以看成同步算法; (不够严谨， 算法上要算上时钟漂移，因为如果两个 电脑在地球两端，则时钟漂移非常大)\nRedLock失败重试 当client不能获取锁时，应该在随机时间后重试获取锁;且最好在同-时刻并发的把set命令发送给所有redis实 例;而且对于已经获取锁的client在完成任务后要及时释放锁，这是为了节省时间;\nRedLock释放锁 由于释放锁时会判断这个锁的value是不是自己设置的,如果是才删除;所以在释放锁时非常简单,只要向所有实 例都发出释放锁的命令，不用考虑能否成功释放锁;\nRedLock注意点(Safety arguments) : 1.先假设client获取所有实例，所有实例包含相同的key和过期时间(TTL) ,但每个实例set命令时间不同导致不能同时 过期，第一个set命令之前是T1,最后一个set命令后为T2,则此client有效获取锁的最小时间为TTL-(T2-T1)-时钟漂移; 2.对于以N/2+ 1(也就是一半以,上)的方式判断获取锁成功,是因为如果小于一半判断为成功的话，有可能出现多 个client都成功获取锁的情况，从而使锁失效 3.-个client锁定大多数事例耗费的时间大于或接近锁的过期时间，就认为锁无效,并且解锁这个redis实例(不执行 业务) ;只要在TTL时间内成功获取一半以上的锁便是有效锁:否则无效\n系统有活性的三个特征 1.能够自动释放锁 2.在获取锁失败(不到一半以上)，或任务完成后 能够自动释放锁,不用等到其自动过期 3.在client重试获取哦锁前(第-次失败到第二 次重试时间间隔) 大于第一次获取锁消耗的时间; 4.重试获取锁要有-定次数限制\nRedLock性能及崩溃恢复的相关解决方法 1.如果redis没有持久化功能，在clientA获取锁成功后，所有redis重启，clientB能够再次获取到锁，这样违法了锁 的排他互斥性; 2.如果启动AOF永久化存储，事情会好些，举例:当我们重启redis后， 由于redis过期机制是按照unix时间戳走的, 所以在重启后，然后会按照规定的时间过期，不影响业务;但是由于AOF同步到磁盘的方式默认是每秒-次,如果在 一秒内断电， 会导致数据丢失,立即重启会造成锁互斥性失效;但如果同步磁盘仿式使用Always(每一个写命令 都同 步到硬盘)造成性能急剧下降;所以在锁完全有效性和性能方面要有所取舍; 3.有效解决既保证锁完全有效性及性能高效及即使断电情况的方法是redis同步到磁盘方式保持默认的每秒,在 redis无论因为什么原因停掉后要等待TTL时间后再重启(学名:延迟重启) ;缺点是在TTL时间内服务相当于暂停状态;\n总结 1.TTL时长要大于正常业务执行的时间+获取所有redis服务消耗时间+时钟漂移 2.获取redis所有服务消耗时间要远小于TTL时间,并且获取成功的锁个数要在总数的一般以上:N/2+1 3.尝试获取每个redis实例锁时的时间要远小于TTL时间 4.尝试获取所有锁失败后重新尝试一定要有一定次数限制 5.在redis崩溃后(无论-个还是所有)，要延迟TTL 时间重启redis 6.在实现多redis节点时要结合单节点分布式锁算法共同实现\n在项目中使用 1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;sync\u0026#34; 6\t\u0026#34;time\u0026#34; 7 8\tgoredislib \u0026#34;github.com/go-redis/redis/v8\u0026#34; 9\t\u0026#34;github.com/go-redsync/redsync/v4\u0026#34; 10\t\u0026#34;github.com/go-redsync/redsync/v4/redis/goredis/v8\u0026#34; 11) 12 13func main() { 14\t// Create a pool with go-redis (or redigo) which is the pool redisync will 15\t// use while communicating with Redis. This can also be any pool that 16\t// implements the `redis.Pool` interface. 17\tclient := goredislib.NewClient(\u0026amp;goredislib.Options{ 18\tAddr: \u0026#34;localhost:36379\u0026#34;, 19\t}) 20\tpool := goredis.NewPool(client) // or, pool := redigo.NewPool(...) 21 22\t// Create an instance of redisync to be used to obtain a mutual exclusion 23\t// lock. 24\trs := redsync.New(pool) 25 26\t// Obtain a new mutex by using the same name for all instances wanting the 27\t// same lock. 28 29\tgNum := 2 30\tmutexname := \u0026#34;my-global-mutex\u0026#34; 31\tvar wg sync.WaitGroup 32\twg.Add(gNum) 33\tfor i := 0; i \u0026lt; gNum; i++ { 34 35\tmutex := rs.NewMutex(mutexname) 36\tfmt.Println(\u0026#34;开始获取锁\u0026#34;) 37\tif err := mutex.Lock(); err != nil { 38\tpanic(err) 39\t} 40\tfmt.Println(\u0026#34;获取锁成功\u0026#34;) 41\ttime.Sleep(time.Second * 5) 42\tfmt.Println(\u0026#34;开始释放锁\u0026#34;) 43\tif ok, err := mutex.Unlock(); !ok || err != nil { 44\tpanic(\u0026#34;unlock failed\u0026#34;) 45\t} 46\tfmt.Println(\u0026#34;释放锁成功\u0026#34;) 47\twg.Done() 48\t} 49\twg.Wait() 50} 设置全局的rs = redsync.New(pool)\n初始化全局的rs\n在需要用到的地方\n1mutex := rs.NewMutex(mutexname) 2fmt.Println(\u0026#34;开始获取锁\u0026#34;) 3if err := mutex.Lock(); err != nil { 4\tpanic(err) 5 //错误处理 6} 7// 处理业务代码 8... 9// 处理业务结束 10if ok, err := mutex.Unlock(); !ok || err != nil { 11\tpanic(\u0026#34;unlock failed\u0026#34;) 12 // 处理错误 13} ","date":"2022-03-31","img":"","permalink":"/posts/c501f7ad/","series":["从0到1实现完整的微服务框架"],"tags":["微服务","gRPC"],"title":"从0到1实现完整的微服务框架-库存服务"},{"categories":[["微服务"],["gRPC"],["熔断"],["限流"],["降级"]],"content":"使用sentinel实现熔断限流和降级。\n服务雪崩 服务提供者不可用导致 服务调用的不可用，并将不可用现象放大\n服务雪崩三个阶段\n服务提供者不可用 硬件故障 程序bug 缓存击穿 用户大量请求 重试加大请求流量 用户重试 代码逻辑重试 服务调用者不可用 同步等待造成资源耗尽。 应对的策略\n应用库容 增加机器数量 升级规格 流控 不至于让服务挂掉 限流 关闭重试 缓存 缓存预加载 服务降级 当前访问用户过多，请稍后重试 服务接口拒绝服务 页面拒绝服务 延迟持久化 随机拒绝 服务熔断 调用方调用都超时？保险丝 服务限流 shop\\api\\user-api\\initialize\\sentinel.go\n1package initialize 2 3import ( 4\tsentinel \u0026#34;github.com/alibaba/sentinel-golang/api\u0026#34; 5\t\u0026#34;github.com/alibaba/sentinel-golang/core/flow\u0026#34; 6\t\u0026#34;go.uber.org/zap\u0026#34; 7 8\t\u0026#34;github.com/jimyag/shop/api/user/global\u0026#34; 9) 10 11func InitSentinel() { 12\terr := sentinel.InitDefault() 13\tif err != nil { 14\tglobal.Logger.Fatal(\u0026#34;初始化 sentinel 失败 .....\u0026#34;, zap.Error(err)) 15\t} 16 17\t_, err = flow.LoadRules([]*flow.Rule{ 18\t{ 19\tResource: \u0026#34;get-user-list\u0026#34;, 20\tTokenCalculateStrategy: flow.Direct, 21\tControlBehavior: flow.Reject, 22\tThreshold: 100, // 通过几个 23\tStatIntervalInMs: 1, // 多少秒 24\t}, 25\t}) 26\tif err != nil { 27\tglobal.Logger.Fatal(\u0026#34;加载 sentinel 配置失败....\u0026#34;, zap.Error(err)) 28\t} 29\tglobal.Logger.Info(\u0026#34;加载 sentinel 配置成功....\u0026#34;, zap.Error(err)) 30} shop\\api\\user-api\\api\\user.go\n1func GetUserList(ctx *gin.Context) { 2\tpageNum := ctx.DefaultQuery(\u0026#34;pageNum\u0026#34;, \u0026#34;1\u0026#34;) 3\tpageNumInt, err := strconv.Atoi(pageNum) 4\tif err != nil { 5\tglobal.Logger.Info(\u0026#34;pageNum invalid\u0026#34;) 6\t} 7\tpageSize := ctx.DefaultQuery(\u0026#34;pageSize\u0026#34;, \u0026#34;5\u0026#34;) 8\tpageSizeInt, err := strconv.Atoi(pageSize) 9\tif err != nil { 10\tglobal.Logger.Info(\u0026#34;pageNum invalid\u0026#34;) 11\t} 12 // 增加的开始 13\te, b := sentinel.Entry(\u0026#34;get-user-list\u0026#34;, sentinel.WithTrafficType(base.Inbound)) 14\tif b != nil { 15\t// block le 16\tresponse.FailWithMsg(\u0026#34;请求频率过快，请稍后重试\u0026#34;, ctx) 17\treturn 18\t} 19 // 增加的结束 20\trsp, err := global.UserSrvClient.GetUserList(ctx, \u0026amp;proto.PageIngo{ 21\tPageNum: uint32(pageNumInt), 22\tPageSize: uint32(pageSizeInt), 23\t}) 24\tif err != nil { 25\thandle_grpc_error.HandleGrpcErrorToHttp(err, ctx) 26\treturn 27\t} 28 // 增加的开始 29 e.Exit() 30 // 增加的结束 31 // .... 32} ","date":"2022-03-29","img":"","permalink":"/posts/71ef7b9d/","series":["从0到1实现完整的微服务框架"],"tags":["微服务","gRPC","熔断","限流","降级"],"title":"从0到1实现完整的微服务框架-熔断限流和降级"},{"categories":[["微服务"],["gRPC"],["链路追踪"]],"content":"在分布式系统，尤其是微服务系统中，一次外部请求往往需要内部多个模块，多个中间件，多台机器的相互调用才能完成。在这一系列的调用中，可能有些是串行的，而有些是并行的。在这种情况下，我们如何才能确定这整个请求调用了哪些应用？哪些模块？哪些节点？以及它们的先后顺序和各部分的性能如何呢？\n这就是涉及到链路追踪。\njaeger安装 1docker run -d --name jaeger -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 -p 5775:5775/udp -p 6831:6831/udp -p 6832:6832/udp -p 5778:5778 -p 16686:16686 -p 14250:14250 -p 14268:14268 -p 14269:14269 -p 9411:9411 jaegertracing/all-in-one:1.32 api层添加链路追踪 链路追踪的起点在每次发起http请求的地方，这时候就需要一个拦截器来生成tracer\nshop\\api\\user-api\\middlewares\\tracing.go\n1package middlewares 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5 6\t\u0026#34;github.com/gin-gonic/gin\u0026#34; 7\t\u0026#34;github.com/uber/jaeger-client-go\u0026#34; 8\tjaegercfg \u0026#34;github.com/uber/jaeger-client-go/config\u0026#34; 9\t\u0026#34;go.uber.org/zap\u0026#34; 10 11\t\u0026#34;github.com/jimyag/shop/api/user/global\u0026#34; 12) 13 14func Tracing() gin.HandlerFunc { 15\treturn func(ctx *gin.Context) { 16\tcfg := jaegercfg.Configuration{ 17\tSampler: \u0026amp;jaegercfg.SamplerConfig{ 18\tType: jaeger.SamplerTypeConst, 19\tParam: 1, // 全部采样 20\t}, 21\tReporter: \u0026amp;jaegercfg.ReporterConfig{ 22\tLogSpans: true, 23\tLocalAgentHostPort: fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, 24\tglobal.ServerConfig.JaegerInfo.Host, // jaeger 位置 25\tglobal.ServerConfig.JaegerInfo.Port, // 6831 26\t), 27\t}, 28\tServiceName: global.ServerConfig.Name, 29\t} 30\ttracer, close, err := cfg.NewTracer(jaegercfg.Logger(jaeger.StdLogger)) 31\tif err != nil { 32\tglobal.Logger.Fatal(\u0026#34;创建 tracer 失败\u0026#34;, zap.Error(err)) 33\t} 34\tdefer close.Close() 35\tstartSpan := tracer.StartSpan(ctx.Request.URL.Path) 36\tdefer startSpan.Finish() 37\tctx.Set(\u0026#34;tracer\u0026#34;, tracer) 38\tctx.Set(\u0026#34;parentSpan\u0026#34;, startSpan) 39\tctx.Next() 40\t} 41} 将这个中间件配置到需要链路追踪的router上\nshop\\api\\user-api\\initialize\\router.go全局都加\n1router.Use(middlewares.Tracing()) 由于我们使用了负载均衡,所以对于其他的grpc的链接要加一个拦截器，来将context加入到grpc服务中。\n1package initialize 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5 6\t\u0026#34;github.com/hashicorp/consul/api\u0026#34; 7\t_ \u0026#34;github.com/mbobakov/grpc-consul-resolver\u0026#34; 8\t\u0026#34;github.com/opentracing/opentracing-go\u0026#34; 9\t\u0026#34;go.uber.org/zap\u0026#34; 10\t\u0026#34;google.golang.org/grpc\u0026#34; 11 12\t\u0026#34;github.com/jimyag/shop/api/user/global\u0026#34; 13\t\u0026#34;github.com/jimyag/shop/api/user/proto\u0026#34; 14\t\u0026#34;github.com/jimyag/shop/api/user/util/otgrpc\u0026#34; 15) 16 17func InitSrvConn() { 18\t// consul 19\tconn, err := grpc.Dial( 20\tfmt.Sprintf(\u0026#34;consul://%s:%d/%s?wait=14s\u0026#34;, 21\tglobal.ServerConfig.ConsulInfo.Host, 22\tglobal.ServerConfig.ConsulInfo.Port, 23\tglobal.ServerConfig.UserSrv.Name, 24\t), 25\tgrpc.WithInsecure(), 26\tgrpc.WithDefaultServiceConfig(`{\u0026#34;loadBalancingPolicy\u0026#34;: \u0026#34;round_robin\u0026#34;}`), 27 // 添加的 28\tgrpc.WithUnaryInterceptor( 29\totgrpc.OpenTracingClientInterceptor( 30\topentracing.GlobalTracer(), 31\t), 32\t), 33 // 结束 34\t) 35\tif err != nil { 36\tglobal.Logger.Fatal(\u0026#34;用户服务发现错误\u0026#34;, zap.Error(err)) 37\t} 38\tglobal.UserSrvClient = proto.NewUserClient(conn) 39 40} shop\\api\\user-api\\util\\otgrpc\\client.go:31修改源码\n1func OpenTracingClientInterceptor(tracer opentracing.Tracer, optFuncs ...Option) grpc.UnaryClientInterceptor { 2\totgrpcOpts := newOptions() 3\totgrpcOpts.apply(optFuncs...) 4\treturn func( 5\tctx context.Context, 6\tmethod string, 7\treq, resp interface{}, 8\tcc *grpc.ClientConn, 9\tinvoker grpc.UnaryInvoker, 10\topts ...grpc.CallOption, 11\t) error { 12\tvar err error 13\tvar parentCtx opentracing.SpanContext 14\t// 从 context 提取 父span 15\tif parent := opentracing.SpanFromContext(ctx); parent != nil { 16\tparentCtx = parent.Context() 17\t} 18 // 修改的 19\tswitch ctx.(type) { 20\tcase *gin.Context: 21\tiTracer, ok := ctx.(*gin.Context).Get(\u0026#34;tracer\u0026#34;) 22\tif ok { 23\ttracer = iTracer.(opentracing.Tracer) 24\t} 25 26\tparentSpan, ok := ctx.(*gin.Context).Get(\u0026#34;parentSpan\u0026#34;) 27\tif ok { 28\tparentCtx = parentSpan.(*jaegerClient.Span).Context() 29\t} 30 31\t} 32 33\tif otgrpcOpts.inclusionFunc != nil \u0026amp;\u0026amp; 34\t!otgrpcOpts.inclusionFunc(parentCtx, method, req, resp) { 35\treturn invoker(ctx, method, req, resp, cc, opts...) 36\t} 37\tclientSpan := tracer.StartSpan( 38\tmethod, 39\topentracing.ChildOf(parentCtx), 40\text.SpanKindRPCClient, 41\tgRPCComponentTag, 42\t) 43\tdefer clientSpan.Finish() 44\t// 使用metadata机制传递 45\tctx = injectSpanContext(ctx, tracer, clientSpan) 46\tif otgrpcOpts.logPayloads { 47\tclientSpan.LogFields(log.Object(\u0026#34;gRPC request\u0026#34;, req)) 48\t} 49\terr = invoker(ctx, method, req, resp, cc, opts...) 50\tif err == nil { 51\tif otgrpcOpts.logPayloads { 52\tclientSpan.LogFields(log.Object(\u0026#34;gRPC response\u0026#34;, resp)) 53\t} 54\t} else { 55\tSetSpanTags(clientSpan, err, true) 56\tclientSpan.LogFields(log.String(\u0026#34;event\u0026#34;, \u0026#34;error\u0026#34;), log.String(\u0026#34;message\u0026#34;, err.Error())) 57\t} 58\tif otgrpcOpts.decorator != nil { 59\totgrpcOpts.decorator(clientSpan, method, req, resp, err) 60\t} 61\treturn err 62\t} 63} 这里修改源码是拿到context中的tracer和parentSpan\ngrpc集成jaeger 在服务端还有子的过程\nclient拦截器的原理\n从context拿到父亲的span\n1// 通过parentSpan生成当前的span 2clientSpan := tracer.StartSpan( 3\tmethod, 4\topentracing.ChildOf(parentCtx), 5\text.SpanKindRPCClient, 6\tgRPCComponentTag, 7\t) 8\tdefer clientSpan.Finish() 通过metadata的机制，将它的内容写到metadata中去\n1// 使用metadata机制传递 2\tctx = injectSpanContext(ctx, tracer, clientSpan) 然后通过shop\\api\\user-api\\util\\otgrpc\\client.go:243\n1func injectSpanContext(ctx context.Context, tracer opentracing.Tracer, clientSpan opentracing.Span) context.Context { 2\tmd, ok := metadata.FromOutgoingContext(ctx) 3\tif !ok { 4\tmd = metadata.New(nil) 5\t} else { 6\tmd = md.Copy() 7\t} 8\tmdWriter := metadataReaderWriter{md} 9\t// 将服务端想要的信息注入到metadata中 10\terr := tracer.Inject(clientSpan.Context(), opentracing.HTTPHeaders, mdWriter) 11\t// We have no better place to record an error than the Span itself :-/ 12\tif err != nil { 13\tclientSpan.LogFields(log.String(\u0026#34;event\u0026#34;, \u0026#34;Tracer.Inject() failed\u0026#34;), log.Error(err)) 14\t} 15\treturn metadata.NewOutgoingContext(ctx, md) 16} 如何写到opentracing中去这是有一个标准，是由opentracing做的，如何提取也是由它来做的。\n将服务端想要的信息注入到metadata中去，如果注入、拿数据我们不用关心。\n在grpc服务端\n1// For example: 2// 3// s := grpc.NewServer( 4// ..., // (existing ServerOptions) 5// grpc.UnaryInterceptor(otgrpc.OpenTracingServerInterceptor(tracer))) 只要在new grpcserver的时候添加一个服务端的拦截器就行\nshop\\service\\user_srv\\main.go\n1// 初始化jaeger 2\tcfg := jaegercfg.Configuration{ 3\tSampler: \u0026amp;jaegercfg.SamplerConfig{ 4\tType: jaeger.SamplerTypeConst, 5\tParam: 1, // 全部采样 6\t}, 7\tReporter: \u0026amp;jaegercfg.ReporterConfig{ 8\tLogSpans: true, 9\tLocalAgentHostPort: fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, 10\tglobal.RemoteConfig.JaegerInfo.Host, 11\tglobal.RemoteConfig.JaegerInfo.Port, 12\t), 13\t}, 14\tServiceName: \u0026#34;user-srv\u0026#34;, 15\t} 16\t// 初始化一jaeger 17\ttracer, cl, err := cfg.NewTracer(jaegercfg.Logger(jaeger.StdLogger)) 18\tif err != nil { 19\tglobal.Logger.Fatal(\u0026#34;创建 tracer 失败\u0026#34;, zap.Error(err)) 20\t} 21\topentracing.SetGlobalTracer(tracer) 22\t// 注册服务 23\tserver := grpc.NewServer(grpc.UnaryInterceptor(otgrpc.OpenTracingServerInterceptor(tracer))) 我们这边可以自己生成tracer，没有必要用服务端的tracer，我们只要处理好父子关系就好，当整个服务挂了之后cl.Close()\n在grpc的服务中如何拿到tracer，\nshop\\service\\user_srv\\util\\otgrpc\\server.go:39从context中拿到span\n1spanContext, err := extractSpanContext(ctx, tracer) 1func extractSpanContext(ctx context.Context, tracer opentracing.Tracer) (opentracing.SpanContext, error) { 2\tmd, ok := metadata.FromIncomingContext(ctx) 3\tif !ok { 4\tmd = metadata.New(nil) 5\t} 6 // 与之前的Inject对应 7\treturn tracer.Extract(opentracing.HTTPHeaders, metadataReaderWriter{md}) 8} 在服务中使用：\nD:\\repository\\shop\\service\\user_srv\\handler\\user.go\n1func (u *UserServer) GetUserList(ctx context.Context, req *proto.PageIngo) (*proto.UserListResponse, error) { 2\t// 省略之前的 3 // 从context总拿到parentSpan 4\tparentSpan := opentracing.SpanFromContext(ctx) 5 // 生成一个span并设置它的父亲 6\tgetUserListSpan := opentracing.GlobalTracer().StartSpan(\u0026#34;get user list form database\u0026#34;, opentracing.ChildOf(parentSpan.Context())) 7\tusers, err := u.Store.ListUsers(ctx, arg) 8\tif err != nil { 9\treturn nil, status.Errorf(codes.Internal, \u0026#34;获得用户列表信息失败\u0026#34;) 10\t} 11\tgetUserListSpan.Finish() 12 // 追踪结束。 13 // 省略其他 14} ","date":"2022-03-28","img":"","permalink":"/posts/c8b300d9/","series":["从0到1实现完整的微服务框架"],"tags":["微服务","gRPC","链路追踪"],"title":"从0到1实现完整的微服务框架-链路追踪"},{"categories":[["微服务"],["gRPC"],["负载均衡"]],"content":"本文主要介绍如何在grpc中使用负载均衡。\n我们使用的是别人写好的一个包mbobakov/grpc-consul-resolver,这个包的使用也很简单，只需要导入进来，在初始化的时候添加\n1package main 2 3import ( 4\t\u0026#34;time\u0026#34; 5\t\u0026#34;log\u0026#34; 6 7 // 添加的 8\t_ \u0026#34;github.com/mbobakov/grpc-consul-resolver\u0026#34; // It\u0026#39;s important 9 10\t\u0026#34;google.golang.org/grpc\u0026#34; 11) 12 13func main() { 14 conn, err := grpc.Dial( 15 \u0026#34;consul://127.0.0.1:8500/whoami?wait=14s\u0026amp;tag=manual\u0026#34;, 16 grpc.WithInsecure(), 17 // 添加的 18 grpc.WithDefaultServiceConfig(`{\u0026#34;loadBalancingPolicy\u0026#34;: \u0026#34;round_robin\u0026#34;}`), 19 ) 20 if err != nil { 21 log.Fatal(err) 22 } 23 defer conn.Close() 24 ... 25} 在这里我们要做一个关于优雅终止的。当我们要结束掉进程之后，我们要把服务在注册中心注销掉。\nshop\\service\\user_srv\\main.go最后\n1\t// 由于我们要一直监听操作，这些启动一个协程 2\tgo func() { 3\terr = server.Serve(lis) 4\tif err != nil { 5\tglobal.Logger.Fatal(\u0026#34;cannot run server.....\u0026#34;) 6\t} 7\t}() 8\t// 优雅退出 9\tquit := make(chan os.Signal) 10\t// 监听信号 11\tsignal.Notify(quit, syscall.SIGINT, syscall.SIGTERM) 12\t\u0026lt;-quit 13\tif err = client.Agent().ServiceDeregister(serviceID.String()); err != nil { 14\tglobal.Logger.Info(\u0026#34;服务注销失败\u0026#34;, zap.String(\u0026#34;serviceID\u0026#34;, serviceID.String())) 15\t} 16\tcl.Close() 17\tglobal.Logger.Info(\u0026#34;服务已注销\u0026#34;, zap.String(\u0026#34;serviceID\u0026#34;, serviceID.String())) ","date":"2022-03-28","img":"","permalink":"/posts/a97428cc/","series":["从0到1实现完整的微服务框架"],"tags":["微服务","gRPC","负载均衡"],"title":"从0到1实现完整的微服务框架-负载均衡"},{"categories":[["微服务"],["gRPC"],["配置中心"],["服务发现"],["服务注册"]],"content":"当某一个服务要以集群的形式进行部署，这时候就要用到服务注册和服务发现。主要介绍使用consul进行服务发现、服务注册以及配置中心。\n​\t假如这个产品已经在线上运行，有一天运营想搞一场促销活动，那么我们相对应的【用户服务】可能就要新开启三个微服务实例来支撑这场促销活动。而与此同时，作为苦逼程序员的你就只有手动去 API gateway 中添加新增的这三个微服务实例的 ip 与port ，一个真正在线的微服务系统可能有成百上千微服务，难道也要一个一个去手动添加吗？有没有让系统自动去实现这些操作的方法呢？答案当然是有的。 ​\t当我们新添加一个微服务实例的时候，微服务就会将自己的 ip 与 port 发送到注册中心，在注册中心里面记录起来。当 API gateway 需要访问某些微服务的时候，就会去注册中心取到相应的 ip 与 port。从而实现自动化操作。\nconsul安装 1docker run -d -p 8500:8500 -p 8300:8300 -p 8301:8301 -p 8302:8302 -p 8600:8600/udp consul consul agent -dev -client=0.0.0.0 8600dns端口,8500http端口\ngrpc的健康检查 1import ( 2 \u0026#34;google.golang.org/grpc/health\u0026#34; 3\t\u0026#34;google.golang.org/grpc/health/grpc_health_v1\u0026#34; 4) 5\t// 注册 grpc 健康检查 6\tgrpc_health_v1.RegisterHealthServer(server, health.NewServer()) 只需在shop\\service\\user_srv\\main.gomain方法中的注册服务之后添加这一句就可以\n1\t// 省略之前的 2\tserver := grpc.NewServer() 3\tsqlStore := model.NewSqlStore(global.DB) 4\tuserServer := handler.UserServer{Store: sqlStore} 5 6\tport, err := util.GetFreePort() 7\t... 8\tproto.RegisterUserServer(server, \u0026amp;userServer) 9\t... 省略listen 10\t// 注册 grpc 健康检查 11\tgrpc_health_v1.RegisterHealthServer(server, health.NewServer()) 将grpc的服务注册到consul 添加consul的配置shop\\service\\user_srv\\config\\consul_info.go\n1type ServerConfig struct{ 2 Host string `mapstructure:\u0026#34;host\u0026#34;` // 服务启动的host 3\tPort int `mapstructure:\u0026#34;port\u0026#34;` // 服务启动的port 4\tName string `mapstructure:\u0026#34;name\u0026#34;` // 服务的名称 5 Consul Consul `mapstructure:\u0026#34;consul\u0026#34;` // consul的配置 6} 7 8type Consul struct { 9 Host string `mapstructure:\u0026#34;host\u0026#34;` // consul的host 10\tPort int `mapstructure:\u0026#34;port\u0026#34;` // consul的port 11} 这里问什么要在severConfig中添加一个name，是因为每一个服务都有一个自己的服务名称，在http客户端之后找服务的时候就找服务名下的一个服务就行。\n在main中\n1import( 2 \u0026#34;github.com/hashicorp/consul/api 3) 4 5func main(){ 6\t// consul服务注册 7\tapiCfg := api.DefaultConfig() 8\tapiCfg.Address = fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, 9\tglobal.ServerConfig.Consul.Host, 10\tglobal.ServerConfig.Consul.Port, 11\t) 12 client, err := api.NewClient(apiCfg) 13\tif err != nil { 14\tglobal.Logger.Fatal(err.Error()) 15\t} 16 17\t// 检查对象 consul 做健康检查的ip 18\tcheck := api.AgentServiceCheck{ 19\tGRPC: fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, 20\tglobal.ServerConfig.Host, // 这里就是你要检测那个服务的host和port 21\tglobal.ServerConfig.Port, 22\t), 23\tTimeout: \u0026#34;3s\u0026#34;, 24\tInterval: \u0026#34;5s\u0026#34;, 25\tDeregisterCriticalServiceAfter: \u0026#34;100s\u0026#34;, // 健康检查失败超过100s之后就会删除这个服务 26\t} 27 // 一个服务中可以 28 var serviceID uuid.UUID 29\tfor { 30\tserviceID, err = uuid.NewRandom() 31\tif err == nil { 32\tbreak 33\t} 34\t} 35 36\t// consul 做健康检查的ip 37\tserviceRegistration := api.AgentServiceRegistration{ 38\tID: serviceID.String(), 39\tName: global.RemoteConfig.ServiceInfo.Name, 40\tPort: global.RemoteConfig.ServiceInfo.Port, 41\tAddress: global.RemoteConfig.ServiceInfo.Host, 42\t} 43 44\tserviceRegistration.Check = \u0026amp;check 45\terr = client.Agent().ServiceRegister(\u0026amp;serviceRegistration) 46\tif err != nil { 47\tlog.Fatalln(\u0026#34;注册失败\u0026#34;, err) 48\t} 49\tglobal.Logger.Info(\u0026#34;启动 grpc 健康检查\u0026#34;) 50 51} 至此，已经将gRPC的服务注册到consul中去了。\n在api中服务发现 同样我们添加consul的配置\n1name: \u0026#39;user-api\u0026#39; 2port: 8021 3 4consul-info: 5 host: \u0026#34;192.168.0.2\u0026#34; 6 port: 8500 在之前的初始化UserClient时，我们是写死的host:port这时候，我们可以使用\n1import( 2 \u0026#34;fmt\u0026#34; 3 4\t\u0026#34;github.com/hashicorp/consul/api\u0026#34; 5) 6// 部分import 7 8func InitSrvConn() { 9\tcfg := api.DefaultConfig() 10\tcfg.Address = fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, 11\tglobal.ServerConfig.ConsulInfo.Host, 12\tglobal.ServerConfig.ConsulInfo.Port, 13\t) 14 // 连接到consul 15\tclient, err := api.NewClient(cfg) 16\tif err != nil { 17\tglobal.Logger.Fatal(\u0026#34;创建 consul 客户端失败\u0026#34;, zap.Error(err)) 18\t} 19\t// 这里一定要有 \u0026#34;\u0026#34; 20 // 从consul中拉取服务，这里的服务也是从配置文件中拉 21\tservices, err := client.Agent().ServicesWithFilter(fmt.Sprintf(`Service == \u0026#34;%s\u0026#34;`, global.ServerConfig.UserSrv.Name)) 22\tif err != nil { 23\tglobal.Logger.Fatal(\u0026#34;获取服务失败\u0026#34;, zap.Error(err)) 24\t} 25\tvar userSrvHost string 26\tvar userSrvPort int 27\tfor _, value := range services { 28\tuserSrvPort = value.Port 29\tuserSrvHost = value.Address 30\tbreak 31\t} 32 // 在拿到host和post之后，就和之前的一样了。 33 // 关键是拿到 host和port 34 用consul做注册中心 在consul是有存储kv的数据库，基于这个我们就可以将配置保存在consul中。具体的实现也很简单，之前我们用viper读本地的配置文件，而viper的强大在于他也能读远程的配置文件。\n这时候，我们本地只需要保存consul的配置就行，首先加载consul的位置，之后从consul中读取配置文件，就可以。\nshop\\api\\user-api\\initialize\\config.go这是api的加载配置文件，同样，srv也是一样的。\n1package initialize 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5 6\t\u0026#34;github.com/fsnotify/fsnotify\u0026#34; 7\t\u0026#34;github.com/spf13/viper\u0026#34; 8\t_ \u0026#34;github.com/spf13/viper/remote\u0026#34; 9\t\u0026#34;go.uber.org/zap\u0026#34; 10 11\t\u0026#34;github.com/jimyag/shop/api/user/global\u0026#34; 12) 13 14func getEnvBool(env string) bool { 15\tviper.AutomaticEnv() 16\treturn viper.GetBool(env) 17} 18 19// LoadConsulConfigInfo 加载本地的 consul 文件 20func LoadConsulConfigInfo() { 21\tconfigFilePath := \u0026#34;consul-info.yaml\u0026#34; 22 23\tv := viper.New() 24\tv.SetConfigFile(configFilePath) 25\tif err := v.ReadInConfig(); err != nil { 26\tglobal.Logger.Fatal(\u0026#34;加载配置文件失败.....\u0026#34;, 27\tzap.Error(err), 28\tzap.String(\u0026#34;path\u0026#34;, configFilePath), 29\t) 30\t} 31 32\tglobal.Logger.Info(\u0026#34;配置加载成功....\u0026#34;, 33\tzap.String(\u0026#34;path\u0026#34;, configFilePath), 34\t) 35\tif err := v.Unmarshal(\u0026amp;global.ConsulCenterInfo); err != nil { 36\tglobal.Logger.Fatal(\u0026#34;解析配置文件失败....\u0026#34;, 37\tzap.Error(err), 38\tzap.String(\u0026#34;path\u0026#34;, configFilePath), 39\t) 40\t} 41\tglobal.Logger.Info(\u0026#34;成功加载配置文件\u0026#34;, 42\tzap.String(\u0026#34;path\u0026#34;, configFilePath), 43\tzap.Any(\u0026#34;content\u0026#34;, global.ConsulCenterInfo), 44\t) 45\tv.WatchConfig() 46\tv.OnConfigChange(func(in fsnotify.Event) { 47\tglobal.Logger.Info(\u0026#34;配置文件产生变化....\u0026#34;, 48\tzap.String(\u0026#34;name\u0026#34;, in.String()), 49\tzap.String(\u0026#34;path\u0026#34;, configFilePath), 50\t) 51 52\tif err := v.ReadInConfig(); err != nil { 53\tglobal.Logger.Fatal(\u0026#34;修改的配置文件字段出错\u0026#34;, 54\tzap.String(\u0026#34;field\u0026#34;, in.String()), 55\tzap.Error(err), 56\t) 57\t} 58\tif err := v.Unmarshal(\u0026amp;global.ConsulCenterInfo); err != nil { 59\tglobal.Logger.Fatal(\u0026#34;解析配置文件出错\u0026#34;, 60\tzap.String(\u0026#34;field\u0026#34;, in.String()), 61\tzap.Error(err), 62\t) 63\t} 64\tglobal.Logger.Info(\u0026#34;配置文件内容\u0026#34;, zap.Any(\u0026#34;config\u0026#34;, global.ConsulCenterInfo)) 65\t}) 66} 67 68func LoadRemoteConfig() { 69\tremoteViper := viper.New() 70\tpath := global.ConsulCenterInfo.ReleasePath 71\tif debug := getEnvBool(global.ConsulCenterInfo.EnvName); debug { 72\tpath = global.ConsulCenterInfo.DebugPath 73\t} 74\tremoteViper.SetConfigType(global.ConsulCenterInfo.FileType) 75\terr := remoteViper.AddRemoteProvider(global.ConsulCenterInfo.Type, 76\tfmt.Sprintf(\u0026#34;%s:%d\u0026#34;, global.ConsulCenterInfo.Host, 77\tglobal.ConsulCenterInfo.Port, 78\t), 79\tpath, 80\t) 81\tif err != nil { 82\tglobal.Logger.Fatal(\u0026#34;添加配置文件失败\u0026#34;, zap.Error(err)) 83\treturn 84\t} 85 86\terr = remoteViper.ReadRemoteConfig() 87\tif err != nil { 88\tglobal.Logger.Fatal(\u0026#34;读取远端配置文件失败\u0026#34;, zap.Error(err)) 89\t} 90\terr = remoteViper.Unmarshal(\u0026amp;global.ServerConfig) 91\tif err != nil { 92\tglobal.Logger.Fatal(\u0026#34;解析远端配置文件失败\u0026#34;, zap.Error(err)) 93\t} 94\tglobal.Logger.Info(\u0026#34;成功加载远端配置文件....\u0026#34;, zap.Any(\u0026#34;config\u0026#34;, global.ServerConfig)) 95} debug.yaml远程的配置文件的内容\n1name: \u0026#39;user-api\u0026#39; 2port: 8021 3 4user-srv: 5 host: \u0026#39;192.168.0.2\u0026#39; 6 host-port: 50051 7 name: \u0026#34;user-srv\u0026#34; 8 9consul-info: 10 host: \u0026#34;192.168.0.2\u0026#34; 11 port: 8500 1host: \u0026#34;192.168.0.2\u0026#34; 2port: 8500 3release-path: \u0026#34;shop/user/api/release.yaml\u0026#34; 4debug-path: \u0026#34;shop/user/api/debug.yaml\u0026#34; 5file-type: \u0026#34;yaml\u0026#34; 6type: \u0026#34;consul\u0026#34; 7env-name: \u0026#34;shop_debug\u0026#34; ","date":"2022-03-28","img":"","permalink":"/posts/5763d21a/","series":["从0到1实现完整的微服务框架"],"tags":["微服务","gRPC","配置中心","服务发现","服务注册"],"title":"从0到1实现完整的微服务框架-服务注册、发现、配置中心"},{"categories":[["微服务"],["gRPC"]],"content":"本篇主要介绍实现用户服务中的相关内容。\n开始 新建项目\n1mkdir shop 2cd shop 3mkdir api,docs,service 本项目采用的是分层的微服务架构，api主要是对外提供的http接口，docs放相关的文档，service主要提供对内的grpc服务。\n1shop 2├── api 3│ └── user-api\t// 用户服务的api 4│ ├── api\t// http接口 5│ ├── config\t// 相关配置文件的go内容 6│ ├── global\t// 全局变量 数据库连接 7│ ├── initialize\t// 初始化相关的 8│ ├── middlewares\t// 中间件 9│ ├── proto\t// proto文件 10│ ├── router\t// 路由 11│ └── util 12│ 13├── docs 14│ └── service 15└── service 16 └── user_srv 17 ├── config\t// 配置文件 18 ├── db\t// 数据库相关的 19 │ ├── migration\t// 数据库同步 20 │ └── query\t// curd\t的 SQL 语句 21 ├── global\t// 全局变量 22 ├── handler\t// 服务处理 23 ├── initialize 24 ├── model\t// 数据库表结构对应的model 25 ├── proto\t26 └── util 用户表结构 进入service/user_srv初始化mod\n1go mod init github.com/jimyag/shop/service/user 用户信息中要包含一下信息\n1CREATE TABLE \u0026#34;user\u0026#34; 2( 3 \u0026#34;id\u0026#34; bigserial PRIMARY KEY, -- 自增id 4 \u0026#34;created_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), -- 信息创建时间 5 \u0026#34;updated_at\u0026#34; timestamptz NOT NULL DEFAULT (now()), -- 信息修改时间 6 \u0026#34;deleted_at\u0026#34; timestamptz DEFAULT null, -- 信息删除时间， 这是的删除使用的是软删除，只是给用户信息打个标记，提示该用户已经被删除了 7 \u0026#34;email\u0026#34; varchar UNIQUE NOT NULL,\t-- 邮件 8 \u0026#34;password\u0026#34; varchar NOT NULL,\t-- 密码 9 \u0026#34;nickname\u0026#34; varchar NOT NULL,\t-- 昵称 10 \u0026#34;gender\u0026#34; varchar(6) NOT NULL DEFAULT \u0026#39;male\u0026#39;,\t-- 性别 11 \u0026#34;role\u0026#34; int8 NOT NULL DEFAULT 1\t-- 权限 12); 13CREATE INDEX ON \u0026#34;user\u0026#34; (\u0026#34;email\u0026#34;); 14 15COMMENT ON COLUMN \u0026#34;user\u0026#34;.\u0026#34;email\u0026#34; IS \u0026#39;user email\u0026#39;; 16 17COMMENT ON COLUMN \u0026#34;user\u0026#34;.\u0026#34;password\u0026#34; IS \u0026#39;user password\u0026#39;; 18 19COMMENT ON COLUMN \u0026#34;user\u0026#34;.\u0026#34;nickname\u0026#34; IS \u0026#39;user nickname default email\u0026#39;; 20 21COMMENT ON COLUMN \u0026#34;user\u0026#34;.\u0026#34;gender\u0026#34; IS \u0026#39;male man ,female women\u0026#39;; 22 23COMMENT ON COLUMN \u0026#34;user\u0026#34;.\u0026#34;role\u0026#34; IS \u0026#39;1 user 2 admin\u0026#39;; 进入user-srv/db文件，执行\n1migrate create -ext sql -dir migration -seq init_schema_user 2D:\\repository\\shop\\service\\user_srv\\db\\migration\\000001_init_schema_user.up.sql 3D:\\repository\\shop\\service\\user_srv\\db\\migration\\000001_init_schema_user.down.sql 生成同步表结构,\n将上述的sql语句写入到shop\\service\\user_srv\\db\\migration\\000001_init_schema_user.up.sql中，\n在shop\\service\\user_srv\\db\\migration\\000001_init_schema_user.down.sql中写入\n1DROP TABLE IF EXISTS \u0026#34;user\u0026#34;; up是用来同步数据库\ndown是用来回滚数据库\n创建user数据库 相关文档会在docs中进行更新，推荐保存下来用到的各个端口，以防后面冲突。\n1docker run --name shop-user -p 35432:5432 -e POSTGRES_PASSWORD=postgres -e TZ=PRC -d postgres:14-alpine 创建用户数据库\n1docker exec -it shop-user createdb --username=postgres --owner=postgres shop 删除用户数据库的命令\n1docker exec -it shop-user dropdb --username=postgres shop 数据库迁移 生成用户表，\n1migrate -path db/migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose up 删除用户表，（如果可以用到的话）\n1migrate -path db/migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose down 生成curd代码 在wsl中 初始化\n1docker run --rm -v /mnt/d/repository/shop/service/user_srv:/src -w /src kjconroy/sqlc init 在生成的sqlc.yaml中写入\n1version: 1 2packages: 3 - path: \u0026#34;./model\u0026#34; # 生成go 代码的位置 4 name: \u0026#34;model\u0026#34; # 生成 go package 的名字 5 engine: \u0026#34;postgresql\u0026#34; # 使用的数据库引擎 6 schema: \u0026#34;./db/migration/\u0026#34; # 迁移表的sql语句 我们使用migrate中的up文件 7 queries: \u0026#34;./db/query\u0026#34; # CRUD的sql 8 emit_json_tags: true # 添加json在生成的struct中 9 emit_prepared_queries: false 10 emit_interface: true # 生成接口 11 emit_exact_table_names: false # 表名是否带s 在shop\\service\\user_srv\\db\\query\\user.sqlcurd的SQL语句\n1-- name: CreateUser :one 2INSERT INTO \u0026#34;user\u0026#34;(email, 3 password, 4 nickname, 5 gender, 6 role) 7VALUES ($1, $2, $3, $4, $5) 8returning *; 9 10-- name: GetUserById :one 11SELECT * 12FROM \u0026#34;user\u0026#34; 13WHERE id = $1 14LIMIT 1; 15 16-- name: GetUserByEmail :one 17SELECT * 18FROM \u0026#34;user\u0026#34; 19WHERE email = $1 20LIMIT 1; 21 22-- name: ListUsers :many 23select * 24from \u0026#34;user\u0026#34; 25where deleted_at IS NULL 26order by id 27limit $1 offset $2; 28 29 30-- name: DeleteUser :execrows 31update \u0026#34;user\u0026#34; 32set deleted_at =$2 33where id = $1 34 and deleted_at is null; 35 36-- name: UpdateUser :one 37update \u0026#34;user\u0026#34; 38set updated_at = $1, 39 nickname = $2, 40 gender = $3, 41 role = $4, 42 password = $5 43where id = $6 44returning *; 生成curd代码\n1docker run --rm -v /mnt/d/repository/shop/service/user_srv:/src -w /src kjconroy/sqlc generate 这里的/mnt/d/repository/shop/service/user_srv是我当前项目的所在的位置\n这时，会在shop\\service\\user_srv\\model中生成四个文件。\n1├── db.go 2├── models.go 3├── querier.go 4├── user.sql.go 测试连接数据库 在shop\\service\\user_srv\\model新建文件夹main/main.go\nshop\\service\\user_srv\\model\\main\\main.go\n1package main 2 3import ( 4\t\u0026#34;context\u0026#34; 5\t\u0026#34;database/sql\u0026#34; 6\t\u0026#34;log\u0026#34; 7 8\t_ \u0026#34;github.com/lib/pq\u0026#34; 9 10\t\u0026#34;github.com/jimyag/shop/service/user/model\u0026#34; 11) 12 13const ( 14\tDbDriver = \u0026#34;postgres\u0026#34; // 数据库的驱动 15\tDbSource = \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; // 数据库的链接 16 // 驱动://用户名:密码@数据库的地址:端口号/数据库名称？sslmode=disable 17) 18 19func main() { 20\tdb, err := sql.Open(DbDriver, DbSource) 21\tif err != nil { 22\tlog.Fatalln(\u0026#34;cannot connect to db :\u0026#34;, err) 23\t} 24\tlog.Println(\u0026#34;connect db ....\u0026#34;) 25\tsqlStore := model.NewSqlStore(db) 26\tuser, err := sqlStore.GetUserByEmail(context.Background(), \u0026#34;jimyag1@126.com\u0026#34;) 27\tlog.Println(user) 28} 测试生成的curd代码 在shop\\service\\user_srv\\model新建两个文件，main_test.go,user.sql_test.go\n1. 2├── db.go 3├── main 4│ └── main.go 5├── main_test.go 6├── models.go 7├── querier.go 8├── user.sql.go 9└── user.sql_test.go 这两个是为了测试生成的curd代码是否正确。\nshop/service/user_srv/model/main_test.go中添加一下内容，这里是一个main测试，在当前包中所有的测试之前都会执行这个方法。\n1package model 2 3import ( 4\t\u0026#34;database/sql\u0026#34; 5\t\u0026#34;log\u0026#34; 6\t\u0026#34;os\u0026#34; 7\t\u0026#34;testing\u0026#34; 8 9\t_ \u0026#34;github.com/lib/pq\u0026#34; 10) 11 12const ( 13\tDbDriver = \u0026#34;postgres\u0026#34; 14\tDbSource = \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; 15) 16 17var ( 18\ttestQueries *Queries 19\ttestDB *sql.DB 20) 21 22func TestMain(m *testing.M) { 23\tvar err error 24\ttestDB, err = sql.Open(DbDriver, DbSource) 25\tif err != nil { 26\tlog.Fatalln(\u0026#34;cannot connect to db :\u0026#34;, err) 27\t} 28\ttestQueries = New(testDB) 29\tlog.Println(\u0026#34;connect db success....\u0026#34;) 30\t// m.Run() 返回一个退出的代码，告诉我们测试是否通过 31\t// 使用 os.Exit() 将测试的结果报告给测试运行程序 32\tos.Exit(m.Run()) 33} 为了测试随机生成相关的用户名密码性别，我们可以创建一个测试的工具包shop\\service\\user_srv\\util\\test_util\\test_util.go\n1package test_util 2 3import ( 4\t\u0026#34;crypto/sha512\u0026#34; 5\t\u0026#34;fmt\u0026#34; 6\t\u0026#34;math/rand\u0026#34; 7\t\u0026#34;strings\u0026#34; 8\t\u0026#34;time\u0026#34; 9 10\t\u0026#34;github.com/anaskhan96/go-password-encoder\u0026#34; 11) 12 13const ( 14\talphabet = \u0026#34;abcdefghijklmopqrstuvwxyz\u0026#34; 15) 16 17var ( 18\tOptions = \u0026amp;password.Options{SaltLen: 16, Iterations: 100, KeyLen: 32, HashFunction: sha512.New} 19) 20 21func init() { 22\t// 设置随机数种子 23\trand.Seed(time.Now().UnixNano()) 24} 25 26func RandomString(n int) string { 27\tvar sb strings.Builder 28\tk := len(alphabet) 29 30\tfor i := 0; i \u0026lt; n; i++ { 31\tc := alphabet[rand.Intn(k)] 32\tsb.WriteByte(c) 33\t} 34\treturn sb.String() 35} 36func RandomInt(min, max int64) int64 { 37\treturn min + rand.Int63n(max-min+1) 38} 39 40func RandomEmail() string { 41\treturn fmt.Sprintf(\u0026#34;jimyag%s@126.com\u0026#34;, RandomString(3)) 42} 43 44type Password struct { 45\tRawPassword string 46\tSlat string 47\tEncryptedPassword string 48} 49 50func RandomPassword() (p Password) { 51\trawPassword := RandomString(10) 52\tslat, encryptedPassword := password.Encode(rawPassword, Options) 53\tp = Password{ 54\tRawPassword: rawPassword, 55\tSlat: slat, 56\tEncryptedPassword: fmt.Sprintf(\u0026#34;$pbkdf2-sha512$%s$%s\u0026#34;, slat, encryptedPassword), 57\t} 58\treturn 59} 60 61func RandomNickName() string { 62\treturn fmt.Sprintf(\u0026#34;jimyag%s\u0026#34;, RandomString(5)) 63} 64 65func RandomGender() string { 66\tgender := []string{\u0026#34;male\u0026#34;, \u0026#34;female\u0026#34;, \u0026#34;middle\u0026#34;} 67\tn := len(gender) 68\treturn gender[rand.Intn(n)] 69} 这里随机生成的password我们之后再做说明。\n在shop\\service\\user_srv\\model\\user.sql_test.go添加，执行测试。\n1package model 2 3import ( 4\t\u0026#34;context\u0026#34; 5\t\u0026#34;database/sql\u0026#34; 6\t\u0026#34;testing\u0026#34; 7\t\u0026#34;time\u0026#34; 8 9\t\u0026#34;github.com/stretchr/testify/require\u0026#34; 10 11\t\u0026#34;github.com/jimyag/shop/service/user/util/test_util\u0026#34; 12) 13 14func createRandomUser(t *testing.T) (User, test_util.Password) { 15\tp := test_util.RandomPassword() 16\targ := CreateUserParams{ 17\tEmail: test_util.RandomEmail(), 18\tPassword: p.EncryptedPassword, 19\tNickname: test_util.RandomNickName(), 20\tGender: test_util.RandomGender(), 21\tRole: 0, 22\t} 23\tuser, err := testQueries.CreateUser(context.Background(), arg) 24 25\trequire.NoError(t, err) 26\trequire.NotEmpty(t, user) 27 28\trequire.Equal(t, arg.Email, user.Email) 29\trequire.Equal(t, arg.Password, user.Password) 30\trequire.Equal(t, arg.Role, user.Role) 31\trequire.Equal(t, arg.Gender, user.Gender) 32\trequire.Equal(t, arg.Nickname, user.Nickname) 33 34\trequire.NotZero(t, user.ID) 35\trequire.NotZero(t, user.CreatedAt) 36\trequire.NotZero(t, user.UpdatedAt) 37 38\treturn user, p 39} 40 41func TestQueries_CreateUser(t *testing.T) { 42\tuser, _ := createRandomUser(t) 43\targ := CreateUserParams{ 44\tEmail: user.Email, 45\tPassword: user.Password, 46\tNickname: user.Nickname, 47\tGender: user.Gender, 48\tRole: user.Role, 49\t} 50\t// 再次创建用户会失败 51\tnewUser, err := testQueries.CreateUser(context.Background(), arg) 52\trequire.Error(t, err) 53\trequire.Empty(t, newUser) 54} 55... 其余详细的测试代码见 https://github.com/jimyag/shop/blob/master/service/user_srv/model/user.sql_test.go 到这里我们数据库方面的都已经测试好了。\n关于用户密码的加密 我们使用一个随机的盐并加密用户的密码，在保存用户密码时，可以保存加密的算法，盐值、加密后的密码。例如\n$pbkdf2-sha512$ScHj3WqUbGWBx0i5$a777173035ac06d8557b603593b49d26961c4cd1d2adaeff\n并且这几个要用特殊的标志分隔开。\n这样可以保证每一个用户的盐都是随机的，生成的密码更安全。\n定义用户proto 在shop\\service\\user_srv\\proto中新建user.proto文件，并写入以下内容。\n1syntax = \u0026#34;proto3\u0026#34;; 2 3option go_package = \u0026#34;.;proto\u0026#34;; 4 5service User{ 6 rpc GetUserList(PageIngo) returns(UserListResponse){}; // 获得用户列表 7 rpc GetUserByEmail(EmailRequest) returns(UserInfoResponse){}; // 使用邮箱获得用户信息 8 rpc GetUserById(IdRequest) returns(UserInfoResponse){}; // 使用Id获得用户信息 9 rpc CreateUser(CreateUserRequest)returns(UserInfoResponse){}; // 添加用户 10 rpc UpdateUser(UpdateUserRequest)returns(UserInfoResponse){}; // 更新用户信息 11 rpc CheckPassword(PasswordCheckInfo) returns(CheckPasswordResponse){}; //检查用户密码 12} 13 14message PasswordCheckInfo{ 15 string password = 1; 16 string encryptedPassword = 2; 17} 18 19message CheckPasswordResponse{ 20 bool success = 1; 21} 22 23message UpdateUserRequest{ 24 int32 id = 1; 25 string email = 2; 26 string password = 3; 27 string nickname = 4; 28 string gender = 5; 29 int32 role = 6; 30} 31 32message CreateUserRequest{ 33 string email = 1; 34 string password = 2; 35 string nickname = 3; 36 string gender = 4; 37 int32 role = 5; 38} 39 40message EmailRequest{ 41 string email = 1; 42} 43 44message IdRequest{ 45 uint32 id = 1; 46} 47 48message PageIngo{ 49 uint32 pageNum = 1; 50 uint32 pageSize = 2; 51} 52 53message UserInfoResponse{ 54 int32 id = 1; 55 int64 created_at = 2; 56 int64 updated_at = 3; 57 string email = 4; 58 string password = 5; 59 string nickname = 6; 60 string gender = 7; 61 int32 role = 8; 62} 63 64message UserListResponse{ 65 int32 total = 1; 66 repeated UserInfoResponse data = 2; 67} 生成用户的pb文件。在shop\\service\\user_srv\\proto中执行\n1protoc -I . user.proto --go_out=plugins=grpc:. 即可在当前文件夹(shop\\service\\user_srv\\proto)下生成user.pb.go\nuser.pb.go的文件中，有server和client要实现的接口\n1// client 要实现的接口 2type UserClient interface { 3\tGetUserList(ctx context.Context, in *PageIngo, opts ...grpc.CallOption) (*UserListResponse, error) 4\tGetUserByEmail(ctx context.Context, in *EmailRequest, opts ...grpc.CallOption) (*UserInfoResponse, error) 5\tGetUserById(ctx context.Context, in *IdRequest, opts ...grpc.CallOption) (*UserInfoResponse, error) 6\tCreateUser(ctx context.Context, in *CreateUserRequest, opts ...grpc.CallOption) (*UserInfoResponse, error) 7\tUpdateUser(ctx context.Context, in *UpdateUserRequest, opts ...grpc.CallOption) (*UserInfoResponse, error) 8\tCheckPassword(ctx context.Context, in *PasswordCheckInfo, opts ...grpc.CallOption) (*CheckPasswordResponse, error) 9} 10// server要实现的接口 11// UserServer is the server API for User service. 12type UserServer interface { 13\tGetUserList(context.Context, *PageIngo) (*UserListResponse, error) 14\tGetUserByEmail(context.Context, *EmailRequest) (*UserInfoResponse, error) 15\tGetUserById(context.Context, *IdRequest) (*UserInfoResponse, error) 16\tCreateUser(context.Context, *CreateUserRequest) (*UserInfoResponse, error) 17\tUpdateUser(context.Context, *UpdateUserRequest) (*UserInfoResponse, error) 18\tCheckPassword(context.Context, *PasswordCheckInfo) (*CheckPasswordResponse, error) 19} 实现grpc用户的相关接口 在实现grpc生成的用户接口之前，我们首先封装数据库。\n在shop\\service\\user_srv\\model新建store.go文件，\n定义一个store的接口，这个是方便之后实现不同的存储。可以使用内存做存储，也可以使用数据库，当然我们这里使用的是数据库做存储。\n1type Store interface { 2\tCreateUserTx(ctx context.Context, arg CreateUserParams) (User, error) 3\tUpdateUserTx(ctx context.Context, arg UpdateUserParams) (User, error) 4\tQuerier 5} CreateUserTx和UpdateUserTx对应的是创建用户和更新用户的事务，在此过程要执行多个SQL操作，我们用事务进行封装。\nQuerier是生成curd的接口。\n定义一个SQLstore，并且实现store的接口，代码如下，完整的代码见store.go)\n1package model 2 3import ( 4 \u0026#34;context\u0026#34; 5 \u0026#34;database/sql\u0026#34; 6 \u0026#34;fmt\u0026#34; 7 \u0026#34;time\u0026#34; 8 9 \u0026#34;google.golang.org/grpc/codes\u0026#34; 10 \u0026#34;google.golang.org/grpc/status\u0026#34; 11) 12 13type Store interface { 14 CreateUserTx(ctx context.Context, arg CreateUserParams) (User, error) 15 UpdateUserTx(ctx context.Context, arg UpdateUserParams) (User, error) 16 Querier 17} 18 19type SqlStore struct { 20 *Queries 21 db *sql.DB 22} 23 24func NewSqlStore(db *sql.DB) Store { 25 return \u0026amp;SqlStore{ 26 Queries: New(db), 27 db: db, 28 } 29} 30 31// 这是一个执行事务的方法，如果在执行中遇到错误，会自动回滚。 32func (store *SqlStore) execTx(ctx context.Context, fn func(queries *Queries) error) error { 33 tx, err := store.db.BeginTx(ctx, nil) 34 if err != nil { 35 return err 36 } 37 38 q := New(tx) 39 err = fn(q) 40 if err != nil { 41 if rbErr := tx.Rollback(); rbErr != nil { 42 return fmt.Errorf(\u0026#34;tx err: %v, rb err: %v\u0026#34;, err, rbErr) 43 } 44 return err 45 } 46 47 return tx.Commit() 48} 49 50func (store *SqlStore) CreateUserTx(ctx context.Context, arg CreateUserParams) (User, error) { 51\t... https://github.com/jimyag/shop/blob/master/service/user_srv/model/store.go 52} 53 54func (store *SqlStore) UpdateUserTx(ctx context.Context, arg UpdateUserParams) (User, error) { 55 .... 省略，https://github.com/jimyag/shop/blob/master/service/user_srv/model/store.go 56} 实现grpc的接口 实现grpc时，我们需要一个结构体UserServer，在实现这些接口的时候，我们需要用到数据库相关的操作，还还记得我们之前封装的接口Store嘛，这时候，就可以把它匿名传入。\n在shop\\service\\user_srv\\handler中新建文件user.go并写入一下内容grpc的接口，这边只实现一个稍微复杂的，其余的可以参考这个复杂的或者在shop/user.go 中查看。\n1package handler 2 3import ( 4\t\u0026#34;context\u0026#34; 5\t\u0026#34;crypto/sha512\u0026#34; 6\t\u0026#34;strings\u0026#34; 7\t\u0026#34;time\u0026#34; 8 9\t\u0026#34;github.com/anaskhan96/go-password-encoder\u0026#34; 10\t\u0026#34;github.com/opentracing/opentracing-go\u0026#34; 11\t\u0026#34;google.golang.org/grpc/codes\u0026#34; 12\t\u0026#34;google.golang.org/grpc/status\u0026#34; 13 14\t\u0026#34;github.com/jimyag/shop/service/user/model\u0026#34; 15\t\u0026#34;github.com/jimyag/shop/service/user/proto\u0026#34; 16) 17 18type UserServer struct { 19\tmodel.Store 20} 21 22// 将userModel转换为UserInfo的响应 23func userModel2UserInfoResponse(user model.User) *proto.UserInfoResponse { 24\treturn \u0026amp;proto.UserInfoResponse{ 25\tId: int32(user.ID), 26\tCreatedAt: user.CreatedAt.Unix(), 27\tUpdatedAt: user.UpdatedAt.Unix(), 28\tEmail: user.Email, 29\tPassword: user.Password, 30\tNickname: user.Nickname, 31\tGender: user.Gender, 32\tRole: int32(user.Role), 33\t} 34} 35 36func (u *UserServer) GetUserList(ctx context.Context, req *proto.PageIngo) (*proto.UserListResponse, error) { 37 .... 38} 39func (u *UserServer) GetUserByEmail(ctx context.Context, req *proto.EmailRequest) (*proto.UserInfoResponse, error) { 40\t... 41} 42func (u *UserServer) GetUserById(ctx context.Context, req *proto.IdRequest) (*proto.UserInfoResponse, error) { 43\t... 44} 45func (u *UserServer) CreateUser(ctx context.Context, req *proto.CreateUserRequest) (*proto.UserInfoResponse, error) { 46\t... 47} 48func (u *UserServer) UpdateUser(ctx context.Context, req *proto.UpdateUserRequest) (*proto.UserInfoResponse, error) { 49 // 拿到请求过来的信息，组成更新用户的参数 50\targ := model.UpdateUserParams{ 51\tUpdatedAt: time.Now(), 52\tNickname: req.GetNickname(), 53\tGender: req.GetGender(), 54\tRole: int64(req.GetRole()), 55\tPassword: req.Password, 56\tID: int64(req.Id), 57\t} 58 // 执行更新用户的事务，如果有错误就返回相应的错误。 59\t// 已经处理过错误了 60\tuser, err := u.Store.UpdateUserTx(ctx, arg) 61\tif err != nil { 62\treturn nil, err 63\t} 64 // 如果没有错所谓就将响应返回 65\trsp := userModel2UserInfoResponse(user) 66\treturn rsp, nil 67} 68func (u *UserServer) CheckPassword(ctx context.Context, req *proto.PasswordCheckInfo) (*proto.CheckPasswordResponse, error) { 69\toptions := \u0026amp;password.Options{SaltLen: 16, Iterations: 100, KeyLen: 32, HashFunction: sha512.New} 70\tencryptedPasswordInfo := strings.Split(req.GetEncryptedPassword(), \u0026#34;$\u0026#34;) 71\tcheck := password.Verify(req.Password, encryptedPasswordInfo[2], encryptedPasswordInfo[3], options) 72\treturn \u0026amp;proto.CheckPasswordResponse{Success: check}, nil 73} 测试grpc接口 在shop\\service\\user_srv\\main.go创建一个服务端。\n1package main 2 3import ( 4\t\u0026#34;flag\u0026#34; 5\t\u0026#34;fmt\u0026#34; 6\t\u0026#34;github.com/jimyag/shop/service/user/golbal\u0026#34; 7\t\u0026#34;github.com/jimyag/shop/service/user/handler\u0026#34; 8\t\u0026#34;github.com/jimyag/shop/service/user/model\u0026#34; 9\t\u0026#34;github.com/jimyag/shop/service/user/proto\u0026#34; 10\t\u0026#34;google.golang.org/grpc\u0026#34; 11\t\u0026#34;log\u0026#34; 12\t\u0026#34;net\u0026#34; 13) 14 15func main() { 16 // 默认地址是本地地址:50051端口 17\tIP := flag.String(\u0026#34;ip\u0026#34;, \u0026#34;0.0.0.0\u0026#34;, \u0026#34;ip地址\u0026#34;) 18\tPort := flag.Int(\u0026#34;port\u0026#34;, 50051, \u0026#34;端口号\u0026#34;) 19\tflag.Parse() 20\tlog.Printf(\u0026#34;server ready run %s:%d.....\u0026#34;, *IP, *Port) 21 22 // grpc的server 23\tserver := grpc.NewServer() 24\tsqlStore := model.NewSqlStore(golbal.DB) 25 // user的server 26\tuserServer := handler.UserServer{Store: sqlStore} 27 // 将userServer注册到grpcServer上 28\tproto.RegisterUserServer(server, \u0026amp;userServer) 29 // 监听端口 30\tlis, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, *IP, *Port)) 31\tif err != nil { 32\tlog.Fatalf(\u0026#34;cannot listen %s:%d.....\\n\u0026#34;, *IP, *Port) 33\t} 34 // server 启动 35\terr = server.Serve(lis) 36\tif err != nil { 37\tlog.Fatalf(\u0026#34;cannot run server.....\u0026#34;) 38\t} 39\tlog.Printf(\u0026#34;server running %s:%d.....\u0026#34;, *IP, *Port) 40} 在shop\\service\\user_srv\\handler新建两个grpc的测试文件\n1package handler 2 3import ( 4\t\u0026#34;log\u0026#34; 5\t\u0026#34;os\u0026#34; 6\t\u0026#34;testing\u0026#34; 7 8\t\u0026#34;google.golang.org/grpc\u0026#34; 9 10\t\u0026#34;github.com/jimyag/shop/service/user/proto\u0026#34; 11) 12 13var ( 14\tuserClient proto.UserClient 15) 16 17const ( 18\ttarget = \u0026#34;127.0.0.1:50051\u0026#34; 19) 20 21func TestMain(m *testing.M) { 22\tconn, err := grpc.Dial(target, grpc.WithInsecure()) 23\tif err != nil { 24\tlog.Fatalf(\u0026#34;cannot dial %s :%v\\n\u0026#34;, target, err) 25\t} 26\tuserClient = proto.NewUserClient(conn) 27 28\tlog.Printf(\u0026#34;dial %s success....\\n\u0026#34;, target) 29\tos.Exit(m.Run()) 30} 1package handler 2 3import ( 4\t\u0026#34;context\u0026#34; 5\t\u0026#34;fmt\u0026#34; 6\t\u0026#34;testing\u0026#34; 7 8\t\u0026#34;github.com/anaskhan96/go-password-encoder\u0026#34; 9\t\u0026#34;github.com/stretchr/testify/require\u0026#34; 10 11\t\u0026#34;github.com/jimyag/shop/service/user/proto\u0026#34; 12\t\u0026#34;github.com/jimyag/shop/service/user/util/test_util\u0026#34; 13) 14 15func createUser(t *testing.T) (*proto.UserInfoResponse, test_util.Password) { 16\tp := test_util.RandomPassword() 17\trequest := proto.CreateUserRequest{ 18\tEmail: test_util.RandomEmail(), 19\tPassword: p.EncryptedPassword, 20\tNickname: test_util.RandomNickName(), 21\tGender: test_util.RandomGender(), 22\tRole: 0, 23\t} 24\trsp, err := userClient.CreateUser(context.Background(), \u0026amp;request) 25\trequire.NoError(t, err) 26\trequire.NotEmpty(t, rsp) 27 28\trequire.Equal(t, request.Email, rsp.GetEmail()) 29\trequire.Equal(t, request.Password, rsp.GetPassword()) 30\trequire.Equal(t, request.Nickname, rsp.GetNickname()) 31\trequire.Equal(t, request.Gender, rsp.GetGender()) 32\trequire.Equal(t, request.Role, rsp.GetRole()) 33\treturn rsp, p 34} 35 36func TestUserServer_CreateUser(t *testing.T) { 37\trsp, p := createUser(t) 38\trequest := proto.CreateUserRequest{ 39\tEmail: rsp.GetEmail(), 40\tPassword: p.EncryptedPassword, 41\tNickname: rsp.GetNickname(), 42\tGender: rsp.GetGender(), 43\tRole: 0, 44\t} 45\tnewRsp, err := userClient.CreateUser(context.Background(), \u0026amp;request) 46\trequire.Error(t, err) 47\trequire.Empty(t, newRsp) 48} 49 50func TestUserServer_GetUserById(t *testing.T) { 51 ... https://github.com/jimyag/shop/tree/master/service/user_srv/handler 52} 53 54func TestUserServer_GetUserByEmail(t *testing.T) { 55\t...https://github.com/jimyag/shop/tree/master/service/user_srv/handler 56} 57 58func TestUserServer_GetUserList(t *testing.T) { 59\t...https://github.com/jimyag/shop/tree/master/service/user_srv/handler 60} 61 62func TestUserServer_UpdateUser(t *testing.T) { 63\t...https://github.com/jimyag/shop/tree/master/service/user_srv/handler 64} 65 66func TestUserServer_CheckPassword(t *testing.T) { 67\t...https://github.com/jimyag/shop/tree/master/service/user_srv/handler 68} 到这里grpc相关的逻辑就已经实现完了。\n目前的目录结构如下。\n1. 2├── config 3├── db 4│ ├── migration 5│ │ ├── 000001_init_schema_user.down.sql 6│ │ └── 000001_init_schema_user.up.sql 7│ └── query 8│ └── user.sql 9├── global 10├── go.mod 11├── go.sum 12├── handler 13│ ├── main_test.go 14│ ├── user.go 15│ └── user_test.go 16├── initialize 17├── main.go 18├── model 19│ ├── db.go 20│ ├── main 21│ │ └── main.go 22│ ├── main_test.go 23│ ├── models.go 24│ ├── querier.go 25│ ├── store.go 26│ ├── user.sql.go 27│ └── user.sql_test.go 28├── proto 29│ ├── user.pb.go 30│ └── user.proto 31├── sqlc.yaml 32└── util 33 └── test_util 34 └── test_util.go 问题 设计一个通用的用户模型 如果让你设计一个用户服务具备通用性，比如可以让所有的系统都可以公共代码?但是不同的系统在user表上可能会有不同的字段，如何设计表让系统具备通用性的同时还能具备好的扩展性?\n思路 基本上所有的系统用户都需要用户名和密码、登录时间等，这些可以设计成一张通用表。 如何可以扩展表并且不会对现有的表产生影响? 拓展 扩展接口,比如将-整套的用户服务完善好, 把一整套的用户相关接口都自己实现好。\n设计一个生成基本service微服务脚手架 自己写一个exe文件可以使得生成基本的service微服务脚手架，这个脚本可以在启动的时候让用户输入一些信息,你觉得有哪些信息可以通过用户输入进行配置?\n某些库可以选择。 选择注册中心 思路点拨 对于service和web端来说,两种代码的目录结构会不一致,所以该命令行可以支持两种类型。 比如后期可以考虑服务名称、否支持服务注册等都考虑进去 进一步思考 命令行模式基本是微服务中必备的，go-micro和go-zero等解决方案都支持通过命令行生成模板目录,大家自 己也应该考虑后期处于维护的角度去长期维护这个脚本,随着以后自己的项目越来越完善，这个命令行业需要跟 着升级\n实现用户服务的web层服务 用户api层的目录如下\n1├── api 2│ └── user-api\t// 用户服务的api 3│ ├── api\t// http接口 4│ ├── config\t// 相关配置文件的go内容 5│ ├── global\t// 全局变量 数据库连接 6│ ├── initialize\t// 初始化相关的 7│ ├── middlewares\t// 中间件 8│ ├── proto\t// proto文件 9│ ├── router\t// 路由 10│ └── util 首先我们将之前shop\\service\\user_srv\\proto文件夹中的文件user.pb.go和user.proto复制到shop\\api\\user-api\\proto。这里把之前的proto文件复制过来是因为在客户端中还要继续使用proto文件中内容，这里有个问题就说如果api端修改了proto文件，那么grpc server端也要修改相应的proto文件。当然大家把api和srv放在一起也是可以的，这就要看个人的喜好了。其实把api和srv放在一起更好一点。\n这个等我们再把第一个服务完成之后，我们会将这个两个合在一起。\n使用全局的zaplogger 在globalshop\\api\\user-api\\global\\global.go中定义全局的logger\n1package global 2 3import ( 4 \u0026#34;go.uber.org/zap\u0026#34; 5) 6 7var ( 8 Logger *zap.Logger 9) 初始化logger 在shop\\api\\user-api\\initialize\\logger.go初始化global.Logger\n1package initialize 2 3import ( 4\t\u0026#34;log\u0026#34; 5 6\t\u0026#34;go.uber.org/zap\u0026#34; 7 8\t\u0026#34;github.com/jimyag/shop/api/user/global\u0026#34; 9) 10 11func InitLogger() { 12\tvar err error 13\tglobal.Logger, err = zap.NewProduction() 14\tif err != nil { 15\tlog.Fatalf(\u0026#34;初始化 logger 失败 :%v\\n\u0026#34;, err) 16\t} 17 18\tglobal.Logger.Info(\u0026#34;初始化 logger 成功.....\u0026#34;) 19} 之后就可以在在项目中使用global.Logger来打日志了。\n连接到grpc的服务端 在globalshop\\api\\user-api\\global\\global.go中定义全局的用户client\n1package global 2 3import ( 4 \u0026#34;go.uber.org/zap\u0026#34; 5 6\t\u0026#34;github.com/jimyag/shop/api/user/proto\u0026#34; 7) 8 9var ( 10 Logger *zap.Logger 11\tUserSrvClient proto.UserClient 12) 初始化userclient 在shop\\api\\user-api\\initialize\\src_conn.go中添加初始化userclient的代码\n1package initialize 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;go.uber.org/zap\u0026#34; 6\t\u0026#34;google.golang.org/grpc\u0026#34; 7 8\t\u0026#34;github.com/jimyag/shop/api/user/global\u0026#34; 9\t\u0026#34;github.com/jimyag/shop/api/user/proto\u0026#34; 10\t\u0026#34;github.com/jimyag/shop/api/user/util/otgrpc\u0026#34; 11) 12 13func InitSrvConnOld1() { 14\tvar userSrvHost string = \u0026#34;localhost\u0026#34; 15\tvar userSrvPort int = 50051 16 17\tuserConn, err := grpc.Dial(fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, 18\tuserSrvHost, 19\tuserSrvPort), 20\tgrpc.WithInsecure()) 21\tif err != nil { 22\tglobal.Logger.Fatal(\u0026#34;用户服务连接失败\u0026#34;, zap.String(\u0026#34;err\u0026#34;, err.Error())) 23\t} 24\t// 已经事先建立好连接，后续就不用在此tcp三次握手 25\t// 一个连接多个gor 共用，grpc 的连接池 26\t// todo 连接池 27\tglobal.UserSrvClient = proto.NewUserClient(userConn) 28} 编写第一个http接口 在shop\\api\\user-api\\api\\user.go中填写获得用户列表的接口\n1package api 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;net/http\u0026#34; 6 7\t\u0026#34;github.com/gin-gonic/gin\u0026#34; 8\t\u0026#34;google.golang.org/grpc/codes\u0026#34; 9\t\u0026#34;google.golang.org/grpc/status\u0026#34; 10 11\t\u0026#34;github.com/jimyag/shop/api/user/global\u0026#34; 12\t\u0026#34;github.com/jimyag/shop/api/user/proto\u0026#34; 13) 14 15// 这里是用来grpc中的错误的 16func HandleGrpcErrorToHttp(err error, ctx *gin.Context) { 17\tif err == nil { 18\treturn 19\t} 20 // 这里使用了grpc自己状态码，在grpc中不用我们自己维护状态码了 21\tif e, ok := status.FromError(err); ok { 22\tswitch e.Code() { 23\tcase codes.NotFound: 24\tctx.JSON(http.StatusNotFound, gin.H{ 25\t\u0026#34;msg\u0026#34;: e.Message(), 26\t}) 27\tcase codes.Internal: 28\tctx.JSON(http.StatusInternalServerError, gin.H{ 29\t\u0026#34;msg\u0026#34;: \u0026#34;内部错误\u0026#34;, 30\t}) 31\tdefault: 32\tctx.JSON(http.StatusInternalServerError, gin.H{ 33\t\u0026#34;msg\u0026#34;: \u0026#34;未知错误\u0026#34;, 34\t}) 35\t} 36 37\t} 38} 39 40func GetUserList(ctx *gin.Context) { 41 // 写死的获得第一页的五个人的信息（从第一页开始） 42\trsp, err := global.UserSrvClient.GetUserList(ctx, \u0026amp;proto.PageIngo{ 43\tPageNum: 1, 44\tPageSize: 5, 45\t}) 46\tif err != nil { 47\tfmt.Println(err) 48\tglobal.Logger.Error(\u0026#34;查询用户列表失败\u0026#34;) 49\tHandleGrpcErrorToHttp(err, ctx) 50\treturn 51\t} 52\tresult := make([]interface{}, 0) 53\tfor _, datum := range rsp.Data { 54\tdata := make(map[string]interface{}) 55\tdata[\u0026#34;id\u0026#34;] = datum.Id 56\tdata[\u0026#34;nickname\u0026#34;] = datum.Nickname 57\tdata[\u0026#34;gender\u0026#34;] = datum.Gender 58\tdata[\u0026#34;email\u0026#34;] = datum.Email 59\tdata[\u0026#34;role\u0026#34;] = datum.Role 60\tresult = append(result, data) 61\t} 62 // 包装响应 63\tctx.JSON(http.StatusOK, gin.H{ 64\t\u0026#34;data\u0026#34;: result, 65\t}) 66} 初始化路由 在shop\\api\\user-api\\router中新建文件user.go初始化user的路由\n1package router 2 3import ( 4\t\u0026#34;github.com/gin-gonic/gin\u0026#34; 5 6\t\u0026#34;github.com/jimyag/shop/api/user/api\u0026#34; 7) 8 9func InitUserRouter(router *gin.RouterGroup) { 10\tuserRouter := router.Group(\u0026#34;user\u0026#34;) 11\t{ 12\tuserRouter.GET(\u0026#34;list\u0026#34;, api.GetUserList) 13\t} 14} 在全局路由中注册shop\\api\\user-api\\initialize\\router.go\n1package initialize 2 3import ( 4\t\u0026#34;github.com/gin-gonic/gin\u0026#34; 5 6\trouter2 \u0026#34;github.com/jimyag/shop/api/user/router\u0026#34; 7) 8 9func Routers() *gin.Engine { 10\trouter := gin.Default() 11\tapiGroup := router.Group(\u0026#34;/user/v1\u0026#34;) 12\trouter2.InitUserRouter(apiGroup) 13\treturn router 14} 测试运行 shop\\api\\user-api\\main.go\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5 6\t\u0026#34;go.uber.org/zap\u0026#34; 7 8\t\u0026#34;github.com/jimyag/shop/api/user/global\u0026#34; 9\t\u0026#34;github.com/jimyag/shop/api/user/initialize\u0026#34; 10) 11 12func main() { 13\tinitialize.InitLogger() 14\tinitialize.InitSrvConn() 15\t// 初始化router 16\trouter := initialize.Routers() 17\terr := router.Run(fmt.Sprintf(\u0026#34;127.0.0.1:%d\u0026#34;, 8888)) 18\tif err != nil { 19\tzap.L().Info(\u0026#34;启动失败\u0026#34;) 20\treturn 21\t} 22} 现在我们第一个http的接口就已经写好了，其余的http的接口均在user-api\n使用viper加载配置文件 在上述内容中，我们看到许多的配置文件都是写死的，万一我们的配置的端口发送变动，这时候就要挨个改配置文件，很是麻烦，我们可以将这些配置写入到指定的配置文件中去。\n在shop\\api\\user-api\\config\\config.go中\n1package config 2 3// user grpc 服务的配置 4type UserSrvConfig struct { 5\tHost string `mapstructure:\u0026#34;host\u0026#34;` 6\tHostPort int `mapstructure:\u0026#34;host-port\u0026#34;` 7\tName string `mapstructure:\u0026#34;name\u0026#34;` 8} 9// 用户http服务的配置 10type ServerInfo struct { 11\tName string `mapstructure:\u0026#34;name\u0026#34;` 12\tPort int `mapstructure:\u0026#34;port\u0026#34;` 13\tUserSrv UserSrvConfig `mapstructure:\u0026#34;user-srv\u0026#34;` 14} 在shop\\api\\user-api\\config-debug.yaml和shop\\api\\user-api\\config-release.yaml中写入\n1name: \u0026#39;user-api\u0026#39; 2port: 8021 3 4user-srv: 5 host: \u0026#39;192.168.0.2\u0026#39; 6 host-port: 50051 7 name: \u0026#34;user-srv\u0026#34; 这里将开发环境和线上环境进行隔离开，可以通过读取环境变量来判断是开发环境还是线上环境，这里开发环境和线上环境的配置是相同的。\n在全局变量文件shop\\api\\user-api\\global\\global.go中添加\n1ServerConfig *config.ServerInfo 初始化加载配置文件shop\\api\\user-api\\initialize\\config.go\n1package initialize 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5 6\t\u0026#34;github.com/fsnotify/fsnotify\u0026#34; 7\t\u0026#34;github.com/spf13/viper\u0026#34; 8\t_ \u0026#34;github.com/spf13/viper/remote\u0026#34; 9\t\u0026#34;go.uber.org/zap\u0026#34; 10 11\t\u0026#34;github.com/jimyag/shop/api/user/global\u0026#34; 12) 13// 加载环境变量 14func getEnvBool(env string) bool { 15\tviper.AutomaticEnv() 16\treturn viper.GetBool(env) 17} 18 19// LoadConfigInfo 加载本地的 consul 文件 20func LoadConfigInfo() { 21 // 默认是读取线上环境的配置 22\tconfigFilePath := \u0026#34;config-release.yaml\u0026#34; 23 // 如果环境变量中\u0026#34;shop_debug\u0026#34;为true就读取开发环境配置 24 if getEnvBool(\u0026#34;shop_debug\u0026#34;){ 25 configFilePath := \u0026#34;config-debug.yaml\u0026#34; 26 } 27\tv := viper.New() 28\tv.SetConfigFile(configFilePath) 29\tif err := v.ReadInConfig(); err != nil { 30\tglobal.Logger.Fatal(\u0026#34;加载配置文件失败.....\u0026#34;, 31\tzap.Error(err), 32\tzap.String(\u0026#34;path\u0026#34;, configFilePath), 33\t) 34\t} 35 36\tglobal.Logger.Info(\u0026#34;配置加载成功....\u0026#34;, 37\tzap.String(\u0026#34;path\u0026#34;, configFilePath), 38\t) 39\tif err := v.Unmarshal(\u0026amp;global.ServerConfig ); err != nil { 40\tglobal.Logger.Fatal(\u0026#34;解析配置文件失败....\u0026#34;, 41\tzap.Error(err), 42\tzap.String(\u0026#34;path\u0026#34;, configFilePath), 43\t) 44\t} 45\tglobal.Logger.Info(\u0026#34;成功加载配置文件\u0026#34;, 46\tzap.String(\u0026#34;path\u0026#34;, configFilePath), 47\tzap.Any(\u0026#34;content\u0026#34;, global.ServerConfig ), 48\t) 49 // 这里做的是监听配置文件的变化，变化之后的操作。 50\tv.WatchConfig() 51\tv.OnConfigChange(func(in fsnotify.Event) { 52\tglobal.Logger.Info(\u0026#34;配置文件产生变化....\u0026#34;, 53\tzap.String(\u0026#34;name\u0026#34;, in.String()), 54\tzap.String(\u0026#34;path\u0026#34;, configFilePath), 55\t) 56 57\tif err := v.ReadInConfig(); err != nil { 58\tglobal.Logger.Fatal(\u0026#34;修改的配置文件字段出错\u0026#34;, 59\tzap.String(\u0026#34;field\u0026#34;, in.String()), 60\tzap.Error(err), 61\t) 62\t} 63\tif err := v.Unmarshal(\u0026amp;global.ServerConfig); err != nil { 64\tglobal.Logger.Fatal(\u0026#34;解析配置文件出错\u0026#34;, 65\tzap.String(\u0026#34;field\u0026#34;, in.String()), 66\tzap.Error(err), 67\t) 68\t} 69\tglobal.Logger.Info(\u0026#34;配置文件内容\u0026#34;, zap.Any(\u0026#34;config\u0026#34;, global.ServerConfig)) 70\t}) 71} 现在我们就可以将用到的所有的配置都可以使用global.ServerConfig .XXX来代替了。这里的替换不做过多说明。\n在shop\\api\\user-api\\main.go中记得要初始化全局的配置文件。\n1initialize.InitLogger() 2// 变更的从这里开始 3initialize.LoadConfigInfo() 4// 这里结束 5initialize.InitSrvConn() 表单数据验证 在写登录接口之前我们首先要处理表单验证，表单验证可以提前帮助我们优雅判断传入的数据是否合法。\n定义验证结构体 首先我们shop\\api\\user-api\\model\\request\\user.go新建使用邮件和密码登录参数\n1package request 2 3// 这里的validate标签就代表是要进行验证，label是我们自定义的标签，可以在之后的翻译中使用。 4type PasswordLoginForm struct { 5\tEmail string `json:\u0026#34;email\u0026#34; validate:\u0026#34;required,email\u0026#34; label:\u0026#34;邮件\u0026#34;` 6\tPassword string `json:\u0026#34;password\u0026#34; validate:\u0026#34;required,min=6,max=20\u0026#34; label:\u0026#34;您的密码\u0026#34;` 7} 初始化翻译器 在使用表单验证的时候需要用到Translator和validator.Validate我们在全局变量shop\\api\\user-api\\global\\global.go中声明他们\n1import ( 2 ut \u0026#34;github.com/go-playground/universal-translator\u0026#34; 3\t\u0026#34;github.com/go-playground/validator/v10\u0026#34; 4) 5var( 6 // 增加的 其余的省略 7 Trans ut.Translator 8\tValidate *validator.Validate 9) 由于在做验证的时候我们首先要初始化这两个全局变量，在shop\\api\\user-api\\initialize\\validator.go初始化包\n1package initialize 2 3import ( 4\t\u0026#34;reflect\u0026#34; 5 6\t\u0026#34;github.com/go-playground/locales/zh\u0026#34; 7\tut \u0026#34;github.com/go-playground/universal-translator\u0026#34; 8\t\u0026#34;github.com/go-playground/validator/v10\u0026#34; 9\tzhtranslations \u0026#34;github.com/go-playground/validator/v10/translations/zh\u0026#34; 10 11\t\u0026#34;github.com/jimyag/shop/api/user/global\u0026#34; 12) 13 14func InitValidateAndTrans() { 15\tglobal.Validate = validator.New() 16 // 第一个是备用翻译，后面的才是主要的翻译 17\tuni := ut.New(zh.New(), zh.New()) 18\tvar ok bool 19 // 拿到中文的翻译器 20\tglobal.Trans, ok = uni.GetTranslator(\u0026#34;zh\u0026#34;) 21\tif !ok { 22\tglobal.Logger.Error(\u0026#34;得到翻译器失败...\u0026#34;) 23\t} 24 // 将翻译器注册 25\terr := zhtranslations.RegisterDefaultTranslations(global.Validate, global.Trans) 26\tif err != nil { 27\tglobal.Logger.Error(\u0026#34;注册翻译器失败......\u0026#34;) 28\t} 29 // 这里是我们自定义的标签名的翻译，可以更好展示错误信息， 30 // 比如定义一个结构体字段，role 权限，如果不定义自己标签进行说明，对看的人不友好。 31\tglobal.Validate.RegisterTagNameFunc(func(field reflect.StructField) string { 32\tlabel := field.Tag.Get(\u0026#34;label\u0026#34;) 33\treturn label 34\t}) 35\tglobal.Logger.Info(\u0026#34;翻译器注册成功......\u0026#34;) 36} 验证逻辑 在初始翻译相关的之后，我们就可以验证了。在shop\\api\\user-api\\util\\validate\\validator.go中\n1package validate 2 3import ( 4\t\u0026#34;github.com/go-playground/validator/v10\u0026#34; 5 6\t\u0026#34;github.com/jimyag/shop/api/user/global\u0026#34; 7) 8// 由于我们传进来的都是结构体，所有我们就用结构体进行验证 9func Validate(data interface{}) (interface{}, error) { 10 11\terr := global.Validate.Struct(data) 12\tif err != nil { 13 // 如果有错误，就将他断言为validator的错误 14\terrs, ok := err.(validator.ValidationErrors) 15\tif ok { 16 // 将多余的信息去掉 17\terrMsg := make([]interface{}, 0) 18\tfor _, fieldError := range errs { 19\terrMsg = append(errMsg, fieldError.Translate(global.Trans)) 20\t} 21\treturn errMsg, err 22 23 }else{ 24 return errs,err 25 } 26\t} 27\treturn nil, nil 28} 如何使用 在shop\\api\\user-api\\api\\user.go继续写入\n1// 省略其余的 2import\t\u0026#34;github.com/jimyag/shop/api/user/util/validate\u0026#34; 3 4func PasswordLogin(ctx *gin.Context) { 5\tpasswordLoginForm := request.PasswordLoginForm{} 6\tif err := ctx.ShouldBindJSON(\u0026amp;passwordLoginForm); err != nil { 7\tglobal.Logger.Info(\u0026#34;ssss\u0026#34;) 8\t} 9 // 获得传来的数据之后，直接验证 10\tmsg, e := validate.Validate(passwordLoginForm) 11\tif e != nil { 12\tctx.JSON(http.StatusBadRequest, gin.H{ 13\t\u0026#34;error\u0026#34;: msg, 14\t}) 15\t} else { 16 .... 省略其余的逻辑，之后再写 17\tctx.JSON(http.StatusOK, gin.H{ 18\t\u0026#34;msg\u0026#34;: \u0026#34;成功\u0026#34;, 19\t}) 20\t} 21\treturn 22} 封装统一的响应 在之前我们的响应都是通过ctx.JSON(http.StatusOK, gin.H{\u0026quot;msg\u0026quot;: \u0026quot;成功\u0026quot;,})来实现的，这里我们将其封装一下。\n在shop\\api\\user-api\\model\\response\\common.go封装\n1package response 2 3import ( 4\t\u0026#34;net/http\u0026#34; 5 6\t\u0026#34;github.com/gin-gonic/gin\u0026#34; 7) 8// 响应的结构体 9type Response struct { 10\tCode int `json:\u0026#34;code\u0026#34;` 11\tData interface{} `json:\u0026#34;data\u0026#34;` 12\tMsg interface{} `json:\u0026#34;msg\u0026#34;` 13} 14// 成功或者失败 15const ( 16\tSUCCESS = 0 17\tERROR = 500 18) 19 20var codeMsg = map[int]string{ 21\tSUCCESS: \u0026#34;成功\u0026#34;, 22\tERROR: \u0026#34;失败\u0026#34;, 23} 24 25func getErrMsg(code int) string { 26\treturn codeMsg[code] 27} 28// 无论成功或者失败都是http.StatusOK 29func result(code int, data interface{}, msg interface{}, context *gin.Context) { 30\tcontext.JSON(http.StatusOK, Response{ 31\tcode, 32\tdata, 33\tmsg, 34\t}) 35} 36 37func Ok(context *gin.Context) { 38\tresult(SUCCESS, nil, getErrMsg(SUCCESS), context) 39} 40func Fail(context *gin.Context) { 41\tresult(ERROR, nil, getErrMsg(ERROR), context) 42} 43 44func OkWithData(data interface{}, context *gin.Context) { 45\tresult(SUCCESS, data, getErrMsg(SUCCESS), context) 46} 47.... 省略 对于处理grpc的错误的方法也进行封装\nshop\\api\\user-api\\util\\handle_grpc_error\\handle_grpc_error.go\n1package handle_grpc_error 2 3import ( 4\t\u0026#34;github.com/gin-gonic/gin\u0026#34; 5\t\u0026#34;google.golang.org/grpc/status\u0026#34; 6 7\t\u0026#34;github.com/jimyag/shop/api/user/model/response\u0026#34; 8) 9 10func HandleGrpcErrorToHttp(err error, ctx *gin.Context) { 11\tif err == nil { 12\treturn 13\t} 14\tif e, ok := status.FromError(err); ok { 15\tresponse.FailWithMsg(e.Message(), ctx) 16\t} 17} 以使用邮箱和密码登录为例子，我们可以这样实现\n1func PasswordLogin(ctx *gin.Context) { 2\tpasswordLoginForm := request.PasswordLoginForm{} 3\t_ = ctx.ShouldBindJSON(\u0026amp;passwordLoginForm) 4 5\tmsg, e := validate.Validate(passwordLoginForm) 6\tif e != nil { 7\tresponse.FailWithMsg(msg, ctx) 8\treturn 9\t} 10 11\tuser, err := global.UserSrvClient.GetUserByEmail(ctx, \u0026amp;proto.EmailRequest{Email: passwordLoginForm.Email}) 12\tif err != nil { 13\tresponse.FailWithMsg(\u0026#34;用户不存在\u0026#34;, ctx) 14\treturn 15\t} 16\tcheckP := proto.PasswordCheckInfo{ 17\tPassword: passwordLoginForm.Password, 18\tEncryptedPassword: user.GetPassword(), 19\t} 20\tpassword, err := global.UserSrvClient.CheckPassword(ctx, \u0026amp;checkP) 21\tif err != nil { 22\tresponse.FailWithMsg(\u0026#34;登录失败\u0026#34;, ctx) 23\treturn 24\t} 25\tif !password.GetSuccess() { 26\tresponse.FailWithMsg(\u0026#34;邮箱或密码错误\u0026#34;, ctx) 27\treturn 28\t} 29 // todo 没有完成 30\tresponse.OkWithMsg(\u0026#34;登录成功\u0026#34;, ctx) 31} 其余的响应可以一起改了\nPASETO认证 在登录的时候，我们需要保存用户的状态，这里使用PASETO进行认证。用户登录成功之后就颁发token\n对于用户的状态我们要保存uid,role，除此之外还有过期签发时间，过期时间。\n我们声明载体shop\\api\\user-api\\util\\paseto\\payload.go\n1package paseto 2 3import ( 4\t\u0026#34;errors\u0026#34; 5\t\u0026#34;time\u0026#34; 6) 7 8// Different types of error returned by the VerifyToken function 9var ( 10\tErrInvalidToken = errors.New(\u0026#34;token is invalid\u0026#34;) 11\tErrExpiredToken = errors.New(\u0026#34;token has expired\u0026#34;) 12) 13 14type Payload struct { 15\tIssuedAt time.Time 16\tExpiredAt time.Time 17\tUID int32 18\tNickname string 19\tRole int32 20} 21 22// NewPayload creates a new token payload with a specific username and duration 23func NewPayload(uid int32, nickname string, role int32) (*Payload, error) { 24 25\tpayload := \u0026amp;Payload{ 26\tUID: uid, 27\tNickname: nickname, 28\tRole: role, 29\t} 30\treturn payload, nil 31} 32 33// Valid checks if the token payload is valid or not 34func (payload *Payload) Valid() error { 35\tif time.Now().After(payload.ExpiredAt) { 36\treturn ErrExpiredToken 37\t} 38\treturn nil 39} PASETO的使用很简单只要两个方法就能实现验证。shop\\api\\user-api\\util\\paseto\\paseto.go\n1package paseto 2 3import ( 4\t\u0026#34;crypto/ed25519\u0026#34; 5\t\u0026#34;time\u0026#34; 6 7\t\u0026#34;github.com/o1egl/paseto\u0026#34; 8) 9 10// PasetoMaker is a PASETO token maker 11type PasetoMaker struct { 12\tpastor *paseto.V2 13\tprivateKey ed25519.PrivateKey 14\tpublicKey ed25519.PublicKey 15\tduration time.Duration 16} 17 18// NewPasetoMaker creates a new PasetoMaker 19func NewPasetoMaker(privateKey ed25519.PrivateKey, publicKey ed25519.PublicKey, duration time.Duration) (*PasetoMaker, error) { 20\tmaker := \u0026amp;PasetoMaker{ 21\tpastor: paseto.NewV2(), 22\tprivateKey: privateKey, 23\tpublicKey: publicKey, 24\tduration: duration, 25\t} 26\treturn maker, nil 27} 28 29// CreateToken creates a new token for a specific username and duration 30func (maker *PasetoMaker) CreateToken(payload *Payload) (string, error) { 31\tpayload.IssuedAt = time.Now() 32\tpayload.ExpiredAt = time.Now().Add(time.Hour * maker.duration) 33\ttoken, err := maker.pastor.Sign(maker.privateKey, payload, nil) 34\treturn token, err 35} 36 37// VerifyToken checks if the token is valid or not 38func (maker *PasetoMaker) VerifyToken(token string) (*Payload, error) { 39\tpayload := \u0026amp;Payload{} 40 41\terr := maker.pastor.Verify(token, maker.publicKey, payload, nil) 42\tif err != nil { 43\treturn nil, ErrInvalidToken 44\t} 45\tif payload.Valid() != nil { 46\treturn nil, err 47\t} 48\treturn payload, nil 49} 这里使用的是一种非对称加密的方式，私钥负责颁发，公钥负责校验。\n从配置文件加载公钥私钥以及过期时间省略，由于我们一直要用到签发token和校验token的，把它加到全局变量中。\n之后在登录的逻辑中shop\\api\\user-api\\api\\user.go:func PasswordLogin(ctx *gin.Context)\n1\t// todo 没有完成 2\tpayload, _ := paseto.NewPayload(user.Id, user.Nickname, user.Role) 3\ttoken, err := global.PasetoMaker.CreateToken(payload) 4\tif err != nil { 5\tglobal.Logger.Info(\u0026#34;创建Token失败\u0026#34;, zap.Error(err)) 6\tresponse.FailWithMsg(\u0026#34;登录失败，请稍后\u0026#34;, ctx) 7\treturn 8\t} 9\tres := make(map[string]string) 10\tres[\u0026#34;token\u0026#34;] = token 11\tresponse.OkWithDataMsg(res, \u0026#34;登录成功\u0026#34;, ctx) 这时候，对于获取用户信息的请求，我们就需要做认证了。\n使用中间件进行拦截。\nshop\\api\\user-api\\middlewares\\paseto.go\n1package middlewares 2 3import ( 4\t\u0026#34;errors\u0026#34; 5\t\u0026#34;strings\u0026#34; 6 7\t\u0026#34;github.com/gin-gonic/gin\u0026#34; 8 9\t\u0026#34;github.com/jimyag/shop/api/user/global\u0026#34; 10\t\u0026#34;github.com/jimyag/shop/api/user/model/response\u0026#34; 11\t\u0026#34;github.com/jimyag/shop/api/user/util/paseto\u0026#34; 12) 13 14func Paseto() gin.HandlerFunc { 15\treturn func(context *gin.Context) { 16 // 使用的是bearer token的格式 17\ttokenHeader := context.Request.Header.Get(\u0026#34;Authorization\u0026#34;) 18\tif tokenHeader == \u0026#34;\u0026#34; { 19\tresponse.FailWithMsg(\u0026#34;token 无效\u0026#34;, context) 20\tcontext.Abort() 21\treturn 22\t} 23 // 解析 24\tcheck := strings.SplitN(tokenHeader, \u0026#34; \u0026#34;, 2) 25\tif len(check) != 2 \u0026amp;\u0026amp; check[0] != \u0026#34;Bearer\u0026#34; { 26\tresponse.FailWithMsg(\u0026#34;token 格式错误\u0026#34;, context) 27\tcontext.Abort() 28\treturn 29\t} 30\tpayload, err := global.PasetoMaker.VerifyToken(check[1]) 31\tif errors.Is(err, paseto.ErrInvalidToken) { 32\tresponse.FailWithMsg(\u0026#34;token 格式错误\u0026#34;, context) 33\tcontext.Abort() 34\treturn 35\t} else if errors.Is(err, paseto.ErrExpiredToken) { 36\tresponse.FailWithMsg(\u0026#34;token 过期\u0026#34;, context) 37\tcontext.Abort() 38\treturn 39\t} 40\tcontext.Set(\u0026#34;payload\u0026#34;, payload) 41\t} 42} ","date":"2022-03-25","img":"","permalink":"/posts/dc2dadae/","series":["从0到1实现完整的微服务框架"],"tags":["微服务","gRPC"],"title":"从0到1实现完整的微服务框架-用户服务"},{"categories":[["微服务"],["gRPC"]],"content":"本系列使用gRPC从0到1实现一个完整的微服务的商城项目。主要用到的技术栈有：gin、postgresql、paseto、sqlc、migrate、docker、consul、jaeger、protobuf、elasticsearch。\n项目中一共涉及到：\n用户服务 商品服务 库存服务 订单和购物车服务 收藏、收货地址、留言服务 elasticsearch实现搜索服务 项目中用到的基础知识的博客如下：\n从单体应用到微服务 | 步履不停 (jimyag.cn)\n为什么paseto比jwt好？ | 步履不停 (jimyag.cn)\n从SQL生成可直接调用的go接口-sqlc | 步履不停 (jimyag.cn)\n数据库迁移工具-migrate | 步履不停 (jimyag.cn)\nRPC基础介绍 | 步履不停 (jimyag.cn)\nGo中rpc包的使用 | 步履不停 (jimyag.cn)\nGin Web Framework (gin-gonic.com)\nDocker基础入门 | 步履不停 (jimyag.cn)\nCasbin-入门demo | 步履不停 (jimyag.cn)\n","date":"2022-03-25","img":"","permalink":"/posts/5f073a52/","series":["从0到1实现完整的微服务框架"],"tags":["微服务","gRPC"],"title":"从0到1实现完整的微服务框架-项目介绍"},{"categories":[["Go"],["RPC"],["教程"]],"content":"Go语言的RPC包的路径为net/rpc，也就是放在了net包目录下面。因此我们可以猜测该RPC包是建立在net包基础之上的。我们基于http实现了一个打印例子。下面我们尝试基于rpc实现一个类似的例子。\n服务端 1packagemain 2 3import( 4\t\u0026#34;log\u0026#34; 5\t\u0026#34;net\u0026#34; 6\t\u0026#34;net/rpc\u0026#34; 7) 8 9type HelloServicestruct{ 10} 11 12func(s*HelloService)Hello(request string, reply*string)error{ 13\t//返回值是通过修改request的值 14\t*reply = \u0026#34;Hello\u0026#34; + request 15\treturn nil 16} 17 18func main(){ 19 20\t//1.实例化一个server 21\tlistener,err:=net.Listen(\u0026#34;tcp\u0026#34;,\u0026#34;:1234\u0026#34;) 22\tif err!=nil{ 23\tlog.Fatalln(err) 24\t} 25\t//2.注册处理逻辑 26\terr=rpc.RegisterName(\u0026#34;HelloService\u0026#34;,\u0026amp;HelloService{}) 27\tif err!=nil{ 28\treturn 29\t} 30\t//3.启动服务 31\tconn,err:=listener.Accept()//当一个新的链接进来的时候， 32\trpc.ServeConn(conn) 33 34//一连串的代码大部分都是net的包好像和rpc没有什么关系 35//1.go语言的rpc序列化的反序列协议是Gob 36} 其中Hello方法必须满足Go语言的RPC规则：\n方法只能有两个可序列化的参数，其中第二个参数是指针类型，并且返回一个error类型，同时必须是公开的方法。 然后就可以将HelloService类型的对象注册为一个RPC服务：(TCP RPC服务)。\n其中rpc.Register()函数调用会将对象类型中所有满足RPC规则的对象方法注册为RPC函数，所有注册的方法会放在“HelloService”服务空间之下。\n然后我们建立一个唯一的TCP链接，并且通过rpc.ServeConn()函数在该TCP链接上为对方提供RPC服务。\n客户端 1package main 2 3import( 4\t\u0026#34;log\u0026#34; 5\t\u0026#34;net/rpc\u0026#34; 6) 7 8func main(){ 9 10\t//1.建立连接 11\tclient,err:=rpc.Dial(\u0026#34;tcp\u0026#34;,\u0026#34;localhost:1234\u0026#34;) 12\tif err!=nil{ 13\tlog.Fatalln(err) 14\t} 15\tvar reply=new(string)//在内存中分配变量，并把指针赋值给变量 16\t//varreplystring//此时的string已经有地址了，而且还有零值使用\u0026amp;reply传递参数 17\t//这里调用的服务的方法是服务名.方法名 18\terr=client.Call(\u0026#34;HelloService.Hello\u0026#34;,\u0026#34;jimyag\u0026#34;,reply) 19\tif err!=nil{ 20\tlog.Fatalln(err) 21\t} 22\tlog.Printf(*reply) 23} 首先是通过rpc.Dial拨号RPC服务，然后通过client.Call调用具体的RPC方法。在调用client.Call时，第一个参数是用点号链接的RPC服务名字和方法名字，第二和第三个参数分别我们定义RPC方法的两个参数。\n改进rpc的调用过程 改进1 前面的rpc调用虽然简单，但是和普通的http的调用差异不大，这次我们解决下面的问题\nserviceName统一和名称冲突的问题 多个server的包中serviceName同名的问题 server端和client端如何统一serviceName 上述实现中服务名称是在客户端和服务端写死的，如果有一方改动，那么双方都要改动\n目录结构\n1. 2├── client 3│ └── main.go 4├── handle 5│ └── handle.go 6└── server 7 └── main.go 新建handler/handler.go文件内容如下：\n1package handle 2 3const ( 4 // 解决命名冲突 5\tHelloServiceName = \u0026#34;handle/HelloService\u0026#34; 6) 为什么要新建这个文件？\n是为了解耦。\n服务端 1package main 2 3import ( 4\t\u0026#34;net\u0026#34; 5\t\u0026#34;net/rpc\u0026#34; 6 7\t\u0026#34;test-rpc/handle\u0026#34; // 自己的包名 8) 9 10type HelloService struct { 11} 12 13func (S *HelloService) Hello(request string, reply *string) error { 14\t*reply = \u0026#34;hello \u0026#34; + request 15\treturn nil 16} 17func main() { 18\t_ = rpc.RegisterName(handle.HelloServiceName, \u0026amp;HelloService{}) 19\tlisener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:1234\u0026#34;) 20\tif err != nil { 21\tpanic(\u0026#34;监听端口失败\u0026#34;) 22\t} 23\tconn, err := lisener.Accept() 24\tif err != nil { 25\tpanic(\u0026#34;建立连接失败\u0026#34;) 26\t} 27 28\trpc.ServeConn(conn) 29} 客户端 1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;net/rpc\u0026#34; 6 7 \u0026#34;test-rpc/handle\u0026#34; // 自己的包名 8) 9 10func main() { 11 client, err := rpc.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;localhost:1234\u0026#34;) 12 if err != nil { 13 panic(\u0026#34;连接到服务器失败\u0026#34;) 14 } 15 16 var reply string 17 // 只要加上调用的方法名即可 18 err = client.Call(handle.HelloServiceName+\u0026#34;.Hello\u0026#34;, \u0026#34;jimyag\u0026#34;, \u0026amp;reply) 19 if err != nil { 20 panic(\u0026#34;服务调用失败\u0026#34;) 21 } 22 23 fmt.Println(reply) 24} 改进2 以上，我们解耦了服务名。但是，对于服务端和客户端来说，他们只要管调用相关的方法就行，不要管相关的实现。\n那么我们可以封装一个client和server端的代理，让client和server端就像调用本地方法一样。\n继续屏蔽HelloserviceName和Hello函数名称\n目录结构 1. 2├── client 3│ └── main.go 4├── client_proxy 5│ └── client_proxy.go 6├── handle 7│ └── handle.go 8├── server 9│ └── main.go 10└── server_porxy 11 └── server_proxy.go handle.go 1package handle 2 3type HelloService struct{} 4 5func (s *HelloService) Hello(request string, reply *string) error { 6 *reply = \u0026#34;hello \u0026#34; + request 7 return nil 8} server_proxy.go 在提供的服务中通过interface进行封装，在这里我们关心的调用的函数，而不是某个结构体。所以封装的时候传入的参数为interface\n1package server_porxy 2 3import \u0026#34;net/rpc\u0026#34; 4 5const HelloServiceName = \u0026#34;handler/HelloService\u0026#34; 6 7type HelloServiceInterface interface { 8 Hello(request string, reply *string) error 9} 10 11// 封装服务的注册 12func RegisterHelloService(srv HelloServiceInterface) error { 13 return rpc.RegisterName(HelloServiceName, srv) 14} server.go 服务端调用的时候,就可以直接注册一个hello的服务。\n1package main 2 3import ( 4 \u0026#34;net\u0026#34; 5 \u0026#34;net/rpc\u0026#34; 6 7 \u0026#34;test-rpc3/handle\u0026#34; // 项目包名 8 \u0026#34;test-rpc3/server_porxy\u0026#34; // 项目包名 9) 10 11func main() { 12 helloHandler := \u0026amp;handle.HelloService{} 13 _ = server_porxy.RegisterHelloService(helloHandler) 14 listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:1234\u0026#34;) 15 if err != nil { 16 panic(\u0026#34;监听端口失败\u0026#34;) 17 } 18 conn, err := listener.Accept() 19 if err != nil { 20 panic(\u0026#34;建立链接失败\u0026#34;) 21 } 22 rpc.ServeConn(conn) 23} client_proxy.go 客户端调用远程的方法时候，要像调用本地方法一样进行调用。封装一个hello的client，只需要调用client里面的方法就行。\n1package client_proxy 2 3import \u0026#34;net/rpc\u0026#34; 4 5const HelloServiceName = \u0026#34;handler/HelloService\u0026#34; 6 7// 将hello client暴露出去 8type HelloServiceClient struct { 9 *rpc.Client 10} 11 12func NewClient(address string) HelloServiceClient { 13 conn, err := rpc.Dial(\u0026#34;tcp\u0026#34;, address) 14 if err != nil { 15 panic(\u0026#34;连接服务器错误\u0026#34;) 16 } 17 return HelloServiceClient{conn} 18} 19 20func (c *HelloServiceClient) Hello(request string, reply *string) error { 21 err := c.Call(HelloServiceName+\u0026#34;.Hello\u0026#34;, request, reply) 22 if err != nil { 23 return err 24 } 25 return nil 26} client.go 1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 6 \u0026#34;test-rpc3/client_proxy\u0026#34; 7) 8 9func main() { 10 client := client_proxy.NewClient(\u0026#34;localhost:1234\u0026#34;) 11 var reply string 12 err := client.Hello(\u0026#34;jimyag\u0026#34;, \u0026amp;reply) 13 if err != nil { 14 panic(\u0026#34;调用失败\u0026#34;) 15 } 16 fmt.Println(reply) 17} ","date":"2022-03-25","img":"","permalink":"/posts/11a90fe7/","series":null,"tags":["Go","RPC","教程"],"title":"Go中rpc包的使用"},{"categories":[["RPC"],["教程"]],"content":"RPC（Remote Procedure Call）远程过程调用协议，一种通过网络从远程计算机上请求服务，而不需要了解底层网络技术的协议。RPC它假定某些协议的存在，例如TPC/UDP等，为通信程序之间携带信息数据。在OSI网络七层模型中，RPC跨越了传输层和应用层，RPC使得开发，包括网络分布式多程序在内的应用程序更加容易。\n本地过程调用 一个简单的本地过程调用的例子\n1package main 2 3func Add(a,b int)int{ 4\treturn a+b 5} 6 7func main(){ 8\tsum:=Add(1,2) 9\tfmt.Println(sum) 10} 此时函数的调用过程是：\n将数字1和2压入Add函数的栈 进入Add函数，从栈中取出1和2分别赋值给a和b 执行 a + b将结果压栈 将栈中的值取出来赋值给main中的sum 远程过程调用的问题 在远程调用时，我们需要执行的函数体是在远程的机器上的，也就是说，Add是在另一个进程中执行的。这就带来了几个新问题：\nCall ID映射。 我们怎么告诉远程机器我们要调用Add，而不是Sub或者Foo呢？\n在本地调用中，函数体是直接通过函数指针来指定的，我们调用Add，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。\n所以，在RPC中，所有的函数都必须有自己的一个ID。这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {函数 \u0026lt;\u0026ndash;\u0026gt; Call ID} 的对应表。两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同。当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。\n序列化和反序列化 客户端怎么把参数值传给远程的函数呢？\n在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言（比如服务端用C++，客户端用Go或者Python）。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。\n**序列化：**把对象转化为可传输的字节序列过程称为序列化。\n**反序列化：**把字节序列还原为对象的过程称为反序列化。\n网络传输 远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。\n因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。Java的Netty也属于这层的东西。\n远程过程调用传输的过程 解决了上面三个机制，就能实现RPC了，具体过程如下：\n客户端发起函数调用 将请求对象序列化为字节流 通过网络传输 服务端接收到字节流 服务端将请求字节流反序列化为对象 服务端进行函数处理 服务端将响应进行序列化为字节流 服务端通过网络传输 客户端接收到响应字节流 客户端将响应字节流反序列化为响应对象 客户端得到响应 实现简单的RPC 客户端 将这个调用映射为Call ID。这里假设用最简单的字符串当Call ID的方法\n将Call ID，a和b序列化。可以直接将它们的值以二进制形式打包\n把2中得到的数据包发送给ServerAddress，这需要使用网络传输层\n等待服务器返回结果\n如果服务器调用成功，那么就将结果反序列化，并赋给sum\n服务端 在本地维护一个Call ID到函数指针的映射call_id_map，可以用dict完成\n等待请求，包括多线程的并发处理能力\n得到一个请求后，将其数据包反序列化，得到Call ID\n通过在call_id_map中查找，得到相应的函数指针\n将a和rb反序列化后，在本地调用add函数，得到结果\n将结果序列化后通过网络返回给Client\n要实现一个rpc框架，其实只需要按照以上流程实现就行了**\n其中：\ncall id 可以使用函数的字符串或者使用其他的，映射便一边就是一个哈希表 序列化和反序列化可以自己手动实现 网络传输协议可以自己写socket、或者用asio、zeroMQ、Netty之类的 除此之外还有网络错误、流量控制、超时和重试等 使用http协议实现一个简单的rpc 客户端 1package main 2 3import( 4\t\u0026#34;encoding/json\u0026#34; 5\t\u0026#34;fmt\u0026#34; 6\t\u0026#34;github.com/kirinlabs/HttpRequest\u0026#34; 7\t\u0026#34;log\u0026#34; 8) 9 10type ResponseDatastruct{ 11\tDataint`json:\u0026#34;data\u0026#34;` 12} 13 14func Add(a,bint)int{ 15\treq:=HttpRequest.NewRequest() 16\tres,_:=req.Get(fmt.Sprintf(\u0026#34;http://127.0.0.1:8000/%s?a=%d\u0026amp;b=%d\u0026#34;,\u0026#34;add\u0026#34;,a,b)) 17\tbody,_:=res.Body() 18\trspData:=ResponseData{} 19\t_=json.Unmarshal(body,\u0026amp;rspData) 20\treturn rspData.Data 21} 22 23func main(){ 24\tlog.Print(Add(10,15)) 25} 服务端 1package main 2 3import( 4\t\u0026#34;encoding/json\u0026#34; 5\t\u0026#34;log\u0026#34; 6\t\u0026#34;net/http\u0026#34; 7\t\u0026#34;strconv\u0026#34; 8) 9 10func main(){ 11\thttp.HandleFunc(\u0026#34;/add\u0026#34;,func(writerhttp.ResponseWriter,request*http.Request){ 12\t_=request.ParseForm() 13\tlog.Printf(request.URL.Path) 14\ta,_:=strconv.Atoi(request.Form[\u0026#34;a\u0026#34;][0]) 15\tb,_:=strconv.Atoi(request.Form[\u0026#34;b\u0026#34;][0]) 16\twriter.Header().Set(\u0026#34;Content-type\u0026#34;,\u0026#34;application/json\u0026#34;) 17\tjData,_:=json.Marshal(map[string]int{\u0026#34;data\u0026#34;:a+b,}) 18\t_,_=writer.Write(jData) 19 }) 20\t_=http.ListenAndServe(\u0026#34;:8000\u0026#34;,nil) 21} 其实http请求就是rpc的一种实现，也相当于远程过程调用。\nrpc、http、restful 不同的应用程序之间的通信方式有很多，比如浏览器和服务器之间广泛使用的基于 HTTP 协议的 Restful API。与 RPC 相比，Restful API 有相对统一的标准，因而更通用，兼容性更好，支持不同的语言。HTTP 协议是基于文本的，一般具备更好的可读性。但是缺点也很明显：\nRestful 接口需要额外的定义，无论是客户端还是服务端，都需要额外的代码来处理，而 RPC 调用则更接近于直接调用。 基于 HTTP 协议的 Restful 报文冗余，承载了过多的无效信息，而 RPC 通常使用自定义的协议格式，减少冗余报文。 RPC 可以采用更高效的序列化协议，将文本转为二进制传输，获得更高的性能。 因为 RPC 的灵活性，所以更容易扩展和集成诸如注册中心、负载均衡等功能。 参考 序列化理解起来很简单 - 知乎 (zhihu.com)\n什么是RESTful？RESTfule风格又是啥？ - 知乎 (zhihu.com)\n","date":"2022-03-25","img":"","permalink":"/posts/8d24f484/","series":null,"tags":["RPC","教程"],"title":"RPC基础介绍"},{"categories":[["SQL"],["教程"],["工具"]],"content":"在 Go 语言中编写数据库操作代码真的非常痛苦！database/sql标准库提供的都是比较底层的接口。我们需要编写大量重复的代码。大量的模板代码不仅写起来烦，而且还容易出错。有时候字段类型修改了一下，可能就需要改动很多地方；添加了一个新字段，之前使用select *查询语句的地方都要修改。如果有些地方有遗漏，可能就会造成运行时panic。即使使用 ORM 库，这些问题也不能完全解决！这时候，sqlc来了！sqlc可以根据我们编写的 SQL 语句生成类型安全的、地道的 Go 接口代码，我们要做的只是调用这些方法。\nsqlc generates fully type-safe idiomatic Go code from SQL. Here’s how it works:\n编写SQL语句 使用 sqlc生成我们所需要的go查询接口 使用这些接口与数据库交互 快速比较 database/sql 快 易出错，且runtime才能捕获问题 gorm （Golang 的库） CRUD已被实现，所需要的代码少 需要用gorm的函数来写查询代码（新的学习成本） 高负载下运行慢 sqlx 速度快，易用 同样易出错，且在runtime 才能捕获问题 sqlc（choose) 快，易用，自动生成代码 编写代码时即可发现SQL的错误 能支持PG 安装sqlc 拉取镜像\n1docker pull kjconroy/sqlc 初始化配置文件\n1docker run -rm -v 你的项目路径:/src -w /src kjconroy/sqlc init 执行命令\n1docker run -rm -v D:\\repository\\simplebank:/src -w /src kjconroy/sqlc init 运行之后会在D:\\repository\\simplebank生成sqlc.yaml文件\n编辑配置文件。\n写入以下内容，配置文件中的目录都要存在\n1version: 1 2packages: 3 - path: \u0026#34;./db/sqlc\u0026#34; # 生成go 代码的位置 4 name: \u0026#34;db\u0026#34; # 生成 go package 的名字 5 engine: \u0026#34;postgresql\u0026#34; # 使用的数据库引擎 6 schema: \u0026#34;./db/migration/\u0026#34; # 迁移表的sql语句 我们使用migrate中的up文件 7 queries: \u0026#34;./db/query\u0026#34; # CRUD的sql 8 emit_json_tags: true # 添加json在生成的struct中 9 emit_prepared_queries: false 10 emit_interface: false 11 emit_exact_table_names: false 在./db/query/account.sql中写入crud语句\n1-- name: CreateAccount :one 2INSERT INTO accounts(owner, 3 balance, 4 currency) 5VALUES ($1, $2, $3) 6returning *; 7 8-- name: GetAccount :one 9SELECT * 10FROM accounts 11WHERE id = $1 12LIMIT 1; 13 14-- name: ListAccounts :many 15select * 16from accounts 17order by id 18limit $1 offset $2; 19 20-- name: UpdateAccount :one 21update accounts 22set balance =$2 23where id = $1 24returning *; 25 26-- name: DeleteAccount :exec 27delete 28from accounts 29where id = $1; 30 31-- 修改sql语句中的展位符号名称 32-- 生成的参数结构体字段名称就是我们自定义的名称了。 33 34-- name: AddAccountBalance :one 35update accounts 36set balance = balance+ $2 37where id = $1 38returning *; 39-- name: AddAccountBalance :one 40update accounts 41set balance = balance+ sqlc.arg(amount) 42where id = sqlc.arg(id) 43returning *; 我们可以看到这和我们自己写sql并无不同，最大的区别就是每一句sql上面都会有一个注释\nname: 后面的是我们要生成的那个go查询接口的方法名，再后后面的one、many、exec都有不同的含义：\none：只有一个返回值 many：多个返回值 exec：没有返回值 生成CRUD代码，执行\n1docker run --rm -v D:\\repository\\simplebank:/src -w /src kjconroy/sqlc generate 在./db/sqlc中会生成CRUD代码\n现在可以在db/sqlc文件夹下查看生成的go code\n其实除了我们需要的account.sql.go,entry.sql.go,transfer.sql.go，还会生成三个.go文件，可以简单看一下里面都是些什么内容：\ndb.go初始化了一个Queries结构，我们需要传入一个自己的db连接对象\n1// Code generated by sqlc. DO NOT EDIT. 2 3package db 4 5import ( 6\t\u0026#34;context\u0026#34; 7\t\u0026#34;database/sql\u0026#34; 8) 9 10type DBTX interface { 11\tExecContext(context.Context, string, ...interface{}) (sql.Result, error) 12\tPrepareContext(context.Context, string) (*sql.Stmt, error) 13\tQueryContext(context.Context, string, ...interface{}) (*sql.Rows, error) 14\tQueryRowContext(context.Context, string, ...interface{}) *sql.Row 15} 16 17func New(db DBTX) *Queries { 18\treturn \u0026amp;Queries{db: db} 19} 20 21type Queries struct { 22\tdb DBTX 23} 24 25func (q *Queries) WithTx(tx *sql.Tx) *Queries { 26\treturn \u0026amp;Queries{ 27\tdb: tx, 28\t} 29} models.go：就是将我们每个表的字段都做了一次结构体的封装\n1// Code generated by sqlc. DO NOT EDIT. 2 3package db 4 5import ( 6\t\u0026#34;time\u0026#34; 7) 8 9type Account struct { 10\tID int64 `json:\u0026#34;id\u0026#34;` 11\tOwner string `json:\u0026#34;owner\u0026#34;` 12\tBalance int64 `json:\u0026#34;balance\u0026#34;` 13\tCurrency string `json:\u0026#34;currency\u0026#34;` 14\tCreatedAt time.Time `json:\u0026#34;created_at\u0026#34;` 15} querier.go：定义一个接口，封装所有的sql查询接口\n1// Code generated by sqlc. DO NOT EDIT. 2 3package db 4 5import ( 6\t\u0026#34;context\u0026#34; 7) 8 9type Querier interface { 10\tCreateAccount(ctx context.Context, arg CreateAccountParams) (Account, error) 11\tDeleteAccount(ctx context.Context, id int64) error 12\tGetAccount(ctx context.Context, id int64) (Account, error) 13\tListAccounts(ctx context.Context, arg ListAccountsParams) ([]Account, error) 14\tUpdateAccount(ctx context.Context, arg UpdateAccountParams) (Account, error) 15} 16 17var _ Querier = (*Queries)(nil) account.sql.go：用go实现了我们刚才写的那些sql语句，一些输入和输出结构都用了struct来定义\n1// Code generated by sqlc. DO NOT EDIT. 2// source: account.sql 3 4package db 5 6import ( 7\t\u0026#34;context\u0026#34; 8) 9 10const addAccountBalance = `-- name: AddAccountBalance :one 11update accounts 12set balance = balance+ $1 13where id = $2 14returning id, owner, balance, currency, created_at 15` 16 17type AddAccountBalanceParams struct { 18\tAmount int64 `json:\u0026#34;amount\u0026#34;` 19\tID int64 `json:\u0026#34;id\u0026#34;` 20} 21 22func (q *Queries) AddAccountBalance(ctx context.Context, arg AddAccountBalanceParams) (Account, error) { 23\trow := q.db.QueryRowContext(ctx, addAccountBalance, arg.Amount, arg.ID) 24\tvar i Account 25\terr := row.Scan( 26\t\u0026amp;i.ID, 27\t\u0026amp;i.Owner, 28\t\u0026amp;i.Balance, 29\t\u0026amp;i.Currency, 30\t\u0026amp;i.CreatedAt, 31\t) 32\treturn i, err 33} 34... 剩下的省略 至此我们就完全可以用go来与数据库实现交互了，sqlc的优势也很明显了，我们只需要写sql，而不需要关心go如何与sql进行交互的\n同时sqlc还支持了语法错误的判断，而不存在我们在运行程序是因为sql出错而panic的情况.\n使用 1package main 2 3import ( 4\t\u0026#34;context\u0026#34; 5\t\u0026#34;database/sql\u0026#34; 6\t\u0026#34;log\u0026#34; 7\t\u0026#34;testing\u0026#34; 8 9\t_ \u0026#34;github.com/lib/pq\u0026#34; 10) 11 12const ( 13\tDB_DRIVER = \u0026#34;postgres\u0026#34; 14\tDB_SOURCE = \u0026#34;postgresql://postgres:postgres@localhost:25432/simple_bank?sslmode=disable\u0026#34; 15) 16 17var ( 18\ttestQueries *Queries // 全局的queries 数据库测试都要用到 19\ttestDB *sql.DB 20) 21 22func main() { 23 24\t// 连接数据库 25\tvar err error 26\ttestDB, err = sql.Open(DB_DRIVER, DB_SOURCE) 27\tif err != nil { 28\tlog.Fatalln(\u0026#34;cannot connect to db :\u0026#34;, err) 29\t} 30\ttestQueries = New(testDB) // 生成测试的queries 31 32\taccount, err := testQueries.CreateAccount(context.Background(), 33\tCreateAccountParams{ 34\tOwner: \u0026#34;jimyag\u0026#34;, 35\tBalance: 1111, 36\tCurrency: \u0026#34;USD\u0026#34;, 37\t}) 38\tif err != nil { 39\tlog.Fatalln(\u0026#34;cannot create account\u0026#34;) 40\t} 41\tlog.Print(account) 42} 参考 Installing sqlc — sqlc 1.12.0 documentation\nsqlc使用说明 - 码农教程 (manongjc.com)\nsqlc-地鼠文档 (topgoer.cn)\n","date":"2022-03-24","img":"","permalink":"/posts/900c3133/","series":null,"tags":["SQL","教程","工具"],"title":"从SQL生成可直接调用的go接口-Sqlc"},{"categories":[["工具"],["教程"],["数据库"]],"content":"在项目中，因需求的变更常常影响到数据库表结构的设计及数据的更新，导致大量的 sql 脚本难以维护。正因为如此，数据库迁移工具的设计之前，就旨在帮助开发者更合理、有效地管理数据库。\n安装migrate 根据migrate/cmd/migrate at master · golang-migrate/migrate (github.com)中的提示选择对应的版本进行安装。\n以windows为例，在[Releases · golang-migrate/migrate (github.com)](https://github.com/golang-migrate/migrate)中选择一个版本，找到windows的对应版本，我这里下载migrate.windows-amd64，将里面对应的.exe可执行文件添加到环境变量中。\n我将可执行文件放到GOPATH/bin中。\nGOPATH的路径可通过go env GOPATH 得到。\n1C:\\Users\\jimyag\u0026gt;migrate -version 24.15.1 安装成功。\n使用migrate 1mkdir migration 1migrate create -ext sql -dir migration -seq init_schema_user 将文件拓展名设为sql\n要存储的目录为.\\migration\\,\n-seq迁移文件的顺序版本号\ninit_schema 迁移的名称\n执行完命令会生成两个文件\n1migration 2├── 000001_init_schema_user.down.sql 3├── 000001_init_schema_user.up.sql 在000001_init_schema_user.down.sql中添加如下内容\n1CREATE TABLE \u0026#34;accounts\u0026#34; ( 2 \u0026#34;id\u0026#34; bigserial PRIMARY KEY, 3 \u0026#34;owner\u0026#34; varchar NOT NULL, 4 \u0026#34;balance\u0026#34; bigint NOT NULL, 5 \u0026#34;currency\u0026#34; varchar NOT NULL, 6 \u0026#34;created_at\u0026#34; timestamp NOT NULL DEFAULT (now()) 7); 8 9CREATE TABLE \u0026#34;entries\u0026#34; ( 10 \u0026#34;id\u0026#34; bigserial PRIMARY KEY, 11 \u0026#34;account_id\u0026#34; bigint NOT NULL, 12 \u0026#34;amount\u0026#34; bigint NOT NULL, 13 \u0026#34;created_at\u0026#34; timestamp NOT NULL DEFAULT (now()) 14); 15 16CREATE TABLE \u0026#34;transfers\u0026#34; ( 17 \u0026#34;id\u0026#34; bigserial PRIMARY KEY, 18 \u0026#34;from_account_id\u0026#34; bigint NOT NULL, 19 \u0026#34;to_account_id\u0026#34; bigint NOT NULL, 20 \u0026#34;amount\u0026#34; bigint NOT NULL, 21 \u0026#34;created_at\u0026#34; timestamp NOT NULL DEFAULT (now()) 22); 23 24ALTER TABLE \u0026#34;entries\u0026#34; ADD FOREIGN KEY (\u0026#34;account_id\u0026#34;) REFERENCES \u0026#34;accounts\u0026#34; (\u0026#34;id\u0026#34;); 25 26ALTER TABLE \u0026#34;transfers\u0026#34; ADD FOREIGN KEY (\u0026#34;from_account_id\u0026#34;) REFERENCES \u0026#34;accounts\u0026#34; (\u0026#34;id\u0026#34;); 27 28ALTER TABLE \u0026#34;transfers\u0026#34; ADD FOREIGN KEY (\u0026#34;to_account_id\u0026#34;) REFERENCES \u0026#34;accounts\u0026#34; (\u0026#34;id\u0026#34;); 29 30CREATE INDEX ON \u0026#34;accounts\u0026#34; (\u0026#34;owner\u0026#34;); 31 32CREATE INDEX ON \u0026#34;entries\u0026#34; (\u0026#34;account_id\u0026#34;); 33 34CREATE INDEX ON \u0026#34;transfers\u0026#34; (\u0026#34;from_account_id\u0026#34;); 35 36CREATE INDEX ON \u0026#34;transfers\u0026#34; (\u0026#34;to_account_id\u0026#34;); 37 38CREATE INDEX ON \u0026#34;transfers\u0026#34; (\u0026#34;from_account_id\u0026#34;, \u0026#34;to_account_id\u0026#34;); 在000001_init_schema_user.up.sql写入一下文件。\n1DROP TABLE IF EXISTS entries; 2DROP TABLE IF EXISTS transfers; 3DROP TABLE IF EXISTS accounts; 创建数据库\n1docker run --name test-pg -p 35432:5432 -e POSTGRES_PASSWORD=postgres -e TZ=PRC -d postgres:14-alpine 创建一个shop的数据库。\n1docker exec -it test-pg createdb --username=postgres --owner=postgres shop 生成表结构。\n1migrate -path ./migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose up 22022/03/24 20:30:43 Start buffering 1/u init_schema_user 32022/03/24 20:30:43 Read and execute 1/u init_schema_user 42022/03/24 20:30:43 Finished 1/u init_schema_user (read 9.4412ms, ran 8.1883ms) 52022/03/24 20:30:43 Finished after 38.1796ms 62022/03/24 20:30:43 Closing source and database 进入docker中\n1\u0026gt; docker exec -it test-pg /bin/sh 1\u0026gt; psql -U postgres 已经有了之前的shop数据库\n1\u0026gt; postgres=# \\list 2 List of databases 3 Name | Owner | Encoding | Collate | Ctype | Access privileges 4-----------+----------+----------+------------+------------+----------------------- 5 postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 | 6 shop | postgres | UTF8 | en_US.utf8 | en_US.utf8 | 7 template0 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + 8 | | | | | postgres=CTc/postgres 9 template1 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + 10 | | | | | postgres=CTc/postgres 进入shop中\n1\u0026gt; postgres=# \\c shop 2You are now connected to database \u0026#34;shop\u0026#34; as user \u0026#34;postgres\u0026#34;. 出现了四张表\n1\u0026gt; select tablename from pg_tables where schemaname=\u0026#39;public\u0026#39;; 2 tablename 3------------------- 4 schema_migrations 5 accounts 6 entries 7 transfers 8(4 rows) schema_migrations是用来同步表用的。\n回滚表，输入y\n1\u0026gt;migrate -path ./migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose down 22022/03/24 20:48:35 Are you sure you want to apply all down migrations? [y/N] 3y 42022/03/24 20:48:37 Applying all down migrations 52022/03/24 20:48:37 Start buffering 1/d init_schema_user 62022/03/24 20:48:37 Read and execute 1/d init_schema_user 72022/03/24 20:48:37 Finished 1/d init_schema_user (read 8.0654ms, ran 25.5793ms) 82022/03/24 20:48:37 Finished after 2.240096s 92022/03/24 20:48:37 Closing source and database 10\u0026gt;shop=# select tablename from pg_tables where schemaname=\u0026#39;public\u0026#39;; 11 tablename 12------------------- 13 schema_migrations 14(1 row) 发现只剩同步表了\n多次同步 为了测试 migrations up [N] 执行多次修改的情形，第二次修改我们使用事务为 account表增加 COLUMN，\n1D:\\Computer\\Desktop\u0026gt;migrate create -ext sql -dir migration -seq add_mood_to_user 2D:\\Computer\\Desktop\\migration\\000002_add_mood_to_user.up.sql 3D:\\Computer\\Desktop\\migration\\000002_add_mood_to_user.down.sql 在000002_add_mood_to_user.up.sql中添加\n1BEGIN; 2CREATE TYPE enum_mood AS ENUM ( 3\t\u0026#39;happy\u0026#39;, 4\t\u0026#39;sad\u0026#39;, 5\t\u0026#39;neutral\u0026#39; 6); 7ALTER TABLE accounts ADD COLUMN IF NOT EXISTS mood enum_mood; 8COMMIT; 在000002_add_mood_to_user.down.sql中添加\n1BEGIN; 2 3ALTER TABLE accounts DROP COLUMN IF EXISTS mood; 4DROP TYPE enum_mood; 5 6COMMIT; 1D:\\Computer\\Desktop\u0026gt;migrate create -ext sql -dir migration -seq add_roleid_to_users 2D:\\Computer\\Desktop\\migration\\000003_add_roleid_to_users.up.sql 3D:\\Computer\\Desktop\\migration\\000003_add_roleid_to_users.down.sql 在000003_add_roleid_to_users.up.sql中添加\n1BEGIN; 2CREATE TYPE enum_mood AS ENUM ( 3\t\u0026#39;happy\u0026#39;, 4\t\u0026#39;sad\u0026#39;, 5\t\u0026#39;neutral\u0026#39; 6); 7ALTER TABLE accounts ADD COLUMN IF NOT EXISTS mood enum_mood; 8COMMIT; 在000003_add_roleid_to_users.down.sql中添加\n1BEGIN; 2 3ALTER TABLE accounts DROP COLUMN IF EXISTS mood; 4DROP TYPE enum_mood; 5 6COMMIT; migration中有以下文件\n12022/03/24 20:46 97 000001_init_schema_user.down.sql 22022/03/24 20:46 1,489 000001_init_schema_user.up.sql 32022/03/24 20:58 91 000002_add_mood_to_user.down.sql 42022/03/24 20:57 147 000002_add_mood_to_user.up.sql 52022/03/24 21:02 51 000003_add_roleid_to_users.down.sql 62022/03/24 21:02 62 000003_add_roleid_to_users.up.sql 1\u0026gt; migrate -path ./migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose up 22022/03/24 21:04:15 Start buffering 1/u init_schema_user 32022/03/24 21:04:15 Start buffering 2/u add_mood_to_user 42022/03/24 21:04:15 Start buffering 3/u add_roleid_to_users 52022/03/24 21:04:15 Read and execute 1/u init_schema_user 62022/03/24 21:04:15 Finished 1/u init_schema_user (read 8.7174ms, ran 124.6018ms) 72022/03/24 21:04:15 Read and execute 2/u add_mood_to_user 82022/03/24 21:04:15 Finished 2/u add_mood_to_user (read 141.2056ms, ran 10.1257ms) 92022/03/24 21:04:15 Read and execute 3/u add_roleid_to_users 102022/03/24 21:04:15 Finished 3/u add_roleid_to_users (read 159.2213ms, ran 9.0379ms) 112022/03/24 21:04:15 Finished after 189.4334ms 122022/03/24 21:04:15 Closing source and database 以上可以看到所有的都已经同步成功，并且是按照序号的顺序进行执行。\n1\u0026gt; migrate -path ./migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose down 22022/03/24 21:04:39 Are you sure you want to apply all down migrations? [y/N] 3y 42022/03/24 21:04:41 Applying all down migrations 52022/03/24 21:04:41 Start buffering 3/d add_roleid_to_users 62022/03/24 21:04:41 Start buffering 2/d add_mood_to_user 72022/03/24 21:04:41 Start buffering 1/d init_schema_user 82022/03/24 21:04:41 Read and execute 3/d add_roleid_to_users 92022/03/24 21:04:41 Finished 3/d add_roleid_to_users (read 9.9293ms, ran 12.7524ms) 102022/03/24 21:04:41 Read and execute 2/d add_mood_to_user 112022/03/24 21:04:41 Finished 2/d add_mood_to_user (read 30.9375ms, ran 10.6209ms) 122022/03/24 21:04:41 Read and execute 1/d init_schema_user 132022/03/24 21:04:41 Finished 1/d init_schema_user (read 47.6036ms, ran 18.4846ms) 142022/03/24 21:04:41 Finished after 1.6015872s 152022/03/24 21:04:41 Closing source and database 以上可以看到所有的回滚成功，并按照序号的逆序进行。\n测试失败的情况 我们回滚所有操作。\n1migrate -path ./migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose down 然后执行注意有2，\n1migrate -path ./migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose up 2 22022/03/24 21:10:33 Start buffering 1/u init_schema_user 32022/03/24 21:10:33 Start buffering 2/u add_mood_to_user 42022/03/24 21:10:33 Read and execute 1/u init_schema_user 52022/03/24 21:10:33 Finished 1/u init_schema_user (read 10.4179ms, ran 54.5128ms) 62022/03/24 21:10:33 Read and execute 2/u add_mood_to_user 72022/03/24 21:10:33 Finished 2/u add_mood_to_user (read 73.7285ms, ran 11.7561ms) 82022/03/24 21:10:33 Finished after 107.6561ms 92022/03/24 21:10:33 Closing source and database 这时候已经应用了前两个同步。\n接下来修改，000003_add_roleid_to_users.up.sql使其语法错误。\n1migrate -path ./migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose up 1 22022/03/24 21:13:46 Start buffering 3/u add_roleid_to_users 32022/03/24 21:13:46 Read and execute 3/u add_roleid_to_users 42022/03/24 21:13:46 error: migration failed: syntax error at or near \u0026#34;%\u0026#34; (column 63) in line 1: ALTER TABLE accounts ADD COLUMN IF NOT EXISTS role_id INTEGER;% (details: pq: syntax error at or near \u0026#34;%\u0026#34;) 此时执行，发现错误。\n这时候，我们进入数据库中查看schema_migrations表中的数据\n1select * from shop.public.schema_migrations; 2 version | dirty 3---------+------- 4 3 | true 这时候显示，当前处于版本3，并且有脏数据。\n如果我们修改正确000003_add_roleid_to_users.up.sql再执行up 1命令\n1migrate -path ./migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose up 1 22022/03/24 21:18:15 error: Dirty database version 3. Fix and force version. 这时候需要使用migrate force 3 来确认说 version=3 的错误问题已修复，\n1migrate -path ./migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose force 3 22022/03/24 21:19:34 Finished after 100.3292ms 32022/03/24 21:19:34 Closing source and database 而且需要执行 migrate down 1 将 version 回退到 version=2 ，才能继续执行。\n1migrate -path ./migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose down 1 22022/03/24 21:19:58 Start buffering 3/d add_roleid_to_users 32022/03/24 21:19:58 Read and execute 3/d add_roleid_to_users 42022/03/24 21:19:58 Finished 3/d add_roleid_to_users (read 9.7019ms, ran 10.2768ms) 52022/03/24 21:19:58 Finished after 40.0968ms 62022/03/24 21:19:58 Closing source and database 同步到版本3\n1migrate -path ./migration -database \u0026#34;postgresql://postgres:postgres@localhost:35432/shop?sslmode=disable\u0026#34; -verbose up 1 22022/03/24 21:20:19 Start buffering 3/u add_roleid_to_users 32022/03/24 21:20:19 Read and execute 3/u add_roleid_to_users 42022/03/24 21:20:19 Finished 3/u add_roleid_to_users (read 10.9011ms, ran 11.6158ms) 52022/03/24 21:20:19 Finished after 45.0244ms 62022/03/24 21:20:19 Closing source and database migrate的工作流程 up 原有的数据通过产生的up文件向上更改\n当我们使用命令migrate up时，产生的up脚本会按照前缀的顺序依次执行\ndown 新的数据通过down脚本进行还原\n当我们使用命令migrate down时，产生的down脚本会按照前缀顺序的逆序进行执行\n参考 golang数据库迁移工具golang-migrate使用_doyzfly的博客-CSDN博客_golang migrate\nmigrate/cmd/migrate at master · golang-migrate/migrate (github.com)\nmigrate/GETTING_STARTED.md at master · golang-migrate/migrate (github.com)\n","date":"2022-03-24","img":"","permalink":"/posts/e7121931/","series":null,"tags":["工具","教程","数据库"],"title":"数据库迁移工具-Migrate"},{"categories":[["教程"],["微服务"]],"content":"从单体应用的痛点到微服务之间的过渡的说明。\n单体应用 一个典型的单体应用就是将所有业务场景的表示层、业务逻辑层和数据访问层放在一个工程中，最终经过编译、打包，部署在一台服务器上。\n单体应用的痛点 每个小团队对于都负责一个小的模块，这些人在开发过程中，可能会在内部代码进行冲突、或者修改了功能的方法，在merge的时候会有大量的冲突，以及执行回归测试（回归测试是指修改了旧代码后，重新进行测试以确认修改没有引入新的错误或导致其他 代码 产生错误。），一旦出错就要回炉重造。 如果发布某个部分出现了bug，不能进行单独回滚，必须要将整个发布种的所有功能回滚。 单体的演变 一个项目，之前是由有网站和后台管理系统，现在要添加小程序端，这时候，如果复制之前的代码过来会有大量的重复代码，并且这几个系统之间还有相互调用，比如秒杀模块还要依赖于商品模块。不仅要对主页、小程序、后台管理提供http接口，还要对系统内部提供相应的服务。这几个系统共用了同一个数据库，如果有某个接口出现性能问题，会影响整个系统的性能。这时候如果一个系统要改表结构了，就要通知其他系统。\n服务的拆分 将所有的服务全部分开，如果某个系统想要相关信息，他们就自己使用即可。\n浅蓝的是一个整体的系统。\n目前我开发的所有单体应用都是以这种方式开发，有一个后端服务，网站小程序等他们需要什么就调用什么接口就行了。\n这里，代码复用没有了。\n微服务 微服务是满足“单一职责原则”的，每个微服务仅负责自己归属于自己业务领域的功能。一个微服务就是一个独立的实体，它可以独立部署、升级，服务与服务之间通过REST等形式的标准接口进行通信，并且一个微服务实例可以被替换成另一种实现，而对其它的微服务不产生影响。\n对于服务拆分中的架构，我们可以继续进行拆分。\n微服务的基本拆分 将服务和数据库单独抽出来，没有数据影响，每一个服务都可以单独存在，每一个服务都有自己的数据库。只要保证被调用的接口不变，服务内部怎么变都不影响。\n这里还有一个问题，对下单这个操作而言，肯定要依赖用户信息。各个模块之间又有了依赖关系。\n微服务进行分层 分层的微服务将service层再进行分层，一个对内提供服务，一个对外提供http接口。\n这个满足了单一职责原则，最底层的grpc的服务之间没有交集，他们只需要向上层的http层提供服务就行。\n微服务存在的问题 在之前都是通过ip:端口的形式来访问相应的服务，如果某个服务的ip和端口变了怎么办，如果有一个服务的集群，如何挑选一个服务。对于服务的配置文件，如果配置文件修改了如何？\n这时候就要引入服务注册、服务发现和注册中心。\n注册中心 服务在启动的时候将自己注册到注册中心，以便上层寻找。\n服务发现 上层想要调用某个服务时，就要寻找可用的服务。\n配置中心 每个服务都从配置中心拉取自己对应的配置，以后修改配置文件只要在配置中心中统一修改即可。\n参考 微服务的定义和优缺点 - 知乎 (zhihu.com)\n什么是单体应用？如何理解？ (itheima.com)\n","date":"2022-03-24","img":"","permalink":"/posts/acba46c5/","series":["从0到1实现完整的微服务框架"],"tags":["微服务","教程"],"title":"从单体应用到微服务"},{"categories":[["Go"],["教程"]],"content":"Go1.18在今天（3-16）已经发布，Go 1.18 是一个包含大量新功能的版本，同时不仅改善了性能，也对语言本身做了有史以来最大的改变。毫不夸张地说，Go 1.18 的部分设计十多年前，在第一次发布 Go 时就开始了构思(例如泛型，最早的时候在2009年Russ Cox 在博客里面讨论过泛型如何设计https://research.swtch.com/generic)。\n如果你想探索使用泛型优化和简化代码的最佳方法。查看最新版本的发行说明(https://go.dev/doc/go1.18) 有更多关于在 Go 1.18 中使用泛型的详细信息。\n安装Go1.18 确保已经存在Go环境并且版本大于1.13.\n1go install golang.org/dl/go1.18@latest 1go1.18 download 使用 1go1.18 env 配置代理\n1go1.18 env -w GOPROXY=https://goproxy.cn,direct 开启go module\n1go1.18 env -w GO111MODULE=on 参考 GoCN\n在同一机器上安装Go的不同版本 | 步履不停 (jimyag.cn)\n","date":"2022-03-16","img":"","permalink":"/posts/1dc739af/","series":null,"tags":["Go","教程"],"title":"安装Go1.18环境"},{"categories":[["教程"],["PASETO"],["JWT"]],"content":"在平常我们做权限控制或者认证的时候，大多数是基于 token 的身份验证。在众多类型中的token中，JSON Web Token（JWT）是最流行的之一。但是人们发现了JWT中一些安全问题，主要是因为它设计了不良的标准。\n本文主要介绍JWT的弊端，以及一种新的token验证PASETO\n基于 Token 的认证 首先我们介绍基于Token的认证的过程.\n客户端使用用户名密码进行登录,服务端接受到请求之后进行校验. 校验通过后,服务端会签发一个access_token给客户端. 在之后客户端请求服务器的资源时都需要带上token, 如果服务器收到客户端请求资源,校验是否有权限访问资源. 我们在JSON Web Tokens - jwt.io可以看到jwt的示例\n它是一个Base64编码的字符串，由3个主要部分组成，由点分隔。\n第一部分（带有颜色红色）是令牌的标题。当我们解码此部分时，我们将获得一个包含令牌类型JWT的JSON对象，以及用于签署令牌的算法：上述的算法是HS256\n令牌的第二部分（紫色）是有效载荷数据。此部分是我们存储有关登录用户的信息，例如用户名，以及该令牌将过期的时间戳。你可以自定义此JSON有效载荷以存储所需的任何其他信息。\n存储在JWT中的所有数据仅为Base64编码，而不是加密。因此，不需要服务器的秘密/私钥以解码其内容。它还意味着我们可以轻松地编码标题和有效载荷数据而无需键。那么服务器如何验证访问令牌的真实性吗？\n这是令牌第三部分的目的：数字签名（蓝色）。这个想法很简单，只有服务器有私钥签署令牌。因此，如果尝试在没有正确密钥的情况下创建虚假令牌，则服务器将在验证过程中轻松检测到它。JWT标准提供了许多不同类型的数字签名算法，但它们可以分为2个主要类别。\n对称加密算法 第一个是对称加密算法，其中相同的密钥用于两个标志并验证令牌。由于只有1个key，它应该保密。因此，此算法适用于仅用于本地服务的本地使用，或用于内部服务，可以共享密钥的内部服务。\n属于该对称加密类别的一些特定算法是：HS256，HS384和HS512。这里HS256是HMAC和SHA-256的组合。HMAC代表基于哈希的消息认证码，SHA是安全散列算法。而256/384/512是输出位的数量。\n对称密钥算法非常有效，适用于大多数应用。但是，如果我们想要验证令牌的外部第三方服务，我们不能使用它，因为它意味着我们必须给他们我们的密钥。在这种情况下，我们必须使用第二类：非对称加密算法。\n非对称加密算法 在这种类型的算法中，有一对key而不是仅为1个单个密钥。\n私钥用于签署令牌，而公钥仅用于验证它。\n因此，我们可以轻松与任何外部第三方服务分享我们的公钥，而无需担心泄露私钥。\n在这种不对称关键类别中，存在几组算法，例如RS组，PS组或ES组。这里，RS256基本上是具有PKCSV1.5和SHA256的RSA算法。PS256也是RSA算法，但具有概率签名方案和SHA256。它的设计比pkcsv1.5更为安全,最后一个ES256只是椭圆曲线数字签名算法\nJWT问题 好的，到目前为止，它听起来像JWT是一个很好的标准，它让我们提供了很多灵活性，可以选择我们想要的任何签名算法。那么它的问题究竟是什么？\n弱算法 第一个问题是弱签名算法。JWT为开发人员提供了太多算法来选择，包括已知易受攻击的算法，例如：带有pkcsv1.5的RSA容易收到 padding Oracle攻击。或ECDSA可以面临无效曲线攻击。对于没有安全性经验的开发人员，他们很难知道哪些算法最好使用。因此，JWT为开发人员提供了太多的灵活性来选择算法的事实就像让搬起石头砸自己的脚.\nJWT 标准设计看起来很不错，实际上包藏祸心，因为其设计，隐藏诸多安全问题，详细如下：\n重置空加密算法缺陷 JWT 支持将算法设定为“None”，如果你使用JWT库时未设置关闭该功能，那么任何Token都是有效的。具体做法是将JWT第一部分 header 中 alg 字段设置为 None ，再将第三部分 signature 设置为空（即不添加signature字段）， 此token 可顺利通过验证。\n密钥混淆攻击 JWT 最常用的两种算法是 HMAC 和 RSA。HMAC（对称加密算法）用同一个密钥对 token 进行签名和认证。而RSA（非对称加密算法）需要两个密钥，先用私钥加密生成 JWT ，然后使用其对应的公钥来解密验证。如果公钥泄露（很多人觉得公钥可以分发），那么将算法 RS256 修改为 HS256 ，即非对称加密向下降级为对称加密。再使用这个泄露的公钥对 token 进行签名，后端收到后根据头中指定的算法，将使用公钥对 token 验证，如此便认证通过。\n密钥暴力破解 如果 JWT 使用对称加密算法（如 HS256）， 这意味着对令牌进行签名的密钥也用于对其进行验证。由于签名验证是一个自包含的过程，因此可以测试 token 本身的有效密钥，而不必将其发送回应用程序进行验证。如果密钥设置过于简单，如常用词汇、生日年份等，结合已知的泄露密码列表，将很快破解出密钥，如此便可伪造出任意token 。\nkid 指定攻击 kid 即为 key ID ，存在于 jwt header 中，是一个可选的字段，用来指定加密算法的密钥。如在头部注入新的 kid 字段，并指定 HS256 算法的 key 为 123456，生成新的token,服务端收到将使用指定的密钥123456来验证token。因此，为了防止这攻击，它在您的服务器代码中至关重要，您必须检查令牌的算法标题，以确保它与您的服务器用于签名和验证令牌的算法匹配。\n好的，所以现在你知道为什么JSON网上令牌不是一个非常精心设计的标准。它打开了许多潜在威胁的门。\n因此，很多人试图远离它，并迁移到更强大的东西。\nPASETO - 与平台无关的密钥验证 PASeto或Platform Andnostic Security Token是社区广泛接受的最成功的设计之一，作为JWT的最佳安全替代品。\n强算法 它首先解决了JWT的所有问题，提供了开箱即用的强大签名算法。开发人员不必再选择算法了。相反，他们只需要选择他们想要使用的 PASETO 版本。每个Paseto版本已经使用1个强大的密码套件实现。在任何时候，只有2个最新版本的PASETO都会有效。\n现在，经常使用的时的Paseto版本是版本1和版本2。(当然也有版本3,4的)\nPASETO version 1 版本1时间较长，只能用于无法使用现代加密的传统系统。与 JWT 类似，PASETO也有2个算法类别，用于2个主要用例。\n对于本地或内部服务，我们使用对称密钥算法。\n但与只有Base64-加密的JWT不同，PASETO 实际上使用具有带有关联数据（或AEAD【转】什么是AEAD加密 - 简书 (jianshu.com)）算法的强度认证加密，使用密钥加密并验证令牌中的所有数据。.PASETO 版本1中使用的AEAD算法是HMAC SHA384的AES256 CTR。\n对于公共情况而言，在有需要验证令牌的外部服务的情况下，我们必须使用非对称密钥算法。在这种情况下，PASETO 使用与JWT相同的方法，这意味着它不会加密令牌数据，而且只使用Base64编码，并使用私钥以数字签名签署内容。PASETO 版本1中所选的不对称关键算法是带SHA384的RSA PSS。\nPASETO version 2 在版本2的PASETO中，正在使用2个安全和现代算法。对于本地对称关键场景，它使用具有Poly1305算法的Xchacha20。并且对于公众非对称关键场景，使用具有曲线25519的爱德华曲线数字签名算法。\nNon-trivial forgery 现在随着Paseto的设计，令牌伪造不再是小事。\n由于算法标题不再存在，因此攻击者无法将其设置为None，或强制服务器使用它在此标题中选择的算法。令牌中的一切也用AEAD认证，因此无法篡改它。\n此外，如果使用本地对称密钥算法，则现在加密有效载荷，而不仅仅是编码，因此黑客不可能在不知道服务器的密钥的情况下读取或更改存储在令牌中的数据。\n与JWT相比，PASETO 不仅更安全，而且更容易实现更简单，更简单。\nPASETO结构 现在，让我们来看看Paseto标记的结构。\n这是一个用于本地使用目的的Paseto版本2令牌。令牌有4个主要部分，用点分开。\n1v2. 2local. 3QAxIpVeECVNI1z4xQbm_qQYomyT3h8FtV8bxkz8pBJWkT8f7HtlOpbroPDEZUKop_vaglyp76CzYy375cHmKCW8e1CCkV0Lflu4GTDyXMqQdpZMM1E6OaoQW27gaRSvWBrR3IgbFIa0AkuUFw. 4UGFyYWdvbiBJbml0aWF0aXZlIEVudGVycHJpc2Vz 每一段是一个部分\n第一部分是PASETO版本，这是版本2。\n第二部分是令牌的目的，它用于本地或公共场景吗？在这种情况下，它是本地的，这意味着使用对称密钥认证加密算法。\n第三部分是令牌的主要内容或有效载荷数据。请注意，它是加密的，因此如果我们使用key解密它，我们将获得3个较小的部分：\nPASETO Example 1 1v2.local.QAxIpVe-ECVNI1z4xQbm_qQYomyT3h8FtV8bxkz8pBJWkT8f7HtlOpbroPDEZUKop_vaglyp76CzYy375cHmKCW8e1CCkV0Lflu4GTDyXMqQdpZMM1E6OaoQW27gaRSvWBrR3IgbFIa0AkuUFw.UGFyYWdvbiBJbml0aWF0aXZlIEVudGVycHJpc2Vz This decodes to:\nVersion: v2\nPurpose: local (shared-key authenticated encryption)\nPayload (hex-encoded):\n1400c48a557be10254d235cf8c506e6fea418a26c93de1f05b55f1bc64cfca412 256913f1fec7b653a96eba0f0c46542a8a7fbda825ca9efa0b3632dfbe5c1e628 325bc7b5082915d0b7e5bb81930f25cca9076964c33513a39aa105b6ee06914af 4581ad1dc881b1486b4024b9417 Nonce: 400c48a557be10254d235cf8c506e6fea418a26c93de1f05 Authentication tag: 6914af581ad1dc881b1486b4024b9417 Decrypted Payload:\n1{ 2 \u0026#34;data\u0026#34;: \u0026#34;this is a signed message\u0026#34;, 3 \u0026#34;exp\u0026#34;: \u0026#34;2039-01-01T00:00:00+00:00\u0026#34; 4} Key used in this example (hex-encoded):\n1707172737475767778797a7b7c7d7e7f808182838485868788898a8b8c8d8e8f Footer:\n1Paragon Initiative Enterprises 首先，有效载荷体。在这种情况下，我们只需存储一个简单的消息和令牌的到期时间。 其次，在加密和消息身份验证过程中使用的nonce值。 最后，消息身份验证标记要验证加密消息及其关联的未加密数据。 在这种情况下，未加密的数据是令牌的版本，用途和页脚。\n您可以存储页脚中的任何公共信息，因为它不会像有效负载体一样加密，但只有Base64编码。所以任何有令牌的人都可以解码它以读取页脚数据。\n请注意，页脚是可选的，因此您可以在没有页脚的情况下拥有Paseto令牌。\n例如，这是公共使用场景的另一个Paseto标记：它只有3份，没有页脚。第一部分是Paseto版本，这是版本2。\nPASETO Example 2 1v2. 2public. 3eyJleHAiOiIyMDM5LTAxLTAxVDAwOjAwOjAwKzAwOjAwIiwiZGF0YSI6InRoaXMgaXMgYSBzaWduZWQgbWVzc2FnZSJ91gC7- 4jCWsN3mv4uJaZxZp0btLJgcyVwL-svJD7f4IHyGteKe3HTLjHYTGHI1MtCqJ-ESDLNoE7otkIzamFskCA This decodes to:\nVersion: v2\nPurpose: public (public-key digital signature)\nPayload:\n1{ 2 \u0026#34;data\u0026#34;: \u0026#34;this is a signed message\u0026#34;, 3 \u0026#34;exp\u0026#34;: \u0026#34;2039-01-01T00:00:00+00:00\u0026#34; 4} Signature (hex-encoded):\n1d600bbfa3096b0dde6bf8b89699c59a746ed2c981cc95c0bfacbc90fb7f8207c 286b5e29edc74cb8c761318723532d0aa27e1120cb36813ba2d908cda985b2408 Public key (hex-encoded):\n111324397f535562178d53ff538e49d5a162242970556b4edd950c87c7d86648a To learn what each version means, please see this page in the documentation.\n第二部分是其目的：在这种情况下公开，这意味着非对称关键数字签名算法用于签署令牌，其有效载荷数据不会被加密，但只有base64编码。\n如您所见，有效载荷的部分实际上是编码的主体，我们可以轻松解码以获得此JSON对象(eyJleHAiOiIyMDM5LTAxLTAxVDAwOjAwOjAwKzAwOjAwIiwiZGF0YSI6InRoaXMgaXMgYSBzaWduZWQgbWVzc2FnZSJ91gC7-)。\n而有效载荷的(jCWsN3mv4uJaZxZp0btLJgcyVwL-svJD7f4IHyGteKe3HTLjHYTGHI1MtCqJ-ESDLNoE7otkIzamFskCA)是令牌的签名，由使用私钥的数字签名算法创建。服务器将使用其配对的公钥来验证此签名的真实性。\n我们已经了解了JSON Web令牌的设计缺陷，这导致了过去的许多安全问题，以及Paseto如何发明解决所有这些问题，从而使我们的开发人员的生活更容易。\nPASETO与JWT的使用 jimyag/token (github.com)\n参考 o1egl/paseto: Platform-Agnostic Security Tokens implementation in GO (Golang) (github.com)\nWhy PASETO is better than JWT for token-based authentication? - DEV Community\n","date":"2022-03-09","img":"","permalink":"/posts/d5376d72/","series":null,"tags":["PASETO","JWT","教程"],"title":"为什么paseto比jwt好？"},{"categories":[["教程"],["gRPC"]],"content":"本文介绍如何使用gRPC的四种模式\ngRPC共有四种模式：简单模式、服务端流模式、客户端流模式、双向流模式。\n在开始之前，我们首先新建proto/hello.proto文件\n1// 表示当前使用的语法版本 2syntax = \u0026#34;proto3\u0026#34;; 3 4//.代表当前文件夹，分号后面是生成go文件引入的包名，abc具体的值根据项目需求而定。 5// 生成.go 文件的package 6option go_package = \u0026#34;.;abc\u0026#34;; 7 8 9// 定义一个Request 10// 类型 变量名 标志（标志在相同目录中必须唯一） 11message LoginRequest{ 12 string username = 1; 13 string password = 2; 14} 15 16message LoginResponse{ 17 int32 code = 1; 18 string meg = 2; 19} 20 21// 定义一个服务 22service HelloService{ 23 // 一元到一元 的服务 24 rpc HelloUnaryToUnary(LoginRequest) returns(LoginResponse){}; 25 // 一元到流的服务 服务端流 26 rpc HelloUnary2Stream(LoginRequest) returns(stream LoginResponse){}; 27 // 流到一元的服务 客户端流 28 rpc HelloStream2Unary(stream LoginRequest) returns(LoginResponse){}; 29 // 双向流的服务 30 rpc HelloStream2Stream(stream LoginRequest) returns(stream LoginResponse){}; 31} 在此之前我们还要下载go的依赖\n在项目中\n1go mod init test 2go get -u google.golang.org/grpc 3go get -u github.com/golang/protobuf 4go get -u github.com/golang/protobuf/protoc-gen-go 5go get github.com/google/uuid 此外还要安装protoc安装完成之后，在项目根目录执行\n1protoc --proto_path=proto proto/*.proto --go_out=plugins=grpc:./proto 在proto文件下就会有hello.pb.go生成。\n简单模式 类似于普通的http请求，客户端请求request服务端进行响应response。\n我说一句话你说一句话。\n我们首先实现客户端。client/main.go\n1package main 2 3import ( 4\t\u0026#34;context\u0026#34; 5\t\u0026#34;fmt\u0026#34; 6\t\u0026#34;github.com/google/uuid\u0026#34; 7\t\u0026#34;google.golang.org/grpc\u0026#34; 8\t\u0026#34;io\u0026#34; 9\t\u0026#34;log\u0026#34; 10\tabc \u0026#34;test/proto\u0026#34; 11) 12 13func main() { 14 // 1. 创建一个连接 15\tconn, err := grpc.Dial(\u0026#34;127.0.0.1:8888\u0026#34;, grpc.WithInsecure()) 16\tif err != nil { 17\tlog.Fatal(\u0026#34;cannot dial server :\u0026#34;, err) 18\t} 19 // 记着close 20\tdefer conn.Close() 21 22 // 2. 创建一个client proto生成的go文件中有一个创建 client的方法 23\tclient := abc.NewHelloServiceClient(conn) 24\t25 // 客户端 26\t{ 27 28 req := \u0026amp;abc.LoginRequest{Username: \u0026#34;admin\u0026#34;, Password: \u0026#34;123456\u0026#34;} 29 // 3. 调用服务，传一个request 30\tresponse, err := client.HelloUnaryToUnary(context.Background(), req) 31\tif err != nil { 32\tlog.Fatalf(\u0026#34;cannot receive response :%v\u0026#34;, err) 33\t} 34\t35\tlog.Printf(\u0026#34;response :%v\\n\u0026#34;, response) 36\t} 实现服务端server/server/hello_service.go\n1package server 2 3import ( 4\t\u0026#34;github.com/google/uuid\u0026#34; 5\t\u0026#34;golang.org/x/net/context\u0026#34; 6\t\u0026#34;google.golang.org/grpc/codes\u0026#34; 7\t\u0026#34;google.golang.org/grpc/status\u0026#34; 8\t\u0026#34;io\u0026#34; 9\t\u0026#34;log\u0026#34; 10\tabc \u0026#34;test/proto\u0026#34; 11) 12 13// 定义server的结构体 14type HelloServer struct { 15} 16 17func NewHelloServer() *HelloServer { 18\treturn \u0026amp;HelloServer{} 19} 20 21// 实现一元-一元服务 22func (server *HelloServer) HelloUnaryToUnary(ctx context.Context, req *abc.LoginRequest) (*abc.LoginResponse, error) { 23 // 这是一个简单是示例，所以就直接写死了 24 // 拿到 request ，如果符合要求就响应 成功，不符合要求就响应 没有该用户。 25\tif req.GetUsername() == \u0026#34;admin\u0026#34; \u0026amp;\u0026amp; req.GetPassword() == \u0026#34;123456\u0026#34; { 26\tlog.Printf(\u0026#34;request :%v\u0026#34;, req) 27\tresp := \u0026amp;abc.LoginResponse{ 28\tCode: 200, 29\tMeg: \u0026#34;成功\u0026#34;, 30\t} 31\treturn resp, nil 32\t} else { 33\tresp := \u0026amp;abc.LoginResponse{ 34\tCode: 404, 35\tMeg: \u0026#34;没有该用户\u0026#34;, 36\t} 37\treturn resp, nil 38\t} 39} 40 41// 空实现 42func (server *HelloServer) HelloUnary2Stream(req *abc.LoginRequest, stream abc.HelloService_HelloUnary2StreamServer) error { 43\treturn nil 44} 45// 空实现 46func (server *HelloServer) HelloStream2Unary(stream abc.HelloService_HelloStream2UnaryServer) error { 47\treturn nil 48} 49// 空实现 50func (server *HelloServer) HelloStream2Stream(stream abc.HelloService_HelloStream2StreamServer) error { 51\treturn nil 52} 实现服务端server/main.go\n1package main 2 3import ( 4\t\u0026#34;google.golang.org/grpc\u0026#34; 5\t\u0026#34;log\u0026#34; 6\t\u0026#34;net\u0026#34; 7\tabc \u0026#34;test/proto\u0026#34; 8\t\u0026#34;test/server/server\u0026#34; 9) 10 11func main() { 12 // 1. 拿出服务 13\tgrpcSever := grpc.NewServer() 14 15\t// 2. 挂载方法 就是上面实现的方法 16\thelloService := server.NewHelloServer() 17 18 // 3. 注册服务 19\tabc.RegisterHelloServiceServer(grpcSever, helloService) 20\tlog.Printf(\u0026#34;gRPC is running ......\u0026#34;) 21 22 // 4. 创建监听 23\tlisten, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8888\u0026#34;) 24\tif err != nil { 25\tlog.Fatalf(\u0026#34;cannot listen port 8888 :%v\u0026#34;, err) 26\t} 27\terr = grpcSever.Serve(listen) 28\tif err != nil { 29\tlog.Fatalf(\u0026#34;gRPC server err: %s\\n\u0026#34;, err) 30\t} 31} 我们分别启动服务端和客户端。\n在server/目录\n1go run .\\main.go 22022/03/09 10:15:08 gRPC is running ...... 32022/03/09 10:15:22 request :username:\u0026#34;admin\u0026#34; password:\u0026#34;123456\u0026#34; 在client/目录\n1go run .\\main.go 22022/03/09 10:15:22 response :code:200 meg:\u0026#34;成功\u0026#34; 现在我们就实现了一个简单的一元服务。\n服务端流模式 客户端发送一个request，服务端的是一个响应流。\n我说一句话，你说一大堆。\nclient.go中括号以外的内容都能复用。\n1{ 2 // 客户端向服务端发一条消息， 3\tstream, err := client.HelloUnary2Stream(context.Background(), req) 4\tif err != nil { 5\tlog.Fatalf(\u0026#34;cannot receiver stream :%v\u0026#34;, err) 6 } 7\t// 客户端不断收服务端的消息流 8\tfor { 9 // 接受服务端的流 10\tresp, err := stream.Recv() 11 // 没有错误就是收到了 12\tif err == nil { 13\tlog.Printf(\u0026#34;receiver :%v\u0026#34;, resp) 14\t} 15 // 接受完了就要结束了 16\tif err == io.EOF { 17\tlog.Printf(\u0026#34;receiver end...\u0026#34;) 18\tbreak 19\t} 20\tif err != nil { 21\tlog.Fatalf(\u0026#34;unknow error:%v\u0026#34;, err) 22\t} 23\t} 24 // 接受完了之后关闭通道 25 err= stream.CloseSend() 26\tif err!=nil{ 27\tlog.Fatal(\u0026#34;cannot close stream\u0026#34;) 28\t} 29 30} 实现func (server *HelloServer) HelloUnary2Stream(req *abc.LoginRequest, stream abc.HelloService_HelloUnary2StreamServer) error方法\n1func (server *HelloServer) HelloUnary2Stream(req *abc.LoginRequest, stream abc.HelloService_HelloUnary2StreamServer) error { 2\t// 服务端收到一条消息 3\tlog.Printf(\u0026#34;request :%v\u0026#34;, req) 4\t// 不断向客服端发消息 5\tfor i := 0; i \u0026lt; 10; i++ { 6\tusername, _ := uuid.NewRandom() 7\tresponse := \u0026amp;abc.LoginResponse{Code: int32(i), Meg: username.String()} 8\terr := stream.Send(response) 9\tlog.Printf(\u0026#34;send %v %v\u0026#34;, response.Code, response.Meg) 10\tif err != nil { 11\treturn err 12\t} 13\t} 14\treturn nil 15} 服务端\n1PS D:\\code\\go\\test\\server\u0026gt; go run .\\main.go 22022/03/09 10:34:28 gRPC is running ...... 32022/03/09 10:34:35 request :username:\u0026#34;admin\u0026#34; password:\u0026#34;123456\u0026#34; 42022/03/09 10:34:35 send 0 6497cd6a-11ce-4d76-b9a6-7e2da224199b 52022/03/09 10:34:35 send 1 1119826f-c7c1-41cb-8d17-19c827d53281 62022/03/09 10:34:35 send 2 7c90922f-212d-4524-b225-d6c2c2e0977a 72022/03/09 10:34:35 send 3 11cafa80-ce70-4e22-98a4-6af1e6c2b545 82022/03/09 10:34:35 send 4 ed87b66c-6d18-4de8-9285-d8587a8f6a53 92022/03/09 10:34:35 send 5 a0db893c-9dfa-4dac-9b77-a39e88763f0d 102022/03/09 10:34:35 send 6 9914e70f-a732-4002-b000-7ded2c66918e 112022/03/09 10:34:35 send 7 b0933c28-078c-48c6-903d-b3b936fa325f 122022/03/09 10:34:35 send 8 e24a9de1-f662-47c9-b7ea-bd9126687b97 132022/03/09 10:34:35 send 9 18e6e09a-206c-4240-9a27-2f27cf5fa0e0 客户端\n12022/03/09 10:34:35 receiver :meg:\u0026#34;6497cd6a-11ce-4d76-b9a6-7e2da224199b\u0026#34; 22022/03/09 10:34:35 receiver :code:1 meg:\u0026#34;1119826f-c7c1-41cb-8d17-19c827d53281\u0026#34; 32022/03/09 10:34:35 receiver :code:2 meg:\u0026#34;7c90922f-212d-4524-b225-d6c2c2e0977a\u0026#34; 42022/03/09 10:34:35 receiver :code:3 meg:\u0026#34;11cafa80-ce70-4e22-98a4-6af1e6c2b545\u0026#34; 52022/03/09 10:34:35 receiver :code:4 meg:\u0026#34;ed87b66c-6d18-4de8-9285-d8587a8f6a53\u0026#34; 62022/03/09 10:34:35 receiver :code:5 meg:\u0026#34;a0db893c-9dfa-4dac-9b77-a39e88763f0d\u0026#34; 72022/03/09 10:34:35 receiver :code:6 meg:\u0026#34;9914e70f-a732-4002-b000-7ded2c66918e\u0026#34; 82022/03/09 10:34:35 receiver :code:7 meg:\u0026#34;b0933c28-078c-48c6-903d-b3b936fa325f\u0026#34; 92022/03/09 10:34:35 receiver :code:8 meg:\u0026#34;e24a9de1-f662-47c9-b7ea-bd9126687b97\u0026#34; 102022/03/09 10:34:35 receiver :code:9 meg:\u0026#34;18e6e09a-206c-4240-9a27-2f27cf5fa0e0\u0026#34; 112022/03/09 10:34:35 receiver end... 客户端流模式 客户端发送流，服务端只是一个响应。\n我说了一大堆，你回了一句话。\nclient.go\n1{ 2\tstream, err := client.HelloStream2Unary(context.Background()) 3\tif err != nil { 4\tlog.Fatal(\u0026#34;cannot send \u0026#34;) 5\t} 6 7\t// 发送10条请求流 8\tfor i := 0; i \u0026lt; 10; i++ { 9\treq := \u0026amp;abc.LoginRequest{Username: uuid.NewString(), Password: uuid.NewString()} 10\terr := stream.Send(req) 11\tif err != nil { 12\tlog.Fatalf(\u0026#34;cannot send %v ,err:%v\u0026#34;, req, err) 13\t} 14\t} 15\tlog.Printf(\u0026#34;send end...\u0026#34;) 16\t// 关闭 发送通道 17\terr = stream.CloseSend() 18\tif err != nil { 19\tlog.Fatal(\u0026#34;cannot close stream\u0026#34;) 20\t} 21\t// 接受响应 22\tres, err := stream.CloseAndRecv() 23\tif err != nil { 24\tlog.Fatal(\u0026#34;cannot receive response\u0026#34;) 25\t} 26\tlog.Printf(\u0026#34;receive response %v\u0026#34;, res) 27} server.go\n1func (server *HelloServer) HelloStream2Unary(stream abc.HelloService_HelloStream2UnaryServer) error { 2 for { 3 req, err := stream.Recv() 4 if err == io.EOF { 5 log.Print(\u0026#34;no more data\u0026#34;) 6 break 7 } 8 if err != nil { 9 return logErr(status.Errorf(codes.Unknown, \u0026#34;cannot receive request\u0026#34;)) 10 } 11 12 log.Printf(\u0026#34;receiver :%v\u0026#34;, req) 13 } 14 err := stream.SendAndClose(\u0026amp;abc.LoginResponse{Code: 200, Meg: \u0026#34;接受完毕\u0026#34;}) 15 if err != nil { 16 return logErr(status.Errorf(codes.Unknown, \u0026#34;cannot send response\u0026#34;)) 17 } 18 return nil 19} 服务端\n12022/03/09 10:53:26 receiver :username:\u0026#34;6a57a4d0-aaa3-41de-bd16-2da29d3a0ff5\u0026#34; password:\u0026#34;1aade1e4-135d-4734-a29c-6a3fd23a5597\u0026#34; 22022/03/09 10:53:26 receiver :username:\u0026#34;7e04862e-efae-439e-94e5-ee0e394002d6\u0026#34; password:\u0026#34;2837e260-c90a-433c-9822-a378ff99fbe9\u0026#34; 32022/03/09 10:53:26 receiver :username:\u0026#34;4204b5b5-3df0-4a61-91f1-6940b14e809f\u0026#34; password:\u0026#34;c139d1f7-89c0-4628-961b-db3c0b2fa23a\u0026#34; 42022/03/09 10:53:26 receiver :username:\u0026#34;52c5153d-f35d-4bc6-ad8c-127df19250fe\u0026#34; password:\u0026#34;1985a5cc-b200-431c-959e-9220a1c8fa85\u0026#34; 52022/03/09 10:53:26 receiver :username:\u0026#34;6f0fc379-93c9-46f5-a374-9d9851a9f56a\u0026#34; password:\u0026#34;2166039e-1b97-4887-a0d1-d6a61bafef87\u0026#34; 62022/03/09 10:53:26 receiver :username:\u0026#34;da7e2195-ec64-448c-b8e6-1e58580b1637\u0026#34; password:\u0026#34;279d7b32-ffcd-4be2-8111-e0cb557e6bd0\u0026#34; 72022/03/09 10:53:26 receiver :username:\u0026#34;7dc698a9-e77a-491d-99f3-d36f17f8ffc0\u0026#34; password:\u0026#34;1b449f77-c6e1-413d-a88f-6b7a8f7b1bb7\u0026#34; 82022/03/09 10:53:26 receiver :username:\u0026#34;186de3d9-de9c-4243-aef7-fc9800991349\u0026#34; password:\u0026#34;731f6ef2-8241-400e-bc57-509cb8cc75e8\u0026#34; 92022/03/09 10:53:26 receiver :username:\u0026#34;5fa98e03-4a95-4653-bc1a-4f0356bcca07\u0026#34; password:\u0026#34;f3cc126c-b4c8-474a-b93e-6d4064545f84\u0026#34; 102022/03/09 10:53:26 receiver :username:\u0026#34;b2157cc2-8244-4e10-887f-b82e29617ce2\u0026#34; password:\u0026#34;f0a5c65e-dcf9-454e-88dd-0b985c2a7cdf\u0026#34; 112022/03/09 10:53:26 no more data 客户端\n1go run .\\main.go 22022/03/09 10:53:26 send req :username:\u0026#34;6a57a4d0-aaa3-41de-bd16-2da29d3a0ff5\u0026#34; password:\u0026#34;1aade1e4-135d-4734-a29c-6a3fd23a5597\u0026#34; 32022/03/09 10:53:26 send req :username:\u0026#34;7e04862e-efae-439e-94e5-ee0e394002d6\u0026#34; password:\u0026#34;2837e260-c90a-433c-9822-a378ff99fbe9\u0026#34; 42022/03/09 10:53:26 send req :username:\u0026#34;4204b5b5-3df0-4a61-91f1-6940b14e809f\u0026#34; password:\u0026#34;c139d1f7-89c0-4628-961b-db3c0b2fa23a\u0026#34; 52022/03/09 10:53:26 send req :username:\u0026#34;52c5153d-f35d-4bc6-ad8c-127df19250fe\u0026#34; password:\u0026#34;1985a5cc-b200-431c-959e-9220a1c8fa85\u0026#34; 62022/03/09 10:53:26 send req :username:\u0026#34;6f0fc379-93c9-46f5-a374-9d9851a9f56a\u0026#34; password:\u0026#34;2166039e-1b97-4887-a0d1-d6a61bafef87\u0026#34; 72022/03/09 10:53:26 send req :username:\u0026#34;da7e2195-ec64-448c-b8e6-1e58580b1637\u0026#34; password:\u0026#34;279d7b32-ffcd-4be2-8111-e0cb557e6bd0\u0026#34; 82022/03/09 10:53:26 send req :username:\u0026#34;7dc698a9-e77a-491d-99f3-d36f17f8ffc0\u0026#34; password:\u0026#34;1b449f77-c6e1-413d-a88f-6b7a8f7b1bb7\u0026#34; 92022/03/09 10:53:26 send req :username:\u0026#34;186de3d9-de9c-4243-aef7-fc9800991349\u0026#34; password:\u0026#34;731f6ef2-8241-400e-bc57-509cb8cc75e8\u0026#34; 102022/03/09 10:53:26 send req :username:\u0026#34;5fa98e03-4a95-4653-bc1a-4f0356bcca07\u0026#34; password:\u0026#34;f3cc126c-b4c8-474a-b93e-6d4064545f84\u0026#34; 112022/03/09 10:53:26 send req :username:\u0026#34;b2157cc2-8244-4e10-887f-b82e29617ce2\u0026#34; password:\u0026#34;f0a5c65e-dcf9-454e-88dd-0b985c2a7cdf\u0026#34; 122022/03/09 10:53:26 send end... 132022/03/09 10:53:26 receive response code:200 meg:\u0026#34;接受完毕\u0026#34; 双向流模式。 两个都不断在向对方发送流。\n两个人都在不断说话。可能是你说一句我回0-N句，我说一句你回0-N。\nclient.go\n1{ 2\tstream, err := client.HelloStream2Stream(context.Background()) 3\tif err != nil { 4\tlog.Fatalf(\u0026#34;unknow error %v\u0026#34;, err) 5\t} 6\t// 由于双方都需要不断发收，所以不能阻塞在一处，通过 chan 进行error的通信 7\twaitResponse := make(chan error) 8\t// 开启一个携程，专门收 9\tgo func() { 10\tfor { 11\tres, err := stream.Recv() 12\tif err == io.EOF { 13\tlog.Printf(\u0026#34;no more response\u0026#34;) 14\twaitResponse \u0026lt;- nil 15\treturn 16\t} 17\tif err != nil { 18\twaitResponse \u0026lt;- fmt.Errorf(\u0026#34;cannot receive stream response %v\u0026#34;, err) 19\treturn 20\t} 21 22\tlog.Printf(\u0026#34;received response :%v\u0026#34;, res) 23\t} 24\t}() 25 26\t// 继续发 27\tfor i := 0; i \u0026lt; 10; i++ { 28\treq := \u0026amp;abc.LoginRequest{Username: uuid.NewString(), Password: uuid.NewString()} 29\terr := stream.Send(req) 30\tlog.Printf(\u0026#34;send %v\u0026#34;, req) 31\tif err != nil { 32\tlog.Fatal(\u0026#34;unknow\u0026#34;) 33\t} 34\t} 35\t// 关闭发送 36\terr = stream.CloseSend() 37\tif err != nil { 38\tlog.Fatal(err) 39\t} 40\t// 如果没有遇到error 会一直阻塞到这，直到遇到error 41\terr = \u0026lt;-waitResponse 42\tlog.Printf(\u0026#34;end %v\u0026#34;, err) 43 44\t} server.go\n1func (server *HelloServer) HelloStream2Stream(stream abc.HelloService_HelloStream2StreamServer) error { 2 for { 3 // 不断接受 4 req, err := stream.Recv() 5 if err == io.EOF { 6 log.Printf(\u0026#34;no more data\u0026#34;) 7 break 8 } 9 if err != nil { 10 return logErr(status.Errorf(codes.Unknown, \u0026#34;cannot receive stream request :%v\u0026#34;, err)) 11 } 12 13 log.Printf(\u0026#34;receive data: %v %v\u0026#34;, req.Username, req.Password) 14 15 // 将接受到的发送 16 res := \u0026amp;abc.LoginResponse{Code: 200, Meg: \u0026#34;receive data username \u0026#34; + req.Username} 17 err = stream.Send(res) 18 if err != nil { 19 return logErr(status.Errorf(codes.Unknown, \u0026#34;cannot send response %v\u0026#34;, err)) 20 } 21 22 } 23 return nil 24} 25 26// 打印并返回 27func logErr(err error) error { 28 if err != nil { 29 log.Print(err) 30 } 31 return err 32} 服务端\n12022/03/09 10:53:26 receiver :username:\u0026#34;6a57a4d0-aaa3-41de-bd16-2da29d3a0ff5\u0026#34; password:\u0026#34;1aade1e4-135d-4734-a29c-6a3fd23a5597\u0026#34; 22022/03/09 10:53:26 receiver :username:\u0026#34;7e04862e-efae-439e-94e5-ee0e394002d6\u0026#34; password:\u0026#34;2837e260-c90a-433c-9822-a378ff99fbe9\u0026#34; 32022/03/09 10:53:26 receiver :username:\u0026#34;4204b5b5-3df0-4a61-91f1-6940b14e809f\u0026#34; password:\u0026#34;c139d1f7-89c0-4628-961b-db3c0b2fa23a\u0026#34; 42022/03/09 10:53:26 receiver :username:\u0026#34;52c5153d-f35d-4bc6-ad8c-127df19250fe\u0026#34; password:\u0026#34;1985a5cc-b200-431c-959e-9220a1c8fa85\u0026#34; 52022/03/09 10:53:26 receiver :username:\u0026#34;6f0fc379-93c9-46f5-a374-9d9851a9f56a\u0026#34; password:\u0026#34;2166039e-1b97-4887-a0d1-d6a61bafef87\u0026#34; 62022/03/09 10:53:26 receiver :username:\u0026#34;da7e2195-ec64-448c-b8e6-1e58580b1637\u0026#34; password:\u0026#34;279d7b32-ffcd-4be2-8111-e0cb557e6bd0\u0026#34; 72022/03/09 10:53:26 receiver :username:\u0026#34;7dc698a9-e77a-491d-99f3-d36f17f8ffc0\u0026#34; password:\u0026#34;1b449f77-c6e1-413d-a88f-6b7a8f7b1bb7\u0026#34; 82022/03/09 10:53:26 receiver :username:\u0026#34;186de3d9-de9c-4243-aef7-fc9800991349\u0026#34; password:\u0026#34;731f6ef2-8241-400e-bc57-509cb8cc75e8\u0026#34; 92022/03/09 10:53:26 receiver :username:\u0026#34;5fa98e03-4a95-4653-bc1a-4f0356bcca07\u0026#34; password:\u0026#34;f3cc126c-b4c8-474a-b93e-6d4064545f84\u0026#34; 102022/03/09 10:53:26 receiver :username:\u0026#34;b2157cc2-8244-4e10-887f-b82e29617ce2\u0026#34; password:\u0026#34;f0a5c65e-dcf9-454e-88dd-0b985c2a7cdf\u0026#34; 112022/03/09 10:53:26 no more data 客户端\n1go run .\\main.go 22022/03/09 10:53:26 send req :username:\u0026#34;6a57a4d0-aaa3-41de-bd16-2da29d3a0ff5\u0026#34; password:\u0026#34;1aade1e4-135d-4734-a29c-6a3fd23a5597\u0026#34; 32022/03/09 10:53:26 send req :username:\u0026#34;7e04862e-efae-439e-94e5-ee0e394002d6\u0026#34; password:\u0026#34;2837e260-c90a-433c-9822-a378ff99fbe9\u0026#34; 42022/03/09 10:53:26 send req :username:\u0026#34;4204b5b5-3df0-4a61-91f1-6940b14e809f\u0026#34; password:\u0026#34;c139d1f7-89c0-4628-961b-db3c0b2fa23a\u0026#34; 52022/03/09 10:53:26 send req :username:\u0026#34;52c5153d-f35d-4bc6-ad8c-127df19250fe\u0026#34; password:\u0026#34;1985a5cc-b200-431c-959e-9220a1c8fa85\u0026#34; 62022/03/09 10:53:26 send req :username:\u0026#34;6f0fc379-93c9-46f5-a374-9d9851a9f56a\u0026#34; password:\u0026#34;2166039e-1b97-4887-a0d1-d6a61bafef87\u0026#34; 72022/03/09 10:53:26 send req :username:\u0026#34;da7e2195-ec64-448c-b8e6-1e58580b1637\u0026#34; password:\u0026#34;279d7b32-ffcd-4be2-8111-e0cb557e6bd0\u0026#34; 82022/03/09 10:53:26 send req :username:\u0026#34;7dc698a9-e77a-491d-99f3-d36f17f8ffc0\u0026#34; password:\u0026#34;1b449f77-c6e1-413d-a88f-6b7a8f7b1bb7\u0026#34; 92022/03/09 10:53:26 send req :username:\u0026#34;186de3d9-de9c-4243-aef7-fc9800991349\u0026#34; password:\u0026#34;731f6ef2-8241-400e-bc57-509cb8cc75e8\u0026#34; 102022/03/09 10:56:49 received response :code:200 meg:\u0026#34;receive data username 4b6bcd51-652a-4a8c-af34-85a667ad4957\u0026#34; 112022/03/09 10:56:49 send username:\u0026#34;d9a3e249-c85e-4a4f-84a5-e43a787dced0\u0026#34; password:\u0026#34;e5e34dbb-585e-4b5e-83f4-e38f367f8bc0\u0026#34; 122022/03/09 10:56:49 send username:\u0026#34;1905bdd1-0a77-4d34-ae38-102038d8a4a9\u0026#34; password:\u0026#34;93bd9964-9c15-40a8-8005-f84d8aada832\u0026#34; 132022/03/09 10:56:49 send username:\u0026#34;a1d2b612-03b5-4166-aa1a-ea29e27c8f9e\u0026#34; password:\u0026#34;5b7d1fec-fba3-4120-b24b-8ee6c8f34713\u0026#34; 142022/03/09 10:56:49 received response :code:200 meg:\u0026#34;receive data username 12903ede-ead0-48d9-8240-6f51c9816ac1\u0026#34; 152022/03/09 10:56:49 received response :code:200 meg:\u0026#34;receive data username 91e8bf53-38c7-493d-b9ab-b3ce273a4780\u0026#34; 162022/03/09 10:56:49 received response :code:200 meg:\u0026#34;receive data username c47db986-b1a1-443b-8e39-e815ea4c65a8\u0026#34; 172022/03/09 10:56:49 received response :code:200 meg:\u0026#34;receive data username f8fa740e-c286-4cc4-829b-d36e571084ab\u0026#34; 182022/03/09 10:56:49 received response :code:200 meg:\u0026#34;receive data username de6112ca-8abf-4c08-9f52-f14f448f5772\u0026#34; 192022/03/09 10:56:49 received response :code:200 meg:\u0026#34;receive data username d9a3e249-c85e-4a4f-84a5-e43a787dced0\u0026#34; 202022/03/09 10:56:49 received response :code:200 meg:\u0026#34;receive data username 1905bdd1-0a77-4d34-ae38-102038d8a4a9\u0026#34; 212022/03/09 10:56:49 received response :code:200 meg:\u0026#34;receive data username a1d2b612-03b5-4166-aa1a-ea29e27c8f9e\u0026#34; 222022/03/09 10:56:49 no more response 232022/03/09 10:56:49 \u0026lt;nil\u0026gt; ","date":"2022-03-09","img":"","permalink":"/posts/3259ac99/","series":null,"tags":["教程","gRPC"],"title":"GRPC-四种模式实践"},{"categories":["Go","踩坑"],"content":"面试时被问到为什么request中的body被访问一次就不能再次访问了。\n1// Body is the request\u0026#39;s body. 2// 3// For client requests, a nil body means the request has no body, such as a GET request. 4// 对于客户端请求，nil 正文表示请求没有body 例如 GET 请求。 5// The HTTP Client\u0026#39;s Transport is responsible for calling the Close method. 6// 对于HTTP 客户端的传输负责调用 Close 方法。 7// For server requests, the Request Body is always non-nil but will return EOF immediately when no body is present. 8// 对于服务器请求，Request Body 始终为非 nil，但在没有 body 时将立即返回 EOF。 9// The Server will close the request body. The ServeHTTP Handler does not need to. 10// Server 将关闭请求正文。ServeHTTP 处理程序不需要这样做。 11// Body must allow Read to be called concurrently with Close. 12// body 必须允许与\u0026#34;关闭\u0026#34;同时调用\u0026#34;读取\u0026#34;。 13// In particular, calling Close should unblock a Read waiting for input. 14// 特别是，调用 Close 应取消阻止等待输入的读取。 15Body io.ReadCloser 以上是http包文档说明。但是为什么body需要被关闭呢，不关闭会如何？\n要了解body，首先要了解http事务是如何处理的。http事务是交由底层的Transport处理的。\n从连接池获取一个连接，这个连接的功能由3个goroutine协同实现，一个主goroutine，一个readLoop(net/http/response.go:2052)，一个writeLoop(net/http/response.go:2383)，后两个goroutine生命周期和连接一致。\n虽说readLoop和writeLoop名字叫循环（也确实是for循环），但实际上是一次循环就完整处理一个http事务，循环本身仅仅是为了连接复用，所以为了便于理解其逻辑可以忽略它的循环结构。\n接下来三个goroutine协同完成http事务：\n主goroutine将request同时发给readLoop和writeLoop。 writeLoop发送request，然后将状态（error）发送给主goroutine和readLoop。 readLoop解析头部 ，然后将状态（error）和response发送给主goroutine。 主goroutine返回用户代码，readLoop等待body读取完成。 readLoop回收连接。 了解http事务的处理流程，然后我们回过头来看看神秘的body到底是什么\n1//源码版本 1.17 2// src/net/http/transfer.go:483 body解析方法 3func readTransfer(msg interface{}, r *bufio.Reader) (err error) 4... 5// src/net/http/transfer.go:560 解析chunked 6t.Body = \u0026amp;body{src: internal.NewChunkedReader(r), hdr: msg, r: r, closing: t.Close} 7 8// src/net/http/transfer.go:565 产生eof 9t.Body = \u0026amp;body{src: io.LimitReader(r, realLength), closing: t.Close} 10 11// src/net/http/transport.go:2167 发送eof信号 12body := \u0026amp;bodyEOFSignal{ 13 14// src/net/http/transport.go:2191 gzip解码 15resp.Body = \u0026amp;gzipReader{body: body} body实际上是一个嵌套了多层的net.TCPConn：\nbufio.Reader，这层尝试将多次小的读操作替换为一次大的读操作，减少系统调用的次数，提高性能； io.LimitedReader，tcp连接在读取完body后不会关闭，继续读会导致阻塞，所以需要LimitedReader在body读完后发出eof终止读取； chunkedReader，解析chunked格式编码（如果不是chunked略过）； bodyEOFSignal，在读到eof，或者是提前关闭body时会对readLoop发出回收连接的通知； gzipReader，解析gzip压缩（如果不是gizp压缩略过）； 从上面可以看出如果body既没有被完全读取，也没有被关闭，那么这次http事务就没有完成，除非连接因超时终止了，否则相关资源无法被回收。\n如果请求头或响应头指明Connection: close呢？还是无法回收，因为close表示在http事务完成后断开连接，而事务尚未完成自然不会断开，更不会回收。\n从实现上看只要body被读完，连接就能被回收，只有需要抛弃body时才需要close，似乎不关闭也可以。但那些正常情况能读完的body，即第一种情况，在出现错误时就不会被读完，即转为第二种情况。而分情况处理则增加了维护者的心智负担，所以始终close body是最佳选择\n简单的来说就是，原生的http包里，每发生一次http请求，在过程中会生成两个协程，一个负责写入request (persistConn.writeLoop)，一个负责读response (persistConn.readLoop), 这两个方法，。由于两个协程是用for+select构成的，所以在没有接收到结束信号\n（获取 writeLoop 返回的写入错误 pc.closech的关闭信息， 连接超时的信息 readLoop的 resp cancel ctx done的信息 之前，都会阻塞住，导致goroutine无法退出，当请求量过大时，gotoutine不能及时释放，就会导致gotoutine数量突增。\n只要这时候只要你读取完body的内容，他就会自动关闭。这样就可以防止内存泄漏。\n参考\n《GO goroutine暴涨与response.Body.Close()的关联》 - 热爱可抵岁月漫长 (jiangailang.cn)\n[golang]为什么Response.Body需要被关闭 - 简书 (jianshu.com)\nGo http 请求（get/post）必须要手动 resp.Body.Close (zhangjiee.com)\n","date":"2022-02-24","img":"","permalink":"/posts/60b013aa/","series":null,"tags":["Go","踩坑","源码"],"title":"为什么Request.Body需要被关闭"},{"categories":[["Go"],["教程"]],"content":"go1.18已经支持泛型，但是目前工作使用的是1.17。如何在不卸载原有版本情况下下载1.18beta版本？\n首先确保机器已经有Go环境。\n在Downloads - The Go Programming Language找到想要下载的版本，我这里是要下载1.18beta2版本的，执行\n1go install golang.org/dl/go1.18beta2@latest 之后执行\n1go install 等待下载完成即可。\n查看GOROOT\n1C:\\Users\\jimyag\u0026gt;go1.18beta2 env GOROOT 2C:\\Users\\jimyag\\sdk\\go1.18beta2 在Goland中，setting-\u0026gt;GO-\u0026gt;GOROOT 选择上述的位置（C:\\Users\\jimyag\\sdk\\go1.18beta2）即可\n","date":"2022-02-17","img":"","permalink":"/posts/17eab2e7/","series":null,"tags":["Go","教程"],"title":"在同一机器上安装Go的不同版本"},{"categories":["教程"],"content":"写proto时，在引入其它自己的定义的proto，之后会发现goland提示import路径不存在\n在实际生成代码中却没有关系，说明Goland配置有问题？\n报红解决。\n","date":"2022-02-13","img":"","permalink":"/posts/155b4227/","series":null,"tags":["踩坑"],"title":"Golang-Import自己的proto文件报红"},{"categories":["NexT","Hexo"],"content":"你是否也遇到了这个问题 pandoc exited with code null. 昨天还可以生成，今天就完了。\n1jimyag@MacBook-Pro jimyag-blog % hexo serve 2INFO Validating config 3INFO ================================== 4 ███╗ ██╗███████╗██╗ ██╗████████╗ 5 ████╗ ██║██╔════╝╚██╗██╔╝╚══██╔══╝ 6 ██╔██╗ ██║█████╗ ╚███╔╝ ██║ 7 ██║╚██╗██║██╔══╝ ██╔██╗ ██║ 8 ██║ ╚████║███████╗██╔╝ ██╗ ██║ 9 ╚═╝ ╚═══╝╚══════╝╚═╝ ╚═╝ ╚═╝ 10======================================== 11NexT version 8.8.2 12Documentation: https://theme-next.js.org 13======================================== 14INFO Start processing 15ERROR { 16 err: Error: 17 [ERROR][hexo-renderer-pandoc] On /Users/jimyag/repo/jimyag-blog/themes/next/languages/README.md 18 [ERROR][hexo-renderer-pandoc] pandoc exited with code null. 19 at Hexo.pandocRenderer (/Users/jimyag/repo/jimyag-blog/node_modules/hexo-renderer-pandoc/index.js:114:11) 20 at Hexo.tryCatcher (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/util.js:16:23) 21 at Hexo.\u0026lt;anonymous\u0026gt; (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/method.js:15:34) 22 at /Users/jimyag/repo/jimyag-blog/node_modules/hexo/lib/hexo/render.js:75:22 23 at tryCatcher (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/util.js:16:23) 24 at Promise._settlePromiseFromHandler (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/promise.js:547:31) 25 at Promise._settlePromise (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/promise.js:604:18) 26 at Promise._settlePromise0 (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/promise.js:649:10) 27 at Promise._settlePromises (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/promise.js:729:18) 28 at _drainQueueStep (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/async.js:93:12) 29 at _drainQueue (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/async.js:86:9) 30 at Async._drainQueues (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/async.js:102:5) 31 at Immediate.Async.drainQueues [as _onImmediate] (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/async.js:15:14) 32 at processImmediate (node:internal/timers:466:21) 33} Process failed: %s languages/README.md 34FATAL { 35 err: Error: 36 [ERROR][hexo-renderer-pandoc] On /Users/jimyag/repo/jimyag-blog/source/_posts/TCP-IP协议三次握手、四次挥手.md 37 [ERROR][hexo-renderer-pandoc] pandoc exited with code null. 38 at Hexo.pandocRenderer (/Users/jimyag/repo/jimyag-blog/node_modules/hexo-renderer-pandoc/index.js:114:11) 39 at Hexo.tryCatcher (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/util.js:16:23) 40 at Hexo.\u0026lt;anonymous\u0026gt; (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/method.js:15:34 41 at /Users/jimyag/repo/jimyag-blog/node_modules/hexo/lib/hexo/render.js:75:22 42 at tryCatcher (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/util.js:16:23) 43 at Promise._settlePromiseFromHandler (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/promise.js:547:31) 44 at Promise._settlePromise (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/promise.js:604:18) 45 at Promise._settlePromiseCtx (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/promise.js:641:10) 46 at _drainQueueStep (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/async.js:97:12) 47 at _drainQueue (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/async.js:86:9) 48 at Async._drainQueues (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/async.js:102:5) 49 at Immediate.Async.drainQueues [as _onImmediate] (/Users/jimyag/repo/jimyag-blog/node_modules/bluebird/js/release/async.js:15:14) 50 at processImmediate (node:internal/timers:466:21) 51} Something\u0026#39;s wrong. Maybe you can find the solution here: %s https://hexo.io/docs/troubleshooting.html 这是hexo-renderer-pandoc包的问题。把它删掉就解决了\n1npm remove --save hexo-renderer-pandoc 命令删不了的话，直接在文件夹里删，在 node_modules 里找到 hexo-renderer-pandoc 删掉。\n","date":"2022-02-12","img":"","permalink":"/posts/80ae3d28/","series":null,"tags":["NexT"],"title":"Pandoc Exited With Code Null"},{"categories":["教程"],"content":"为了实现可靠传输，TCP采用了面向字节流的方式发送数据。TCP在发送数据时，是从发送缓冲区取出一部分或全部字节并给其添加一个首部使之成为TCP报文段后进行发送。\nTCP报文介绍 TCP 报文是 TCP 层传输的数据单元，也称为报文段。TCP 报文中每个字段如图所示。\n源端口和目的端口字段 源端口（Source Port）：标识发送该TCP报文段的应用进程（端口号），占 16 位。 目的端口（Destination Port）：标识接受该TCP报文段的应用进程（端口号），占 16 位。 序列号字段 TCP序列号（Sequence Number）：占 32 位，序号增加到最后一个后下一个序号又回到0。它表示本报文段所发送数据的第一个字节的编号。\n确认号字段 TCP 确认号（Acknowledgment Number，ACK Number）：占 32 位。它表示期望收到发送方下一个TCP报文段的数据载荷的第一个字节数据的序号，同时也是对之前所有数据的确认。其值是接收计算机即将接收到的下一个序列号，也就是下一个接收到的字节的序列号加1。\n若确认号为n，则表明，到序号n-1为止的所有数据都已经正确接受，期望收到序号为n的数据\n当确认标志位ACK为1是确认号字段有效，取值为0是无效。\nTCP 规定，在建立连接之后的所有传送的TCP报文端都必须把ACK置为1.\nA发送序号为201，载荷长度为100字节的数据给B。并且确认了800之前的数据（不包含800），ACK为1表示确认是有效的。\nB收到A发来的数据报之后，又给A发送了A想要的800序号之后的数据，数据长度为200字节。并且确认了301（A的序号+长度）之前的数据（不包含301，其实数据只收到到300序号）\n数据偏移字段 TCP 首部长度（Header Length）：数据偏移是指数据段中的“数据”部分起始处距离 TCP 数据段起始处的字节偏移量，占 4 比特。其实这里的“数据偏移”也是在确定 TCP 数据段头部分的长度，告诉接收端的应用程序，数据从何处开始。\n偏移量的是以4字节为单位，该字段实际指出了TCP报文段的首部长度，首部的固定长度为20字节（定义的）也就是5个单位的偏移量。用二进制表示是0101。最大为1111也就是15个单位，等于60个字节，所以首部最长是60个字节。\n保留字段 保留（Reserved）：占 6 位。为 TCP 将来的发展预留空间，目前必须全部为 0。\n标志位字段 CWR（Congestion Window Reduce）：拥塞窗口减少标志，用来表明它接收到了设置 ECE 标志的 TCP 包。并且，发送方收到消息之后，通过减小发送窗口的大小来降低发送速率。 ECE（ECN Echo）：用来在 TCP 三次握手时表明一个 TCP 端是具备 ECN 功能的。在数据传输过程中，它也用来表明接收到的 TCP 包的 IP 头部的 ECN 被设置为 11，即网络线路拥堵。 URG（Urgent）：表示本报文段中发送的数据是否包含紧急数据。URG=1 时表示有紧急数据。当 URG=1 时，后面的紧急指针字段才有效。 ACK：表示前面的确认号字段是否有效。ACK=1 时表示有效。只有当 ACK=1 时，前面的确认号字段才有效。TCP 规定，连接建立后，ACK 必须为 1。 PSH（Push）：告诉对方收到该报文段后是否立即把数据推送给上层。如果值为 1，表示应当立即把数据提交给上层，而不是缓存起来。 RST：表示是否重置连接。如果 RST=1，说明 TCP 连接出现了严重错误（如主机崩溃），必须释放连接，然后再重新建立连接。还可以用来拒绝一个非法的报文火拒绝打开一个TCP连接。 SYN：在建立连接时使用，用来同步序号。当 SYN=1，ACK=0 时，表示这是一个请求建立连接的报文段；当 SYN=1，ACK=1 时，表示对方同意建立连接。SYN=1 时，说明这是一个请求建立连接或同意建立连接的报文。只有在前两次握手中 SYN 才为 1。 FIN：标记数据是否发送完毕。如果 FIN=1，表示数据已经发送完成，可以释放连接。 窗口字段 窗口大小（Window Size）：占 16 位。它表示从 Ack Number 开始还可以接收多少字节的数据量，也表示当前接收端的接收窗口还有多少剩余空间（发送本报文端的一方的接受窗口，是以接收方的接受能力来控制发送方的发送能力）。该字段可以用于 TCP 的流量控制。发送窗口的大小还取决于拥塞窗口的大小，是min（接受窗口，拥塞窗口）\nTCP 校验和字段 校验位（TCP Checksum）：占 16 位。它用于确认传输的数据是否有损坏。发送端基于数据内容校验生成一个数值，接收端根据接收的数据校验生成一个值。两个值必须相同，才能证明数据是有效的。如果两个值不同，则丢掉这个数据包。\n紧急指针字段 紧急指针（Urgent Pointer）：仅当前面的 URG 控制位为 1 时才有意义。它指出本数据段中为紧急数据的字节数，占 16 位。当所有紧急数据处理完后，TCP 就会告诉应用程序恢复到正常操作。即使当前窗口大小为 0，也是可以发送紧急数据的，因为紧急数据无须缓存。\n可选项字段 选项（Option）：长度不定，但长度必须是 32bits 的整数倍。\n三次握手 三次握手（Three-way Handshake）其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备。实质上其实就是连接服务器指定端口，建立TCP连接，并同步连接双方的序列号和确认号，交换TCP窗口大小信息。\n过程 首先A向B发起TCP连接请求，请求中不携带数据，报文首部的标志位SYN置为1表示这是一个TCP请求连接报文段，序号取值为x是A自己生成的序号。\n主机B收到A发来的TCP连接请求报文段后给A发送TCP连接请求确认报文段，该报文段也不携带数据，只有首部。SYN和ACK都为1表示这是一个TCP连接请求确认报文段。序号为y是B自己生成的自己的初始序号，确认号x+1表示确认了连接请求。\nA收到B发来的请求确认报文段，要再次发送一个普通的TCP确认报文段，这个报文段可以携带数据，也可以不携带数据。序号为x+1表示这是A发送的第二个数据报文段（第一个数据报文段没有携带数据），确认号为y+1表示收到了连接请求确认报文段。\n为什么需要三次握手，两次不行吗？ 弄清这个问题，我们需要先弄明白三次握手的目的是什么，能不能只用两次握手来达到同样的目的。\n第一次握手：客户端发送网络包，服务端收到了。\n这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。\n第二次握手：服务端发包，客户端收到了。\n这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。\n第三次握手：客户端发包，服务端收到了。\n这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。\n因此，需要三次握手才能确认双方的接收与发送能力是否正常。\n试想如果是用两次握手，则会出现下面这种情况：\n如客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请求。\n后来收到了确认，建立了连接。\n数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端，\n此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一致等待客户端发送数据，浪费资源。\n三次握手过程中可以携带数据吗？ 其实第三次握手的时候，是可以携带数据的。但是，第一次、第二次握手不可以携带数据\n为什么这样呢?假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据。因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。\n也就是说，第一次握手不可以放数据，其中一个简单的原因就是会让服务器更加容易受到攻击了。而对于第三次的话，此时客户端已经处于 established 状态。对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据也没啥毛病。\nSYN攻击是什么？ 服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器容易受到SYN洪泛攻击。\nSYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。\n检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。\n四次挥手 建立一个连接需要三次握手，而终止一个连接要经过四次挥手。这由TCP的半关闭（half-close）造成的。所谓的半关闭，其实就是TCP提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力\n过程 A向B发起TCP释放报文段（FIN和ACK都为1表示这是一个释放报文段），序号为u表示之前已经发送过数据的序号+1，确认号为v表示之前已经收到的数据的最后一个字节+1。此时客户端处于 FIN_WAIT1 状态。即发出连接释放报文段，并停止再发送数据，主动关闭TCP连接，进入FIN_WAIT1（终止等待1）状态，等待服务端的确认。\nB收到A发送的释放报文段后，给A发送普通的确认报文段（ACK=1 序号=v，确认号=u+1）。服务端收到连接释放报文段后即发出确认报文段，服务端进入CLOSE_WAIT（关闭等待）状态，此时的TCP处于半关闭状态，客户端到服务端的连接释放。客户端收到服务端的确认后，进入FIN_WAIT2（终止等待2）状态，等待服务端发出的连接释放报文段。\n在此，如果B有数据还要传输，这时候还可以传输数据。如果B已经没有数据要传输了就要进行下一步。\nB给A发送TCP释放报文段（FIN，ACK=1，序号=w【对之前收到的数据进行确认】，确认号=u+1）。服务端没有要向客户端发出的数据，服务端发出连接释放报文段，服务端进入LAST_ACK（最后确认）状态，等待客户端的确认。\nA收到B的释放报文段后，还要给B发送一个普通的确认报文段（ACK=1，序号=u+1，确认号=w+1）。客户端收到服务端的连接释放报文段后，对此发出确认报文段，客户端进入TIME_WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL后，客户端才进入CLOSED状态。\n挥手为什么需要四次？ 因为当服务端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。\n但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，“你发的FIN报文我收到了”。\n只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手。\n","date":"2022-02-10","img":"","permalink":"/posts/c4697fb2/","series":null,"tags":["TCP","教程"],"title":"TCP/IP协议三次握手、四次挥手"},{"categories":[["算法"]],"content":"差分与前缀和相对，可以视为前缀和的逆运算。差分它可以维护多次对序列的一个区间修改一个数。\n一维差分 定义 给定一个数组num = [a1,a2,a3,a4,...,an],构造一个数组b = [b1,b2,...,bn],使得数组b满足\n$$a_i = b_1+b_2+\u0026hellip;+b_{i-1}+b_i$$\n构造完成之后就可以使得，num数组是b数组的前缀和数组\n构造 构造其实不是很重要\nb1 = a1\nb2 = a2-a1\nb3 = a3-a2\n\u0026hellip;\nbn =an-a(n-1)\n作用 可以在O(n)时间内求得前缀和数组num 假设要求在[l,r]区间内，给原数组num的第l到第r项每一项都加上一个常数c，求区间内所有数的和的速度可以在O(1)时间复杂度完成 利用差分后再做前缀和可以得到原数列的性质，可以通过改变差分后的数组从而改变原数组。\n使差分数组的第一个元素加上了常数C,可以想到，在做前缀和处理，回到原数组的时候，由递推公式为：\n$$num[i] = num[i-1]+b[i]$$\n可以得到原数组所有的元素都将加上C 再通过这个性质，做一点变形，\n对于作用2，我们对于b[l]+c，就相当于给num[l]+c,num[l+1]+c,...,num[n]+c，就是给num数组中l后面所有数全加上c。同理对于b[r]-c，就相当于给num中r后面的所有数减去c，对于num中r之后的数字加c减c之后相当于没有变化。\n如果我们需要给原数组某个区间加上同一个数字，我们只需要给差分数组做b[l]+c和b[r]-c处理就行。\n基于此，我们甚至可以使用全初始化为0的数组来初始化原数组。只要把区间[l,r]缩小到每一个元素(l和r重合时)，根据函数可以将原数组[l,r]部分每个元素都加上c可以将一个元素赋予要赋的值。\n对于原数组num = [a1,a2,a3,a4,...,an]可以看作是n次插入操作，\n给num[1,1]加上a1\n给num[2,2]加上a2\n\u0026hellip;.\n给num[n,n]加上an\n所以所有的操作可以直接从差分数组本身开始，而不必用原数组做差分后操作，最后再前缀和。\n例子 1094. 拼车 假设你是一位顺风车司机，车上最初有 capacity 个空座位可以用来载客。由于道路的限制，车 只能 向一个方向行驶（也就是说，不允许掉头或改变方向，你可以将其想象为一个向量）。\n这儿有一份乘客行程计划表 trips[][]，其中 trips[i] = [num_passengers, start_location, end_location] 包含了第 i 组乘客的行程信息：\n必须接送的乘客数量； 乘客的上车地点； 以及乘客的下车地点。 这些给出的地点位置是从你的 初始 出发位置向前行驶到这些地点所需的距离（它们一定在你的行驶方向上）。\n请你根据给出的行程计划表和车子的座位数，来判断你的车是否可以顺利完成接送所有乘客的任务（当且仅当你可以在所有给定的行程中接送所有乘客时，返回 true，否则请返回 false）。\n示例 1：\n1输入：trips = [[2,1,5],[3,3,7]], capacity = 4 2输出：false 示例 2：\n1输入：trips = [[2,1,5],[3,3,7]], capacity = 5 2输出：true 示例 3：\n1输入：trips = [[2,1,5],[3,5,7]], capacity = 3 2输出：true 示例 4：\n1输入：trips = [[3,2,7],[3,7,9],[8,3,9]], capacity = 11 2输出：true 提示：\n你可以假设乘客会自觉遵守 “先下后上” 的良好素质 trips.length \u0026lt;= 1000 trips[i].length == 3 1 \u0026lt;= trips[i][0] \u0026lt;= 100 0 \u0026lt;= trips[i][1] \u0026lt; trips[i][2] \u0026lt;= 1000 1 \u0026lt;= capacity \u0026lt;= 100000 代码 此处建立差分数组diff,遍历到trips[i]时,diff[trips[i][1]]加上该地上车的乘客数目trips[i][0]表示比上一位置增加了这么多乘客,在diff[trip[i][2]]处减去trips[i][0]表示乘客已下车，那么数组diff的前缀和prefixSum[i]就表示i处的当前乘客数目，如果超过容量capacity就不能完成任务了。\n由于我们只需要判断当前车上的人数是否超过capacity，所以我们对于差分数组之和就用不到了，我们可以把前缀和更新到原来的差分数组中。或者重新声明一个变量来存当前车上的人数。\n1// 构造差分 2void insert(vector\u0026lt;int\u0026gt; \u0026amp;d, int l, int r, int c) { 3 // 在l站上车 4 d[l] += c; 5 // 在r站下车 6 // 满足先下后上，将位置腾出来了。 7 d[r] -= c; 8} 9 10bool carPooling(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; \u0026amp;trips, int capacity) { 11 // 1001是因为最远断点是1000 12 vector\u0026lt;int\u0026gt; difference(1001, 0); 13 // 构造差分 14 for (int i = 1; i \u0026lt;= trips.size(); i++) { 15 insert(difference,trips[i-1][1],trips[i-1][2],trips[i-1][0]); 16 } 17 // 单独判断第一站的乘客 18 if(difference[0]\u0026gt;capacity){ 19 return false; 20 } 21 for(int i = 1;i\u0026lt;1001;i++){ 22 // 计算第i站的车上乘客数量 23 difference[i]+=difference[i-1]; 24 if(difference[i]\u0026gt;capacity){ 25 return false; 26 } 27 } 28 return true; 29} 1893. 检查是否区域内所有整数都被覆盖 给你一个二维整数数组 ranges 和两个整数 left 和 right 。每个 ranges[i] = [starti, endi] 表示一个从 starti 到 endi 的 闭区间 。\n如果闭区间 [left, right] 内每个整数都被 ranges 中 至少一个 区间覆盖，那么请你返回 true ，否则返回 false 。\n已知区间 ranges[i] = [starti, endi] ，如果整数 x 满足 starti \u0026lt;= x \u0026lt;= endi ，那么我们称整数x 被覆盖了。\n示例 1：\n1输入：ranges = [[1,2],[3,4],[5,6]], left = 2, right = 5 2输出：true 3解释：2 到 5 的每个整数都被覆盖了： 4- 2 被第一个区间覆盖。 5- 3 和 4 被第二个区间覆盖。 6- 5 被第三个区间覆盖。 示例 2：\n1输入：ranges = [[1,10],[10,20]], left = 21, right = 21 2输出：false 3解释：21 没有被任何一个区间覆盖。 代码 其中 diff[i] 对应覆盖整数 i的区间数量相对于覆盖 i-1的区间数量变化量。\n这样，当遍历到闭区间[l,r] 时，l相对于l−1 被覆盖区间数量多 1，r+1 相对于 r 被覆盖区间数量少 1。对应到差分数组上，我们需要将diff[l]加上 1，并将 diff[r+1] 减去 1。\n在维护完差分数组 diff 后，我们遍历diff 求前缀和得出覆盖每个整数的区间数量。下标 i 对应的被覆盖区间数量即为初始数量 00 加上 [1,i] 闭区间的变化量之和。在计算被覆盖区间数量的同时，我们可以一并判断 [left,right] 闭区间内的所有整数是否都被覆盖。\n1// 构造差分 2void insert(vector\u0026lt;int\u0026gt; \u0026amp;d, int l, int r, int c) { 3 d[l] += c; 4 d[r+1] -= c; 5} 6bool isCovered(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; ranges, int left, int right) { 7 vector\u0026lt;int\u0026gt;difference(60,0); 8 for(int i = 1;i\u0026lt;=ranges.size();i++){ 9 insert(difference,ranges[i-1][0],ranges[i-1][1],1); 10 } 11 // 12 int preSum = 0; 13 for(int i =1;i\u0026lt;=right;i++){ 14 preSum+=difference[i]; 15 if(i\u0026gt;=left\u0026amp;\u0026amp;i\u0026lt;=right){ 16 if(preSum\u0026lt;=0){ 17 return false; 18 } 19 } 20 } 21 return true; 22} 二维差分 二位前缀和是计算矩阵中的一个点包括其和左上角的所有点的值的和，那么差分的作用就是在时间复杂度是 O(1) 的情况下对一个矩阵操作，比如某区域的点都加上一个数。\n那么我们应该怎么构建差分数组呢，其实和一维差分差不多，只不过是多了一维。那么有了一维差分的构建经验对于二位差分我们直接用插入函数即可，原理下面会说。\n由一维差分我们可以知道， a[i] 是 b[1]\u0026hellip;b[i] 的前缀和，如果我们要对区间 [l , r] 中的数都加上一个数c的话只需要让 b[l] += c 并且 b[r + 1] -= c 即可，这样用差分数组构建新数组时，区间 [l , r] 中的数都会在原基础上加上c。\n如果我们把这个区间放缩一下，并且让数组元素都为0的这个数组a作为我们的原数组，那么数组a的差分数组b也是全为0，这样我们就构成了差分数组，那么我们真正需要输入到数组中的数就可以利用二位差分的性质进行了，也就是当区间 l = r时，我们让其加上一个需要输入的数，这样既输入了数据，也构成了差分数组。\n我们来看一下对任意子矩阵都加上一个数的话，应该怎么利用差分数组。\n从图中我们可以很清楚的看到，如果在x1，y1上加一个数c那么它右下角的数都会加上c，那么该怎么办呢，其实这也是容斥定理。我们只需要减去右边多加的部分和下边多加的部分最后再加上重复减去的部分即可\n$$dif[x1][y1]+=c $$\n$$dif[x1][y2+1]-=c$$\n$$ dif[x2+1][y1]-=c $$\n$$dif[x2+1][y2+1]+=c$$\n例子 输入一个n行m列的整数矩阵，再输入q个操作，每个操作包含五个整数 x 1 , y 1 , x 2 , y 2 , c ， 其 中 ( x 1 , y 1 ) 和 ( x 2 , y 2 ) 表 示 一 个 子 矩 阵 的 左 上 角 坐 标 和 右 下 角 坐 标 。 x1,y1,x2,y2,c，其中 (x1,y1) 和 (x2,y2) 表示一个子矩阵的左上角坐标和右下角坐标。x1,y1,x2,y2,c，其中(x1,y1)和(x2,y2)表示一个子矩阵的左上角坐标和右下角坐标。\n每 个 操 作 都 要 将 选 中 的 子 矩 阵 中 的 每 个 元 素 的 值 加 上 c 。 每个操作都要将选中的子矩阵中的每个元素的值加上 c。每个操作都要将选中的子矩阵中的每个元素的值加上c。\n请 你 将 进 行 完 所 有 操 作 后 的 矩 阵 输 出 。 请你将进行完所有操作后的矩阵输出。请你将进行完所有操作后的矩阵输出。\n输入格式\n第 一 行 包 含 整 数 n , m , q 。 第一行包含整数 n,m,q。第一行包含整数n,m,q。 接 下 来 n 行 ， 每 行 包 含 m 个 整 数 ， 表 示 整 数 矩 阵 。 接下来 n 行，每行包含 m 个整数，表示整数矩阵。接下来n行，每行包含m个整数，表示整数矩阵。 接 下 来 q 行 ， 每 行 包 含 5 个 整 数 x 1 , y 1 , x 2 , y 2 , c ， 表 示 一 个 操 作 。 接下来 q 行，每行包含 5 个整数 x1,y1,x2,y2,c，表示一个操作。接下来q行，每行包含5个整数x1,y1,x2,y2,c，表示一个操作。\n输出格式\n共 n 行 ， 每 行 m 个 整 数 ， 表 示 所 有 操 作 进 行 完 毕 后 的 最 终 矩 阵 。 共 n 行，每行 m 个整数，表示所有操作进行完毕后的最终矩阵。共n行，每行m个整数，表示所有操作进行完毕后的最终矩阵。\n数据范围\n1 ≤ n , m ≤ 1000 , 1≤n,m≤1000,1≤n,m≤1000, 1 ≤ q ≤ 100000 , 1≤q≤100000,1≤q≤100000, 1 ≤ x 1 ≤ x 2 ≤ n , 1≤x1≤x2≤n,1≤x1≤x2≤n, 1 ≤ y 1 ≤ y 2 ≤ m , 1≤y1≤y2≤m,1≤y1≤y2≤m, − 1000 ≤ c ≤ 1000 , −1000≤c≤1000,−1000≤c≤1000, − 1000 ≤ 矩 阵 内 元 素 的 值 ≤ 1000 −1000≤矩阵内元素的值≤1000−1000≤矩阵内元素的值≤1000\n输入样例：\n3 4 3 1 2 2 1 3 2 2 1 1 1 1 1 1 1 2 2 1 1 3 2 3 2 3 1 3 4 1 1 2 3 4 5 6 7\n输出样例：\n2 3 4 1 4 3 4 1 2 2 2 2\n1#include \u0026lt;iostream\u0026gt; 2 3using namespace std; 4 5const int N = 1010; 6 7int n, m, q; 8int a[N][N], b[N][N]; 9 10void insert(int x1, int y1, int x2, int y2, int c) 11{ 12 b[x1][y1] += c; 13 b[x2 + 1][y1] -= c; 14 b[x1][y2 + 1] -= c; 15 b[x2 + 1][y2 + 1] += c; 16} 17 18int main() 19{ 20 scanf(\u0026#34;%d%d%d\u0026#34;, \u0026amp;n, \u0026amp;m, \u0026amp;q); 21 22 for (int i = 1; i \u0026lt;= n; i ++ ) 23 for (int j = 1; j \u0026lt;= m; j ++ ) 24 scanf(\u0026#34;%d\u0026#34;, \u0026amp;a[i][j]); 25 26 for (int i = 1; i \u0026lt;= n; i ++ ) 27 for (int j = 1; j \u0026lt;= m; j ++ ) 28 insert(i, j, i, j, a[i][j]); 29 30 while (q -- ) 31 { 32 int x1, y1, x2, y2, c; 33 cin \u0026gt;\u0026gt; x1 \u0026gt;\u0026gt; y1 \u0026gt;\u0026gt; x2 \u0026gt;\u0026gt; y2 \u0026gt;\u0026gt; c; 34 insert(x1, y1, x2, y2, c); 35 } 36 37 for (int i = 1; i \u0026lt;= n; i ++ ) 38 for (int j = 1; j \u0026lt;= m; j ++ ) 39 b[i][j] += b[i - 1][j] + b[i][j - 1] - b[i - 1][j - 1]; 40 41 for (int i = 1; i \u0026lt;= n; i ++ ) 42 { 43 for (int j = 1; j \u0026lt;= m; j ++ ) printf(\u0026#34;%d \u0026#34;, b[i][j]); 44 puts(\u0026#34;\u0026#34;); 45 } 46 47 return 0; 48} ","date":"2022-01-29","img":"","permalink":"/posts/7c729863/","series":null,"tags":["算法","差分"],"title":"差分学习记录"},{"categories":[["算法"]],"content":"假设我们有一个字符串ABCDE，什么是这个单词的前缀，A、AB、ABC、ABCD、ABCDE就是这个单词的前缀，就是从第一个字母开始，依次往后拼接。E、ED、EDC、EDCB、EDCBA被称为这个单词的后缀。\n那么对于一个数组的前缀，例如数组a = [a1,a2,a3,a4,a5]，我们维护一个由前缀的和组成的数组sum，sum[i]表示数组中前i个数的和。\nsum[i] = a1+a2+\u0026hellip;+ai\nsum数组就被称为前缀和数组。\n一维前缀和 如何求sum数组 求sum数组很简单\n1# num 表示原来的数组 2# n表示num.size(); 3# sum表示前缀和数组 4# 其中sum[0] = 0 下面解释为什么 5for(int i = 1;i\u0026lt;=n){ 6 sum[i] = sum[i-1]+num[i]; 7} 前缀和作用 前缀和的最主要目的就是求子数组的和的大小。例如元素a[1]到a[3]的和。 a[1] + a[2] + a[3] = sum[3] - sum[0] 注意：这里sum中的i表示的是前i个数的和，不是下标，因为题目中需要用到前0个数的和。\n前缀和sum的下标一般从1开始，这样就不用处理边界问题了。\n前缀和是一种预处理，用于降低查询时的时间复杂度。\n举个例子：给定 n个整数，然后进行 m 次询问，每次询问求一个区间内值的和。\n如果用暴力写法，那每次询问都需要从区间左端点循环到区间右端点求和，时间复杂度较大。\n这种时候就可以预先求出该数组的一维前缀和。例如我们需要求[left,right]区间上的和（包括断点）\n由于$$sum[right] = num[1]+num[2]+\u0026hellip;+num[left-1]+num[left]+\u0026hellip;+num[right]$$\n$$sum[left-1] = num[1]+num[2]+\u0026hellip;+\u0026hellip;num[left-1]$$\n我们发现要求的结果为$$num[left]+num[left+1]+\u0026hellip;+num[right] = sum[right]-sum[left - 1]$$\n则$$ans = sum[right]-sum[left - 1] $$\n这时候如果我们需要求[1,5]区间上的和就是sum[5]，我们为了统一，所以规定sum[0] = 0，则结果可以表示为：\n$$ans = sum[5]-sum[0]$$\n这时候就需要sum[0]了\n其中right和left是给定的区间，每次询问可直接输出答案，这样时间复杂度就降到了O(m+n)\n例子 560. 和为 K 的子数组 - 力扣（LeetCode） (leetcode-cn.com)\n给你一个整数数组 nums 和一个整数 k ，请你统计并返回该数组中和为 k 的连续子数组的个数。\n示例 1： 输入：nums = [1,1,1], k = 2 输出：2 示例 2： 输入：nums = [1,2,3], k = 3 输出：2\n题目中很明确连续子数组，我们可以使用前缀和来求\n代码如下：\n1int subarraySum(vector\u0026lt;int\u0026gt; \u0026amp;nums, int k) { 2 //定义一个前缀和数组，下标从1开始，所以比num要多1 3 vector\u0026lt;int\u0026gt; sum(nums.size() + 1, 0); 4 for (int i = 1; i \u0026lt;= nums.size(); i++) { 5 // 原来num中的下标还是从0开始的，所以这里要用num[i-1] 6 sum[i] = sum[i - 1] + nums[i - 1]; 7 } 8 // 记录共有多少次 9 int ans = 0; 10 // 双指针进行遍历， 11 for (int i = 0; i \u0026lt; sum.size(); i++) { 12 for (int j = i + 1; j \u0026lt; sum.size(); j++) { 13 // 如果某个区间的和为k ans++ 14 if ((sum[j] - sum[i] == k)) { 15 ans++; 16 } 17 } 18 } 19 return ans; 20 } 一运行发现，超时了。虽然超时了，但证明我们的想法是没错的，只需要一点点优化就行。\n1int subarraySum(vector\u0026lt;int\u0026gt;\u0026amp; nums, int k) { 2 // map记录前几个数字之和为K出现相同和的次数为V 3 unordered_map\u0026lt;int, int\u0026gt; mp; 4 // 初始化 5 mp[0] = 1; 6 // hash 7 // 记录合适的连续字符串数量 8 int count = 0; 9\t// 记录前面数字相加之和 10 int pre = 0; 11 for (auto\u0026amp; x:nums) { 12 pre += x; 13 / 前缀和 14 // 设 15 // pre[i]=pre[i−1]+nums[i] 16 // 由于补上了0，1这个情况 问题由多少个连续数字之和等于k 转为 17 // pre[i]−pre[j−1]==k （前缀和之差为k，代表这两个前缀和中间的数字相加就是K） 18 // 如果前面某些数字之和加上这个数字正好等于K（存在一个数字加上nums[i]结果为K 19 // 说明找到了 20 if (mp.find(pre - k) != mp.end()) { 21 // 累计 22 count += mp[pre - k]; 23 } 24 // 计算新的和放入map 25 mp[pre]++; 26 } 27 return count; 28 } 二维前缀和 类似一维前缀和，二维前缀和就是对于一个二维数组num[m][n]，前缀和数组sum[i][j]表示如下图红色所示的区域的之和。\n二维前缀和求矩阵元素和 我们首先推出来如何求矩阵元素和，再求二维前缀和怎么构造。\n一维前缀和你可以用来O(1)求某个点的值 那么类比一下 二维前缀和也是可以用来求某个矩阵的值的\n但是怎么来求呢？\n就如图中 知道了两个点的位置和他们的二维前缀和 图中红色是左上角的那个点的二维前缀和 红色+黄色部分是右下角的那个点的二维前缀和 是不是可以用这个来求出他们之间的矩阵的和呢？ 也就是这一部分：\nD点表示的二维前缀和值是红色部分+两个黄色部分+黑色部分\nA点表示的是红色部分\nB点表示的是上面的黄色部分+红色部分\nC点表示的是下面的黄色部分+红色部分\n这样是不是发现有什么神奇的东西快要出现了 这里面只有D的前缀和里面包括黑色部分 只要减去D里面的哪两个黄色部分和红色部分是不是就剩下了我们要求的黑色部分了？ 那怎么减去呢？ 可以这样： D - B - C + A 这就是二维前缀和最重要的部分了 化成二维数组的形式就是这样的\n$$ans = sum[x2][y2] - sum[x1-1][y2]-sum[x2][y1-1]+sum[x1-1][y1-1]$$\n构造sum 这个可以类比上面求矩阵的思想 只是这个矩阵的右下角是（i，j），左上角也是（i,j） 就是一个1X1的矩阵 所以也是很好求的 但是上面是已知D，A，B，C求黑色部分 这里你只知道A，B，C和黑色部分 因为是一个1X1的矩阵吗 所以黑色部分就只有一个元素也就是（i，j）坐标上的那个元素值 所以就可以个加法变减法，减法变加法一个性质的 通过A，B，C和黑色部分来求出D\n1D点表示的二维前缀和值是红色部分+两个黄色部分+黑色部分 2A点表示的是红色部分 3B点表示的是上面的黄色部分+红色部分 4C点表示的是下面的黄色部分+红色部分 所以D就可以等于B+C-D+黑色部分： 上面的黄色部分+红色部分+下面的黄色部分+红色部分-红色部分+黑色部分 =上面的黄色部分+红色部分+下面的黄色部分+黑色部分 刚好等于D 方程式为\n$$sum[i][j]=sum[i-1][j]+sum[i][j-1]-sum[i-1][sum[j-1]]+num[i][j]$$\n例子 304. 二维区域和检索 - 矩阵不可变 - 力扣（LeetCode） (leetcode-cn.com)\n给定一个二维矩阵 matrix，以下类型的多个请求：\n计算其子矩形范围内元素的总和，该子矩阵的 左上角 为 (row1, col1) ，右下角 为 (row2, col2) 。 实现 NumMatrix 类：\nNumMatrix(int[][] matrix) 给定整数矩阵 matrix 进行初始化 int sumRegion(int row1, int col1, int row2, int col2) 返回 左上角 (row1, col1) 、右下角 (row2, col2) 所描述的子矩阵的元素 总和 。 示例 1：\n1输入: 2[\u0026#34;NumMatrix\u0026#34;,\u0026#34;sumRegion\u0026#34;,\u0026#34;sumRegion\u0026#34;,\u0026#34;sumRegion\u0026#34;] 3[[[[3,0,1,4,2],[5,6,3,2,1],[1,2,0,1,5],[4,1,0,1,7],[1,0,3,0,5]]],[2,1,4,3],[1,1,2,2],[1,2,2,4]] 4输出: 5[null, 8, 11, 12] 6 7解释: 8NumMatrix numMatrix = new NumMatrix([[3,0,1,4,2],[5,6,3,2,1],[1,2,0,1,5],[4,1,0,1,7],[1,0,3,0,5]]); 9numMatrix.sumRegion(2, 1, 4, 3); // return 8 (红色矩形框的元素总和) 10numMatrix.sumRegion(1, 1, 2, 2); // return 11 (绿色矩形框的元素总和) 11numMatrix.sumRegion(1, 2, 2, 4); // return 12 (蓝色矩形框的元素总和) 代码\n直接套模板就行\n1vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; sum; 2NumMatrix(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; \u0026amp;matrix) { 3 sum = vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(matrix.size() + 2, vector\u0026lt;int\u0026gt;(matrix[0].size() + 2, 0)); 4 for (int i = 1; i \u0026lt;= matrix.size(); i++) { 5 for (int j = 1; j \u0026lt;= matrix[0].size(); j++) { 6 sum[i][j] = sum[i - 1][j] + sum[i][j - 1] - sum[i - 1][j - 1] + matrix[i - 1][j - 1]; 7 } 8 } 9} 10int sumRegion(int row1, int col1, int row2, int col2) { 11 return sum[row2 + 1][col2 + 1] - sum[row1][col2 + 1] - sum[row2 + 1][col1] + sum[row1 ][col1]; 12} ","date":"2022-01-29","img":"","permalink":"/posts/b19a7723/","series":null,"tags":["算法","前缀和"],"title":"前缀和学习记录"},{"categories":[["k8s"],["教程"]],"content":"学习k8s的记录\n1. Kubernetes介绍 1.1 应用部署方式演变 在部署应用程序的方式上，主要经历了三个时代：\n传统部署：互联网早期，会直接将应用程序部署在物理机上\n优点：简单，不需要其它技术的参与\n缺点：不能为应用程序定义资源使用边界，很难合理地分配计算资源，而且程序之间容易产生影响\n虚拟化部署：可以在一台物理机上运行多个虚拟机，每个虚拟机都是独立的一个环境\n优点：程序环境不会相互产生影响，提供了一定程度的安全性\n缺点：增加了操作系统，浪费了部分资源\n容器化部署：与虚拟化类似，但是共享了操作系统\n优点：\n可以保证每个容器拥有自己的文件系统、CPU、内存、进程空间等\n运行应用程序所需要的资源都被容器包装，并和底层基础架构解耦\n容器化的应用程序可以跨云服务商、跨Linux操作系统发行版进行部署\n容器化部署方式给带来很多的便利，但是也会出现一些问题，比如说：\n一个容器故障停机了，怎么样让另外一个容器立刻启动去替补停机的容器 当并发访问量变大的时候，怎么样做到横向扩展容器数量 这些容器管理的问题统称为容器编排问题，为了解决这些容器编排问题，就产生了一些容器编排的软件：\nSwarm：Docker自己的容器编排工具 Mesos：Apache的一个资源统一管控的工具，需要和Marathon结合使用 Kubernetes：Google开源的的容器编排工具 1.2 kubernetes简介 kubernetes，是一个全新的基于容器技术的分布式架构领先方案，是谷歌严格保密十几年的秘密武器\u0026mdash;-Borg系统的一个开源版本，于2014年9月发布第一个版本，2015年7月发布第一个正式版本。\nkubernetes的本质是一组服务器集群，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理。目的是实现资源管理的自动化，主要提供了如下的主要功能：\n自我修复：一旦某一个容器崩溃，能够在1秒中左右迅速启动新的容器 弹性伸缩：可以根据需要，自动对集群中正在运行的容器数量进行调整 服务发现：服务可以通过自动发现的形式找到它所依赖的服务 负载均衡：如果一个服务起动了多个容器，能够自动实现请求的负载均衡 版本回退：如果发现新发布的程序版本有问题，可以立即回退到原来的版本 存储编排：可以根据容器自身的需求自动创建存储卷 1.3 kubernetes组件 一个kubernetes集群主要是由控制节点(master)、**工作节点(node)**构成，每个节点上都会安装不同的组件。\nmaster：集群的控制平面，负责集群的决策 ( 管理 )\nApiServer : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制\nScheduler : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上\nControllerManager : 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等\nEtcd ：负责存储集群中各种资源对象的信息\nnode：集群的数据平面，负责为容器提供运行环境 ( 干活 )\nKubelet : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器\nKubeProxy : 负责提供集群内部的服务发现和负载均衡\nDocker : 负责节点上容器的各种操作\n下面，以部署一个nginx服务来说明kubernetes系统各个组件调用关系：\n首先要明确，一旦kubernetes环境启动之后，master和node都会将自身的信息存储到etcd数据库中\n一个nginx服务的安装请求会首先被发送到master节点的apiServer组件\napiServer组件会调用scheduler组件来决定到底应该把这个服务安装到哪个node节点上\n在此时，它会从etcd中读取各个node节点的信息，然后按照一定的算法进行选择，并将结果告知apiServer\napiServer调用controller-manager去调度Node节点安装nginx服务\nkubelet接收到指令后，会通知docker，然后由docker来启动一个nginx的pod\npod是kubernetes的最小操作单元，容器必须跑在pod中至此，\n一个nginx服务就运行了，如果需要访问nginx，就需要通过kube-proxy来对pod产生访问的代理\n这样，外界用户就可以访问集群中的nginx服务了\n1.4 kubernetes概念 Master：集群控制节点，每个集群需要至少一个master节点负责集群的管控\nNode：工作负载节点，由master分配容器到这些node工作节点上，然后node节点上的docker负责容器的运行\nPod：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器\nController：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等\nService：pod对外服务的统一入口，下面可以维护者同一类的多个pod\nLabel：标签，用于对pod进行分类，同一类pod会拥有相同的标签\nNameSpace：命名空间，用来隔离pod的运行环境\n2. kubernetes集群环境搭建 2.1 前置知识点 目前生产部署Kubernetes 集群主要有两种方式：\nkubeadm\nKubeadm 是一个K8s 部署工具，提供kubeadm init 和kubeadm join，用于快速部署Kubernetes 集群。\n官方地址：https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/\n二进制包\n从github 下载发行版的二进制包，手动部署每个组件，组成Kubernetes 集群。\nKubeadm 降低部署门槛，但屏蔽了很多细节，遇到问题很难排查。如果想更容易可控，推荐使用二进制包部署Kubernetes 集群，虽然手动部署麻烦点，期间可以学习很多工作原理，也利于后期维护。\n2.2 kubeadm 部署方式介绍 kubeadm 是官方社区推出的一个用于快速部署kubernetes 集群的工具，这个工具能通过两条指令完成一个kubernetes 集群的部署：\n创建一个Master 节点kubeadm init 将Node 节点加入到当前集群中$ kubeadm join \u0026lt;Master 节点的IP 和端口\u0026gt; 2.3 安装要求 在开始之前，部署Kubernetes 集群机器需要满足以下几个条件：\n一台或多台机器，操作系统CentOS8.x-86_x64 硬件配置：2GB 或更多RAM，2 个CPU 或更多CPU，硬盘30GB 或更多 集群中所有机器之间网络互通 可以访问外网，需要拉取镜像 禁止swap 分区 2.4 最终目标 在所有节点上安装Docker 和kubeadm 部署Kubernetes Master 部署容器网络插件 部署Kubernetes Node，将节点加入Kubernetes 集群中 部署Dashboard Web 页面，可视化查看Kubernetes 资源 2.5 准备环境 角色 IP地址 组件 master01 192.168.211.100 docker，kubectl，kubeadm，kubelet node01 192.168.211.101 docker，kubectl，kubeadm，kubelet node02 192.168.211.102 docker，kubectl，kubeadm，kubelet 2.6 环境初始化 在2.6中除特殊说明都是在所有服务器中进行配置\n2.6.1 检查操作系统的版本 1# 此方式下安装kubernetes集群要求Centos版本要在7.5或之上 2[root@master ~]# cat /etc/redhat-release 3CentOS Linux release 8.5.2111 2.6.2 主机名解析 为了方便集群节点间的直接调用，在这个配置一下主机名解析，企业中推荐使用内部DNS服务器\n1# 主机名成解析 编辑三台服务器的/etc/hosts文件，添加下面内容 2192.168.221.100 master 3192.168.221.106 node1 4192.168.221.107 node2 2.6.3 时间同步 kubernetes要求集群中的节点时间必须精确一直，这里使用chronyd服务从网络同步时间\n企业中建议配置内部的会见同步服务器\n1# 启动chronyd服务 2[root@master ~]# systemctl start chronyd 3[root@master ~]# systemctl enable chronyd 4[root@master ~]# date 2.6.4 禁用iptable和firewalld服务 kubernetes和docker 在运行的中会产生大量的iptables规则，为了不让系统规则跟它们混淆，直接关闭系统的规则\n1# 1 关闭firewalld服务 2[root@master ~]# systemctl stop firewalld 3[root@master ~]# systemctl disable firewalld 4# 2 关闭iptables服务 5[root@master ~]# systemctl stop iptables 6[root@master ~]# systemctl disable iptables 2.6.5 禁用selinux selinux是linux系统下的一个安全服务，如果不关闭它，在安装集群中会产生各种各样的奇葩问题\n1# 编辑 /etc/selinux/config 文件，修改SELINUX的值为disable 2# 注意修改完毕之后需要重启linux服务 3SELINUX=disabled 2.6.6 禁用swap分区 swap分区指的是虚拟内存分区，它的作用是物理内存使用完，之后将磁盘空间虚拟成内存来使用，启用swap设备会对系统的性能产生非常负面的影响，因此kubernetes要求每个节点都要禁用swap设备，但是如果因为某些原因确实不能关闭swap分区，就需要在集群安装过程中通过明确的参数进行配置说明\n1# 编辑分区配置文件/etc/fstab，注释掉swap分区一行 2# 注意修改完毕之后需要重启linux服务 3vim /etc/fstab 4注释掉 /dev/mapper/centos-swap swap 5# /dev/mapper/centos-swap swap 2.6.7 修改linux的内核参数 1# 修改linux的内核采纳数，添加网桥过滤和地址转发功能 2# 编辑/etc/sysctl.d/kubernetes.conf文件，添加如下配置： 3net.bridge.bridge-nf-call-ip6tables = 1 4net.bridge.bridge-nf-call-iptables = 1 5net.ipv4.ip_forward = 1 6 7# 重新加载配置 8[root@master ~]# sysctl -p 9# 加载网桥过滤模块 10[root@master ~]# modprobe br_netfilter 11# 查看网桥过滤模块是否加载成功 12[root@master ~]# lsmod | grep br_netfilter 2.6.8 配置ipvs功能 在Kubernetes中Service有两种带来模型，一种是基于iptables的，一种是基于ipvs的两者比较的话，ipvs的性能明显要高一些，但是如果要使用它，需要手动载入ipvs模块\n1# 1.安装ipset和ipvsadm 2[root@master ~]# yum install ipset ipvsadm -y 3# 2.添加需要加载的模块写入脚本文件 4[root@master ~]# cat \u0026lt;\u0026lt;EOF\u0026gt; /etc/sysconfig/modules/ipvs.modules 5#!/bin/bash 6modprobe -- ip_vs 7modprobe -- ip_vs_rr 8modprobe -- ip_vs_wrr 9modprobe -- ip_vs_sh 10modprobe -- nf_conntrack 11EOF 12# 3.为脚本添加执行权限 13[root@master ~]# chmod +x /etc/sysconfig/modules/ipvs.modules 14# 4.执行脚本文件 15[root@master ~]# /bin/bash /etc/sysconfig/modules/ipvs.modules 16# 5.查看对应的模块是否加载成功 17[root@master ~]# lsmod | grep -e ip_vs -e nf_conntrack 2.6.9 安装docker 1# 1、切换镜像源 2[root@master ~]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo 3 4# 2、查看当前镜像源中支持的docker版本 5[root@master ~]# yum list docker-ce --showduplicates 6 7# 3、安装docker-ce 8[root@master ~]# sudo yum install docker-ce docker-ce-cli containerd.io --allowerasing 9 10# 4、添加一个配置文件 11#Docker 在默认情况下使用Vgroup Driver为cgroupfs，而Kubernetes推荐使用systemd来替代cgroupfs 12[root@master ~]# mkdir /etc/docker 13[root@master ~]# cat \u0026lt;\u0026lt;EOF\u0026gt; /etc/docker/daemon.json 14{ 15\t\u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], 16\t\u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://kn0t2bca.mirror.aliyuncs.com\u0026#34;] 17} 18EOF 19 20# 5、启动dokcer 21[root@master ~]# systemctl restart docker 22[root@master ~]# systemctl enable docker 2.6.10 安装Kubernetes组件 1# 1、由于kubernetes的镜像在国外，速度比较慢，这里切换成国内的镜像源 2# 2、编辑/etc/yum.repos.d/kubernetes.repo,添加下面的配置 3[kubernetes] 4name=Kubernetes 5baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 6enabled=1 7gpgchech=0 8repo_gpgcheck=0 9gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg 10\thttp://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg 11 12# 3、安装kubeadm、kubelet和kubectl 13[root@master ~]# yum install --setopt=obsoletes=0 kubeadm-1.17.4-0 kubelet-1.17.4-0 kubectl-1.17.4-0 -y 14 15# 4、配置kubelet的cgroup 16#编辑/etc/sysconfig/kubelet, 添加下面的配置 17KUBELET_CGROUP_ARGS=\u0026#34;--cgroup-driver=systemd\u0026#34; 18KUBE_PROXY_MODE=\u0026#34;ipvs\u0026#34; 19 20# 5、设置kubelet开机自启 21[root@master ~]# systemctl enable kubelet 2.6.11 准备集群镜像 1# 在安装kubernetes集群之前，必须要提前准备好集群需要的镜像，所需镜像可以通过下面命令查看 2[root@master ~]# kubeadm config images list 3 4# 以下步骤可以省略 5# 下载镜像 6# 此镜像kubernetes的仓库中，由于网络原因，无法连接，下面提供了一种替换方案 7images=( 8\tk8s.gcr.io/kube-apiserver:v1.23.3 9\tk8s.gcr.io/kube-controller-manager:v1.23.3 10\tk8s.gcr.io/kube-scheduler:v1.23.3 11\tk8s.gcr.io/kube-proxy:v1.23.3 12\tk8s.gcr.io/pause:3.6 13\tk8s.gcr.io/etcd:3.5.1-0 14\tk8s.gcr.io/coredns/coredns:v1.8.6 15) 16 17for imageName in ${images[@]};do 18\tdocker pull gotok8s/$imageName 19\tdocker tag gotok8s/$imageName k8s.gcr.io/$imageName 20\tdocker rmi gotok8s/$imageName 21done 2.6.12 集群初始化 下面的操作只需要在master节点上执行即可\n1# 创建集群 2[root@master ~]# kubeadm init \\ 3\t--apiserver-advertise-address=192.168.221.100 \\ 4\t--image-repository registry.aliyuncs.com/google_containers \\ 5\t--kubernetes-version=v1.23.3 \\ 6\t--service-cidr=10.96.0.0/12 \\ 7\t--pod-network-cidr=10.244.0.0/16 8# 创建必要文件 9[root@master ~]# mkdir -p $HOME/.kube 10[root@master ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config 11[root@master ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config apiserver-advertise-address 是master的ip\nkubernetes-version=v1.23.3 是2.6.11步骤中的k8s.gcr.io/kube-apiserver的版本号\n\u0026ndash;service-cidr=10.96.0.0/12 \\ \u0026ndash;pod-network-cidr=10.244.0.0/16 在后续介绍\n下面的操作只需要在node节点上执行即可\n1kubeadm join 192.168.0.100:6443 --token awk15p.t6bamck54w69u4s8 \\ 2 --discovery-token-ca-cert-hash sha256:a94fa09562466d32d29523ab6cff122186f1127599fa4dcd5fa0152694f17117 在master上查看节点信息\n1[root@master ~]# kubectl get nodes 2NAME STATUS ROLES AGE VERSION 3master NotReady master 6m v1.17.4 4node1 NotReady \u0026lt;none\u0026gt; 22s v1.17.4 5node2 NotReady \u0026lt;none\u0026gt; 19s v1.17.4 2.6.13 安装网络插件，只在master节点操作即可 1wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 2kubectl apply -f kube-flannel.yml 由于外网不好访问，如果出现无法访问的情况，可以直接用下面的 记得文件名是kube-flannel.yml，位置：/root/kube-flannel.yml内容：\n1https://github.com/flannel-io/flannel/tree/master/Documentation/kube-flannel.yml 2.6.14 使用kubeadm reset重置集群 1#在master节点之外的节点进行操作 2kubeadm reset 3systemctl stop kubelet 4systemctl stop docker 5rm -rf /var/lib/cni/ 6rm -rf /var/lib/kubelet/* 7rm -rf /etc/cni/ 8ifconfig cni0 down 9ifconfig flannel.1 down 10ifconfig docker0 down 11ip link delete cni0 12ip link delete flannel.1 13##重启kubelet 14systemctl restart kubelet 15##重启docker 16systemctl restart docker 2.6.15 重启kubelet和docker 1# 重启kubelet 2systemctl restart kubelet 3# 重启docker 4systemctl restart docker 使用配置文件启动fannel\n1kubectl apply -f kube-flannel.yml 等待它安装完毕 发现已经是 集群的状态已经是Ready\n2.6.16 kubeadm中的命令 1# 生成 新的token 2[root@master ~]# kubeadm token create --print-join-command 2.7 集群测试 在master中\n2.7.1 创建一个nginx服务 1kubectl create deployment nginx --image=nginx 2.7.2 暴露端口 1kubectl expose deploy nginx --port=80 --target-port=80 --type=NodePort 2.7.3 查看服务 1kubectl get pod,svc 2.7.4 查看pod 浏览器测试结果：\n3. 资源管理 3.1 资源管理介绍 在kubernetes中，所有的内容都抽象为资源，用户需要通过操作资源来管理kubernetes。\nkubernetes的本质上就是一个集群系统，用户可以在集群中部署各种服务，所谓的部署服务，其实就是在kubernetes集群中运行一个个的容器，并将指定的程序跑在容器中。\nkubernetes的最小管理单元是pod而不是容器，所以只能将容器放在Pod中，而kubernetes一般也不会直接管理Pod，而是通过Pod控制器来管理Pod的。\nPod可以提供服务之后，就要考虑如何访问Pod中服务，kubernetes提供了Service资源实现这个功能。\n当然，如果Pod中程序的数据需要持久化，kubernetes还提供了各种存储系统。\nkubernetes的核心，就是学习如何对集群上的Pod、Pod控制器、Service、存储等各种资源进行操作\n3.2 YAML语言介绍 YAML是一个类似 XML、JSON 的标记性语言。它强调以数据为中心，并不是以标识语言为重点。因而YAML本身的定义比较简单，号称\u0026quot;一种人性化的数据格式语言\u0026quot;。\n1jimyag: 2 age: 6 3 address: shanghai YAML的语法比较简单，主要有下面几个：\n大小写敏感 使用缩进表示层级关系 缩进不允许使用tab，只允许空格( 低版本限制 ) 缩进的空格数不重要，只要相同层级的元素左对齐即可 \u0026lsquo;#\u0026lsquo;表示注释 YAML支持以下几种数据类型：\n纯量：单个的、不可再分的值 对象：键值对的集合，又称为映射（mapping）/ 哈希（hash） / 字典（dictionary） 数组：一组按次序排列的值，又称为序列（sequence） / 列表（list） 1# 纯量, 就是指的一个简单的值，字符串、布尔值、整数、浮点数、Null、时间、日期 2# 1 布尔类型 3c1: true (或者True) 4# 2 整型 5c2: 234 6# 3 浮点型 7c3: 3.14 8# 4 null类型 9c4: ~ # 使用~表示null 10# 5 日期类型 11c5: 2018-02-17 # 日期必须使用ISO 8601格式，即yyyy-MM-dd 12# 6 时间类型 13c6: 2018-02-17T15:02:31+08:00 # 时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表时区 14# 7 字符串类型 15c7: heima # 简单写法，直接写值 , 如果字符串中间有特殊字符，必须使用双引号或者单引号包裹 16c8: line1 17 line2 # 字符串过多的情况可以拆成多行，每一行会被转化成一个空格 1# 对象 2# 形式一(推荐): 3heima: 4 age: 15 5 address: Beijing 6# 形式二(了解): 7heima: {age: 15,address: Beijing} 1# 数组 2# 形式一(推荐): 3address: 4 - 浦东 5 - 崇明 6# 形式二(了解): 7address: [浦东,崇明] 小提示：\n1 书写yaml切记: 后面要加一个空格\n2 如果需要将多段yaml配置放在一个文件中，中间要使用---分隔\n3 下面是一个yaml转json的网站，可以通过它验证yaml是否书写正确\nhttps://www.json2yaml.com/convert-yaml-to-json\n3.3 资源管理方式 命令式对象管理：直接使用命令去操作kubernetes资源\n1kubectl run nginx-pod --image=nginx --port=80 命令式对象配置：通过命令配置和配置文件去操作kubernetes资源\n1kubectl create/patch -f nginx-pod.yaml 声明式对象配置：通过apply命令和配置文件去操作kubernetes资源\n1kubectl apply -f nginx-pod.yaml 类型 操作对象 适用环境 优点 缺点 命令式对象管理 对象 测试 简单 只能操作活动对象，无法审计、跟踪 命令式对象配置 文件 开发 可以审计、跟踪 项目大时，配置文件多，操作麻烦 声明式对象配置 目录 开发 支持目录操作 意外情况下难以调试 3.3.1 命令式对象管理 kubectl命令\nkubectl是kubernetes集群的命令行工具，通过它能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署。kubectl命令的语法如下：\n1kubectl [command] [type] [name] [flags] comand：指定要对资源执行的操作，例如create、get、delete\ntype：指定资源类型，比如deployment、pod、service\nname：指定资源的名称，名称大小写敏感\nflags：指定额外的可选参数\n1# 查看所有pod 2kubectl get pod 3 4# 查看某个pod 5kubectl get pod pod_name 6 7# 查看某个pod,以yaml格式展示结果 8kubectl get pod pod_name -o yaml 资源类型\nkubernetes中所有的内容都抽象为资源，可以通过下面的命令进行查看:\n1kubectl api-resources 经常使用的资源有下面这些：\n资源分类 资源名称 缩写 资源作用 集群级别资源 nodes no 集群组成部分 namespaces ns 隔离Pod pod资源 pods po 装载容器 pod资源控制器 replicationcontrollers rc 控制pod资源 replicasets rs 控制pod资源 deployments deploy 控制pod资源 daemonsets ds 控制pod资源 jobs 控制pod资源 cronjobs cj 控制pod资源 horizontalpodautoscalers hpa 控制pod资源 statefulsets sts 控制pod资源 服务发现资源 services svc 统一pod对外接口 ingress ing 统一pod对外接口 存储资源 volumeattachments 存储 persistentvolumes pv 存储 persistentvolumeclaims pvc 存储 配置资源 configmaps cm 配置 secrets 配置 操作\nkubernetes允许对资源进行多种操作，可以通过\u0026ndash;help查看详细的操作命令\n1kubectl --help 经常使用的操作有下面这些：\n命令分类 命令 翻译 命令作用 基本命令 create 创建 创建一个资源 edit 编辑 编辑一个资源 get 获取 获取一个资源 patch 更新 更新一个资源 delete 删除 删除一个资源 explain 解释 展示资源文档 运行和调试 run 运行 在集群中运行一个指定的镜像 expose 暴露 暴露资源为Service describe 描述 显示资源内部信息 logs 日志输出容器在 pod 中的日志 输出容器在 pod 中的日志 attach 缠绕进入运行中的容器 进入运行中的容器 exec 执行容器中的一个命令 执行容器中的一个命令 cp 复制 在Pod内外复制文件 rollout 首次展示 管理资源的发布 scale 规模 扩(缩)容Pod的数量 autoscale 自动调整 自动调整Pod的数量 高级命令 apply rc 通过文件对资源进行配置 label 标签 更新资源上的标签 其他命令 cluster-info 集群信息 显示集群信息 version 版本 显示当前Server和Client的版本 下面以一个namespace / pod的创建和删除简单演示下命令的使用：\n1# 创建一个namespace 2[root@master ~]# kubectl create namespace dev 3namespace/dev created 4 5# 获取namespace 6[root@master ~]# kubectl get ns 7NAME STATUS AGE 8default Active 21h 9dev Active 21s 10kube-node-lease Active 21h 11kube-public Active 21h 12kube-system Active 21h 13 14# 在此namespace下创建并运行一个nginx的Pod 15[root@master ~]# kubectl run pod --image=nginx:latest -n dev 16kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. 17deployment.apps/pod created 18 19# 查看新创建的pod 20[root@master ~]# kubectl get pod -n dev 21NAME READY STATUS RESTARTS AGE 22pod 1/1 Running 0 21s 23 24# 删除指定的pod 25[root@master ~]# kubectl delete pod pod-864f9875b9-pcw7x 26pod \u0026#34;pod\u0026#34; deleted 27 28# 删除指定的namespace 29[root@master ~]# kubectl delete ns dev 30namespace \u0026#34;dev\u0026#34; deleted 3.3.2 命令式对象配置 命令式对象配置就是使用命令配合配置文件一起来操作kubernetes资源。\n1） 创建一个nginxpod.yaml，内容如下：\n1apiVersion: v1 2kind: Namespace 3metadata: 4 name: dev 5 6--- 7 8apiVersion: v1 9kind: Pod 10metadata: 11 name: nginxpod 12 namespace: dev 13spec: 14 containers: 15 - name: nginx-containers 16 image: nginx:latest 2）执行create命令，创建资源：\n1[root@master ~]# kubectl create -f nginxpod.yaml 2namespace/dev created 3pod/nginxpod created 此时发现创建了两个资源对象，分别是namespace和pod\n3）执行get命令，查看资源：\n1[root@master ~]# kubectl get -f nginxpod.yaml 2NAME STATUS AGE 3namespace/dev Active 18s 4 5NAME READY STATUS RESTARTS AGE 6pod/nginxpod 1/1 Running 0 17s 这样就显示了两个资源对象的信息\n4）执行delete命令，删除资源：\n1[root@master ~]# kubectl delete -f nginxpod.yaml 2namespace \u0026#34;dev\u0026#34; deleted 3pod \u0026#34;nginxpod\u0026#34; deleted 此时发现两个资源对象被删除了\n1总结: 2 命令式对象配置的方式操作资源，可以简单的认为：命令 + yaml配置文件（里面是命令需要的各种参数） 3.3.3 声明式对象配置 声明式对象配置跟命令式对象配置很相似，但是它只有一个命令apply。\n1# 首先执行一次kubectl apply -f yaml文件，发现创建了资源 2[root@master ~]# kubectl apply -f nginxpod.yaml 3namespace/dev created 4pod/nginxpod created 5 6# 再次执行一次kubectl apply -f yaml文件，发现说资源没有变动 7[root@master ~]# kubectl apply -f nginxpod.yaml 8namespace/dev unchanged 9pod/nginxpod unchanged 1总结: 2 其实声明式对象配置就是使用apply描述一个资源最终的状态（在yaml中定义状态） 3 使用apply操作资源： 4 如果资源不存在，就创建，相当于 kubectl create 5 如果资源已存在，就更新，相当于 kubectl patch 扩展：kubectl可以在node节点上运行吗 ?\nkubectl的运行是需要进行配置的，它的配置文件是$HOME/.kube，如果想要在node节点运行此命令，需要将master上的.kube文件复制到node节点上，即在master节点上执行下面操作：\n1scp -r ~/.kube node1:~/ 使用推荐: 三种方式应该怎么用 ?\n创建/更新资源 使用声明式对象配置 kubectl apply -f XXX.yaml\n删除资源 使用命令式对象配置 kubectl delete -f XXX.yaml\n查询资源 使用命令式对象管理 kubectl get(describe) 资源名称\n4. 实战入门 本章节将介绍如何在kubernetes集群中部署一个nginx服务，并且能够对其进行访问。\n4.1 Namespace Namespace是kubernetes系统中的一种非常重要资源，它的主要作用是用来实现多套环境的资源隔离或者多租户的资源隔离。\n默认情况下，kubernetes集群中的所有的Pod都是可以相互访问的。但是在实际中，可能不想让两个Pod之间进行互相的访问，那此时就可以将两个Pod划分到不同的namespace下。kubernetes通过将集群内部的资源分配到不同的Namespace中，可以形成逻辑上的\u0026quot;组\u0026quot;，以方便不同的组的资源进行隔离使用和管理。\n可以通过kubernetes的授权机制，将不同的namespace交给不同租户进行管理，这样就实现了多租户的资源隔离。此时还能结合kubernetes的资源配额机制，限定不同租户能占用的资源，例如CPU使用量、内存使用量等等，来实现租户可用资源的管理。\nkubernetes在集群启动之后，会默认创建几个namespace\n1[root@master ~]# kubectl get namespace 2NAME STATUS AGE 3default Active 45h # 所有未指定Namespace的对象都会被分配在default命名空间 4kube-node-lease Active 45h # 集群节点之间的心跳维护，v1.13开始引入 5kube-public Active 45h # 此命名空间下的资源可以被所有人访问（包括未认证用户） 6kube-system Active 45h # 所有由Kubernetes系统创建的资源都处于这个命名空间 下面来看namespace资源的具体操作：\n4.1.1 查看 1# 1 查看所有的ns 命令：kubectl get ns 2[root@master ~]# kubectl get ns 3NAME STATUS AGE 4default Active 45h 5kube-node-lease Active 45h 6kube-public Active 45h 7kube-system Active 45h 8 9# 2 查看指定的ns 命令：kubectl get ns ns名称 10[root@master ~]# kubectl get ns default 11NAME STATUS AGE 12default Active 45h 13 14# 3 指定输出格式 命令：kubectl get ns ns名称 -o 格式参数 15# kubernetes支持的格式有很多，比较常见的是wide、json、yaml 16[root@master ~]# kubectl get ns default -o yaml 17apiVersion: v1 18kind: Namespace 19metadata: 20 creationTimestamp: \u0026#34;2021-05-08T04:44:16Z\u0026#34; 21 name: default 22 resourceVersion: \u0026#34;151\u0026#34; 23 selfLink: /api/v1/namespaces/default 24 uid: 7405f73a-e486-43d4-9db6-145f1409f090 25spec: 26 finalizers: 27 - kubernetes 28status: 29 phase: Active 30 31# 4 查看ns详情 命令：kubectl describe ns ns名称 32[root@master ~]# kubectl describe ns default 33Name: default 34Labels: \u0026lt;none\u0026gt; 35Annotations: \u0026lt;none\u0026gt; 36Status: Active # Active 命名空间正在使用中 Terminating 正在删除命名空间 37 38# ResourceQuota 针对namespace做的资源限制 39# LimitRange针对namespace中的每个组件做的资源限制 40No resource quota. 41No LimitRange resource. 4.1.2 创建 1# 创建namespace 2[root@master ~]# kubectl create ns dev 3namespace/dev created 4.1.3 删除 1# 删除namespace 2[root@master ~]# kubectl delete ns dev 3namespace \u0026#34;dev\u0026#34; deleted 4.1.4 配置方式 首先准备一个yaml文件：ns-dev.yaml\n1apiVersion: v1 2kind: Namespace 3metadata: 4 name: dev 然后就可以执行对应的创建和删除命令了：\n创建：kubectl create -f ns-dev.yaml\n删除：kubectl delete -f ns-dev.yaml\n4.2 Pod Pod是kubernetes集群进行管理的最小单元，程序要运行必须部署在容器中，而容器必须存在于Pod中。\nPod可以认为是容器的封装，一个Pod中可以存在一个或者多个容器。\nkubernetes在集群启动之后，集群中的各个组件也都是以Pod方式运行的。可以通过下面命令查看：\n1[root@master ~]# kubectl get pod -n kube-system 2NAMESPACE NAME READY STATUS RESTARTS AGE 3kube-system coredns-6955765f44-68g6v 1/1 Running 0 2d1h 4kube-system coredns-6955765f44-cs5r8 1/1 Running 0 2d1h 5kube-system etcd-master 1/1 Running 0 2d1h 6kube-system kube-apiserver-master 1/1 Running 0 2d1h 7kube-system kube-controller-manager-master 1/1 Running 0 2d1h 8kube-system kube-flannel-ds-amd64-47r25 1/1 Running 0 2d1h 9kube-system kube-flannel-ds-amd64-ls5lh 1/1 Running 0 2d1h 10kube-system kube-proxy-685tk 1/1 Running 0 2d1h 11kube-system kube-proxy-87spt 1/1 Running 0 2d1h 12kube-system kube-scheduler-master 1/1 Running 0 2d1h 4.2.1 创建并运行 kubernetes没有提供单独运行Pod的命令，都是通过Pod控制器来实现的\n1# 命令格式： kubectl run (pod控制器名称) [参数] 2# --image 指定Pod的镜像 3# --port 指定端口 4# --namespace 指定namespace 5[root@master ~]# kubectl run nginx --image=nginx:latest --port=80 --namespace dev 4.2.2 查看pod信息 1# 查看Pod基本信息 2[root@master ~]# kubectl get pods -n dev 3NAME READY STATUS RESTARTS AGE 4nginx 1/1 Running 0 43s 5 6# 查看Pod的详细信息 7[root@master ~]# kubectl describe pod nginx -n dev 8Name: nginx 9Namespace: dev 10Priority: 0 11Node: node1/192.168.221.101 12Start Time: Wed, 08 May 2021 09:29:24 +0800 13Labels: pod-template-hash=5ff7956ff6 14 run=nginx 15Annotations: \u0026lt;none\u0026gt; 16Status: Running 17IP: 10.244.1.23 18IPs: 19 IP: 10.244.1.23 20Controlled By: ReplicaSet/nginx 21Containers: 22 nginx: 23 Container ID: docker://4c62b8c0648d2512380f4ffa5da2c99d16e05634979973449c98e9b829f6253c 24 Image: nginx:latest 25 Image ID: docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 26 Port: 80/TCP 27 Host Port: 0/TCP 28 State: Running 29 Started: Wed, 08 May 2021 09:30:01 +0800 30 Ready: True 31 Restart Count: 0 32 Environment: \u0026lt;none\u0026gt; 33 Mounts: 34 /var/run/secrets/kubernetes.io/serviceaccount from default-token-hwvvw (ro) 35Conditions: 36 Type Status 37 Initialized True 38 Ready True 39 ContainersReady True 40 PodScheduled True 41Volumes: 42 default-token-hwvvw: 43 Type: Secret (a volume populated by a Secret) 44 SecretName: default-token-hwvvw 45 Optional: false 46QoS Class: BestEffort 47Node-Selectors: \u0026lt;none\u0026gt; 48Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s 49 node.kubernetes.io/unreachable:NoExecute for 300s 50Events: 51 Type Reason Age From Message 52 ---- ------ ---- ---- ------- 53 Normal Scheduled \u0026lt;unknown\u0026gt; default-scheduler Successfully assigned dev/nginx-5ff7956ff6-fg2db to node1 54 Normal Pulling 4m11s kubelet, node1 Pulling image \u0026#34;nginx:latest\u0026#34; 55 Normal Pulled 3m36s kubelet, node1 Successfully pulled image \u0026#34;nginx:latest\u0026#34; 56 Normal Created 3m36s kubelet, node1 Created container nginx 57 Normal Started 3m36s kubelet, node1 Started container nginx 4.2.3 访问Pod 1# 获取podIP 2[root@master ~]# kubectl get pods -n dev -o wide 3NAME READY STATUS RESTARTS AGE IP NODE ... 4nginx 1/1 Running 0 190s 10.244.1.23 node1 ... 5 6#访问POD 7[root@master ~]# curl http://10.244.1.23:80 8\u0026lt;!DOCTYPE html\u0026gt; 9\u0026lt;html\u0026gt; 10\u0026lt;head\u0026gt; 11\t\u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; 12\u0026lt;/head\u0026gt; 13\u0026lt;body\u0026gt; 14\t\u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; 15\u0026lt;/body\u0026gt; 16\u0026lt;/html\u0026gt; 4.2.4 删除指定Pod 1# 删除指定Pod 2[root@master ~]# kubectl delete pod nginx -n dev 3pod \u0026#34;nginx\u0026#34; deleted 4 5# 此时，显示删除Pod成功，但是再查询，发现又新产生了一个 6[root@master ~]# kubectl get pods -n dev 7NAME READY STATUS RESTARTS AGE 8nginx 1/1 Running 0 21s 9 10# 这是因为当前Pod是由Pod控制器创建的，控制器会监控Pod状况，一旦发现Pod死亡，会立即重建 11# 此时要想删除Pod，必须删除Pod控制器 12 13# 先来查询一下当前namespace下的Pod控制器 14[root@master ~]# kubectl get deploy -n dev 15NAME READY UP-TO-DATE AVAILABLE AGE 16nginx 1/1 1 1 9m7s 17 18# 接下来，删除此PodPod控制器 19[root@master ~]# kubectl delete deploy nginx -n dev 20deployment.apps \u0026#34;nginx\u0026#34; deleted 21 22# 稍等片刻，再查询Pod，发现Pod被删除了 23[root@master ~]# kubectl get pods -n dev 24No resources found in dev namespace. 4.2.5 配置操作 创建一个pod-nginx.yaml，内容如下：\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: nginx 5 namespace: dev 6spec: 7 containers: 8 - image: nginx:latest 9 name: pod 10 ports: 11 - name: nginx-port 12 containerPort: 80 13 protocol: TCP 然后就可以执行对应的创建和删除命令了：\n创建：kubectl create -f pod-nginx.yaml\n删除：kubectl delete -f pod-nginx.yaml\n4.3 Label Label是kubernetes系统中的一个重要概念。它的作用就是在资源上添加标识，用来对它们进行区分和选择。\nLabel的特点：\n一个Label会以key/value键值对的形式附加到各种对象上，如Node、Pod、Service等等 一个资源对象可以定义任意数量的Label ，同一个Label也可以被添加到任意数量的资源对象上去 Label通常在资源对象定义时确定，当然也可以在对象创建后动态添加或者删除 可以通过Label实现资源的多维度分组，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作。\n一些常用的Label 示例如下：\n版本标签：\u0026ldquo;version\u0026rdquo;:\u0026ldquo;release\u0026rdquo;, \u0026ldquo;version\u0026rdquo;:\u0026ldquo;stable\u0026rdquo;\u0026hellip;\u0026hellip; 环境标签：\u0026ldquo;environment\u0026rdquo;:\u0026ldquo;dev\u0026rdquo;，\u0026ldquo;environment\u0026rdquo;:\u0026ldquo;test\u0026rdquo;，\u0026ldquo;environment\u0026rdquo;:\u0026ldquo;pro\u0026rdquo; 架构标签：\u0026ldquo;tier\u0026rdquo;:\u0026ldquo;frontend\u0026rdquo;，\u0026ldquo;tier\u0026rdquo;:\u0026ldquo;backend\u0026rdquo; 标签定义完毕之后，还要考虑到标签的选择，这就要使用到Label Selector，即：\nLabel用于给某个资源对象定义标识\nLabel Selector用于查询和筛选拥有某些标签的资源对象\n当前有两种Label Selector：\n基于等式的Label Selector\nname = slave: 选择所有包含Label中key=\u0026ldquo;name\u0026quot;且value=\u0026ldquo;slave\u0026quot;的对象\nenv != production: 选择所有包括Label中的key=\u0026ldquo;env\u0026quot;且value不等于\u0026quot;production\u0026quot;的对象\n基于集合的Label Selector\nname in (master, slave): 选择所有包含Label中的key=\u0026ldquo;name\u0026quot;且value=\u0026ldquo;master\u0026quot;或\u0026quot;slave\u0026quot;的对象\nname not in (frontend): 选择所有包含Label中的key=\u0026ldquo;name\u0026quot;且value不等于\u0026quot;frontend\u0026quot;的对象\n标签的选择条件可以使用多个，此时将多个Label Selector进行组合，使用逗号\u0026rdquo;,\u0026ldquo;进行分隔即可。例如：\nname=slave，env!=production\nname not in (frontend)，env!=production\n4.3.1 命令方式 1# 为pod资源打标签 2[root@master ~] kubectl label pod nginx-pod version=1.0 -n dev 3pod/nginx-pod labeled 4 5# 为pod资源更新标签 6[root@master ~] kubectl label pod nginx-pod version=2.0 -n dev --overwrite 7pod/nginx-pod labeled 8 9# 查看标签 10[root@master ~] kubectl get pod nginx-pod -n dev --show-labels 11NAME READY STATUS RESTARTS AGE LABELS 12nginx-pod 1/1 Running 0 10m version=2.0 13 14# 筛选标签 15[root@master ~] kubectl get pod -n dev -l version=2.0 --show-labels 16NAME READY STATUS RESTARTS AGE LABELS 17nginx-pod 1/1 Running 0 17m version=2.0 18[root@master ~] ubectl get pod -n dev -l version!=2.0 --show-labels 19No resources found in dev namespace. 20 21#删除标签 22[root@master ~]kubectl label pod nginx-pod version- -n dev 23pod/nginx-pod labeled 4.3.2 配置方式 1apiVersion: v1 2kind: Pod 3metadata: 4 name: nginx 5 namespace: dev 6 labels: 7 version: \u0026#34;3.0\u0026#34; 8 env: \u0026#34;test\u0026#34; 9spec: 10 containers: 11 - image: nginx:latest 12 name: pod 13 ports: 14 - name: nginx-port 15 containerPort: 80 16 protocol: TCP 然后就可以执行对应的更新命令了：kubectl apply -f pod-nginx.yaml\n4.4 Deployment 在kubernetes中，Pod是最小的控制单元，但是kubernetes很少直接控制Pod，一般都是通过Pod控制器来完成的。Pod控制器用于pod的管理，确保pod资源符合预期的状态，当pod的资源出现故障时，会尝试进行重启或重建pod。\n在kubernetes中Pod控制器的种类有很多，本章节只介绍一种：Deployment。\n4.4.1 命令操作 1# 命令格式: kubectl create deployment 名称 [参数] 2# --image 指定pod的镜像 3# --port 指定端口 4# --replicas 指定创建pod数量 5# --namespace 指定namespace 6[root@master ~]kubectl create deployment nginx --image=nginx:latest --port=80 --replicas=3 -n dev 7deployment.apps/nginx created 8 9# 查看创建的Pod 10[root@master ~]# kubectl get pods -n dev 11NAME READY STATUS RESTARTS AGE 12nginx-5ff7956ff6-6k8cb 1/1 Running 0 19s 13nginx-5ff7956ff6-jxfjt 1/1 Running 0 19s 14nginx-5ff7956ff6-v6jqw 1/1 Running 0 19s 15 16# 查看deployment的信息 17[root@master ~]# kubectl get deploy -n dev 18NAME READY UP-TO-DATE AVAILABLE AGE 19nginx 3/3 3 3 2m42s 20 21# UP-TO-DATE：成功升级的副本数量 22# AVAILABLE：可用副本的数量 23[root@master ~]# kubectl get deploy -n dev -o wide 24NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR 25nginx 3/3 3 3 2m51s nginx nginx:latest run=nginx 26 27# 查看deployment的详细信息 28[root@master ~]# kubectl describe deploy nginx -n dev 29Name: nginx 30Namespace: dev 31CreationTimestamp: Wed, 08 May 2021 11:14:14 +0800 32Labels: run=nginx 33Annotations: deployment.kubernetes.io/revision: 1 34Selector: run=nginx 35Replicas: 3 desired | 3 updated | 3 total | 3 available | 0 unavailable 36StrategyType: RollingUpdate 37MinReadySeconds: 0 38RollingUpdateStrategy: 25% max unavailable, 25% max surge 39Pod Template: 40 Labels: run=nginx 41 Containers: 42 nginx: 43 Image: nginx:latest 44 Port: 80/TCP 45 Host Port: 0/TCP 46 Environment: \u0026lt;none\u0026gt; 47 Mounts: \u0026lt;none\u0026gt; 48 Volumes: \u0026lt;none\u0026gt; 49Conditions: 50 Type Status Reason 51 ---- ------ ------ 52 Available True MinimumReplicasAvailable 53 Progressing True NewReplicaSetAvailable 54OldReplicaSets: \u0026lt;none\u0026gt; 55NewReplicaSet: nginx-5ff7956ff6 (3/3 replicas created) 56Events: 57 Type Reason Age From Message 58 ---- ------ ---- ---- ------- 59 Normal ScalingReplicaSet 5m43s deployment-controller Scaled up replicaset nginx-5ff7956ff6 to 3 60 61# 删除 62[root@master ~]# kubectl delete deploy nginx -n dev 63deployment.apps \u0026#34;nginx\u0026#34; deleted 4.4.2 配置操作 创建一个deploy-nginx.yaml，内容如下：\n1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: nginx 5 namespace: dev 6spec: 7 replicas: 3 8 selector: 9 matchLabels: 10 run: nginx 11 template: 12 metadata: 13 labels: 14 run: nginx 15 spec: 16 containers: 17 - image: nginx:latest 18 name: nginx 19 ports: 20 - containerPort: 80 21 protocol: TCP 然后就可以执行对应的创建和删除命令了：\n创建：kubectl create -f deploy-nginx.yaml\n删除：kubectl delete -f deploy-nginx.yaml\n4.5 Service 虽然每个Pod都会分配一个单独的Pod IP，然而却存在如下两问题：\nPod IP 会随着Pod的重建产生变化 Pod IP 仅仅是集群内可见的虚拟IP，外部无法访问 这样对于访问这个服务带来了难度。因此，kubernetes设计了Service来解决这个问题。\nService可以看作是一组同类Pod对外的访问接口。借助Service，应用可以方便地实现服务发现和负载均衡。\n4.5.1 创建集群内部可访问的Service 1# 暴露Service 2# --port 暴露到外部的端口 3# --target-port pod的端口 4[root@master ~] kubectl expose deploy nginx --name=svc-nginx1 --type=ClusterIP --port=80 --target-port=80 -n dev 5service/svc-nginx1 exposed 6 7# 查看service 8[root@master ~]kubectl get svc svc-nginx1 -n dev -o wide 9NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR 10svc-nginx1 ClusterIP 10.109.179.231 \u0026lt;none\u0026gt; 80/TCP 3m51s run=nginx 11 12# 这里产生了一个CLUSTER-IP，这就是service的IP，在Service的生命周期中，这个地址是不会变动的 13# 可以通过这个IP访问当前service对应的POD 14[root@master ~]curl 10.109.179.231:80 15\u0026lt;!DOCTYPE html\u0026gt; 16\u0026lt;html\u0026gt; 17\u0026lt;head\u0026gt; 18\u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; 19\u0026lt;/head\u0026gt; 20\u0026lt;body\u0026gt; 21\u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; 22....... 23\u0026lt;/body\u0026gt; 24\u0026lt;/html\u0026gt; 4.5.2 创建集群外部也可访问的Service 1# 上面创建的Service的type类型为ClusterIP，这个ip地址只用集群内部可访问 2# 如果需要创建外部也可以访问的Service，需要修改type为NodePort 3[root@master ~]kubectl expose deploy nginx --name=svc-nginx2 --type=NodePort --port=80 --target-port=80 -n dev 4service/svc-nginx2 exposed 5 6# 此时查看，会发现出现了NodePort类型的Service，而且有一对Port（80:31928/TC） 7[root@master ~]kubectl get svc svc-nginx2 -n dev -o wide 8NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR 9svc-nginx2 NodePort 10.100.94.0 \u0026lt;none\u0026gt; 80:31928/TCP 9s run=nginx 10 11# 接下来就可以通过集群外的主机访问 节点IP:31928访问服务了 12# 例如在的电脑主机上通过浏览器访问下面的地址 13http://192.168.90.100:31928/ 4.5.3 删除Service 1[root@master ~]# kubectl delete svc svc-nginx-1 -n dev 2service \u0026#34;svc-nginx-1\u0026#34; deleted 4.5.4 配置方式 创建一个svc-nginx.yaml，内容如下：\n1apiVersion: v1 2kind: Service 3metadata: 4 name: svc-nginx 5 namespace: dev 6spec: 7 clusterIP: 10.109.179.231 #固定svc的内网ip 8 ports: 9 - port: 80 10 protocol: TCP 11 targetPort: 80 12 selector: 13 run: nginx 14 type: ClusterIP 然后就可以执行对应的创建和删除命令了：\n创建：kubectl create -f svc-nginx.yaml\n删除：kubectl delete -f svc-nginx.yaml\n5. Pod详解 5.1 Pod介绍 5.1.1 Pod结构 每个Pod中都可以包含一个或者多个容器，这些容器可以分为两类：\n用户程序所在的容器，数量可多可少\nPause容器，这是每个Pod都会有的一个根容器，它的作用有两个：\n可以以它为依据，评估整个Pod的健康状态\n可以在根容器上设置Ip地址，其它容器都此Ip（Pod IP），以实现Pod内部的网路通信\n1这里是Pod内部的通讯，Pod的之间的通讯采用虚拟二层网络技术来实现，我们当前环境用的是Flannel 5.1.2 Pod定义 下面是Pod的资源清单：\n1apiVersion: v1 #必选，版本号，例如v1 2kind: Pod #必选，资源类型，例如 Pod 3metadata: #必选，元数据 4 name: string #必选，Pod名称 5 namespace: string #Pod所属的命名空间,默认为\u0026#34;default\u0026#34; 6 labels: #自定义标签列表 7 - name: string 8spec: #必选，Pod中容器的详细定义 9 containers: #必选，Pod中容器列表 10 - name: string #必选，容器名称 11 image: string #必选，容器的镜像名称 12 imagePullPolicy: [ Always|Never|IfNotPresent ] #获取镜像的策略 13 command: [string] #容器的启动命令列表，如不指定，使用打包时使用的启动命令 14 args: [string] #容器的启动命令参数列表 15 workingDir: string #容器的工作目录 16 volumeMounts: #挂载到容器内部的存储卷配置 17 - name: string #引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名 18 mountPath: string #存储卷在容器内mount的绝对路径，应少于512字符 19 readOnly: boolean #是否为只读模式 20 ports: #需要暴露的端口库号列表 21 - name: string #端口的名称 22 containerPort: int #容器需要监听的端口号 23 hostPort: int #容器所在主机需要监听的端口号，默认与Container相同 24 protocol: string #端口协议，支持TCP和UDP，默认TCP 25 env: #容器运行前需设置的环境变量列表 26 - name: string #环境变量名称 27 value: string #环境变量的值 28 resources: #资源限制和请求的设置 29 limits: #资源限制的设置 30 cpu: string #Cpu的限制，单位为core数，将用于docker run --cpu-shares参数 31 memory: string #内存限制，单位可以为Mib/Gib，将用于docker run --memory参数 32 requests: #资源请求的设置 33 cpu: string #Cpu请求，容器启动的初始可用数量 34 memory: string #内存请求,容器启动的初始可用数量 35 lifecycle: #生命周期钩子 36 postStart: #容器启动后立即执行此钩子,如果执行失败,会根据重启策略进行重启 37 preStop: #容器终止前执行此钩子,无论结果如何,容器都会终止 38 livenessProbe: #对Pod内各容器健康检查的设置，当探测无响应几次后将自动重启该容器 39 exec: #对Pod容器内检查方式设置为exec方式 40 command: [string] #exec方式需要制定的命令或脚本 41 httpGet: #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port 42 path: string 43 port: number 44 host: string 45 scheme: string 46 HttpHeaders: 47 - name: string 48 value: string 49 tcpSocket: #对Pod内个容器健康检查方式设置为tcpSocket方式 50 port: number 51 initialDelaySeconds: 0 #容器启动完成后首次探测的时间，单位为秒 52 timeoutSeconds: 0 #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒 53 periodSeconds: 0 #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次 54 successThreshold: 0 55 failureThreshold: 0 56 securityContext: 57 privileged: false 58 restartPolicy: [Always | Never | OnFailure] #Pod的重启策略 59 nodeName: \u0026lt;string\u0026gt; #设置NodeName表示将该Pod调度到指定到名称的node节点上 60 nodeSelector: obeject #设置NodeSelector表示将该Pod调度到包含这个label的node上 61 imagePullSecrets: #Pull镜像时使用的secret名称，以key：secretkey格式指定 62 - name: string 63 hostNetwork: false #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 64 volumes: #在该pod上定义共享存储卷列表 65 - name: string #共享存储卷名称 （volumes类型有很多种） 66 emptyDir: {} #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值 67 hostPath: string #类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 68 path: string #Pod所在宿主机的目录，将被用于同期中mount的目录 69 secret: #类型为secret的存储卷，挂载集群与定义的secret对象到容器内部 70 scretname: string 71 items: 72 - key: string 73 path: string 74 configMap: #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 75 name: string 76 items: 77 - key: string 78 path: string 1#小提示： 2# 在这里，可通过一个命令来查看每种资源的可配置项 3# kubectl explain 资源类型 查看某种资源可以配置的一级属性 4# kubectl explain 资源类型.属性 查看属性的子属性 5[root@k8s-master01 ~]# kubectl explain pod 6KIND: Pod 7VERSION: v1 8FIELDS: 9 apiVersion \u0026lt;string\u0026gt; 10 kind \u0026lt;string\u0026gt; 11 metadata \u0026lt;Object\u0026gt; 12 spec \u0026lt;Object\u0026gt; 13 status \u0026lt;Object\u0026gt; 14 15[root@k8s-master01 ~]# kubectl explain pod.metadata 16KIND: Pod 17VERSION: v1 18RESOURCE: metadata \u0026lt;Object\u0026gt; 19FIELDS: 20 annotations \u0026lt;map[string]string\u0026gt; 21 clusterName \u0026lt;string\u0026gt; 22 creationTimestamp \u0026lt;string\u0026gt; 23 deletionGracePeriodSeconds \u0026lt;integer\u0026gt; 24 deletionTimestamp \u0026lt;string\u0026gt; 25 finalizers \u0026lt;[]string\u0026gt; 26 generateName \u0026lt;string\u0026gt; 27 generation \u0026lt;integer\u0026gt; 28 labels \u0026lt;map[string]string\u0026gt; 29 managedFields \u0026lt;[]Object\u0026gt; 30 name \u0026lt;string\u0026gt; 31 namespace \u0026lt;string\u0026gt; 32 ownerReferences \u0026lt;[]Object\u0026gt; 33 resourceVersion \u0026lt;string\u0026gt; 34 selfLink \u0026lt;string\u0026gt; 35 uid \u0026lt;string\u0026gt; 在kubernetes中基本所有资源的一级属性都是一样的，主要包含5部分：\napiVersion 版本，由kubernetes内部定义，版本号必须可以用 kubectl api-versions 查询到 kind 类型，由kubernetes内部定义，版本号必须可以用 kubectl api-resources 查询到 metadata 元数据，主要是资源标识和说明，常用的有name、namespace、labels等 spec 描述，这是配置中最重要的一部分，里面是对各种资源配置的详细描述 status 状态信息，里面的内容不需要定义，由kubernetes自动生成 在上面的属性中，spec是接下来研究的重点，继续看下它的常见子属性:\ncontainers \u0026lt;[]Object\u0026gt; 容器列表，用于定义容器的详细信息 nodeName 根据nodeName的值将pod调度到指定的Node节点上 nodeSelector \u0026lt;map[]\u0026gt; 根据NodeSelector中定义的信息选择将该Pod调度到包含这些label的Node 上 hostNetwork 是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 volumes \u0026lt;[]Object\u0026gt; 存储卷，用于定义Pod上面挂在的存储信息 restartPolicy 重启策略，表示Pod在遇到故障的时候的处理策略 5.2 Pod配置 本小节主要来研究pod.spec.containers属性，这也是pod配置中最为关键的一项配置。\n1[root@k8s-master01 ~]# kubectl explain pod.spec.containers 2KIND: Pod 3VERSION: v1 4RESOURCE: containers \u0026lt;[]Object\u0026gt; # 数组，代表可以有多个容器 5FIELDS: 6 name \u0026lt;string\u0026gt; # 容器名称 7 image \u0026lt;string\u0026gt; # 容器需要的镜像地址 8 imagePullPolicy \u0026lt;string\u0026gt; # 镜像拉取策略 9 command \u0026lt;[]string\u0026gt; # 容器的启动命令列表，如不指定，使用打包时使用的启动命令 10 args \u0026lt;[]string\u0026gt; # 容器的启动命令需要的参数列表 11 env \u0026lt;[]Object\u0026gt; # 容器环境变量的配置 12 ports \u0026lt;[]Object\u0026gt; # 容器需要暴露的端口号列表 13 resources \u0026lt;Object\u0026gt; # 资源限制和资源请求的设置 5.2.1 基本配置 创建pod-base.yaml文件，内容如下：\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-base 5 namespace: dev 6 labels: 7 user: heima 8spec: 9 containers: 10 - name: nginx 11 image: nginx:1.17.1 12 - name: busybox 13 image: busybox:1.30 上面定义了一个比较简单Pod的配置，里面有两个容器：\nnginx：用1.17.1版本的nginx镜像创建，（nginx是一个轻量级web容器） busybox：用1.30版本的busybox镜像创建，（busybox是一个小巧的linux命令集合） 1# 创建Pod 2[root@k8s-master01 pod]# kubectl apply -f pod-base.yaml 3pod/pod-base created 4 5# 查看Pod状况 6# READY 1/2 : 表示当前Pod中有2个容器，其中1个准备就绪，1个未就绪 7# RESTARTS : 重启次数，因为有1个容器故障了，Pod一直在重启试图恢复它 8[root@k8s-master01 pod]# kubectl get pod -n dev 9NAME READY STATUS RESTARTS AGE 10pod-base 1/2 Running 4 95s 11 12# 可以通过describe查看内部的详情 13# 此时已经运行起来了一个基本的Pod，虽然它暂时有问题 14[root@k8s-master01 pod]# kubectl describe pod pod-base -n dev 5.2.2 镜像拉取 创建pod-imagepullpolicy.yaml文件，内容如下：\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-imagepullpolicy 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 imagePullPolicy: Never # 用于设置镜像拉取策略 11 - name: busybox 12 image: busybox:1.30 imagePullPolicy，用于设置镜像拉取策略，kubernetes支持配置三种拉取策略：\nAlways：总是从远程仓库拉取镜像（一直远程下载） IfNotPresent：本地有则使用本地镜像，本地没有则从远程仓库拉取镜像（本地有就本地 本地没远程下载） Never：只使用本地镜像，从不去远程仓库拉取，本地没有就报错 （一直使用本地） 默认值说明：\n如果镜像tag为具体版本号， 默认策略是：IfNotPresent\n如果镜像tag为：latest（最终版本） ，默认策略是always\n1# 创建Pod 2[root@k8s-master01 pod]# kubectl create -f pod-imagepullpolicy.yaml 3pod/pod-imagepullpolicy created 4 5# 查看Pod详情 6# 此时明显可以看到nginx镜像有一步Pulling image \u0026#34;nginx:1.17.1\u0026#34;的过程 7[root@k8s-master01 pod]# kubectl describe pod pod-imagepullpolicy -n dev 8...... 9Events: 10 Type Reason Age From Message 11 ---- ------ ---- ---- ------- 12 Normal Scheduled \u0026lt;unknown\u0026gt; default-scheduler Successfully assigned dev/pod-imagePullPolicy to node1 13 Normal Pulling 32s kubelet, node1 Pulling image \u0026#34;nginx:1.17.1\u0026#34; 14 Normal Pulled 26s kubelet, node1 Successfully pulled image \u0026#34;nginx:1.17.1\u0026#34; 15 Normal Created 26s kubelet, node1 Created container nginx 16 Normal Started 25s kubelet, node1 Started container nginx 17 Normal Pulled 7s (x3 over 25s) kubelet, node1 Container image \u0026#34;busybox:1.30\u0026#34; already present on machine 18 Normal Created 7s (x3 over 25s) kubelet, node1 Created container busybox 19 Normal Started 7s (x3 over 25s) kubelet, node1 Started container busybox 5.2.3 启动命令 在前面的案例中，一直有一个问题没有解决，就是的busybox容器一直没有成功运行，那么到底是什么原因导致这个容器的故障呢？\n原来busybox并不是一个程序，而是类似于一个工具类的集合，kubernetes集群启动管理后，它会自动关闭。解决方法就是让其一直在运行，这就用到了command配置。\n创建pod-command.yaml文件，内容如下：\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-command 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 - name: busybox 11 image: busybox:1.30 12 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;touch /tmp/hello.txt;while true;do /bin/echo $(date +%T) \u0026gt;\u0026gt; /tmp/hello.txt; sleep 3; done;\u0026#34;] command，用于在pod中的容器初始化完毕之后运行一个命令。\n稍微解释下上面命令的意思：\n\u0026ldquo;/bin/sh\u0026rdquo;,\u0026quot;-c\u0026rdquo;, 使用sh执行命令\ntouch /tmp/hello.txt; 创建一个/tmp/hello.txt 文件\nwhile true;do /bin/echo $(date +%T) \u0026raquo; /tmp/hello.txt; sleep 3; done; 每隔3秒向文件中写入当前时间\n1# 创建Pod 2[root@k8s-master01 pod]# kubectl create -f pod-command.yaml 3pod/pod-command created 4 5# 查看Pod状态 6# 此时发现两个pod都正常运行了 7[root@k8s-master01 pod]# kubectl get pods pod-command -n dev 8NAME READY STATUS RESTARTS AGE 9pod-command 2/2 Runing 0 2s 10 11# 进入pod中的busybox容器，查看文件内容 12# 补充一个命令: kubectl exec pod名称 -n 命名空间 -it -c 容器名称 /bin/sh 在容器内部执行命令 13# 使用这个命令就可以进入某个容器的内部，然后进行相关操作了 14# 比如，可以查看txt文件的内容 15[root@k8s-master01 pod]# kubectl exec pod-command -n dev -it -c busybox /bin/sh 16/ # tail -f /tmp/hello.txt 1714:44:19 1814:44:22 1914:44:25 1特别说明： 2 通过上面发现command已经可以完成启动命令和传递参数的功能，为什么这里还要提供一个args选项，用于传递参数呢?这其实跟docker有点关系，kubernetes中的command、args两项其实是实现覆盖Dockerfile中ENTRYPOINT的功能。 3 1 如果command和args均没有写，那么用Dockerfile的配置。 4 2 如果command写了，但args没有写，那么Dockerfile默认的配置会被忽略，执行输入的command 5 3 如果command没写，但args写了，那么Dockerfile中配置的ENTRYPOINT的命令会被执行，使用当前args的参数 6 4 如果command和args都写了，那么Dockerfile的配置被忽略，执行command并追加上args参数 5.2.4 环境变量 创建pod-env.yaml文件，内容如下：\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-env 5 namespace: dev 6spec: 7 containers: 8 - name: busybox 9 image: busybox:1.30 10 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;while true;do /bin/echo $(date +%T);sleep 60; done;\u0026#34;] 11 env: # 设置环境变量列表 12 - name: \u0026#34;username\u0026#34; 13 value: \u0026#34;admin\u0026#34; 14 - name: \u0026#34;password\u0026#34; 15 value: \u0026#34;123456\u0026#34; env，环境变量，用于在pod中的容器设置环境变量。\n1# 创建Pod 2[root@k8s-master01 ~]# kubectl create -f pod-env.yaml 3pod/pod-env created 4 5# 进入容器，输出环境变量 6[root@k8s-master01 ~]# kubectl exec pod-env -n dev -c busybox -it /bin/sh 7/ # echo $username 8admin 9/ # echo $password 10123456 这种方式不是很推荐，推荐将这些配置单独存储在配置文件中，这种方式将在后面介绍。\n5.2.5 端口设置 本小节来介绍容器的端口设置，也就是containers的ports选项。\n首先看下ports支持的子选项：\n1[root@k8s-master01 ~]# kubectl explain pod.spec.containers.ports 2KIND: Pod 3VERSION: v1 4RESOURCE: ports \u0026lt;[]Object\u0026gt; 5FIELDS: 6 name \u0026lt;string\u0026gt; # 端口名称，如果指定，必须保证name在pod中是唯一的\t7 containerPort\u0026lt;integer\u0026gt; # 容器要监听的端口(0\u0026lt;x\u0026lt;65536) 8 hostPort \u0026lt;integer\u0026gt; # 容器要在主机上公开的端口，如果设置，主机上只能运行容器的一个副本(一般省略) 9 hostIP \u0026lt;string\u0026gt; # 要将外部端口绑定到的主机IP(一般省略) 10 protocol \u0026lt;string\u0026gt; # 端口协议。必须是UDP、TCP或SCTP。默认为“TCP”。 接下来，编写一个测试案例，创建pod-ports.yaml\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-ports 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 ports: # 设置容器暴露的端口列表 11 - name: nginx-port 12 containerPort: 80 13 protocol: TCP 1# 创建Pod 2[root@k8s-master01 ~]# kubectl create -f pod-ports.yaml 3pod/pod-ports created 4 5# 查看pod 6# 在下面可以明显看到配置信息 7[root@k8s-master01 ~]# kubectl get pod pod-ports -n dev -o yaml 8...... 9spec: 10 containers: 11 - image: nginx:1.17.1 12 imagePullPolicy: IfNotPresent 13 name: nginx 14 ports: 15 - containerPort: 80 16 name: nginx-port 17 protocol: TCP 18...... 访问容器中的程序需要使用的是Podip:containerPort\n5.2.6 资源配额 容器中的程序要运行，肯定是要占用一定资源的，比如cpu和内存等，如果不对某个容器的资源做限制，那么它就可能吃掉大量资源，导致其它容器无法运行。针对这种情况，kubernetes提供了对内存和cpu的资源进行配额的机制，这种机制主要通过resources选项实现，他有两个子选项：\nlimits：用于限制运行时容器的最大占用资源，当容器占用资源超过limits时会被终止，并进行重启 requests ：用于设置容器需要的最小资源，如果环境资源不够，容器将无法启动 可以通过上面两个选项设置资源的上下限。\n接下来，编写一个测试案例，创建pod-resources.yaml\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-resources 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 resources: # 资源配额 11 limits: # 限制资源（上限） 12 cpu: \u0026#34;2\u0026#34; # CPU限制，单位是core数 13 memory: \u0026#34;10Gi\u0026#34; # 内存限制 14 requests: # 请求资源（下限） 15 cpu: \u0026#34;1\u0026#34; # CPU限制，单位是core数 16 memory: \u0026#34;10Mi\u0026#34; # 内存限制 在这对cpu和memory的单位做一个说明：\ncpu：core数，可以为整数或小数 memory： 内存大小，可以使用Gi、Mi、G、M等形式 1# 运行Pod 2[root@k8s-master01 ~]# kubectl create -f pod-resources.yaml 3pod/pod-resources created 4 5# 查看发现pod运行正常 6[root@k8s-master01 ~]# kubectl get pod pod-resources -n dev 7NAME READY STATUS RESTARTS AGE 8pod-resources 1/1 Running 0 39s 9 10# 接下来，停止Pod 11[root@k8s-master01 ~]# kubectl delete -f pod-resources.yaml 12pod \u0026#34;pod-resources\u0026#34; deleted 13 14# 编辑pod，修改resources.requests.memory的值为10Gi 15[root@k8s-master01 ~]# vim pod-resources.yaml 16 17# 再次启动pod 18[root@k8s-master01 ~]# kubectl create -f pod-resources.yaml 19pod/pod-resources created 20 21# 查看Pod状态，发现Pod启动失败 22[root@k8s-master01 ~]# kubectl get pod pod-resources -n dev -o wide 23NAME READY STATUS RESTARTS AGE 24pod-resources 0/1 Pending 0 20s 25 26# 查看pod详情会发现，如下提示 27[root@k8s-master01 ~]# kubectl describe pod pod-resources -n dev 28...... 29Warning FailedScheduling 35s default-scheduler 0/3 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn\u0026#39;t tolerate, 2 Insufficient memory.(内存不足) 5.3 Pod生命周期 我们一般将pod对象从创建至终的这段时间范围称为pod的生命周期，它主要包含下面的过程：\npod创建过程 运行初始化容器（init container）过程 运行主容器（main container） 容器启动后钩子（post start）、容器终止前钩子（pre stop） 容器的存活性探测（liveness probe）、就绪性探测（readiness probe） pod终止过程 在整个生命周期中，Pod会出现5种状态（相位），分别如下：\n挂起（Pending）：apiserver已经创建了pod资源对象，但它尚未被调度完成或者仍处于下载镜像的过程中 运行中（Running）：pod已经被调度至某节点，并且所有容器都已经被kubelet创建完成 成功（Succeeded）：pod中的所有容器都已经成功终止并且不会被重启 失败（Failed）：所有容器都已经终止，但至少有一个容器终止失败，即容器返回了非0值的退出状态 未知（Unknown）：apiserver无法正常获取到pod对象的状态信息，通常由网络通信失败所导致 5.3.1 创建和终止 pod的创建过程\n用户通过kubectl或其他api客户端提交需要创建的pod信息给apiServer\napiServer开始生成pod对象的信息，并将信息存入etcd，然后返回确认信息至客户端\napiServer开始反映etcd中的pod对象的变化，其它组件使用watch机制来跟踪检查apiServer上的变动\nscheduler发现有新的pod对象要创建，开始为Pod分配主机并将结果信息更新至apiServer\nnode节点上的kubelet发现有pod调度过来，尝试调用docker启动容器，并将结果回送至apiServer\napiServer将接收到的pod状态信息存入etcd中\npod的终止过程\n用户向apiServer发送删除pod对象的命令 apiServcer中的pod对象信息会随着时间的推移而更新，在宽限期内（默认30s），pod被视为dead 将pod标记为terminating状态 kubelet在监控到pod对象转为terminating状态的同时启动pod关闭过程 端点控制器监控到pod对象的关闭行为时将其从所有匹配到此端点的service资源的端点列表中移除 如果当前pod对象定义了preStop钩子处理器，则在其标记为terminating后即会以同步的方式启动执行 pod对象中的容器进程收到停止信号 宽限期结束后，若pod中还存在仍在运行的进程，那么pod对象会收到立即终止的信号 kubelet请求apiServer将此pod资源的宽限期设置为0从而完成删除操作，此时pod对于用户已不可见 5.3.2 初始化容器 初始化容器是在pod的主容器启动之前要运行的容器，主要是做一些主容器的前置工作，它具有两大特征：\n初始化容器必须运行完成直至结束，若某初始化容器运行失败，那么kubernetes需要重启它直到成功完成 初始化容器必须按照定义的顺序执行，当且仅当前一个成功之后，后面的一个才能运行 初始化容器有很多的应用场景，下面列出的是最常见的几个：\n提供主容器镜像中不具备的工具程序或自定义代码 初始化容器要先于应用容器串行启动并运行完成，因此可用于延后应用容器的启动直至其依赖的条件得到满足 接下来做一个案例，模拟下面这个需求：\n假设要以主容器来运行nginx，但是要求在运行nginx之前先要能够连接上mysql和redis所在服务器\n为了简化测试，事先规定好mysql(192.168.90.14)和redis(192.168.90.15)服务器的地址\n创建pod-initcontainer.yaml，内容如下：\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-initcontainer 5 namespace: dev 6spec: 7 containers: 8 - name: main-container 9 image: nginx:1.17.1 10 ports: 11 - name: nginx-port 12 containerPort: 80 13 initContainers: 14 - name: test-mysql 15 image: busybox:1.30 16 command: [\u0026#39;sh\u0026#39;, \u0026#39;-c\u0026#39;, \u0026#39;until ping 192.168.90.14 -c 1 ; do echo waiting for mysql...; sleep 2; done;\u0026#39;] 17 - name: test-redis 18 image: busybox:1.30 19 command: [\u0026#39;sh\u0026#39;, \u0026#39;-c\u0026#39;, \u0026#39;until ping 192.168.90.15 -c 1 ; do echo waiting for reids...; sleep 2; done;\u0026#39;] 1# 创建pod 2[root@k8s-master01 ~]# kubectl create -f pod-initcontainer.yaml 3pod/pod-initcontainer created 4 5# 查看pod状态 6# 发现pod卡在启动第一个初始化容器过程中，后面的容器不会运行 7root@k8s-master01 ~]# kubectl describe pod pod-initcontainer -n dev 8........ 9Events: 10 Type Reason Age From Message 11 ---- ------ ---- ---- ------- 12 Normal Scheduled 49s default-scheduler Successfully assigned dev/pod-initcontainer to node1 13 Normal Pulled 48s kubelet, node1 Container image \u0026#34;busybox:1.30\u0026#34; already present on machine 14 Normal Created 48s kubelet, node1 Created container test-mysql 15 Normal Started 48s kubelet, node1 Started container test-mysql 16 17# 动态查看pod 18[root@k8s-master01 ~]# kubectl get pods pod-initcontainer -n dev -w 19NAME READY STATUS RESTARTS AGE 20pod-initcontainer 0/1 Init:0/2 0 15s 21pod-initcontainer 0/1 Init:1/2 0 52s 22pod-initcontainer 0/1 Init:1/2 0 53s 23pod-initcontainer 0/1 PodInitializing 0 89s 24pod-initcontainer 1/1 Running 0 90s 25 26# 接下来新开一个shell，为当前服务器新增两个ip，观察pod的变化 27[root@k8s-master01 ~]# ifconfig ens33:1 192.168.90.14 netmask 255.255.255.0 up 28[root@k8s-master01 ~]# ifconfig ens33:2 192.168.90.15 netmask 255.255.255.0 up 5.3.3 钩子函数 钩子函数能够感知自身生命周期中的事件，并在相应的时刻到来时运行用户指定的程序代码。\nkubernetes在主容器的启动之后和停止之前提供了两个钩子函数：\npost start：容器创建之后执行，如果失败了会重启容器 pre stop ：容器终止之前执行，执行完成之后容器将成功终止，在其完成之前会阻塞删除容器的操作 钩子处理器支持使用下面三种方式定义动作：\nExec命令：在容器内执行一次命令\n1…… 2 lifecycle: 3 postStart: 4 exec: 5 command: 6 - cat 7 - /tmp/healthy 8…… TCPSocket：在当前容器尝试访问指定的socket\n1…… 2 lifecycle: 3 postStart: 4 tcpSocket: 5 port: 8080 6…… HTTPGet：在当前容器中向某url发起http请求\n1…… 2 lifecycle: 3 postStart: 4 httpGet: 5 path: / #URI地址 6 port: 80 #端口号 7 host: 192.168.5.3 #主机地址 8 scheme: HTTP #支持的协议，http或者https 9…… 接下来，以exec方式为例，演示下钩子函数的使用，创建pod-hook-exec.yaml文件，内容如下：\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-hook-exec 5 namespace: dev 6spec: 7 containers: 8 - name: main-container 9 image: nginx:1.17.1 10 ports: 11 - name: nginx-port 12 containerPort: 80 13 lifecycle: 14 postStart: 15 exec: # 在容器启动的时候执行一个命令，修改掉nginx的默认首页内容 16 command: [\u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;echo postStart... \u0026gt; /usr/share/nginx/html/index.html\u0026#34;] 17 preStop: 18 exec: # 在容器停止之前停止nginx服务 19 command: [\u0026#34;/usr/sbin/nginx\u0026#34;,\u0026#34;-s\u0026#34;,\u0026#34;quit\u0026#34;] 1# 创建pod 2[root@k8s-master01 ~]# kubectl create -f pod-hook-exec.yaml 3pod/pod-hook-exec created 4 5# 查看pod 6[root@k8s-master01 ~]# kubectl get pods pod-hook-exec -n dev -o wide 7NAME READY STATUS RESTARTS AGE IP NODE 8pod-hook-exec 1/1 Running 0 29s 10.244.2.48 node2 9 10# 访问pod 11[root@k8s-master01 ~]# curl 10.244.2.48 12postStart... 5.3.4 容器探测 容器探测用于检测容器中的应用实例是否正常工作，是保障业务可用性的一种传统机制。如果经过探测，实例的状态不符合预期，那么kubernetes就会把该问题实例\u0026rdquo; 摘除 \u0026ldquo;，不承担业务流量。kubernetes提供了两种探针来实现容器探测，分别是：\nliveness probes：存活性探针，用于检测应用实例当前是否处于正常运行状态，如果不是，k8s会重启容器 readiness probes：就绪性探针，用于检测应用实例当前是否可以接收请求，如果不能，k8s不会转发流量 livenessProbe 决定是否重启容器，readinessProbe 决定是否将请求转发给容器。\n上面两种探针目前均支持三种探测方式：\nExec命令：在容器内执行一次命令，如果命令执行的退出码为0，则认为程序正常，否则不正常\n1…… 2 livenessProbe: 3 exec: 4 command: 5 - cat 6 - /tmp/healthy 7…… TCPSocket：将会尝试访问一个用户容器的端口，如果能够建立这条连接，则认为程序正常，否则不正常\n1…… 2 livenessProbe: 3 tcpSocket: 4 port: 8080 5…… HTTPGet：调用容器内Web应用的URL，如果返回的状态码在200和399之间，则认为程序正常，否则不正常\n1…… 2 livenessProbe: 3 httpGet: 4 path: / #URI地址 5 port: 80 #端口号 6 host: 127.0.0.1 #主机地址 7 scheme: HTTP #支持的协议，http或者https 8…… 下面以liveness probes为例，做几个演示：\n方式一：Exec\n创建pod-liveness-exec.yaml\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-liveness-exec 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 ports: 11 - name: nginx-port 12 containerPort: 80 13 livenessProbe: 14 exec: 15 command: [\u0026#34;/bin/cat\u0026#34;,\u0026#34;/tmp/hello.txt\u0026#34;] # 执行一个查看文件的命令 创建pod，观察效果\n1# 创建Pod 2[root@k8s-master01 ~]# kubectl create -f pod-liveness-exec.yaml 3pod/pod-liveness-exec created 4 5# 查看Pod详情 6[root@k8s-master01 ~]# kubectl describe pods pod-liveness-exec -n dev 7...... 8 Normal Created 20s (x2 over 50s) kubelet, node1 Created container nginx 9 Normal Started 20s (x2 over 50s) kubelet, node1 Started container nginx 10 Normal Killing 20s kubelet, node1 Container nginx failed liveness probe, will be restarted 11 Warning Unhealthy 0s (x5 over 40s) kubelet, node1 Liveness probe failed: cat: can\u0026#39;t open \u0026#39;/tmp/hello11.txt\u0026#39;: No such file or directory 12 13# 观察上面的信息就会发现nginx容器启动之后就进行了健康检查 14# 检查失败之后，容器被kill掉，然后尝试进行重启（这是重启策略的作用，后面讲解） 15# 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长 16[root@k8s-master01 ~]# kubectl get pods pod-liveness-exec -n dev 17NAME READY STATUS RESTARTS AGE 18pod-liveness-exec 0/1 CrashLoopBackOff 2 3m19s 19 20# 当然接下来，可以修改成一个存在的文件，比如/tmp/hello.txt，再试，结果就正常了...... 方式二：TCPSocket\n创建pod-liveness-tcpsocket.yaml\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-liveness-tcpsocket 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 ports: 11 - name: nginx-port 12 containerPort: 80 13 livenessProbe: 14 tcpSocket: 15 port: 8080 # 尝试访问8080端口 创建pod，观察效果\n1# 创建Pod 2[root@k8s-master01 ~]# kubectl create -f pod-liveness-tcpsocket.yaml 3pod/pod-liveness-tcpsocket created 4 5# 查看Pod详情 6[root@k8s-master01 ~]# kubectl describe pods pod-liveness-tcpsocket -n dev 7...... 8 Normal Scheduled 31s default-scheduler Successfully assigned dev/pod-liveness-tcpsocket to node2 9 Normal Pulled \u0026lt;invalid\u0026gt; kubelet, node2 Container image \u0026#34;nginx:1.17.1\u0026#34; already present on machine 10 Normal Created \u0026lt;invalid\u0026gt; kubelet, node2 Created container nginx 11 Normal Started \u0026lt;invalid\u0026gt; kubelet, node2 Started container nginx 12 Warning Unhealthy \u0026lt;invalid\u0026gt; (x2 over \u0026lt;invalid\u0026gt;) kubelet, node2 Liveness probe failed: dial tcp 10.244.2.44:8080: connect: connection refused 13 14# 观察上面的信息，发现尝试访问8080端口,但是失败了 15# 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长 16[root@k8s-master01 ~]# kubectl get pods pod-liveness-tcpsocket -n dev 17NAME READY STATUS RESTARTS AGE 18pod-liveness-tcpsocket 0/1 CrashLoopBackOff 2 3m19s 19 20# 当然接下来，可以修改成一个可以访问的端口，比如80，再试，结果就正常了...... 方式三：HTTPGet\n创建pod-liveness-httpget.yaml\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-liveness-httpget 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 ports: 11 - name: nginx-port 12 containerPort: 80 13 livenessProbe: 14 httpGet: # 其实就是访问http://127.0.0.1:80/hello 15 scheme: HTTP #支持的协议，http或者https 16 port: 80 #端口号 17 path: /hello #URI地址 创建pod，观察效果\n1# 创建Pod 2[root@k8s-master01 ~]# kubectl create -f pod-liveness-httpget.yaml 3pod/pod-liveness-httpget created 4 5# 查看Pod详情 6[root@k8s-master01 ~]# kubectl describe pod pod-liveness-httpget -n dev 7....... 8 Normal Pulled 6s (x3 over 64s) kubelet, node1 Container image \u0026#34;nginx:1.17.1\u0026#34; already present on machine 9 Normal Created 6s (x3 over 64s) kubelet, node1 Created container nginx 10 Normal Started 6s (x3 over 63s) kubelet, node1 Started container nginx 11 Warning Unhealthy 6s (x6 over 56s) kubelet, node1 Liveness probe failed: HTTP probe failed with statuscode: 404 12 Normal Killing 6s (x2 over 36s) kubelet, node1 Container nginx failed liveness probe, will be restarted 13 14# 观察上面信息，尝试访问路径，但是未找到,出现404错误 15# 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长 16[root@k8s-master01 ~]# kubectl get pod pod-liveness-httpget -n dev 17NAME READY STATUS RESTARTS AGE 18pod-liveness-httpget 1/1 Running 5 3m17s 19 20# 当然接下来，可以修改成一个可以访问的路径path，比如/，再试，结果就正常了...... 至此，已经使用liveness Probe演示了三种探测方式，但是查看livenessProbe的子属性，会发现除了这三种方式，还有一些其他的配置，在这里一并解释下：\n1[root@k8s-master01 ~]# kubectl explain pod.spec.containers.livenessProbe 2FIELDS: 3 exec \u0026lt;Object\u0026gt; 4 tcpSocket \u0026lt;Object\u0026gt; 5 httpGet \u0026lt;Object\u0026gt; 6 initialDelaySeconds \u0026lt;integer\u0026gt; # 容器启动后等待多少秒执行第一次探测 7 timeoutSeconds \u0026lt;integer\u0026gt; # 探测超时时间。默认1秒，最小1秒 8 periodSeconds \u0026lt;integer\u0026gt; # 执行探测的频率。默认是10秒，最小1秒 9 failureThreshold \u0026lt;integer\u0026gt; # 连续探测失败多少次才被认定为失败。默认是3。最小值是1 10 successThreshold \u0026lt;integer\u0026gt; # 连续探测成功多少次才被认定为成功。默认是1 下面稍微配置两个，演示下效果即可：\n1[root@k8s-master01 ~]# more pod-liveness-httpget.yaml 2apiVersion: v1 3kind: Pod 4metadata: 5 name: pod-liveness-httpget 6 namespace: dev 7spec: 8 containers: 9 - name: nginx 10 image: nginx:1.17.1 11 ports: 12 - name: nginx-port 13 containerPort: 80 14 livenessProbe: 15 httpGet: 16 scheme: HTTP 17 port: 80 18 path: / 19 initialDelaySeconds: 30 # 容器启动后30s开始探测 20 timeoutSeconds: 5 # 探测超时时间为5s 5.3.5 重启策略 在上一节中，一旦容器探测出现了问题，kubernetes就会对容器所在的Pod进行重启，其实这是由pod的重启策略决定的，pod的重启策略有 3 种，分别如下：\nAlways ：容器失效时，自动重启该容器，这也是默认值。 OnFailure ： 容器终止运行且退出码不为0时重启 Never ： 不论状态为何，都不重启该容器 重启策略适用于pod对象中的所有容器，首次需要重启的容器，将在其需要时立即进行重启，随后再次需要重启的操作将由kubelet延迟一段时间后进行，且反复的重启操作的延迟时长以此为10s、20s、40s、80s、160s和300s，300s是最大延迟时长。\n创建pod-restartpolicy.yaml：\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-restartpolicy 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 ports: 11 - name: nginx-port 12 containerPort: 80 13 livenessProbe: 14 httpGet: 15 scheme: HTTP 16 port: 80 17 path: /hello 18 restartPolicy: Never # 设置重启策略为Never 运行Pod测试\n1# 创建Pod 2[root@k8s-master01 ~]# kubectl create -f pod-restartpolicy.yaml 3pod/pod-restartpolicy created 4 5# 查看Pod详情，发现nginx容器失败 6[root@k8s-master01 ~]# kubectl describe pods pod-restartpolicy -n dev 7...... 8 Warning Unhealthy 15s (x3 over 35s) kubelet, node1 Liveness probe failed: HTTP probe failed with statuscode: 404 9 Normal Killing 15s kubelet, node1 Container nginx failed liveness probe 10 11# 多等一会，再观察pod的重启次数，发现一直是0，并未重启 12[root@k8s-master01 ~]# kubectl get pods pod-restartpolicy -n dev 13NAME READY STATUS RESTARTS AGE 14pod-restartpolicy 0/1 Running 0 5min42s 5.4 Pod调度 在默认情况下，一个Pod在哪个Node节点上运行，是由Scheduler组件采用相应的算法计算出来的，这个过程是不受人工控制的。但是在实际使用中，这并不满足的需求，因为很多情况下，我们想控制某些Pod到达某些节点上，那么应该怎么做呢？这就要求了解kubernetes对Pod的调度规则，kubernetes提供了四大类调度方式：\n自动调度：运行在哪个节点上完全由Scheduler经过一系列的算法计算得出 定向调度：NodeName、NodeSelector 亲和性调度：NodeAffinity、PodAffinity、PodAntiAffinity 污点（容忍）调度：Taints、Toleration 5.4.1 定向调度 定向调度，指的是利用在pod上声明nodeName或者nodeSelector，以此将Pod调度到期望的node节点上。注意，这里的调度是强制的，这就意味着即使要调度的目标Node不存在，也会向上面进行调度，只不过pod运行失败而已。\nNodeName\nNodeName用于强制约束将Pod调度到指定的Name的Node节点上。这种方式，其实是直接跳过Scheduler的调度逻辑，直接将Pod调度到指定名称的节点。\n接下来，实验一下：创建一个pod-nodename.yaml文件\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-nodename 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 nodeName: node1 # 指定调度到node1节点上 1#创建Pod 2[root@k8s-master01 ~]# kubectl create -f pod-nodename.yaml 3pod/pod-nodename created 4 5#查看Pod调度到NODE属性，确实是调度到了node1节点上 6[root@k8s-master01 ~]# kubectl get pods pod-nodename -n dev -o wide 7NAME READY STATUS RESTARTS AGE IP NODE ...... 8pod-nodename 1/1 Running 0 56s 10.244.1.87 node1 ...... 9 10# 接下来，删除pod，修改nodeName的值为node3（并没有node3节点） 11[root@k8s-master01 ~]# kubectl delete -f pod-nodename.yaml 12pod \u0026#34;pod-nodename\u0026#34; deleted 13[root@k8s-master01 ~]# vim pod-nodename.yaml 14[root@k8s-master01 ~]# kubectl create -f pod-nodename.yaml 15pod/pod-nodename created 16 17#再次查看，发现已经向Node3节点调度，但是由于不存在node3节点，所以pod无法正常运行 18[root@k8s-master01 ~]# kubectl get pods pod-nodename -n dev -o wide 19NAME READY STATUS RESTARTS AGE IP NODE ...... 20pod-nodename 0/1 Pending 0 6s \u0026lt;none\u0026gt; node3 ...... NodeSelector\nNodeSelector用于将pod调度到添加了指定标签的node节点上。它是通过kubernetes的label-selector机制实现的，也就是说，在pod创建之前，会由scheduler使用MatchNodeSelector调度策略进行label匹配，找出目标node，然后将pod调度到目标节点，该匹配规则是强制约束。\n接下来，实验一下：\n1 首先分别为node节点添加标签\n1[root@k8s-master01 ~]# kubectl label nodes node1 nodeenv=pro 2node/node2 labeled 3[root@k8s-master01 ~]# kubectl label nodes node2 nodeenv=test 4node/node2 labeled 2 创建一个pod-nodeselector.yaml文件，并使用它创建Pod\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-nodeselector 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 nodeSelector: 11 nodeenv: pro # 指定调度到具有nodeenv=pro标签的节点上 1#创建Pod 2[root@k8s-master01 ~]# kubectl create -f pod-nodeselector.yaml 3pod/pod-nodeselector created 4 5#查看Pod调度到NODE属性，确实是调度到了node1节点上 6[root@k8s-master01 ~]# kubectl get pods pod-nodeselector -n dev -o wide 7NAME READY STATUS RESTARTS AGE IP NODE ...... 8pod-nodeselector 1/1 Running 0 47s 10.244.1.87 node1 ...... 9 10# 接下来，删除pod，修改nodeSelector的值为nodeenv: xxxx（不存在打有此标签的节点） 11[root@k8s-master01 ~]# kubectl delete -f pod-nodeselector.yaml 12pod \u0026#34;pod-nodeselector\u0026#34; deleted 13[root@k8s-master01 ~]# vim pod-nodeselector.yaml 14[root@k8s-master01 ~]# kubectl create -f pod-nodeselector.yaml 15pod/pod-nodeselector created 16 17#再次查看，发现pod无法正常运行,Node的值为none 18[root@k8s-master01 ~]# kubectl get pods -n dev -o wide 19NAME READY STATUS RESTARTS AGE IP NODE 20pod-nodeselector 0/1 Pending 0 2m20s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 21 22# 查看详情,发现node selector匹配失败的提示 23[root@k8s-master01 ~]# kubectl describe pods pod-nodeselector -n dev 24....... 25Events: 26 Type Reason Age From Message 27 ---- ------ ---- ---- ------- 28 Warning FailedScheduling \u0026lt;unknown\u0026gt; default-scheduler 0/3 nodes are available: 3 node(s) didn\u0026#39;t match node selector. 5.4.2 亲和性调度 上一节，介绍了两种定向调度的方式，使用起来非常方便，但是也有一定的问题，那就是如果没有满足条件的Node，那么Pod将不会被运行，即使在集群中还有可用Node列表也不行，这就限制了它的使用场景。\n基于上面的问题，kubernetes还提供了一种亲和性调度（Affinity）。它在NodeSelector的基础之上的进行了扩展，可以通过配置的形式，实现优先选择满足条件的Node进行调度，如果没有，也可以调度到不满足条件的节点上，使调度更加灵活。\nAffinity主要分为三类：\nnodeAffinity(node亲和性）: 以node为目标，解决pod可以调度到哪些node的问题 podAffinity(pod亲和性) : 以pod为目标，解决pod可以和哪些已存在的pod部署在同一个拓扑域中的问题 podAntiAffinity(pod反亲和性) : 以pod为目标，解决pod不能和哪些已存在pod部署在同一个拓扑域中的问题 关于亲和性(反亲和性)使用场景的说明：\n亲和性：如果两个应用频繁交互，那就有必要利用亲和性让两个应用的尽可能的靠近，这样可以减少因网络通信而带来的性能损耗。\n反亲和性：当应用的采用多副本部署时，有必要采用反亲和性让各个应用实例打散分布在各个node上，这样可以提高服务的高可用性。\nNodeAffinity\n首先来看一下NodeAffinity的可配置项：\n1pod.spec.affinity.nodeAffinity 2 requiredDuringSchedulingIgnoredDuringExecution Node节点必须满足指定的所有规则才可以，相当于硬限制 3 nodeSelectorTerms 节点选择列表 4 matchFields 按节点字段列出的节点选择器要求列表 5 matchExpressions 按节点标签列出的节点选择器要求列表(推荐) 6 key 键 7 values 值 8 operat or 关系符 支持Exists, DoesNotExist, In, NotIn, Gt, Lt 9 preferredDuringSchedulingIgnoredDuringExecution 优先调度到满足指定的规则的Node，相当于软限制 (倾向) 10 preference 一个节点选择器项，与相应的权重相关联 11 matchFields 按节点字段列出的节点选择器要求列表 12 matchExpressions 按节点标签列出的节点选择器要求列表(推荐) 13 key 键 14 values 值 15 operator 关系符 支持In, NotIn, Exists, DoesNotExist, Gt, Lt 16\tweight 倾向权重，在范围1-100。 1关系符的使用说明: 2 3- matchExpressions: 4 - key: nodeenv # 匹配存在标签的key为nodeenv的节点 5 operator: Exists 6 - key: nodeenv # 匹配标签的key为nodeenv,且value是\u0026#34;xxx\u0026#34;或\u0026#34;yyy\u0026#34;的节点 7 operator: In 8 values: [\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;] 9 - key: nodeenv # 匹配标签的key为nodeenv,且value大于\u0026#34;xxx\u0026#34;的节点 10 operator: Gt 11 values: \u0026#34;xxx\u0026#34; 接下来首先演示一下requiredDuringSchedulingIgnoredDuringExecution ,\n创建pod-nodeaffinity-required.yaml\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-nodeaffinity-required 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 affinity: #亲和性设置 11 nodeAffinity: #设置node亲和性 12 requiredDuringSchedulingIgnoredDuringExecution: # 硬限制 13 nodeSelectorTerms: 14 - matchExpressions: # 匹配env的值在[\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;]中的标签 15 - key: nodeenv 16 operator: In 17 values: [\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;] 1# 创建pod 2[root@k8s-master01 ~]# kubectl create -f pod-nodeaffinity-required.yaml 3pod/pod-nodeaffinity-required created 4 5# 查看pod状态 （运行失败） 6[root@k8s-master01 ~]# kubectl get pods pod-nodeaffinity-required -n dev -o wide 7NAME READY STATUS RESTARTS AGE IP NODE ...... 8pod-nodeaffinity-required 0/1 Pending 0 16s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; ...... 9 10# 查看Pod的详情 11# 发现调度失败，提示node选择失败 12[root@k8s-master01 ~]# kubectl describe pod pod-nodeaffinity-required -n dev 13...... 14 Warning FailedScheduling \u0026lt;unknown\u0026gt; default-scheduler 0/3 nodes are available: 3 node(s) didn\u0026#39;t match node selector. 15 Warning FailedScheduling \u0026lt;unknown\u0026gt; default-scheduler 0/3 nodes are available: 3 node(s) didn\u0026#39;t match node selector. 16 17#接下来，停止pod 18[root@k8s-master01 ~]# kubectl delete -f pod-nodeaffinity-required.yaml 19pod \u0026#34;pod-nodeaffinity-required\u0026#34; deleted 20 21# 修改文件，将values: [\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;]------\u0026gt; [\u0026#34;pro\u0026#34;,\u0026#34;yyy\u0026#34;] 22[root@k8s-master01 ~]# vim pod-nodeaffinity-required.yaml 23 24# 再次启动 25[root@k8s-master01 ~]# kubectl create -f pod-nodeaffinity-required.yaml 26pod/pod-nodeaffinity-required created 27 28# 此时查看，发现调度成功，已经将pod调度到了node1上 29[root@k8s-master01 ~]# kubectl get pods pod-nodeaffinity-required -n dev -o wide 30NAME READY STATUS RESTARTS AGE IP NODE ...... 31pod-nodeaffinity-required 1/1 Running 0 11s 10.244.1.89 node1 ...... 接下来再演示一下requiredDuringSchedulingIgnoredDuringExecution ,\n创建pod-nodeaffinity-preferred.yaml\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-nodeaffinity-preferred 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 affinity: #亲和性设置 11 nodeAffinity: #设置node亲和性 12 preferredDuringSchedulingIgnoredDuringExecution: # 软限制 13 - weight: 1 14 preference: 15 matchExpressions: # 匹配env的值在[\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;]中的标签(当前环境没有) 16 - key: nodeenv 17 operator: In 18 values: [\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;] 1# 创建pod 2[root@k8s-master01 ~]# kubectl create -f pod-nodeaffinity-preferred.yaml 3pod/pod-nodeaffinity-preferred created 4 5# 查看pod状态 （运行成功） 6[root@k8s-master01 ~]# kubectl get pod pod-nodeaffinity-preferred -n dev 7NAME READY STATUS RESTARTS AGE 8pod-nodeaffinity-preferred 1/1 Running 0 40s 1NodeAffinity规则设置的注意事项： 2 1 如果同时定义了nodeSelector和nodeAffinity，那么必须两个条件都得到满足，Pod才能运行在指定的Node上 3 2 如果nodeAffinity指定了多个nodeSelectorTerms，那么只需要其中一个能够匹配成功即可 4 3 如果一个nodeSelectorTerms中有多个matchExpressions ，则一个节点必须满足所有的才能匹配成功 5 4 如果一个pod所在的Node在Pod运行期间其标签发生了改变，不再符合该Pod的节点亲和性需求，则系统将忽略此变化 PodAffinity\nPodAffinity主要实现以运行的Pod为参照，实现让新创建的Pod跟参照pod在一个区域的功能。\n首先来看一下PodAffinity的可配置项：\n1pod.spec.affinity.podAffinity 2 requiredDuringSchedulingIgnoredDuringExecution 硬限制 3 namespaces 指定参照pod的namespace 4 topologyKey 指定调度作用域 5 labelSelector 标签选择器 6 matchExpressions 按节点标签列出的节点选择器要求列表(推荐) 7 key 键 8 values 值 9 operator 关系符 支持In, NotIn, Exists, DoesNotExist. 10 matchLabels 指多个matchExpressions映射的内容 11 preferredDuringSchedulingIgnoredDuringExecution 软限制 12 podAffinityTerm 选项 13 namespaces 14 topologyKey 15 labelSelector 16 matchExpressions 17 key 键 18 values 值 19 operator 20 matchLabels 21 weight 倾向权重，在范围1-100 1topologyKey用于指定调度时作用域,例如: 2 如果指定为kubernetes.io/hostname，那就是以Node节点为区分范围 3\t如果指定为beta.kubernetes.io/os,则以Node节点的操作系统类型来区分 接下来，演示下requiredDuringSchedulingIgnoredDuringExecution,\n1）首先创建一个参照Pod，pod-podaffinity-target.yaml：\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-podaffinity-target 5 namespace: dev 6 labels: 7 podenv: pro #设置标签 8spec: 9 containers: 10 - name: nginx 11 image: nginx:1.17.1 12 nodeName: node1 # 将目标pod名确指定到node1上 1# 启动目标pod 2[root@k8s-master01 ~]# kubectl create -f pod-podaffinity-target.yaml 3pod/pod-podaffinity-target created 4 5# 查看pod状况 6[root@k8s-master01 ~]# kubectl get pods pod-podaffinity-target -n dev 7NAME READY STATUS RESTARTS AGE 8pod-podaffinity-target 1/1 Running 0 4s 2）创建pod-podaffinity-required.yaml，内容如下：\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-podaffinity-required 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 affinity: #亲和性设置 11 podAffinity: #设置pod亲和性 12 requiredDuringSchedulingIgnoredDuringExecution: # 硬限制 13 - labelSelector: 14 matchExpressions: # 匹配env的值在[\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;]中的标签 15 - key: podenv 16 operator: In 17 values: [\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;] 18 topologyKey: kubernetes.io/hostname 上面配置表达的意思是：新Pod必须要与拥有标签nodeenv=xxx或者nodeenv=yyy的pod在同一Node上，显然现在没有这样pod，接下来，运行测试一下。\n1# 启动pod 2[root@k8s-master01 ~]# kubectl create -f pod-podaffinity-required.yaml 3pod/pod-podaffinity-required created 4 5# 查看pod状态，发现未运行 6[root@k8s-master01 ~]# kubectl get pods pod-podaffinity-required -n dev 7NAME READY STATUS RESTARTS AGE 8pod-podaffinity-required 0/1 Pending 0 9s 9 10# 查看详细信息 11[root@k8s-master01 ~]# kubectl describe pods pod-podaffinity-required -n dev 12...... 13Events: 14 Type Reason Age From Message 15 ---- ------ ---- ---- ------- 16 Warning FailedScheduling \u0026lt;unknown\u0026gt; default-scheduler 0/3 nodes are available: 2 node(s) didn\u0026#39;t match pod affinity rules, 1 node(s) had taints that the pod didn\u0026#39;t tolerate. 17 18# 接下来修改 values: [\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;]-----\u0026gt;values:[\u0026#34;pro\u0026#34;,\u0026#34;yyy\u0026#34;] 19# 意思是：新Pod必须要与拥有标签nodeenv=xxx或者nodeenv=yyy的pod在同一Node上 20[root@k8s-master01 ~]# vim pod-podaffinity-required.yaml 21 22# 然后重新创建pod，查看效果 23[root@k8s-master01 ~]# kubectl delete -f pod-podaffinity-required.yaml 24pod \u0026#34;pod-podaffinity-required\u0026#34; de leted 25[root@k8s-master01 ~]# kubectl create -f pod-podaffinity-required.yaml 26pod/pod-podaffinity-required created 27 28# 发现此时Pod运行正常 29[root@k8s-master01 ~]# kubectl get pods pod-podaffinity-required -n dev 30NAME READY STATUS RESTARTS AGE LABELS 31pod-podaffinity-required 1/1 Running 0 6s \u0026lt;none\u0026gt; 关于PodAffinity的 preferredDuringSchedulingIgnoredDuringExecution，这里不再演示。\nPodAntiAffinity\nPodAntiAffinity主要实现以运行的Pod为参照，让新创建的Pod跟参照pod不在一个区域中的功能。\n它的配置方式和选项跟PodAffinty是一样的，这里不再做详细解释，直接做一个测试案例。\n1）继续使用上个案例中目标pod\n1[root@k8s-master01 ~]# kubectl get pods -n dev -o wide --show-labels 2NAME READY STATUS RESTARTS AGE IP NODE LABELS 3pod-podaffinity-required 1/1 Running 0 3m29s 10.244.1.38 node1 \u0026lt;none\u0026gt; 4pod-podaffinity-target 1/1 Running 0 9m25s 10.244.1.37 node1 podenv=pro 2）创建pod-podantiaffinity-required.yaml，内容如下：\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-podantiaffinity-required 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 affinity: #亲和性设置 11 podAntiAffinity: #设置pod亲和性 12 requiredDuringSchedulingIgnoredDuringExecution: # 硬限制 13 - labelSelector: 14 matchExpressions: # 匹配podenv的值在[\u0026#34;pro\u0026#34;]中的标签 15 - key: podenv 16 operator: In 17 values: [\u0026#34;pro\u0026#34;] 18 topologyKey: kubernetes.io/hostname 上面配置表达的意思是：新Pod必须要与拥有标签nodeenv=pro的pod不在同一Node上，运行测试一下。\n1# 创建pod 2[root@k8s-master01 ~]# kubectl create -f pod-podantiaffinity-required.yaml 3pod/pod-podantiaffinity-required created 4 5# 查看pod 6# 发现调度到了node2上 7[root@k8s-master01 ~]# kubectl get pods pod-podantiaffinity-required -n dev -o wide 8NAME READY STATUS RESTARTS AGE IP NODE .. 9pod-podantiaffinity-required 1/1 Running 0 30s 10.244.1.96 node2 .. 5.4.3 污点和容忍 污点（Taints）\n前面的调度方式都是站在Pod的角度上，通过在Pod上添加属性，来确定Pod是否要调度到指定的Node上，其实我们也可以站在Node的角度上，通过在Node上添加污点属性，来决定是否允许Pod调度过来。\nNode被设置上污点之后就和Pod之间存在了一种相斥的关系，进而拒绝Pod调度进来，甚至可以将已经存在的Pod驱逐出去。\n污点的格式为：key=value:effect, key和value是污点的标签，effect描述污点的作用，支持如下三个选项：\nPreferNoSchedule：kubernetes将尽量避免把Pod调度到具有该污点的Node上，除非没有其他节点可调度 NoSchedule：kubernetes将不会把Pod调度到具有该污点的Node上，但不会影响当前Node上已存在的Pod NoExecute：kubernetes将不会把Pod调度到具有该污点的Node上，同时也会将Node上已存在的Pod驱离 使用kubectl设置和去除污点的命令示例如下：\n1# 设置污点 2kubectl taint nodes node1 key=value:effect 3 4# 去除污点 5kubectl taint nodes node1 key:effect- 6 7# 去除所有污点 8kubectl taint nodes node1 key- 接下来，演示下污点的效果：\n准备节点node1（为了演示效果更加明显，暂时停止node2节点） 为node1节点设置一个污点: tag=heima:PreferNoSchedule；然后创建pod1( pod1 可以 ) 修改为node1节点设置一个污点: tag=heima:NoSchedule；然后创建pod2( pod1 正常 pod2 失败 ) 修改为node1节点设置一个污点: tag=heima:NoExecute；然后创建pod3 ( 3个pod都失败 ) 1# 为node1设置污点(PreferNoSchedule) 2[root@k8s-master01 ~]# kubectl taint nodes node1 tag=heima:PreferNoSchedule 3 4# 创建pod1 5[root@k8s-master01 ~]# kubectl run taint1 --image=nginx:1.17.1 -n dev 6[root@k8s-master01 ~]# kubectl get pods -n dev -o wide 7NAME READY STATUS RESTARTS AGE IP NODE 8taint1-7665f7fd85-574h4 1/1 Running 0 2m24s 10.244.1.59 node1 9 10# 为node1设置污点(取消PreferNoSchedule，设置NoSchedule) 11[root@k8s-master01 ~]# kubectl taint nodes node1 tag:PreferNoSchedule- 12[root@k8s-master01 ~]# kubectl taint nodes node1 tag=heima:NoSchedule 13 14# 创建pod2 15[root@k8s-master01 ~]# kubectl run taint2 --image=nginx:1.17.1 -n dev 16[root@k8s-master01 ~]# kubectl get pods taint2 -n dev -o wide 17NAME READY STATUS RESTARTS AGE IP NODE 18taint1-7665f7fd85-574h4 1/1 Running 0 2m24s 10.244.1.59 node1 19taint2-544694789-6zmlf 0/1 Pending 0 21s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 20 21# 为node1设置污点(取消NoSchedule，设置NoExecute) 22[root@k8s-master01 ~]# kubectl taint nodes node1 tag:NoSchedule- 23[root@k8s-master01 ~]# kubectl taint nodes node1 tag=heima:NoExecute 24 25# 创建pod3 26[root@k8s-master01 ~]# kubectl run taint3 --image=nginx:1.17.1 -n dev 27[root@k8s-master01 ~]# kubectl get pods -n dev -o wide 28NAME READY STATUS RESTARTS AGE IP NODE NOMINATED 29taint1-7665f7fd85-htkmp 0/1 Pending 0 35s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 30taint2-544694789-bn7wb 0/1 Pending 0 35s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 31taint3-6d78dbd749-tktkq 0/1 Pending 0 6s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 1小提示： 2 使用kubeadm搭建的集群，默认就会给master节点添加一个污点标记,所以pod就不会调度到master节点上. 容忍（Toleration）\n上面介绍了污点的作用，我们可以在node上添加污点用于拒绝pod调度上来，但是如果就是想将一个pod调度到一个有污点的node上去，这时候应该怎么做呢？这就要使用到容忍。\n污点就是拒绝，容忍就是忽略，Node通过污点拒绝pod调度上去，Pod通过容忍忽略拒绝\n下面先通过一个案例看下效果：\n上一小节，已经在node1节点上打上了NoExecute的污点，此时pod是调度不上去的 本小节，可以通过给pod添加容忍，然后将其调度上去 创建pod-toleration.yaml,内容如下\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-toleration 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 tolerations: # 添加容忍 11 - key: \u0026#34;tag\u0026#34; # 要容忍的污点的key 12 operator: \u0026#34;Equal\u0026#34; # 操作符 13 value: \u0026#34;heima\u0026#34; # 容忍的污点的value 14 effect: \u0026#34;NoExecute\u0026#34; # 添加容忍的规则，这里必须和标记的污点规则相同 1# 添加容忍之前的pod 2[root@k8s-master01 ~]# kubectl get pods -n dev -o wide 3NAME READY STATUS RESTARTS AGE IP NODE NOMINATED 4pod-toleration 0/1 Pending 0 3s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 5 6# 添加容忍之后的pod 7[root@k8s-master01 ~]# kubectl get pods -n dev -o wide 8NAME READY STATUS RESTARTS AGE IP NODE NOMINATED 9pod-toleration 1/1 Running 0 3s 10.244.1.62 node1 \u0026lt;none\u0026gt; 下面看一下容忍的详细配置:\n1[root@k8s-master01 ~]# kubectl explain pod.spec.tolerations 2...... 3FIELDS: 4 key # 对应着要容忍的污点的键，空意味着匹配所有的键 5 value # 对应着要容忍的污点的值 6 operator # key-value的运算符，支持Equal和Exists（默认） 7 effect # 对应污点的effect，空意味着匹配所有影响 8 tolerationSeconds # 容忍时间, 当effect为NoExecute时生效，表示pod在Node上的停留时间 6. Pod控制器详解 6.1 Pod控制器介绍 Pod是kubernetes的最小管理单元，在kubernetes中，按照pod的创建方式可以将其分为两类：\n自主式pod：kubernetes直接创建出来的Pod，这种pod删除后就没有了，也不会重建 控制器创建的pod：kubernetes通过控制器创建的pod，这种pod删除了之后还会自动重建 什么是Pod控制器\nPod控制器是管理pod的中间层，使用Pod控制器之后，只需要告诉Pod控制器，想要多少个什么样的Pod就可以了，它会创建出满足条件的Pod并确保每一个Pod资源处于用户期望的目标状态。如果Pod资源在运行中出现故障，它会基于指定策略重新编排Pod。\n在kubernetes中，有很多类型的pod控制器，每种都有自己的适合的场景，常见的有下面这些：\nReplicationController：比较原始的pod控制器，已经被废弃，由ReplicaSet替代 ReplicaSet：保证副本数量一直维持在期望值，并支持pod数量扩缩容，镜像版本升级 Deployment：通过控制ReplicaSet来控制Pod，并支持滚动升级、回退版本 Horizontal Pod Autoscaler：可以根据集群负载自动水平调整Pod的数量，实现削峰填谷 DaemonSet：在集群中的指定Node上运行且仅运行一个副本，一般用于守护进程类的任务 Job：它创建出来的pod只要完成任务就立即退出，不需要重启或重建，用于执行一次性任务 Cronjob：它创建的Pod负责周期性任务控制，不需要持续后台运行 StatefulSet：管理有状态应用 6.2 ReplicaSet(RS) ReplicaSet的主要作用是保证一定数量的pod正常运行，它会持续监听这些Pod的运行状态，一旦Pod发生故障，就会重启或重建。同时它还支持对pod数量的扩缩容和镜像版本的升降级。\nReplicaSet的资源清单文件：\n1apiVersion: apps/v1 # 版本号 2kind: ReplicaSet # 类型 3metadata: # 元数据 4 name: # rs名称 5 namespace: # 所属命名空间 6 labels: #标签 7 controller: rs 8spec: # 详情描述 9 replicas: 3 # 副本数量 10 selector: # 选择器，通过它指定该控制器管理哪些pod 11 matchLabels: # Labels匹配规则 12 app: nginx-pod 13 matchExpressions: # Expressions匹配规则 14 - {key: app, operator: In, values: [nginx-pod]} 15 template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 16 metadata: 17 labels: 18 app: nginx-pod 19 spec: 20 containers: 21 - name: nginx 22 image: nginx:1.17.1 23 ports: 24 - containerPort: 80 在这里面，需要新了解的配置项就是spec下面几个选项：\nreplicas：指定副本数量，其实就是当前rs创建出来的pod的数量，默认为1\nselector：选择器，它的作用是建立pod控制器和pod之间的关联关系，采用的Label Selector机制\n在pod模板上定义label，在控制器上定义选择器，就可以表明当前控制器能管理哪些pod了\ntemplate：模板，就是当前控制器创建pod所使用的模板板，里面其实就是前一章学过的pod的定义\n创建ReplicaSet\n创建pc-replicaset.yaml文件，内容如下：\n1apiVersion: apps/v1 2kind: ReplicaSet 3metadata: 4 name: pc-replicaset 5 namespace: dev 6spec: 7 replicas: 3 8 selector: 9 matchLabels: 10 app: nginx-pod 11 template: 12 metadata: 13 labels: 14 app: nginx-pod 15 spec: 16 containers: 17 - name: nginx 18 image: nginx:1.17.1 1# 创建rs 2[root@k8s-master01 ~]# kubectl create -f pc-replicaset.yaml 3replicaset.apps/pc-replicaset created 4 5# 查看rs 6# DESIRED:期望副本数量 7# CURRENT:当前副本数量 8# READY:已经准备好提供服务的副本数量 9[root@k8s-master01 ~]# kubectl get rs pc-replicaset -n dev -o wide 10NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR 11pc-replicaset 3 3 3 22s nginx nginx:1.17.1 app=nginx-pod 12 13# 查看当前控制器创建出来的pod 14# 这里发现控制器创建出来的pod的名称是在控制器名称后面拼接了-xxxxx随机码 15[root@k8s-master01 ~]# kubectl get pod -n dev 16NAME READY STATUS RESTARTS AGE 17pc-replicaset-6vmvt 1/1 Running 0 54s 18pc-replicaset-fmb8f 1/1 Running 0 54s 19pc-replicaset-snrk2 1/1 Running 0 54s 扩缩容\n1# 编辑rs的副本数量，修改spec:replicas: 6即可 2[root@k8s-master01 ~]# kubectl edit rs pc-replicaset -n dev 3replicaset.apps/pc-replicaset edited 4 5# 查看pod 6[root@k8s-master01 ~]# kubectl get pods -n dev 7NAME READY STATUS RESTARTS AGE 8pc-replicaset-6vmvt 1/1 Running 0 114m 9pc-replicaset-cftnp 1/1 Running 0 10s 10pc-replicaset-fjlm6 1/1 Running 0 10s 11pc-replicaset-fmb8f 1/1 Running 0 114m 12pc-replicaset-s2whj 1/1 Running 0 10s 13pc-replicaset-snrk2 1/1 Running 0 114m 14 15# 当然也可以直接使用命令实现 16# 使用scale命令实现扩缩容， 后面--replicas=n直接指定目标数量即可 17[root@k8s-master01 ~]# kubectl scale rs pc-replicaset --replicas=2 -n dev 18replicaset.apps/pc-replicaset scaled 19 20# 命令运行完毕，立即查看，发现已经有4个开始准备退出了 21[root@k8s-master01 ~]# kubectl get pods -n dev 22NAME READY STATUS RESTARTS AGE 23pc-replicaset-6vmvt 0/1 Terminating 0 118m 24pc-replicaset-cftnp 0/1 Terminating 0 4m17s 25pc-replicaset-fjlm6 0/1 Terminating 0 4m17s 26pc-replicaset-fmb8f 1/1 Running 0 118m 27pc-replicaset-s2whj 0/1 Terminating 0 4m17s 28pc-replicaset-snrk2 1/1 Running 0 118m 29 30#稍等片刻，就只剩下2个了 31[root@k8s-master01 ~]# kubectl get pods -n dev 32NAME READY STATUS RESTARTS AGE 33pc-replicaset-fmb8f 1/1 Running 0 119m 34pc-replicaset-snrk2 1/1 Running 0 119m 镜像升级\n1# 编辑rs的容器镜像 - image: nginx:1.17.2 2[root@k8s-master01 ~]# kubectl edit rs pc-replicaset -n dev 3replicaset.apps/pc-replicaset edited 4 5# 再次查看，发现镜像版本已经变更了 6[root@k8s-master01 ~]# kubectl get rs -n dev -o wide 7NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES ... 8pc-replicaset 2 2 2 140m nginx nginx:1.17.2 ... 9 10# 同样的道理，也可以使用命令完成这个工作 11# kubectl set image rs rs名称 容器=镜像版本 -n namespace 12[root@k8s-master01 ~]# kubectl set image rs pc-replicaset nginx=nginx:1.17.1 -n dev 13replicaset.apps/pc-replicaset image updated 14 15# 再次查看，发现镜像版本已经变更了 16[root@k8s-master01 ~]# kubectl get rs -n dev -o wide 17NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES ... 18pc-replicaset 2 2 2 145m nginx nginx:1.17.1 ... 删除ReplicaSet\n1# 使用kubectl delete命令会删除此RS以及它管理的Pod 2# 在kubernetes删除RS前，会将RS的replicasclear调整为0，等待所有的Pod被删除后，在执行RS对象的删除 3[root@k8s-master01 ~]# kubectl delete rs pc-replicaset -n dev 4replicaset.apps \u0026#34;pc-replicaset\u0026#34; deleted 5[root@k8s-master01 ~]# kubectl get pod -n dev -o wide 6No resources found in dev namespace. 7 8# 如果希望仅仅删除RS对象（保留Pod），可以使用kubectl delete命令时添加--cascade=false选项（不推荐）。 9[root@k8s-master01 ~]# kubectl delete rs pc-replicaset -n dev --cascade=false 10replicaset.apps \u0026#34;pc-replicaset\u0026#34; deleted 11[root@k8s-master01 ~]# kubectl get pods -n dev 12NAME READY STATUS RESTARTS AGE 13pc-replicaset-cl82j 1/1 Running 0 75s 14pc-replicaset-dslhb 1/1 Running 0 75s 15 16# 也可以使用yaml直接删除(推荐) 17[root@k8s-master01 ~]# kubectl delete -f pc-replicaset.yaml 18replicaset.apps \u0026#34;pc-replicaset\u0026#34; deleted 6.3 Deployment(Deploy) 为了更好的解决服务编排的问题，kubernetes在V1.2版本开始，引入了Deployment控制器。值得一提的是，这种控制器并不直接管理pod，而是通过管理ReplicaSet来简介管理Pod，即：Deployment管理ReplicaSet，ReplicaSet管理Pod。所以Deployment比ReplicaSet功能更加强大。\nDeployment主要功能有下面几个：\n支持ReplicaSet的所有功能 支持发布的停止、继续 支持滚动升级和回滚版本 Deployment的资源清单文件：\n1apiVersion: apps/v1 # 版本号 2kind: Deployment # 类型 3metadata: # 元数据 4 name: # rs名称 5 namespace: # 所属命名空间 6 labels: #标签 7 controller: deploy 8spec: # 详情描述 9 replicas: 3 # 副本数量 10 revisionHistoryLimit: 3 # 保留历史版本 11 paused: false # 暂停部署，默认是false 12 progressDeadlineSeconds: 600 # 部署超时时间（s），默认是600 13 strategy: # 策略 14 type: RollingUpdate # 滚动更新策略 15 rollingUpdate: # 滚动更新 16 maxSurge: 30% # 最大额外可以存在的副本数，可以为百分比，也可以为整数 17 maxUnavailable: 30% # 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数 18 selector: # 选择器，通过它指定该控制器管理哪些pod 19 matchLabels: # Labels匹配规则 20 app: nginx-pod 21 matchExpressions: # Expressions匹配规则 22 - {key: app, operator: In, values: [nginx-pod]} 23 template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 24 metadata: 25 labels: 26 app: nginx-pod 27 spec: 28 containers: 29 - name: nginx 30 image: nginx:1.17.1 31 ports: 32 - containerPort: 80 6.3.1 创建deployment 创建pc-deployment.yaml，内容如下：\n1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: pc-deployment 5 namespace: dev 6spec: 7 replicas: 3 8 selector: 9 matchLabels: 10 app: nginx-pod 11 template: 12 metadata: 13 labels: 14 app: nginx-pod 15 spec: 16 containers: 17 - name: nginx 18 image: nginx:1.17.1 1# 创建deployment 2[root@k8s-master01 ~]# kubectl create -f pc-deployment.yaml --record=true 3deployment.apps/pc-deployment created 4 5# 查看deployment 6# UP-TO-DATE 最新版本的pod的数量 7# AVAILABLE 当前可用的pod的数量 8[root@k8s-master01 ~]# kubectl get deploy pc-deployment -n dev 9NAME READY UP-TO-DATE AVAILABLE AGE 10pc-deployment 3/3 3 3 15s 11 12# 查看rs 13# 发现rs的名称是在原来deployment的名字后面添加了一个10位数的随机串 14[root@k8s-master01 ~]# kubectl get rs -n dev 15NAME DESIRED CURRENT READY AGE 16pc-deployment-6696798b78 3 3 3 23s 17 18# 查看pod 19[root@k8s-master01 ~]# kubectl get pods -n dev 20NAME READY STATUS RESTARTS AGE 21pc-deployment-6696798b78-d2c8n 1/1 Running 0 107s 22pc-deployment-6696798b78-smpvp 1/1 Running 0 107s 23pc-deployment-6696798b78-wvjd8 1/1 Running 0 107s 6.3.2 扩缩容 1# 变更副本数量为5个 2[root@k8s-master01 ~]# kubectl scale deploy pc-deployment --replicas=5 -n dev 3deployment.apps/pc-deployment scaled 4 5# 查看deployment 6[root@k8s-master01 ~]# kubectl get deploy pc-deployment -n dev 7NAME READY UP-TO-DATE AVAILABLE AGE 8pc-deployment 5/5 5 5 2m 9 10# 查看pod 11[root@k8s-master01 ~]# kubectl get pods -n dev 12NAME READY STATUS RESTARTS AGE 13pc-deployment-6696798b78-d2c8n 1/1 Running 0 4m19s 14pc-deployment-6696798b78-jxmdq 1/1 Running 0 94s 15pc-deployment-6696798b78-mktqv 1/1 Running 0 93s 16pc-deployment-6696798b78-smpvp 1/1 Running 0 4m19s 17pc-deployment-6696798b78-wvjd8 1/1 Running 0 4m19s 18 19# 编辑deployment的副本数量，修改spec:replicas: 4即可 20[root@k8s-master01 ~]# kubectl edit deploy pc-deployment -n dev 21deployment.apps/pc-deployment edited 22 23# 查看pod 24[root@k8s-master01 ~]# kubectl get pods -n dev 25NAME READY STATUS RESTARTS AGE 26pc-deployment-6696798b78-d2c8n 1/1 Running 0 5m23s 27pc-deployment-6696798b78-jxmdq 1/1 Running 0 2m38s 28pc-deployment-6696798b78-smpvp 1/1 Running 0 5m23s 29pc-deployment-6696798b78-wvjd8 1/1 Running 0 5m23s 镜像更新\ndeployment支持两种更新策略:重建更新和滚动更新,可以通过strategy指定策略类型,支持两个属性:\n1strategy：指定新的Pod替换旧的Pod的策略， 支持两个属性： 2 type：指定策略类型，支持两种策略 3 Recreate：在创建出新的Pod之前会先杀掉所有已存在的Pod 4 RollingUpdate：滚动更新，就是杀死一部分，就启动一部分，在更新过程中，存在两个版本Pod 5 rollingUpdate：当type为RollingUpdate时生效，用于为RollingUpdate设置参数，支持两个属性： 6 maxUnavailable：用来指定在升级过程中不可用Pod的最大数量，默认为25%。 7 maxSurge： 用来指定在升级过程中可以超过期望的Pod的最大数量，默认为25%。 重建更新\n编辑pc-deployment.yaml,在spec节点下添加更新策略 1spec: 2 strategy: # 策略 3 type: Recreate # 重建更新 创建deploy进行验证 1# 变更镜像 2[root@k8s-master01 ~]# kubectl set image deployment pc-deployment nginx=nginx:1.17.2 -n dev 3deployment.apps/pc-deployment image updated 4 5# 观察升级过程 6[root@k8s-master01 ~]# kubectl get pods -n dev -w 7NAME READY STATUS RESTARTS AGE 8pc-deployment-5d89bdfbf9-65qcw 1/1 Running 0 31s 9pc-deployment-5d89bdfbf9-w5nzv 1/1 Running 0 31s 10pc-deployment-5d89bdfbf9-xpt7w 1/1 Running 0 31s 11 12pc-deployment-5d89bdfbf9-xpt7w 1/1 Terminating 0 41s 13pc-deployment-5d89bdfbf9-65qcw 1/1 Terminating 0 41s 14pc-deployment-5d89bdfbf9-w5nzv 1/1 Terminating 0 41s 15 16pc-deployment-675d469f8b-grn8z 0/1 Pending 0 0s 17pc-deployment-675d469f8b-hbl4v 0/1 Pending 0 0s 18pc-deployment-675d469f8b-67nz2 0/1 Pending 0 0s 19 20pc-deployment-675d469f8b-grn8z 0/1 ContainerCreating 0 0s 21pc-deployment-675d469f8b-hbl4v 0/1 ContainerCreating 0 0s 22pc-deployment-675d469f8b-67nz2 0/1 ContainerCreating 0 0s 23 24pc-deployment-675d469f8b-grn8z 1/1 Running 0 1s 25pc-deployment-675d469f8b-67nz2 1/1 Running 0 1s 26pc-deployment-675d469f8b-hbl4v 1/1 Running 0 2s 滚动更新\n编辑pc-deployment.yaml,在spec节点下添加更新策略 1spec: 2 strategy: # 策略 3 type: RollingUpdate # 滚动更新策略 4 rollingUpdate: 5 maxSurge: 25% 6 maxUnavailable: 25% 创建deploy进行验证 1# 变更镜像 2[root@k8s-master01 ~]# kubectl set image deployment pc-deployment nginx=nginx:1.17.3 -n dev 3deployment.apps/pc-deployment image updated 4 5# 观察升级过程 6[root@k8s-master01 ~]# kubectl get pods -n dev -w 7NAME READY STATUS RESTARTS AGE 8pc-deployment-c848d767-8rbzt 1/1 Running 0 31m 9pc-deployment-c848d767-h4p68 1/1 Running 0 31m 10pc-deployment-c848d767-hlmz4 1/1 Running 0 31m 11pc-deployment-c848d767-rrqcn 1/1 Running 0 31m 12 13pc-deployment-966bf7f44-226rx 0/1 Pending 0 0s 14pc-deployment-966bf7f44-226rx 0/1 ContainerCreating 0 0s 15pc-deployment-966bf7f44-226rx 1/1 Running 0 1s 16pc-deployment-c848d767-h4p68 0/1 Terminating 0 34m 17 18pc-deployment-966bf7f44-cnd44 0/1 Pending 0 0s 19pc-deployment-966bf7f44-cnd44 0/1 ContainerCreating 0 0s 20pc-deployment-966bf7f44-cnd44 1/1 Running 0 2s 21pc-deployment-c848d767-hlmz4 0/1 Terminating 0 34m 22 23pc-deployment-966bf7f44-px48p 0/1 Pending 0 0s 24pc-deployment-966bf7f44-px48p 0/1 ContainerCreating 0 0s 25pc-deployment-966bf7f44-px48p 1/1 Running 0 0s 26pc-deployment-c848d767-8rbzt 0/1 Terminating 0 34m 27 28pc-deployment-966bf7f44-dkmqp 0/1 Pending 0 0s 29pc-deployment-966bf7f44-dkmqp 0/1 ContainerCreating 0 0s 30pc-deployment-966bf7f44-dkmqp 1/1 Running 0 2s 31pc-deployment-c848d767-rrqcn 0/1 Terminating 0 34m 32 33# 至此，新版本的pod创建完毕，就版本的pod销毁完毕 34# 中间过程是滚动进行的，也就是边销毁边创建 滚动更新的过程：\n镜像更新中rs的变化\n1# 查看rs,发现原来的rs的依旧存在，只是pod数量变为了0，而后又新产生了一个rs，pod数量为4 2# 其实这就是deployment能够进行版本回退的奥妙所在，后面会详细解释 3[root@k8s-master01 ~]# kubectl get rs -n dev 4NAME DESIRED CURRENT READY AGE 5pc-deployment-6696798b78 0 0 0 7m37s 6pc-deployment-6696798b11 0 0 0 5m37s 7pc-deployment-c848d76789 4 4 4 72s 6.3.3 版本回退 deployment支持版本升级过程中的暂停、继续功能以及版本回退等诸多功能，下面具体来看.\nkubectl rollout： 版本升级相关功能，支持下面的选项：\nstatus\t显示当前升级状态 history 显示 升级历史记录 pause 暂停版本升级过程 resume 继续已经暂停的版本升级过程 restart 重启版本升级过程 undo 回滚到上一级版本（可以使用\u0026ndash;to-revision回滚到指定版本） 1# 查看当前升级版本的状态 2[root@k8s-master01 ~]# kubectl rollout status deploy pc-deployment -n dev 3deployment \u0026#34;pc-deployment\u0026#34; successfully rolled out 4 5# 查看升级历史记录 6[root@k8s-master01 ~]# kubectl rollout history deploy pc-deployment -n dev 7deployment.apps/pc-deployment 8REVISION CHANGE-CAUSE 91 kubectl create --filename=pc-deployment.yaml --record=true 102 kubectl create --filename=pc-deployment.yaml --record=true 113 kubectl create --filename=pc-deployment.yaml --record=true 12# 可以发现有三次版本记录，说明完成过两次升级 13 14# 版本回滚 15# 这里直接使用--to-revision=1回滚到了1版本， 如果省略这个选项，就是回退到上个版本，就是2版本 16[root@k8s-master01 ~]# kubectl rollout undo deployment pc-deployment --to-revision=1 -n dev 17deployment.apps/pc-deployment rolled back 18 19# 查看发现，通过nginx镜像版本可以发现到了第一版 20[root@k8s-master01 ~]# kubectl get deploy -n dev -o wide 21NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES 22pc-deployment 4/4 4 4 74m nginx nginx:1.17.1 23 24# 查看rs，发现第一个rs中有4个pod运行，后面两个版本的rs中pod为运行 25# 其实deployment之所以可是实现版本的回滚，就是通过记录下历史rs来实现的， 26# 一旦想回滚到哪个版本，只需要将当前版本pod数量降为0，然后将回滚版本的pod提升为目标数量就可以了 27[root@k8s-master01 ~]# kubectl get rs -n dev 28NAME DESIRED CURRENT READY AGE 29pc-deployment-6696798b78 4 4 4 78m 30pc-deployment-966bf7f44 0 0 0 37m 31pc-deployment-c848d767 0 0 0 71m 6.3.4 金丝雀发布 Deployment控制器支持控制更新过程中的控制，如“暂停(pause)”或“继续(resume)”更新操作。\n比如有一批新的Pod资源创建完成后立即暂停更新过程，此时，仅存在一部分新版本的应用，主体部分还是旧的版本。然后，再筛选一小部分的用户请求路由到新版本的Pod应用，继续观察能否稳定地按期望的方式运行。确定没问题之后再继续完成余下的Pod资源滚动更新，否则立即回滚更新操作。这就是所谓的金丝雀发布。\n1# 更新deployment的版本，并配置暂停deployment 2[root@k8s-master01 ~]# kubectl set image deploy pc-deployment nginx=nginx:1.17.4 -n dev \u0026amp;\u0026amp; kubectl rollout pause deployment pc-deployment -n dev 3deployment.apps/pc-deployment image updated 4deployment.apps/pc-deployment paused 5 6#观察更新状态 7[root@k8s-master01 ~]# kubectl rollout status deploy pc-deployment -n dev　8Waiting for deployment \u0026#34;pc-deployment\u0026#34; rollout to finish: 2 out of 4 new replicas have been updated... 9 10# 监控更新的过程，可以看到已经新增了一个资源，但是并未按照预期的状态去删除一个旧的资源，就是因为使用了pause暂停命令 11 12[root@k8s-master01 ~]# kubectl get rs -n dev -o wide 13NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES 14pc-deployment-5d89bdfbf9 3 3 3 19m nginx nginx:1.17.1 15pc-deployment-675d469f8b 0 0 0 14m nginx nginx:1.17.2 16pc-deployment-6c9f56fcfb 2 2 2 3m16s nginx nginx:1.17.4 17[root@k8s-master01 ~]# kubectl get pods -n dev 18NAME READY STATUS RESTARTS AGE 19pc-deployment-5d89bdfbf9-rj8sq 1/1 Running 0 7m33s 20pc-deployment-5d89bdfbf9-ttwgg 1/1 Running 0 7m35s 21pc-deployment-5d89bdfbf9-v4wvc 1/1 Running 0 7m34s 22pc-deployment-6c9f56fcfb-996rt 1/1 Running 0 3m31s 23pc-deployment-6c9f56fcfb-j2gtj 1/1 Running 0 3m31s 24 25# 确保更新的pod没问题了，继续更新 26[root@k8s-master01 ~]# kubectl rollout resume deploy pc-deployment -n dev 27deployment.apps/pc-deployment resumed 28 29# 查看最后的更新情况 30[root@k8s-master01 ~]# kubectl get rs -n dev -o wide 31NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES 32pc-deployment-5d89bdfbf9 0 0 0 21m nginx nginx:1.17.1 33pc-deployment-675d469f8b 0 0 0 16m nginx nginx:1.17.2 34pc-deployment-6c9f56fcfb 4 4 4 5m11s nginx nginx:1.17.4 35 36[root@k8s-master01 ~]# kubectl get pods -n dev 37NAME READY STATUS RESTARTS AGE 38pc-deployment-6c9f56fcfb-7bfwh 1/1 Running 0 37s 39pc-deployment-6c9f56fcfb-996rt 1/1 Running 0 5m27s 40pc-deployment-6c9f56fcfb-j2gtj 1/1 Running 0 5m27s 41pc-deployment-6c9f56fcfb-rf84v 1/1 Running 0 37s 删除Deployment\n1# 删除deployment，其下的rs和pod也将被删除 2[root@k8s-master01 ~]# kubectl delete -f pc-deployment.yaml 3deployment.apps \u0026#34;pc-deployment\u0026#34; deleted 6.4 Horizontal Pod Autoscaler(HPA) 在前面的课程中，我们已经可以实现通过手工执行kubectl scale命令实现Pod扩容或缩容，但是这显然不符合Kubernetes的定位目标\u0026ndash;自动化、智能化。 Kubernetes期望可以实现通过监测Pod的使用情况，实现pod数量的自动调整，于是就产生了Horizontal Pod Autoscaler（HPA）这种控制器。\nHPA可以获取每个Pod利用率，然后和HPA中定义的指标进行对比，同时计算出需要伸缩的具体值，最后实现Pod的数量的调整。其实HPA与之前的Deployment一样，也属于一种Kubernetes资源对象，它通过追踪分析RC控制的所有目标Pod的负载变化情况，来确定是否需要针对性地调整目标Pod的副本数，这是HPA的实现原理。\n接下来，我们来做一个实验\n6.4.1 安装metrics-server metrics-server可以用来收集集群中的资源使用情况\n1# 安装git 2[root@k8s-master01 ~]# yum install git -y 3# 获取metrics-server, 注意使用的版本 4[root@k8s-master01 ~]# git clone -b v0.3.6 https://github.com/kubernetes-incubator/metrics-server 5# 修改deployment, 注意修改的是镜像和初始化参数 6[root@k8s-master01 ~]# cd /root/metrics-server/deploy/1.8+/ 7[root@k8s-master01 1.8+]# vim metrics-server-deployment.yaml 8按图中添加下面选项 9hostNetwork: true 10image: registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server-amd64:v0.3.6 11args: 12- --kubelet-insecure-tls 13- --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP 1# 安装metrics-server 2[root@k8s-master01 1.8+]# kubectl apply -f ./ 3 4# 查看pod运行情况 5[root@k8s-master01 1.8+]# kubectl get pod -n kube-system 6metrics-server-6b976979db-2xwbj 1/1 Running 0 90s 7 8# 使用kubectl top node 查看资源使用情况 9[root@k8s-master01 1.8+]# kubectl top node 10NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% 11k8s-master01 289m 14% 1582Mi 54% 12k8s-node01 81m 4% 1195Mi 40% 13k8s-node02 72m 3% 1211Mi 41% 14[root@k8s-master01 1.8+]# kubectl top pod -n kube-system 15NAME CPU(cores) MEMORY(bytes) 16coredns-6955765f44-7ptsb 3m 9Mi 17coredns-6955765f44-vcwr5 3m 8Mi 18etcd-master 14m 145Mi 19... 20# 至此,metrics-server安装完成 6.4.2 准备deployment和servie 创建pc-hpa-pod.yaml文件，内容如下：\n1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: nginx 5 namespace: dev 6spec: 7 strategy: # 策略 8 type: RollingUpdate # 滚动更新策略 9 replicas: 1 10 selector: 11 matchLabels: 12 app: nginx-pod 13 template: 14 metadata: 15 labels: 16 app: nginx-pod 17 spec: 18 containers: 19 - name: nginx 20 image: nginx:1.17.1 21 resources: # 资源配额 22 limits: # 限制资源（上限） 23 cpu: \u0026#34;1\u0026#34; # CPU限制，单位是core数 24 requests: # 请求资源（下限） 25 cpu: \u0026#34;100m\u0026#34; # CPU限制，单位是core数 1# 创建deployment 2[root@k8s-master01 1.8+]# kubectl run nginx --image=nginx:1.17.1 --requests=cpu=100m -n dev 3# 创建service 4[root@k8s-master01 1.8+]# kubectl expose deployment nginx --type=NodePort --port=80 -n dev 1# 查看 2[root@k8s-master01 1.8+]# kubectl get deployment,pod,svc -n dev 3NAME READY UP-TO-DATE AVAILABLE AGE 4deployment.apps/nginx 1/1 1 1 47s 5 6NAME READY STATUS RESTARTS AGE 7pod/nginx-7df9756ccc-bh8dr 1/1 Running 0 47s 8 9NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE 10service/nginx NodePort 10.101.18.29 \u0026lt;none\u0026gt; 80:31830/TCP 35s 6.4.3 部署HPA 创建pc-hpa.yaml文件，内容如下：\n1apiVersion: autoscaling/v1 2kind: HorizontalPodAutoscaler 3metadata: 4 name: pc-hpa 5 namespace: dev 6spec: 7 minReplicas: 1 #最小pod数量 8 maxReplicas: 10 #最大pod数量 9 targetCPUUtilizationPercentage: 3 # CPU使用率指标 10 scaleTargetRef: # 指定要控制的nginx信息 11 apiVersion: /v1 12 kind: Deployment 13 name: nginx 1# 创建hpa 2[root@k8s-master01 1.8+]# kubectl create -f pc-hpa.yaml 3horizontalpodautoscaler.autoscaling/pc-hpa created 4 5# 查看hpa 6 [root@k8s-master01 1.8+]# kubectl get hpa -n dev 7NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE 8pc-hpa Deployment/nginx 0%/3% 1 10 1 62s 6.4.4 测试 使用压测工具对service地址192.168.5.4:31830进行压测，然后通过控制台查看hpa和pod的变化\nhpa变化\n1[root@k8s-master01 ~]# kubectl get hpa -n dev -w 2NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE 3pc-hpa Deployment/nginx 0%/3% 1 10 1 4m11s 4pc-hpa Deployment/nginx 0%/3% 1 10 1 5m19s 5pc-hpa Deployment/nginx 22%/3% 1 10 1 6m50s 6pc-hpa Deployment/nginx 22%/3% 1 10 4 7m5s 7pc-hpa Deployment/nginx 22%/3% 1 10 8 7m21s 8pc-hpa Deployment/nginx 6%/3% 1 10 8 7m51s 9pc-hpa Deployment/nginx 0%/3% 1 10 8 9m6s 10pc-hpa Deployment/nginx 0%/3% 1 10 8 13m 11pc-hpa Deployment/nginx 0%/3% 1 10 1 14m deployment变化\n1[root@k8s-master01 ~]# kubectl get deployment -n dev -w 2NAME READY UP-TO-DATE AVAILABLE AGE 3nginx 1/1 1 1 11m 4nginx 1/4 1 1 13m 5nginx 1/4 1 1 13m 6nginx 1/4 1 1 13m 7nginx 1/4 4 1 13m 8nginx 1/8 4 1 14m 9nginx 1/8 4 1 14m 10nginx 1/8 4 1 14m 11nginx 1/8 8 1 14m 12nginx 2/8 8 2 14m 13nginx 3/8 8 3 14m 14nginx 4/8 8 4 14m 15nginx 5/8 8 5 14m 16nginx 6/8 8 6 14m 17nginx 7/8 8 7 14m 18nginx 8/8 8 8 15m 19nginx 8/1 8 8 20m 20nginx 8/1 8 8 20m 21nginx 1/1 1 1 20m pod变化\n1[root@k8s-master01 ~]# kubectl get pods -n dev -w 2NAME READY STATUS RESTARTS AGE 3nginx-7df9756ccc-bh8dr 1/1 Running 0 11m 4nginx-7df9756ccc-cpgrv 0/1 Pending 0 0s 5nginx-7df9756ccc-8zhwk 0/1 Pending 0 0s 6nginx-7df9756ccc-rr9bn 0/1 Pending 0 0s 7nginx-7df9756ccc-cpgrv 0/1 ContainerCreating 0 0s 8nginx-7df9756ccc-8zhwk 0/1 ContainerCreating 0 0s 9nginx-7df9756ccc-rr9bn 0/1 ContainerCreating 0 0s 10nginx-7df9756ccc-m9gsj 0/1 Pending 0 0s 11nginx-7df9756ccc-g56qb 0/1 Pending 0 0s 12nginx-7df9756ccc-sl9c6 0/1 Pending 0 0s 13nginx-7df9756ccc-fgst7 0/1 Pending 0 0s 14nginx-7df9756ccc-g56qb 0/1 ContainerCreating 0 0s 15nginx-7df9756ccc-m9gsj 0/1 ContainerCreating 0 0s 16nginx-7df9756ccc-sl9c6 0/1 ContainerCreating 0 0s 17nginx-7df9756ccc-fgst7 0/1 ContainerCreating 0 0s 18nginx-7df9756ccc-8zhwk 1/1 Running 0 19s 19nginx-7df9756ccc-rr9bn 1/1 Running 0 30s 20nginx-7df9756ccc-m9gsj 1/1 Running 0 21s 21nginx-7df9756ccc-cpgrv 1/1 Running 0 47s 22nginx-7df9756ccc-sl9c6 1/1 Running 0 33s 23nginx-7df9756ccc-g56qb 1/1 Running 0 48s 24nginx-7df9756ccc-fgst7 1/1 Running 0 66s 25nginx-7df9756ccc-fgst7 1/1 Terminating 0 6m50s 26nginx-7df9756ccc-8zhwk 1/1 Terminating 0 7m5s 27nginx-7df9756ccc-cpgrv 1/1 Terminating 0 7m5s 28nginx-7df9756ccc-g56qb 1/1 Terminating 0 6m50s 29nginx-7df9756ccc-rr9bn 1/1 Terminating 0 7m5s 30nginx-7df9756ccc-m9gsj 1/1 Terminating 0 6m50s 31nginx-7df9756ccc-sl9c6 1/1 Terminating 0 6m50s 6.5 DaemonSet(DS) DaemonSet类型的控制器可以保证在集群中的每一台（或指定）节点上都运行一个副本。一般适用于日志收集、节点监控等场景。也就是说，如果一个Pod提供的功能是节点级别的（每个节点都需要且只需要一个），那么这类Pod就适合使用DaemonSet类型的控制器创建。\nDaemonSet控制器的特点：\n每当向集群中添加一个节点时，指定的 Pod 副本也将添加到该节点上 当节点从集群中移除时，Pod 也就被垃圾回收了 下面先来看下DaemonSet的资源清单文件\n1apiVersion: apps/v1 # 版本号 2kind: DaemonSet # 类型 3metadata: # 元数据 4 name: # rs名称 5 namespace: # 所属命名空间 6 labels: #标签 7 controller: daemonset 8spec: # 详情描述 9 revisionHistoryLimit: 3 # 保留历史版本 10 updateStrategy: # 更新策略 11 type: RollingUpdate # 滚动更新策略 12 rollingUpdate: # 滚动更新 13 maxUnavailable: 1 # 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数 14 selector: # 选择器，通过它指定该控制器管理哪些pod 15 matchLabels: # Labels匹配规则 16 app: nginx-pod 17 matchExpressions: # Expressions匹配规则 18 - {key: app, operator: In, values: [nginx-pod]} 19 template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 20 metadata: 21 labels: 22 app: nginx-pod 23 spec: 24 containers: 25 - name: nginx 26 image: nginx:1.17.1 27 ports: 28 - containerPort: 80 创建pc-daemonset.yaml，内容如下：\n1apiVersion: apps/v1 2kind: DaemonSet 3metadata: 4 name: pc-daemonset 5 namespace: dev 6spec: 7 selector: 8 matchLabels: 9 app: nginx-pod 10 template: 11 metadata: 12 labels: 13 app: nginx-pod 14 spec: 15 containers: 16 - name: nginx 17 image: nginx:1.17.1 1# 创建daemonset 2[root@k8s-master01 ~]# kubectl create -f pc-daemonset.yaml 3daemonset.apps/pc-daemonset created 4 5# 查看daemonset 6[root@k8s-master01 ~]# kubectl get ds -n dev -o wide 7NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES 8pc-daemonset 2 2 2 2 2 24s nginx nginx:1.17.1 9 10# 查看pod,发现在每个Node上都运行一个pod 11[root@k8s-master01 ~]# kubectl get pods -n dev -o wide 12NAME READY STATUS RESTARTS AGE IP NODE 13pc-daemonset-9bck8 1/1 Running 0 37s 10.244.1.43 node1 14pc-daemonset-k224w 1/1 Running 0 37s 10.244.2.74 node2 15 16# 删除daemonset 17[root@k8s-master01 ~]# kubectl delete -f pc-daemonset.yaml 18daemonset.apps \u0026#34;pc-daemonset\u0026#34; deleted 6.6 Job Job，主要用于负责**批量处理(一次要处理指定数量任务)短暂的一次性(每个任务仅运行一次就结束)**任务。Job特点如下：\n当Job创建的pod执行成功结束时，Job将记录成功结束的pod数量 当成功结束的pod达到指定的数量时，Job将完成执行 Job的资源清单文件：\n1apiVersion: batch/v1 # 版本号 2kind: Job # 类型 3metadata: # 元数据 4 name: # rs名称 5 namespace: # 所属命名空间 6 labels: #标签 7 controller: job 8spec: # 详情描述 9 completions: 1 # 指定job需要成功运行Pods的次数。默认值: 1 10 parallelism: 1 # 指定job在任一时刻应该并发运行Pods的数量。默认值: 1 11 activeDeadlineSeconds: 30 # 指定job可运行的时间期限，超过时间还未结束，系统将会尝试进行终止。 12 backoffLimit: 6 # 指定job失败后进行重试的次数。默认是6 13 manualSelector: true # 是否可以使用selector选择器选择pod，默认是false 14 selector: # 选择器，通过它指定该控制器管理哪些pod 15 matchLabels: # Labels匹配规则 16 app: counter-pod 17 matchExpressions: # Expressions匹配规则 18 - {key: app, operator: In, values: [counter-pod]} 19 template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 20 metadata: 21 labels: 22 app: counter-pod 23 spec: 24 restartPolicy: Never # 重启策略只能设置为Never或者OnFailure 25 containers: 26 - name: counter 27 image: busybox:1.30 28 command: [\u0026#34;bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 2;done\u0026#34;] 1关于重启策略设置的说明： 2 如果指定为OnFailure，则job会在pod出现故障时重启容器，而不是创建pod，failed次数不变 3 如果指定为Never，则job会在pod出现故障时创建新的pod，并且故障pod不会消失，也不会重启，failed次数加1 4 如果指定为Always的话，就意味着一直重启，意味着job任务会重复去执行了，当然不对，所以不能设置为Always 创建pc-job.yaml，内容如下：\n1apiVersion: batch/v1 2kind: Job 3metadata: 4 name: pc-job 5 namespace: dev 6spec: 7 manualSelector: true 8 selector: 9 matchLabels: 10 app: counter-pod 11 template: 12 metadata: 13 labels: 14 app: counter-pod 15 spec: 16 restartPolicy: Never 17 containers: 18 - name: counter 19 image: busybox:1.30 20 command: [\u0026#34;bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 3;done\u0026#34;] 1# 创建job 2[root@k8s-master01 ~]# kubectl create -f pc-job.yaml 3job.batch/pc-job created 4 5# 查看job 6[root@k8s-master01 ~]# kubectl get job -n dev -o wide -w 7NAME COMPLETIONS DURATION AGE CONTAINERS IMAGES SELECTOR 8pc-job 0/1 21s 21s counter busybox:1.30 app=counter-pod 9pc-job 1/1 31s 79s counter busybox:1.30 app=counter-pod 10 11# 通过观察pod状态可以看到，pod在运行完毕任务后，就会变成Completed状态 12[root@k8s-master01 ~]# kubectl get pods -n dev -w 13NAME READY STATUS RESTARTS AGE 14pc-job-rxg96 1/1 Running 0 29s 15pc-job-rxg96 0/1 Completed 0 33s 16 17# 接下来，调整下pod运行的总数量和并行数量 即：在spec下设置下面两个选项 18# completions: 6 # 指定job需要成功运行Pods的次数为6 19# parallelism: 3 # 指定job并发运行Pods的数量为3 20# 然后重新运行job，观察效果，此时会发现，job会每次运行3个pod，总共执行了6个pod 21[root@k8s-master01 ~]# kubectl get pods -n dev -w 22NAME READY STATUS RESTARTS AGE 23pc-job-684ft 1/1 Running 0 5s 24pc-job-jhj49 1/1 Running 0 5s 25pc-job-pfcvh 1/1 Running 0 5s 26pc-job-684ft 0/1 Completed 0 11s 27pc-job-v7rhr 0/1 Pending 0 0s 28pc-job-v7rhr 0/1 Pending 0 0s 29pc-job-v7rhr 0/1 ContainerCreating 0 0s 30pc-job-jhj49 0/1 Completed 0 11s 31pc-job-fhwf7 0/1 Pending 0 0s 32pc-job-fhwf7 0/1 Pending 0 0s 33pc-job-pfcvh 0/1 Completed 0 11s 34pc-job-5vg2j 0/1 Pending 0 0s 35pc-job-fhwf7 0/1 ContainerCreating 0 0s 36pc-job-5vg2j 0/1 Pending 0 0s 37pc-job-5vg2j 0/1 ContainerCreating 0 0s 38pc-job-fhwf7 1/1 Running 0 2s 39pc-job-v7rhr 1/1 Running 0 2s 40pc-job-5vg2j 1/1 Running 0 3s 41pc-job-fhwf7 0/1 Completed 0 12s 42pc-job-v7rhr 0/1 Completed 0 12s 43pc-job-5vg2j 0/1 Completed 0 12s 44 45# 删除job 46[root@k8s-master01 ~]# kubectl delete -f pc-job.yaml 47job.batch \u0026#34;pc-job\u0026#34; deleted 6.7 CronJob(CJ) CronJob控制器以 Job控制器资源为其管控对象，并借助它管理pod资源对象，Job控制器定义的作业任务在其控制器资源创建之后便会立即执行，但CronJob可以以类似于Linux操作系统的周期性任务作业计划的方式控制其运行时间点及重复运行的方式。也就是说，CronJob可以在特定的时间点(反复的)去运行job任务。\nCronJob的资源清单文件：\n1apiVersion: batch/v1beta1 # 版本号 2kind: CronJob # 类型 3metadata: # 元数据 4 name: # rs名称 5 namespace: # 所属命名空间 6 labels: #标签 7 controller: cronjob 8spec: # 详情描述 9 schedule: # cron格式的作业调度运行时间点,用于控制任务在什么时间执行 10 concurrencyPolicy: # 并发执行策略，用于定义前一次作业运行尚未完成时是否以及如何运行后一次的作业 11 failedJobHistoryLimit: # 为失败的任务执行保留的历史记录数，默认为1 12 successfulJobHistoryLimit: # 为成功的任务执行保留的历史记录数，默认为3 13 startingDeadlineSeconds: # 启动作业错误的超时时长 14 jobTemplate: # job控制器模板，用于为cronjob控制器生成job对象;下面其实就是job的定义 15 metadata: 16 spec: 17 completions: 1 18 parallelism: 1 19 activeDeadlineSeconds: 30 20 backoffLimit: 6 21 manualSelector: true 22 selector: 23 matchLabels: 24 app: counter-pod 25 matchExpressions: 规则 26 - {key: app, operator: In, values: [counter-pod]} 27 template: 28 metadata: 29 labels: 30 app: counter-pod 31 spec: 32 restartPolicy: Never 33 containers: 34 - name: counter 35 image: busybox:1.30 36 command: [\u0026#34;bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 20;done\u0026#34;] 1需要重点解释的几个选项： 2schedule: cron表达式，用于指定任务的执行时间 3 */1 * * * * 4 \u0026lt;分钟\u0026gt; \u0026lt;小时\u0026gt; \u0026lt;日\u0026gt; \u0026lt;月份\u0026gt; \u0026lt;星期\u0026gt; 5 6 分钟 值从 0 到 59. 7 小时 值从 0 到 23. 8 日 值从 1 到 31. 9 月 值从 1 到 12. 10 星期 值从 0 到 6, 0 代表星期日 11 多个时间可以用逗号隔开； 范围可以用连字符给出；*可以作为通配符； /表示每... 12concurrencyPolicy: 13 Allow: 允许Jobs并发运行(默认) 14 Forbid: 禁止并发运行，如果上一次运行尚未完成，则跳过下一次运行 15 Replace: 替换，取消当前正在运行的作业并用新作业替换它 创建pc-cronjob.yaml，内容如下：\n1apiVersion: batch/v1beta1 2kind: CronJob 3metadata: 4 name: pc-cronjob 5 namespace: dev 6 labels: 7 controller: cronjob 8spec: 9 schedule: \u0026#34;*/1 * * * *\u0026#34; 10 jobTemplate: 11 metadata: 12 spec: 13 template: 14 spec: 15 restartPolicy: Never 16 containers: 17 - name: counter 18 image: busybox:1.30 19 command: [\u0026#34;bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 3;done\u0026#34;] 1# 创建cronjob 2[root@k8s-master01 ~]# kubectl create -f pc-cronjob.yaml 3cronjob.batch/pc-cronjob created 4 5# 查看cronjob 6[root@k8s-master01 ~]# kubectl get cronjobs -n dev 7NAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE 8pc-cronjob */1 * * * * False 0 \u0026lt;none\u0026gt; 6s 9 10# 查看job 11[root@k8s-master01 ~]# kubectl get jobs -n dev 12NAME COMPLETIONS DURATION AGE 13pc-cronjob-1592587800 1/1 28s 3m26s 14pc-cronjob-1592587860 1/1 28s 2m26s 15pc-cronjob-1592587920 1/1 28s 86s 16 17# 查看pod 18[root@k8s-master01 ~]# kubectl get pods -n dev 19pc-cronjob-1592587800-x4tsm 0/1 Completed 0 2m24s 20pc-cronjob-1592587860-r5gv4 0/1 Completed 0 84s 21pc-cronjob-1592587920-9dxxq 1/1 Running 0 24s 22 23 24# 删除cronjob 25[root@k8s-master01 ~]# kubectl delete -f pc-cronjob.yaml 26cronjob.batch \u0026#34;pc-cronjob\u0026#34; deleted 7. Service详解 7.1 Service介绍 在kubernetes中，pod是应用程序的载体，我们可以通过pod的ip来访问应用程序，但是pod的ip地址不是固定的，这也就意味着不方便直接采用pod的ip对服务进行访问。\n为了解决这个问题，kubernetes提供了Service资源，Service会对提供同一个服务的多个pod进行聚合，并且提供一个统一的入口地址。通过访问Service的入口地址就能访问到后面的pod服务。\nService在很多情况下只是一个概念，真正起作用的其实是kube-proxy服务进程，每个Node节点上都运行着一个kube-proxy服务进程。当创建Service的时候会通过api-server向etcd写入创建的service的信息，而kube-proxy会基于监听的机制发现这种Service的变动，然后它会将最新的Service信息转换成对应的访问规则。\n1# 10.97.97.97:80 是service提供的访问入口 2# 当访问这个入口的时候，可以发现后面有三个pod的服务在等待调用， 3# kube-proxy会基于rr（轮询）的策略，将请求分发到其中一个pod上去 4# 这个规则会同时在集群内的所有节点上都生成，所以在任何一个节点上访问都可以。 5[root@node1 ~]# ipvsadm -Ln 6IP Virtual Server version 1.2.1 (size=4096) 7Prot LocalAddress:Port Scheduler Flags 8 -\u0026gt; RemoteAddress:Port Forward Weight ActiveConn InActConn 9TCP 10.97.97.97:80 rr 10 -\u0026gt; 10.244.1.39:80 Masq 1 0 0 11 -\u0026gt; 10.244.1.40:80 Masq 1 0 0 12 -\u0026gt; 10.244.2.33:80 Masq 1 0 0 kube-proxy目前支持三种工作模式:\n7.1.1 userspace 模式 userspace模式下，kube-proxy会为每一个Service创建一个监听端口，发向Cluster IP的请求被Iptables规则重定向到kube-proxy监听的端口上，kube-proxy根据LB算法选择一个提供服务的Pod并和其建立链接，以将请求转发到Pod上。 该模式下，kube-proxy充当了一个四层负责均衡器的角色。由于kube-proxy运行在userspace中，在进行转发处理时会增加内核和用户空间之间的数据拷贝，虽然比较稳定，但是效率比较低。\n7.1.2 iptables 模式 iptables模式下，kube-proxy为service后端的每个Pod创建对应的iptables规则，直接将发向Cluster IP的请求重定向到一个Pod IP。 该模式下kube-proxy不承担四层负责均衡器的角色，只负责创建iptables规则。该模式的优点是较userspace模式效率更高，但不能提供灵活的LB策略，当后端Pod不可用时也无法进行重试。\n7.1.3 ipvs 模式 ipvs模式和iptables类似，kube-proxy监控Pod的变化并创建相应的ipvs规则。ipvs相对iptables转发效率更高。除此以外，ipvs支持更多的LB算法。\n1# 此模式必须安装ipvs内核模块，否则会降级为iptables 2# 开启ipvs 3[root@k8s-master01 ~]# kubectl edit cm kube-proxy -n kube-system 4# 修改mode: \u0026#34;ipvs\u0026#34; 5[root@k8s-master01 ~]# kubectl delete pod -l k8s-app=kube-proxy -n kube-system 6[root@node1 ~]# ipvsadm -Ln 7IP Virtual Server version 1.2.1 (size=4096) 8Prot LocalAddress:Port Scheduler Flags 9 -\u0026gt; RemoteAddress:Port Forward Weight ActiveConn InActConn 10TCP 10.97.97.97:80 rr 11 -\u0026gt; 10.244.1.39:80 Masq 1 0 0 12 -\u0026gt; 10.244.1.40:80 Masq 1 0 0 13 -\u0026gt; 10.244.2.33:80 Masq 1 0 0 7.2 Service类型 Service的资源清单文件：\n1kind: Service # 资源类型 2apiVersion: v1 # 资源版本 3metadata: # 元数据 4 name: service # 资源名称 5 namespace: dev # 命名空间 6spec: # 描述 7 selector: # 标签选择器，用于确定当前service代理哪些pod 8 app: nginx 9 type: # Service类型，指定service的访问方式 10 clusterIP: # 虚拟服务的ip地址 11 sessionAffinity: # session亲和性，支持ClientIP、None两个选项 12 ports: # 端口信息 13 - protocol: TCP 14 port: 3017 # service端口 15 targetPort: 5003 # pod端口 16 nodePort: 31122 # 主机端口 ClusterIP：默认值，它是Kubernetes系统自动分配的虚拟IP，只能在集群内部访问 NodePort：将Service通过指定的Node上的端口暴露给外部，通过此方法，就可以在集群外部访问服务 LoadBalancer：使用外接负载均衡器完成到服务的负载分发，注意此模式需要外部云环境支持 ExternalName： 把集群外部的服务引入集群内部，直接使用 7.3 Service使用 7.3.1 实验环境准备 在使用service之前，首先利用Deployment创建出3个pod，注意要为pod设置app=nginx-pod的标签\n创建deployment.yaml，内容如下：\n1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: pc-deployment 5 namespace: dev 6spec: 7 replicas: 3 8 selector: 9 matchLabels: 10 app: nginx-pod 11 template: 12 metadata: 13 labels: 14 app: nginx-pod 15 spec: 16 containers: 17 - name: nginx 18 image: nginx:1.17.1 19 ports: 20 - containerPort: 80 1[root@k8s-master01 ~]# kubectl create -f deployment.yaml 2deployment.apps/pc-deployment created 3 4# 查看pod详情 5[root@k8s-master01 ~]# kubectl get pods -n dev -o wide --show-labels 6NAME READY STATUS IP NODE LABELS 7pc-deployment-66cb59b984-8p84h 1/1 Running 10.244.1.39 node1 app=nginx-pod 8pc-deployment-66cb59b984-vx8vx 1/1 Running 10.244.2.33 node2 app=nginx-pod 9pc-deployment-66cb59b984-wnncx 1/1 Running 10.244.1.40 node1 app=nginx-pod 10 11# 为了方便后面的测试，修改下三台nginx的index.html页面（三台修改的IP地址不一致） 12# kubectl exec -it pc-deployment-66cb59b984-8p84h -n dev /bin/sh 13# echo \u0026#34;10.244.1.39\u0026#34; \u0026gt; /usr/share/nginx/html/index.html 14 15#修改完毕之后，访问测试 16[root@k8s-master01 ~]# curl 10.244.1.39 1710.244.1.39 18[root@k8s-master01 ~]# curl 10.244.2.33 1910.244.2.33 20[root@k8s-master01 ~]# curl 10.244.1.40 2110.244.1.40 7.3.2 ClusterIP类型的Service 创建service-clusterip.yaml文件\n1apiVersion: v1 2kind: Service 3metadata: 4 name: service-clusterip 5 namespace: dev 6spec: 7 selector: 8 app: nginx-pod 9 clusterIP: 10.97.97.97 # service的ip地址，如果不写，默认会生成一个 10 type: ClusterIP 11 ports: 12 - port: 80 # Service端口 13 targetPort: 80 # pod端口 1# 创建service 2[root@k8s-master01 ~]# kubectl create -f service-clusterip.yaml 3service/service-clusterip created 4 5# 查看service 6[root@k8s-master01 ~]# kubectl get svc -n dev -o wide 7NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR 8service-clusterip ClusterIP 10.97.97.97 \u0026lt;none\u0026gt; 80/TCP 13s app=nginx-pod 9 10# 查看service的详细信息 11# 在这里有一个Endpoints列表，里面就是当前service可以负载到的服务入口 12[root@k8s-master01 ~]# kubectl describe svc service-clusterip -n dev 13Name: service-clusterip 14Namespace: dev 15Labels: \u0026lt;none\u0026gt; 16Annotations: \u0026lt;none\u0026gt; 17Selector: app=nginx-pod 18Type: ClusterIP 19IP: 10.97.97.97 20Port: \u0026lt;unset\u0026gt; 80/TCP 21TargetPort: 80/TCP 22Endpoints: 10.244.1.39:80,10.244.1.40:80,10.244.2.33:80 23Session Affinity: None 24Events: \u0026lt;none\u0026gt; 25 26# 查看ipvs的映射规则 27[root@k8s-master01 ~]# ipvsadm -Ln 28TCP 10.97.97.97:80 rr 29 -\u0026gt; 10.244.1.39:80 Masq 1 0 0 30 -\u0026gt; 10.244.1.40:80 Masq 1 0 0 31 -\u0026gt; 10.244.2.33:80 Masq 1 0 0 32 33# 访问10.97.97.97:80观察效果 34[root@k8s-master01 ~]# curl 10.97.97.97:80 3510.244.2.33 7.3.3 Endpoint Endpoint是kubernetes中的一个资源对象，存储在etcd中，用来记录一个service对应的所有pod的访问地址，它是根据service配置文件中selector描述产生的。\n一个Service由一组Pod组成，这些Pod通过Endpoints暴露出来，Endpoints是实现实际服务的端点集合。换句话说，service和pod之间的联系是通过endpoints实现的。\n负载分发策略\n对Service的访问被分发到了后端的Pod上去，目前kubernetes提供了两种负载分发策略：\n如果不定义，默认使用kube-proxy的策略，比如随机、轮询\n基于客户端地址的会话保持模式，即来自同一个客户端发起的所有请求都会转发到固定的一个Pod上\n此模式可以使在spec中添加sessionAffinity:ClientIP选项\n1# 查看ipvs的映射规则【rr 轮询】 2[root@k8s-master01 ~]# ipvsadm -Ln 3TCP 10.97.97.97:80 rr 4 -\u0026gt; 10.244.1.39:80 Masq 1 0 0 5 -\u0026gt; 10.244.1.40:80 Masq 1 0 0 6 -\u0026gt; 10.244.2.33:80 Masq 1 0 0 7 8# 循环访问测试 9[root@k8s-master01 ~]# while true;do curl 10.97.97.97:80; sleep 5; done; 1010.244.1.40 1110.244.1.39 1210.244.2.33 1310.244.1.40 1410.244.1.39 1510.244.2.33 16 17# 修改分发策略----sessionAffinity:ClientIP 18 19# 查看ipvs规则【persistent 代表持久】 20[root@k8s-master01 ~]# ipvsadm -Ln 21TCP 10.97.97.97:80 rr persistent 10800 22 -\u0026gt; 10.244.1.39:80 Masq 1 0 0 23 -\u0026gt; 10.244.1.40:80 Masq 1 0 0 24 -\u0026gt; 10.244.2.33:80 Masq 1 0 0 25 26# 循环访问测试 27[root@k8s-master01 ~]# while true;do curl 10.97.97.97; sleep 5; done; 2810.244.2.33 2910.244.2.33 3010.244.2.33 31 32# 删除service 33[root@k8s-master01 ~]# kubectl delete -f service-clusterip.yaml 34service \u0026#34;service-clusterip\u0026#34; deleted 7.3.4 HeadLiness类型的Service 在某些场景中，开发人员可能不想使用Service提供的负载均衡功能，而希望自己来控制负载均衡策略，针对这种情况，kubernetes提供了HeadLiness Service，这类Service不会分配Cluster IP，如果想要访问service，只能通过service的域名进行查询。\n创建service-headliness.yaml\n1apiVersion: v1 2kind: Service 3metadata: 4 name: service-headliness 5 namespace: dev 6spec: 7 selector: 8 app: nginx-pod 9 clusterIP: None # 将clusterIP设置为None，即可创建headliness Service 10 type: ClusterIP 11 ports: 12 - port: 80 13 targetPort: 80 1# 创建service 2[root@k8s-master01 ~]# kubectl create -f service-headliness.yaml 3service/service-headliness created 4 5# 获取service， 发现CLUSTER-IP未分配 6[root@k8s-master01 ~]# kubectl get svc service-headliness -n dev -o wide 7NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR 8service-headliness ClusterIP None \u0026lt;none\u0026gt; 80/TCP 11s app=nginx-pod 9 10# 查看service详情 11[root@k8s-master01 ~]# kubectl describe svc service-headliness -n dev 12Name: service-headliness 13Namespace: dev 14Labels: \u0026lt;none\u0026gt; 15Annotations: \u0026lt;none\u0026gt; 16Selector: app=nginx-pod 17Type: ClusterIP 18IP: None 19Port: \u0026lt;unset\u0026gt; 80/TCP 20TargetPort: 80/TCP 21Endpoints: 10.244.1.39:80,10.244.1.40:80,10.244.2.33:80 22Session Affinity: None 23Events: \u0026lt;none\u0026gt; 24 25# 查看域名的解析情况 26[root@k8s-master01 ~]# kubectl exec -it pc-deployment-66cb59b984-8p84h -n dev /bin/sh 27/ # cat /etc/resolv.conf 28nameserver 10.96.0.10 29search dev.svc.cluster.local svc.cluster.local cluster.local 30 31[root@k8s-master01 ~]# dig @10.96.0.10 service-headliness.dev.svc.cluster.local 32service-headliness.dev.svc.cluster.local. 30 IN A 10.244.1.40 33service-headliness.dev.svc.cluster.local. 30 IN A 10.244.1.39 34service-headliness.dev.svc.cluster.local. 30 IN A 10.244.2.33 7.3.5 NodePort类型的Service 在之前的样例中，创建的Service的ip地址只有集群内部才可以访问，如果希望将Service暴露给集群外部使用，那么就要使用到另外一种类型的Service，称为NodePort类型。NodePort的工作原理其实就是将service的端口映射到Node的一个端口上，然后就可以通过NodeIp:NodePort来访问service了。\n创建service-nodeport.yaml\n1apiVersion: v1 2kind: Service 3metadata: 4 name: service-nodeport 5 namespace: dev 6spec: 7 selector: 8 app: nginx-pod 9 type: NodePort # service类型 10 ports: 11 - port: 80 12 nodePort: 30002 # 指定绑定的node的端口(默认的取值范围是：30000-32767), 如果不指定，会默认分配 13 targetPort: 80 1# 创建service 2[root@k8s-master01 ~]# kubectl create -f service-nodeport.yaml 3service/service-nodeport created 4 5# 查看service 6[root@k8s-master01 ~]# kubectl get svc -n dev -o wide 7NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) SELECTOR 8service-nodeport NodePort 10.105.64.191 \u0026lt;none\u0026gt; 80:30002/TCP app=nginx-pod 9 10# 接下来可以通过电脑主机的浏览器去访问集群中任意一个nodeip的30002端口，即可访问到pod 7.3.6 LoadBalancer类型的Service LoadBalancer和NodePort很相似，目的都是向外部暴露一个端口，区别在于LoadBalancer会在集群的外部再来做一个负载均衡设备，而这个设备需要外部环境支持的，外部服务发送到这个设备上的请求，会被设备负载之后转发到集群中。\n7.3.7 ExternalName类型的Service ExternalName类型的Service用于引入集群外部的服务，它通过externalName属性指定外部一个服务的地址，然后在集群内部访问此service就可以访问到外部的服务了。\n1apiVersion: v1 2kind: Service 3metadata: 4 name: service-externalname 5 namespace: dev 6spec: 7 type: ExternalName # service类型 8 externalName: www.baidu.com #改成ip地址也可以 1# 创建service 2[root@k8s-master01 ~]# kubectl create -f service-externalname.yaml 3service/service-externalname created 4 5# 域名解析 6[root@k8s-master01 ~]# dig @10.96.0.10 service-externalname.dev.svc.cluster.local 7service-externalname.dev.svc.cluster.local. 30 IN CNAME www.baidu.com. 8www.baidu.com. 30 IN CNAME www.a.shifen.com. 9www.a.shifen.com. 30 IN A 39.156.66.18 10www.a.shifen.com. 30 IN A 39.156.66.14 7.4 Ingress介绍 在前面课程中已经提到，Service对集群之外暴露服务的主要方式有两种：NotePort和LoadBalancer，但是这两种方式，都有一定的缺点：\nNodePort方式的缺点是会占用很多集群机器的端口，那么当集群服务变多的时候，这个缺点就愈发明显 LB方式的缺点是每个service需要一个LB，浪费、麻烦，并且需要kubernetes之外设备的支持 基于这种现状，kubernetes提供了Ingress资源对象，Ingress只需要一个NodePort或者一个LB就可以满足暴露多个Service的需求。工作机制大致如下图表示：\n实际上，Ingress相当于一个7层的负载均衡器，是kubernetes对反向代理的一个抽象，它的工作原理类似于Nginx，可以理解成在Ingress里建立诸多映射规则，Ingress Controller通过监听这些配置规则并转化成Nginx的反向代理配置 , 然后对外部提供服务。在这里有两个核心概念：\ningress：kubernetes中的一个对象，作用是定义请求如何转发到service的规则 ingress controller：具体实现反向代理及负载均衡的程序，对ingress定义的规则进行解析，根据配置的规则来实现请求转发，实现方式有很多，比如Nginx, Contour, Haproxy等等 Ingress（以Nginx为例）的工作原理如下：\n用户编写Ingress规则，说明哪个域名对应kubernetes集群中的哪个Service Ingress控制器动态感知Ingress服务规则的变化，然后生成一段对应的Nginx反向代理配置 Ingress控制器会将生成的Nginx配置写入到一个运行着的Nginx服务中，并动态更新 到此为止，其实真正在工作的就是一个Nginx了，内部配置了用户定义的请求转发规则 7.5 Ingress使用 7.5.1 环境准备 搭建ingress环境 1# 创建文件夹 2[root@k8s-master01 ~]# mkdir ingress-controller 3[root@k8s-master01 ~]# cd ingress-controller/ 4 5# 获取ingress-nginx，本次案例使用的是0.30版本 6[root@k8s-master01 ingress-controller]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/mandatory.yaml 7[root@k8s-master01 ingress-controller]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/provider/baremetal/service-nodeport.yaml 8 9# 修改mandatory.yaml文件中的仓库 10# 修改quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0 11# 为quay-mirror.qiniu.com/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0 12# 创建ingress-nginx 13[root@k8s-master01 ingress-controller]# kubectl apply -f ./ 14 15# 查看ingress-nginx 16[root@k8s-master01 ingress-controller]# kubectl get pod -n ingress-nginx 17NAME READY STATUS RESTARTS AGE 18pod/nginx-ingress-controller-fbf967dd5-4qpbp 1/1 Running 0 12h 19 20# 查看service 21[root@k8s-master01 ingress-controller]# kubectl get svc -n ingress-nginx 22NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE 23ingress-nginx NodePort 10.98.75.163 \u0026lt;none\u0026gt; 80:32240/TCP,443:31335/TCP 11h 7.5.2 准备service和pod 为了后面的实验比较方便，创建如下图所示的模型\n创建tomcat-nginx.yaml\n1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: nginx-deployment 5 namespace: dev 6spec: 7 replicas: 3 8 selector: 9 matchLabels: 10 app: nginx-pod 11 template: 12 metadata: 13 labels: 14 app: nginx-pod 15 spec: 16 containers: 17 - name: nginx 18 image: nginx:1.17.1 19 ports: 20 - containerPort: 80 21 22--- 23 24apiVersion: apps/v1 25kind: Deployment 26metadata: 27 name: tomcat-deployment 28 namespace: dev 29spec: 30 replicas: 3 31 selector: 32 matchLabels: 33 app: tomcat-pod 34 template: 35 metadata: 36 labels: 37 app: tomcat-pod 38 spec: 39 containers: 40 - name: tomcat 41 image: tomcat:8.5-jre10-slim 42 ports: 43 - containerPort: 8080 44 45--- 46 47apiVersion: v1 48kind: Service 49metadata: 50 name: nginx-service 51 namespace: dev 52spec: 53 selector: 54 app: nginx-pod 55 clusterIP: None 56 type: ClusterIP 57 ports: 58 - port: 80 59 targetPort: 80 60 61--- 62 63apiVersion: v1 64kind: Service 65metadata: 66 name: tomcat-service 67 namespace: dev 68spec: 69 selector: 70 app: tomcat-pod 71 clusterIP: None 72 type: ClusterIP 73 ports: 74 - port: 8080 75 targetPort: 8080 1# 创建 2[root@k8s-master01 ~]# kubectl create -f tomcat-nginx.yaml 3 4# 查看 5[root@k8s-master01 ~]# kubectl get svc -n dev 6NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE 7nginx-service ClusterIP None \u0026lt;none\u0026gt; 80/TCP 48s 8tomcat-service ClusterIP None \u0026lt;none\u0026gt; 8080/TCP 48s 7.5.3 Http代理 创建ingress-http.yaml\n1apiVersion: extensions/v1beta1 2kind: Ingress 3metadata: 4 name: ingress-http 5 namespace: dev 6spec: 7 rules: 8 - host: nginx.itheima.com 9 http: 10 paths: 11 - path: / 12 backend: 13 serviceName: nginx-service 14 servicePort: 80 15 - host: tomcat.itheima.com 16 http: 17 paths: 18 - path: / 19 backend: 20 serviceName: tomcat-service 21 servicePort: 8080 1# 创建 2[root@k8s-master01 ~]# kubectl create -f ingress-http.yaml 3ingress.extensions/ingress-http created 4 5# 查看 6[root@k8s-master01 ~]# kubectl get ing ingress-http -n dev 7NAME HOSTS ADDRESS PORTS AGE 8ingress-http nginx.itheima.com,tomcat.itheima.com 80 22s 9 10# 查看详情 11[root@k8s-master01 ~]# kubectl describe ing ingress-http -n dev 12... 13Rules: 14Host Path Backends 15---- ---- -------- 16nginx.itheima.com / nginx-service:80 (10.244.1.96:80,10.244.1.97:80,10.244.2.112:80) 17tomcat.itheima.com / tomcat-service:8080(10.244.1.94:8080,10.244.1.95:8080,10.244.2.111:8080) 18... 19 20# 接下来,在本地电脑上配置host文件,解析上面的两个域名到192.168.109.100(master)上 21# 然后,就可以分别访问tomcat.itheima.com:32240 和 nginx.itheima.com:32240 查看效果了 7.5.4 Https代理 创建证书\n1# 生成证书 2openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj \u0026#34;/C=CN/ST=BJ/L=BJ/O=nginx/CN=itheima.com\u0026#34; 3 4# 创建密钥 5kubectl create secret tls tls-secret --key tls.key --cert tls.crt 创建ingress-https.yaml\n1apiVersion: extensions/v1beta1 2kind: Ingress 3metadata: 4 name: ingress-https 5 namespace: dev 6spec: 7 tls: 8 - hosts: 9 - nginx.itheima.com 10 - tomcat.itheima.com 11 secretName: tls-secret # 指定秘钥 12 rules: 13 - host: nginx.itheima.com 14 http: 15 paths: 16 - path: / 17 backend: 18 serviceName: nginx-service 19 servicePort: 80 20 - host: tomcat.itheima.com 21 http: 22 paths: 23 - path: / 24 backend: 25 serviceName: tomcat-service 26 servicePort: 8080 1# 创建 2[root@k8s-master01 ~]# kubectl create -f ingress-https.yaml 3ingress.extensions/ingress-https created 4 5# 查看 6[root@k8s-master01 ~]# kubectl get ing ingress-https -n dev 7NAME HOSTS ADDRESS PORTS AGE 8ingress-https nginx.itheima.com,tomcat.itheima.com 10.104.184.38 80, 443 2m42s 9 10# 查看详情 11[root@k8s-master01 ~]# kubectl describe ing ingress-https -n dev 12... 13TLS: 14 tls-secret terminates nginx.itheima.com,tomcat.itheima.com 15Rules: 16Host Path Backends 17---- ---- -------- 18nginx.itheima.com / nginx-service:80 (10.244.1.97:80,10.244.1.98:80,10.244.2.119:80) 19tomcat.itheima.com / tomcat-service:8080(10.244.1.99:8080,10.244.2.117:8080,10.244.2.120:8080) 20... 21 22# 下面可以通过浏览器访问https://nginx.itheima.com:31335 和 https://tomcat.itheima.com:31335来查看了 8. 数据存储 在前面已经提到，容器的生命周期可能很短，会被频繁地创建和销毁。那么容器在销毁时，保存在容器中的数据也会被清除。这种结果对用户来说，在某些情况下是不乐意看到的。为了持久化保存容器的数据，kubernetes引入了Volume的概念。\nVolume是Pod中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个Pod里的多个容器挂载到具体的文件目录下，kubernetes通过Volume实现同一个Pod中不同容器之间的数据共享以及数据的持久化存储。Volume的生命容器不与Pod中单个容器的生命周期相关，当容器终止或者重启时，Volume中的数据也不会丢失。\nkubernetes的Volume支持多种类型，比较常见的有下面几个：\n简单存储：EmptyDir、HostPath、NFS 高级存储：PV、PVC 配置存储：ConfigMap、Secret 8.1 基本存储 8.1.1 EmptyDir EmptyDir是最基础的Volume类型，一个EmptyDir就是Host上的一个空目录。\nEmptyDir是在Pod被分配到Node时创建的，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为kubernetes会自动分配一个目录，当Pod销毁时， EmptyDir中的数据也会被永久删除。 EmptyDir用途如下：\n临时空间，例如用于某些应用程序运行时所需的临时目录，且无须永久保留 一个容器需要从另一个容器中获取数据的目录（多容器共享目录） 接下来，通过一个容器之间文件共享的案例来使用一下EmptyDir。\n在一个Pod中准备两个容器nginx和busybox，然后声明一个Volume分别挂在到两个容器的目录中，然后nginx容器负责向Volume中写日志，busybox中通过命令将日志内容读到控制台。\n创建一个volume-emptydir.yaml\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: volume-emptydir 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 ports: 11 - containerPort: 80 12 volumeMounts: # 将logs-volume挂在到nginx容器中，对应的目录为 /var/log/nginx 13 - name: logs-volume 14 mountPath: /var/log/nginx 15 - name: busybox 16 image: busybox:1.30 17 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;tail -f /logs/access.log\u0026#34;] # 初始命令，动态读取指定文件中内容 18 volumeMounts: # 将logs-volume 挂在到busybox容器中，对应的目录为 /logs 19 - name: logs-volume 20 mountPath: /logs 21 volumes: # 声明volume， name为logs-volume，类型为emptyDir 22 - name: logs-volume 23 emptyDir: {} 1# 创建Pod 2[root@k8s-master01 ~]# kubectl create -f volume-emptydir.yaml 3pod/volume-emptydir created 4 5# 查看pod 6[root@k8s-master01 ~]# kubectl get pods volume-emptydir -n dev -o wide 7NAME READY STATUS RESTARTS AGE IP NODE ...... 8volume-emptydir 2/2 Running 0 97s 10.42.2.9 node1 ...... 9 10# 通过podIp访问nginx 11[root@k8s-master01 ~]# curl 10.42.2.9 12...... 13 14# 通过kubectl logs命令查看指定容器的标准输出 15[root@k8s-master01 ~]# kubectl logs -f volume-emptydir -n dev -c busybox 1610.42.1.0 - - [27/Jun/2021:15:08:54 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 200 612 \u0026#34;-\u0026#34; \u0026#34;curl/7.29.0\u0026#34; \u0026#34;-\u0026#34; 8.1.2 HostPath 上节课提到，EmptyDir中数据不会被持久化，它会随着Pod的结束而销毁，如果想简单的将数据持久化到主机中，可以选择HostPath。\nHostPath就是将Node主机中一个实际目录挂在到Pod中，以供容器使用，这样的设计就可以保证Pod销毁了，但是数据依据可以存在于Node主机上。\n创建一个volume-hostpath.yaml：\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: volume-hostpath 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 ports: 11 - containerPort: 80 12 volumeMounts: 13 - name: logs-volume 14 mountPath: /var/log/nginx 15 - name: busybox 16 image: busybox:1.30 17 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;tail -f /logs/access.log\u0026#34;] 18 volumeMounts: 19 - name: logs-volume 20 mountPath: /logs 21 volumes: 22 - name: logs-volume 23 hostPath: 24 path: /root/logs 25 type: DirectoryOrCreate # 目录存在就使用，不存在就先创建后使用 1关于type的值的一点说明： 2 DirectoryOrCreate 目录存在就使用，不存在就先创建后使用 3 Directory 目录必须存在 4 FileOrCreate 文件存在就使用，不存在就先创建后使用 5 File 文件必须存在 6 Socket unix套接字必须存在 7 CharDevice 字符设备必须存在 8 BlockDevice 块设备必须存在 1# 创建Pod 2[root@k8s-master01 ~]# kubectl create -f volume-hostpath.yaml 3pod/volume-hostpath created 4 5# 查看Pod 6[root@k8s-master01 ~]# kubectl get pods volume-hostpath -n dev -o wide 7NAME READY STATUS RESTARTS AGE IP NODE ...... 8pod-volume-hostpath 2/2 Running 0 16s 10.42.2.10 node1 ...... 9 10#访问nginx 11[root@k8s-master01 ~]# curl 10.42.2.10 12 13[root@k8s-master01 ~]# kubectl logs -f volume-emptydir -n dev -c busybox 14 15# 接下来就可以去host的/root/logs目录下查看存储的文件了 16### 注意: 下面的操作需要到Pod所在的节点运行（案例中是node1） 17[root@node1 ~]# ls /root/logs/ 18access.log error.log 19 20# 同样的道理，如果在此目录下创建一个文件，到容器中也是可以看到的 8.1.3 NFS HostPath可以解决数据持久化的问题，但是一旦Node节点故障了，Pod如果转移到了别的节点，又会出现问题了，此时需要准备单独的网络存储系统，比较常用的用NFS、CIFS。\nNFS是一个网络文件存储系统，可以搭建一台NFS服务器，然后将Pod中的存储直接连接到NFS系统上，这样的话，无论Pod在节点上怎么转移，只要Node跟NFS的对接没问题，数据就可以成功访问。\n1）首先要准备nfs的服务器，这里为了简单，直接是master节点做nfs服务器\n1# 在nfs上安装nfs服务 2[root@nfs ~]# yum install nfs-utils -y 3 4# 准备一个共享目录 5[root@nfs ~]# mkdir /root/data/nfs -pv 6 7# 将共享目录以读写权限暴露给192.168.5.0/24网段中的所有主机 8[root@nfs ~]# vim /etc/exports 9[root@nfs ~]# more /etc/exports 10/root/data/nfs 192.168.5.0/24(rw,no_root_squash) 11 12# 启动nfs服务 13[root@nfs ~]# systemctl restart nfs 2）接下来，要在的每个node节点上都安装下nfs，这样的目的是为了node节点可以驱动nfs设备\n1# 在node上安装nfs服务，注意不需要启动 2[root@k8s-master01 ~]# yum install nfs-utils -y 3）接下来，就可以编写pod的配置文件了，创建volume-nfs.yaml\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: volume-nfs 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 ports: 11 - containerPort: 80 12 volumeMounts: 13 - name: logs-volume 14 mountPath: /var/log/nginx 15 - name: busybox 16 image: busybox:1.30 17 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;tail -f /logs/access.log\u0026#34;] 18 volumeMounts: 19 - name: logs-volume 20 mountPath: /logs 21 volumes: 22 - name: logs-volume 23 nfs: 24 server: 192.168.5.6 #nfs服务器地址 25 path: /root/data/nfs #共享文件路径 4）最后，运行下pod，观察结果\n1# 创建pod 2[root@k8s-master01 ~]# kubectl create -f volume-nfs.yaml 3pod/volume-nfs created 4 5# 查看pod 6[root@k8s-master01 ~]# kubectl get pods volume-nfs -n dev 7NAME READY STATUS RESTARTS AGE 8volume-nfs 2/2 Running 0 2m9s 9 10# 查看nfs服务器上的共享目录，发现已经有文件了 11[root@k8s-master01 ~]# ls /root/data/ 12access.log error.log 8.2 高级存储 前面已经学习了使用NFS提供存储，此时就要求用户会搭建NFS系统，并且会在yaml配置nfs。由于kubernetes支持的存储系统有很多，要求客户全都掌握，显然不现实。为了能够屏蔽底层存储实现的细节，方便用户使用， kubernetes引入PV和PVC两种资源对象。\nPV（Persistent Volume）是持久化卷的意思，是对底层的共享存储的一种抽象。一般情况下PV由kubernetes管理员进行创建和配置，它与底层具体的共享存储技术有关，并通过插件完成与共享存储的对接。\nPVC（Persistent Volume Claim）是持久卷声明的意思，是用户对于存储需求的一种声明。换句话说，PVC其实就是用户向kubernetes系统发出的一种资源需求申请。\n使用了PV和PVC之后，工作可以得到进一步的细分：\n存储：存储工程师维护 PV： kubernetes管理员维护 PVC：kubernetes用户维护 8.2.1 PV PV是存储资源的抽象，下面是资源清单文件:\n1apiVersion: v1 2kind: PersistentVolume 3metadata: 4 name: pv2 5spec: 6 nfs: # 存储类型，与底层真正存储对应 7 capacity: # 存储能力，目前只支持存储空间的设置 8 storage: 2Gi 9 accessModes: # 访问模式 10 storageClassName: # 存储类别 11 persistentVolumeReclaimPolicy: # 回收策略 PV 的关键配置参数说明：\n存储类型\n底层实际存储的类型，kubernetes支持多种存储类型，每种存储类型的配置都有所差异\n存储能力（capacity）\n目前只支持存储空间的设置( storage=1Gi )，不过未来可能会加入IOPS、吞吐量等指标的配置\n访问模式（accessModes）\n用于描述用户应用对存储资源的访问权限，访问权限包括下面几种方式：\nReadWriteOnce（RWO）：读写权限，但是只能被单个节点挂载 ReadOnlyMany（ROX）： 只读权限，可以被多个节点挂载 ReadWriteMany（RWX）：读写权限，可以被多个节点挂载 需要注意的是，底层不同的存储类型可能支持的访问模式不同\n回收策略（persistentVolumeReclaimPolicy）\n当PV不再被使用了之后，对其的处理方式。目前支持三种策略：\nRetain （保留） 保留数据，需要管理员手工清理数据 Recycle（回收） 清除 PV 中的数据，效果相当于执行 rm -rf /thevolume/* Delete （删除） 与 PV 相连的后端存储完成 volume 的删除操作，当然这常见于云服务商的存储服务 需要注意的是，底层不同的存储类型可能支持的回收策略不同\n存储类别\nPV可以通过storageClassName参数指定一个存储类别\n具有特定类别的PV只能与请求了该类别的PVC进行绑定 未设定类别的PV则只能与不请求任何类别的PVC进行绑定 状态（status）\n一个 PV 的生命周期中，可能会处于4中不同的阶段：\nAvailable（可用）： 表示可用状态，还未被任何 PVC 绑定 Bound（已绑定）： 表示 PV 已经被 PVC 绑定 Released（已释放）： 表示 PVC 被删除，但是资源还未被集群重新声明 Failed（失败）： 表示该 PV 的自动回收失败 实验\n使用NFS作为存储，来演示PV的使用，创建3个PV，对应NFS中的3个暴露的路径。\n准备NFS环境 1# 创建目录 2[root@nfs ~]# mkdir /root/data/{pv1,pv2,pv3} -pv 3 4# 暴露服务 5[root@nfs ~]# more /etc/exports 6/root/data/pv1 192.168.5.0/24(rw,no_root_squash) 7/root/data/pv2 192.168.5.0/24(rw,no_root_squash) 8/root/data/pv3 192.168.5.0/24(rw,no_root_squash) 9 10# 重启服务 11[root@nfs ~]# systemctl restart nfs 创建pv.yaml 1apiVersion: v1 2kind: PersistentVolume 3metadata: 4 name: pv1 5spec: 6 capacity: 7 storage: 1Gi 8 accessModes: 9 - ReadWriteMany 10 persistentVolumeReclaimPolicy: Retain 11 nfs: 12 path: /root/data/pv1 13 server: 192.168.5.6 14 15--- 16 17apiVersion: v1 18kind: PersistentVolume 19metadata: 20 name: pv2 21spec: 22 capacity: 23 storage: 2Gi 24 accessModes: 25 - ReadWriteMany 26 persistentVolumeReclaimPolicy: Retain 27 nfs: 28 path: /root/data/pv2 29 server: 192.168.5.6 30 31--- 32 33apiVersion: v1 34kind: PersistentVolume 35metadata: 36 name: pv3 37spec: 38 capacity: 39 storage: 3Gi 40 accessModes: 41 - ReadWriteMany 42 persistentVolumeReclaimPolicy: Retain 43 nfs: 44 path: /root/data/pv3 45 server: 192.168.5.6 1# 创建 pv 2[root@k8s-master01 ~]# kubectl create -f pv.yaml 3persistentvolume/pv1 created 4persistentvolume/pv2 created 5persistentvolume/pv3 created 6 7# 查看pv 8[root@k8s-master01 ~]# kubectl get pv -o wide 9NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS AGE VOLUMEMODE 10pv1 1Gi RWX Retain Available 10s Filesystem 11pv2 2Gi RWX Retain Available 10s Filesystem 12pv3 3Gi RWX Retain Available 9s Filesystem 8.2.2 PVC PVC是资源的申请，用来声明对存储空间、访问模式、存储类别需求信息。下面是资源清单文件:\n1apiVersion: v1 2kind: PersistentVolumeClaim 3metadata: 4 name: pvc 5 namespace: dev 6spec: 7 accessModes: # 访问模式 8 selector: # 采用标签对PV选择 9 storageClassName: # 存储类别 10 resources: # 请求空间 11 requests: 12 storage: 5Gi PVC 的关键配置参数说明：\n访问模式（accessModes） 用于描述用户应用对存储资源的访问权限\n选择条件（selector）\n通过Label Selector的设置，可使PVC对于系统中己存在的PV进行筛选\n存储类别（storageClassName）\nPVC在定义时可以设定需要的后端存储的类别，只有设置了该class的pv才能被系统选出\n资源请求（Resources ）\n描述对存储资源的请求\n实验\n创建pvc.yaml，申请pv 1apiVersion: v1 2kind: PersistentVolumeClaim 3metadata: 4 name: pvc1 5 namespace: dev 6spec: 7 accessModes: 8 - ReadWriteMany 9 resources: 10 requests: 11 storage: 1Gi 12--- 13apiVersion: v1 14kind: PersistentVolumeClaim 15metadata: 16 name: pvc2 17 namespace: dev 18spec: 19 accessModes: 20 - ReadWriteMany 21 resources: 22 requests: 23 storage: 1Gi 24--- 25apiVersion: v1 26kind: PersistentVolumeClaim 27metadata: 28 name: pvc3 29 namespace: dev 30spec: 31 accessModes: 32 - ReadWriteMany 33 resources: 34 requests: 35 storage: 1Gi 1# 创建pvc 2[root@k8s-master01 ~]# kubectl create -f pvc.yaml 3persistentvolumeclaim/pvc1 created 4persistentvolumeclaim/pvc2 created 5persistentvolumeclaim/pvc3 created 6 7# 查看pvc 8[root@k8s-master01 ~]# kubectl get pvc -n dev -o wide 9NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE 10pvc1 Bound pv1 1Gi RWX 15s Filesystem 11pvc2 Bound pv2 2Gi RWX 15s Filesystem 12pvc3 Bound pv3 3Gi RWX 15s Filesystem 13 14# 查看pv 15[root@k8s-master01 ~]# kubectl get pv -o wide 16NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM AGE VOLUMEMODE 17pv1 1Gi RWx Retain Bound dev/pvc1 3h37m Filesystem 18pv2 2Gi RWX Retain Bound dev/pvc2 3h37m Filesystem 19pv3 3Gi RWX Retain Bound dev/pvc3 3h37m Filesystem 创建pods.yaml, 使用pv 1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod1 5 namespace: dev 6spec: 7 containers: 8 - name: busybox 9 image: busybox:1.30 10 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;while true;do echo pod1 \u0026gt;\u0026gt; /root/out.txt; sleep 10; done;\u0026#34;] 11 volumeMounts: 12 - name: volume 13 mountPath: /root/ 14 volumes: 15 - name: volume 16 persistentVolumeClaim: 17 claimName: pvc1 18 readOnly: false 19--- 20apiVersion: v1 21kind: Pod 22metadata: 23 name: pod2 24 namespace: dev 25spec: 26 containers: 27 - name: busybox 28 image: busybox:1.30 29 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;while true;do echo pod2 \u0026gt;\u0026gt; /root/out.txt; sleep 10; done;\u0026#34;] 30 volumeMounts: 31 - name: volume 32 mountPath: /root/ 33 volumes: 34 - name: volume 35 persistentVolumeClaim: 36 claimName: pvc2 37 readOnly: false 1# 创建pod 2[root@k8s-master01 ~]# kubectl create -f pods.yaml 3pod/pod1 created 4pod/pod2 created 5 6# 查看pod 7[root@k8s-master01 ~]# kubectl get pods -n dev -o wide 8NAME READY STATUS RESTARTS AGE IP NODE 9pod1 1/1 Running 0 14s 10.244.1.69 node1 10pod2 1/1 Running 0 14s 10.244.1.70 node1 11 12# 查看pvc 13[root@k8s-master01 ~]# kubectl get pvc -n dev -o wide 14NAME STATUS VOLUME CAPACITY ACCESS MODES AGE VOLUMEMODE 15pvc1 Bound pv1 1Gi RWX 94m Filesystem 16pvc2 Bound pv2 2Gi RWX 94m Filesystem 17pvc3 Bound pv3 3Gi RWX 94m Filesystem 18 19# 查看pv 20[root@k8s-master01 ~]# kubectl get pv -n dev -o wide 21NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM AGE VOLUMEMODE 22pv1 1Gi RWX Retain Bound dev/pvc1 5h11m Filesystem 23pv2 2Gi RWX Retain Bound dev/pvc2 5h11m Filesystem 24pv3 3Gi RWX Retain Bound dev/pvc3 5h11m Filesystem 25 26# 查看nfs中的文件存储 27[root@nfs ~]# more /root/data/pv1/out.txt 28node1 29node1 30[root@nfs ~]# more /root/data/pv2/out.txt 31node2 32node2 8.2.3 生命周期 PVC和PV是一一对应的，PV和PVC之间的相互作用遵循以下生命周期：\n资源供应：管理员手动创建底层存储和PV\n资源绑定：用户创建PVC，kubernetes负责根据PVC的声明去寻找PV，并绑定\n在用户定义好PVC之后，系统将根据PVC对存储资源的请求在已存在的PV中选择一个满足条件的\n一旦找到，就将该PV与用户定义的PVC进行绑定，用户的应用就可以使用这个PVC了 如果找不到，PVC则会无限期处于Pending状态，直到等到系统管理员创建了一个符合其要求的PV PV一旦绑定到某个PVC上，就会被这个PVC独占，不能再与其他PVC进行绑定了\n资源使用：用户可在pod中像volume一样使用pvc\nPod使用Volume的定义，将PVC挂载到容器内的某个路径进行使用。\n资源释放：用户删除pvc来释放pv\n当存储资源使用完毕后，用户可以删除PVC，与该PVC绑定的PV将会被标记为“已释放”，但还不能立刻与其他PVC进行绑定。通过之前PVC写入的数据可能还被留在存储设备上，只有在清除之后该PV才能再次使用。\n资源回收：kubernetes根据pv设置的回收策略进行资源的回收\n对于PV，管理员可以设定回收策略，用于设置与之绑定的PVC释放资源之后如何处理遗留数据的问题。只有PV的存储空间完成回收，才能供新的PVC绑定和使用\n8.3 配置存储 8.3.1 ConfigMap ConfigMap是一种比较特殊的存储卷，它的主要作用是用来存储配置信息的。\n创建configmap.yaml，内容如下：\n1apiVersion: v1 2kind: ConfigMap 3metadata: 4 name: configmap 5 namespace: dev 6data: 7 info: | 8 username:admin 9 password:123456 接下来，使用此配置文件创建configmap\n1# 创建configmap 2[root@k8s-master01 ~]# kubectl create -f configmap.yaml 3configmap/configmap created 4 5# 查看configmap详情 6[root@k8s-master01 ~]# kubectl describe cm configmap -n dev 7Name: configmap 8Namespace: dev 9Labels: \u0026lt;none\u0026gt; 10Annotations: \u0026lt;none\u0026gt; 11 12Data 13==== 14info: 15---- 16username:admin 17password:123456 18 19Events: \u0026lt;none\u0026gt; 接下来创建一个pod-configmap.yaml，将上面创建的configmap挂载进去\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-configmap 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 volumeMounts: # 将configmap挂载到目录 11 - name: config 12 mountPath: /configmap/config 13 volumes: # 引用configmap 14 - name: config 15 configMap: 16 name: configmap 1# 创建pod 2[root@k8s-master01 ~]# kubectl create -f pod-configmap.yaml 3pod/pod-configmap created 4 5# 查看pod 6[root@k8s-master01 ~]# kubectl get pod pod-configmap -n dev 7NAME READY STATUS RESTARTS AGE 8pod-configmap 1/1 Running 0 6s 9 10#进入容器 11[root@k8s-master01 ~]# kubectl exec -it pod-configmap -n dev /bin/sh 12# cd /configmap/config/ 13# ls 14info 15# more info 16username:admin 17password:123456 18 19# 可以看到映射已经成功，每个configmap都映射成了一个目录 20# key---\u0026gt;文件 value----\u0026gt;文件中的内容 21# 此时如果更新configmap的内容, 容器中的值也会动态更新 8.3.2 Secret 在kubernetes中，还存在一种和ConfigMap非常类似的对象，称为Secret对象。它主要用于存储敏感信息，例如密码、秘钥、证书等等。\n首先使用base64对数据进行编码 1[root@k8s-master01 ~]# echo -n \u0026#39;admin\u0026#39; | base64 #准备username 2YWRtaW4= 3[root@k8s-master01 ~]# echo -n \u0026#39;123456\u0026#39; | base64 #准备password 4MTIzNDU2 接下来编写secret.yaml，并创建Secret 1apiVersion: v1 2kind: Secret 3metadata: 4 name: secret 5 namespace: dev 6type: Opaque 7data: 8 username: YWRtaW4= 9 password: MTIzNDU2 1# 创建secret 2[root@k8s-master01 ~]# kubectl create -f secret.yaml 3secret/secret created 4 5# 查看secret详情 6[root@k8s-master01 ~]# kubectl describe secret secret -n dev 7Name: secret 8Namespace: dev 9Labels: \u0026lt;none\u0026gt; 10Annotations: \u0026lt;none\u0026gt; 11Type: Opaque 12Data 13==== 14password: 6 bytes 15username: 5 bytes 创建pod-secret.yaml，将上面创建的secret挂载进去： 1apiVersion: v1 2kind: Pod 3metadata: 4 name: pod-secret 5 namespace: dev 6spec: 7 containers: 8 - name: nginx 9 image: nginx:1.17.1 10 volumeMounts: # 将secret挂载到目录 11 - name: config 12 mountPath: /secret/config 13 volumes: 14 - name: config 15 secret: 16 secretName: secret 1# 创建pod 2[root@k8s-master01 ~]# kubectl create -f pod-secret.yaml 3pod/pod-secret created 4 5# 查看pod 6[root@k8s-master01 ~]# kubectl get pod pod-secret -n dev 7NAME READY STATUS RESTARTS AGE 8pod-secret 1/1 Running 0 2m28s 9 10# 进入容器，查看secret信息，发现已经自动解码了 11[root@k8s-master01 ~]# kubectl exec -it pod-secret /bin/sh -n dev 12/ # ls /secret/config/ 13password username 14/ # more /secret/config/username 15admin 16/ # more /secret/config/password 17123456 至此，已经实现了利用secret实现了信息的编码。\n9. 安全认证 9.1 访问控制概述 Kubernetes作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。所谓的安全性其实就是保证对Kubernetes的各种客户端进行认证和鉴权操作。\n客户端\n在Kubernetes集群中，客户端通常有两类：\nUser Account：一般是独立于kubernetes之外的其他服务管理的用户账号。 Service Account：kubernetes管理的账号，用于为Pod中的服务进程在访问Kubernetes时提供身份标识。 认证、授权与准入控制\nApiServer是访问及管理资源对象的唯一入口。任何一个请求访问ApiServer，都要经过下面三个流程：\nAuthentication（认证）：身份鉴别，只有正确的账号才能够通过认证 Authorization（授权）： 判断用户是否有权限对访问的资源执行特定的动作 Admission Control（准入控制）：用于补充授权机制以实现更加精细的访问控制功能。 9.2 认证管理 Kubernetes集群安全的最关键点在于如何识别并认证客户端身份，它提供了3种客户端身份认证方式：\nHTTP Base认证：通过用户名+密码的方式认证\n1 这种认证方式是把“用户名:密码”用BASE64算法进行编码后的字符串放在HTTP请求中的Header Authorization域里发送给服务端。服务端收到后进行解码，获取用户名及密码，然后进行用户身份认证的过程。 HTTP Token认证：通过一个Token来识别合法用户\n1 这种认证方式是用一个很长的难以被模仿的字符串--Token来表明客户身份的一种方式。每个Token对应一个用户名，当客户端发起API调用请求时，需要在HTTP Header里放入Token，API Server接到Token后会跟服务器中保存的token进行比对，然后进行用户身份认证的过程。 HTTPS证书认证：基于CA根证书签名的双向数字证书认证方式\n1 这种认证方式是安全性最高的一种方式，但是同时也是操作起来最麻烦的一种方式。 HTTPS认证大体分为3个过程：\n证书申请和下发\n1 HTTPS通信双方的服务器向CA机构申请证书，CA机构下发根证书、服务端证书及私钥给申请者 客户端和服务端的双向认证\n1 1\u0026gt; 客户端向服务器端发起请求，服务端下发自己的证书给客户端， 2 客户端接收到证书后，通过私钥解密证书，在证书中获得服务端的公钥， 3 客户端利用服务器端的公钥认证证书中的信息，如果一致，则认可这个服务器 4 2\u0026gt; 客户端发送自己的证书给服务器端，服务端接收到证书后，通过私钥解密证书， 5 在证书中获得客户端的公钥，并用该公钥认证证书信息，确认客户端是否合法 服务器端和客户端进行通信\n1 服务器端和客户端协商好加密方案后，客户端会产生一个随机的秘钥并加密，然后发送到服务器端。 2 服务器端接收这个秘钥后，双方接下来通信的所有内容都通过该随机秘钥加密 注意: Kubernetes允许同时配置多种认证方式，只要其中任意一个方式认证通过即可\n9.3 授权管理 授权发生在认证成功之后，通过认证就可以知道请求用户是谁， 然后Kubernetes会根据事先定义的授权策略来决定用户是否有权限访问，这个过程就称为授权。\n每个发送到ApiServer的请求都带上了用户和资源的信息：比如发送请求的用户、请求的路径、请求的动作等，授权就是根据这些信息和授权策略进行比较，如果符合策略，则认为授权通过，否则会返回错误。\nAPI Server目前支持以下几种授权策略：\nAlwaysDeny：表示拒绝所有请求，一般用于测试 AlwaysAllow：允许接收所有请求，相当于集群不需要授权流程（Kubernetes默认的策略） ABAC：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制 Webhook：通过调用外部REST服务对用户进行授权 Node：是一种专用模式，用于对kubelet发出的请求进行访问控制 RBAC：基于角色的访问控制（kubeadm安装方式下的默认选项） RBAC(Role-Based Access Control) 基于角色的访问控制，主要是在描述一件事情：给哪些对象授予了哪些权限\n其中涉及到了下面几个概念：\n对象：User、Groups、ServiceAccount 角色：代表着一组定义在资源上的可操作动作(权限)的集合 绑定：将定义好的角色跟用户绑定在一起 RBAC引入了4个顶级资源对象：\nRole、ClusterRole：角色，用于指定一组权限 RoleBinding、ClusterRoleBinding：角色绑定，用于将角色（权限）赋予给对象 Role、ClusterRole\n一个角色就是一组权限的集合，这里的权限都是许可形式的（白名单）。\n1# Role只能对命名空间内的资源进行授权，需要指定nameapce 2kind: Role 3apiVersion: rbac.authorization.k8s.io/v1beta1 4metadata: 5 namespace: dev 6 name: authorization-role 7rules: 8- apiGroups: [\u0026#34;\u0026#34;] # 支持的API组列表,\u0026#34;\u0026#34; 空字符串，表示核心API群 9 resources: [\u0026#34;pods\u0026#34;] # 支持的资源对象列表 10 verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] # 允许的对资源对象的操作方法列表 1# ClusterRole可以对集群范围内资源、跨namespaces的范围资源、非资源类型进行授权 2kind: ClusterRole 3apiVersion: rbac.authorization.k8s.io/v1beta1 4metadata: 5 name: authorization-clusterrole 6rules: 7- apiGroups: [\u0026#34;\u0026#34;] 8 resources: [\u0026#34;pods\u0026#34;] 9 verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] 需要详细说明的是，rules中的参数：\napiGroups: 支持的API组列表\n1\u0026#34;\u0026#34;,\u0026#34;apps\u0026#34;, \u0026#34;autoscaling\u0026#34;, \u0026#34;batch\u0026#34; resources：支持的资源对象列表\n1\u0026#34;services\u0026#34;, \u0026#34;endpoints\u0026#34;, \u0026#34;pods\u0026#34;,\u0026#34;secrets\u0026#34;,\u0026#34;configmaps\u0026#34;,\u0026#34;crontabs\u0026#34;,\u0026#34;deployments\u0026#34;,\u0026#34;jobs\u0026#34;, 2\u0026#34;nodes\u0026#34;,\u0026#34;rolebindings\u0026#34;,\u0026#34;clusterroles\u0026#34;,\u0026#34;daemonsets\u0026#34;,\u0026#34;replicasets\u0026#34;,\u0026#34;statefulsets\u0026#34;, 3\u0026#34;horizontalpodautoscalers\u0026#34;,\u0026#34;replicationcontrollers\u0026#34;,\u0026#34;cronjobs\u0026#34; verbs：对资源对象的操作方法列表\n1\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;create\u0026#34;, \u0026#34;update\u0026#34;, \u0026#34;patch\u0026#34;, \u0026#34;delete\u0026#34;, \u0026#34;exec\u0026#34; RoleBinding、ClusterRoleBinding\n角色绑定用来把一个角色绑定到一个目标对象上，绑定目标可以是User、Group或者ServiceAccount。\n1# RoleBinding可以将同一namespace中的subject绑定到某个Role下，则此subject即具有该Role定义的权限 2kind: RoleBinding 3apiVersion: rbac.authorization.k8s.io/v1beta1 4metadata: 5 name: authorization-role-binding 6 namespace: dev 7subjects: 8- kind: User 9 name: heima 10 apiGroup: rbac.authorization.k8s.io 11roleRef: 12 kind: Role 13 name: authorization-role 14 apiGroup: rbac.authorization.k8s.io 1# ClusterRoleBinding在整个集群级别和所有namespaces将特定的subject与ClusterRole绑定，授予权限 2kind: ClusterRoleBinding 3apiVersion: rbac.authorization.k8s.io/v1beta1 4metadata: 5 name: authorization-clusterrole-binding 6subjects: 7- kind: User 8 name: heima 9 apiGroup: rbac.authorization.k8s.io 10roleRef: 11 kind: ClusterRole 12 name: authorization-clusterrole 13 apiGroup: rbac.authorization.k8s.io RoleBinding引用ClusterRole进行授权\nRoleBinding可以引用ClusterRole，对属于同一命名空间内ClusterRole定义的资源主体进行授权。\n1 一种很常用的做法就是，集群管理员为集群范围预定义好一组角色（ClusterRole），然后在多个命名空间中重复使用这些ClusterRole。这样可以大幅提高授权管理工作效率，也使得各个命名空间下的基础性授权规则与使用体验保持一致。 1# 虽然authorization-clusterrole是一个集群角色，但是因为使用了RoleBinding 2# 所以heima只能读取dev命名空间中的资源 3kind: RoleBinding 4apiVersion: rbac.authorization.k8s.io/v1beta1 5metadata: 6 name: authorization-role-binding-ns 7 namespace: dev 8subjects: 9- kind: User 10 name: heima 11 apiGroup: rbac.authorization.k8s.io 12roleRef: 13 kind: ClusterRole 14 name: authorization-clusterrole 15 apiGroup: rbac.authorization.k8s.io 实战：创建一个只能管理dev空间下Pods资源的账号\n创建账号 1# 1) 创建证书 2[root@k8s-master01 pki]# cd /etc/kubernetes/pki/ 3[root@k8s-master01 pki]# (umask 077;openssl genrsa -out devman.key 2048) 4 5# 2) 用apiserver的证书去签署 6# 2-1) 签名申请，申请的用户是devman,组是devgroup 7[root@k8s-master01 pki]# openssl req -new -key devman.key -out devman.csr -subj \u0026#34;/CN=devman/O=devgroup\u0026#34; 8# 2-2) 签署证书 9[root@k8s-master01 pki]# openssl x509 -req -in devman.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out devman.crt -days 3650 10 11# 3) 设置集群、用户、上下文信息 12[root@k8s-master01 pki]# kubectl config set-cluster kubernetes --embed-certs=true --certificate-authority=/etc/kubernetes/pki/ca.crt --server=https://192.168.109.100:6443 13 14[root@k8s-master01 pki]# kubectl config set-credentials devman --embed-certs=true --client-certificate=/etc/kubernetes/pki/devman.crt --client-key=/etc/kubernetes/pki/devman.key 15 16[root@k8s-master01 pki]# kubectl config set-context devman@kubernetes --cluster=kubernetes --user=devman 17 18# 切换账户到devman 19[root@k8s-master01 pki]# kubectl config use-context devman@kubernetes 20Switched to context \u0026#34;devman@kubernetes\u0026#34;. 21 22# 查看dev下pod，发现没有权限 23[root@k8s-master01 pki]# kubectl get pods -n dev 24Error from server (Forbidden): pods is forbidden: User \u0026#34;devman\u0026#34; cannot list resource \u0026#34;pods\u0026#34; in API group \u0026#34;\u0026#34; in the namespace \u0026#34;dev\u0026#34; 25 26# 切换到admin账户 27[root@k8s-master01 pki]# kubectl config use-context kubernetes-admin@kubernetes 28Switched to context \u0026#34;kubernetes-admin@kubernetes\u0026#34;. 2） 创建Role和RoleBinding，为devman用户授权\n1kind: Role 2apiVersion: rbac.authorization.k8s.io/v1beta1 3metadata: 4 namespace: dev 5 name: dev-role 6rules: 7- apiGroups: [\u0026#34;\u0026#34;] 8 resources: [\u0026#34;pods\u0026#34;] 9 verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] 10 11--- 12 13kind: RoleBinding 14apiVersion: rbac.authorization.k8s.io/v1beta1 15metadata: 16 name: authorization-role-binding 17 namespace: dev 18subjects: 19- kind: User 20 name: devman 21 apiGroup: rbac.authorization.k8s.io 22roleRef: 23 kind: Role 24 name: dev-role 25 apiGroup: rbac.authorization.k8s.io 1[root@k8s-master01 pki]# kubectl create -f dev-role.yaml 2role.rbac.authorization.k8s.io/dev-role created 3rolebinding.rbac.authorization.k8s.io/authorization-role-binding created 切换账户，再次验证 1# 切换账户到devman 2[root@k8s-master01 pki]# kubectl config use-context devman@kubernetes 3Switched to context \u0026#34;devman@kubernetes\u0026#34;. 4 5# 再次查看 6[root@k8s-master01 pki]# kubectl get pods -n dev 7NAME READY STATUS RESTARTS AGE 8nginx-deployment-66cb59b984-8wp2k 1/1 Running 0 4d1h 9nginx-deployment-66cb59b984-dc46j 1/1 Running 0 4d1h 10nginx-deployment-66cb59b984-thfck 1/1 Running 0 4d1h 11 12# 为了不影响后面的学习,切回admin账户 13[root@k8s-master01 pki]# kubectl config use-context kubernetes-admin@kubernetes 14Switched to context \u0026#34;kubernetes-admin@kubernetes\u0026#34;. 9.4 准入控制 通过了前面的认证和授权之后，还需要经过准入控制处理通过之后，apiserver才会处理这个请求。\n准入控制是一个可配置的控制器列表，可以通过在Api-Server上通过命令行设置选择执行哪些准入控制器：\n1--admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel, 2 DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds 只有当所有的准入控制器都检查通过之后，apiserver才执行该请求，否则返回拒绝。\n当前可配置的Admission Control准入控制如下：\nAlwaysAdmit：允许所有请求 AlwaysDeny：禁止所有请求，一般用于测试 AlwaysPullImages：在启动容器之前总去下载镜像 DenyExecOnPrivileged：它会拦截所有想在Privileged Container上执行命令的请求 ImagePolicyWebhook：这个插件将允许后端的一个Webhook程序来完成admission controller的功能。 Service Account：实现ServiceAccount实现了自动化 SecurityContextDeny：这个插件将使用SecurityContext的Pod中的定义全部失效 ResourceQuota：用于资源配额管理目的，观察所有请求，确保在namespace上的配额不会超标 LimitRanger：用于资源限制管理，作用于namespace上，确保对Pod进行资源限制 InitialResources：为未设置资源请求与限制的Pod，根据其镜像的历史资源的使用情况进行设置 NamespaceLifecycle：如果尝试在一个不存在的namespace中创建资源对象，则该创建请求将被拒绝。当删除一个namespace时，系统将会删除该namespace中所有对象。 DefaultStorageClass：为了实现共享存储的动态供应，为未指定StorageClass或PV的PVC尝试匹配默认的StorageClass，尽可能减少用户在申请PVC时所需了解的后端存储细节 DefaultTolerationSeconds：这个插件为那些没有设置forgiveness tolerations并具有notready:NoExecute和unreachable:NoExecute两种taints的Pod设置默认的“容忍”时间，为5min PodSecurityPolicy：这个插件用于在创建或修改Pod时决定是否根据Pod的security context和可用的PodSecurityPolicy对Pod的安全策略进行控制 10. DashBoard 之前在kubernetes中完成的所有操作都是通过命令行工具kubectl完成的。其实，为了提供更丰富的用户体验，kubernetes还开发了一个基于web的用户界面（Dashboard）。用户可以使用Dashboard部署容器化的应用，还可以监控应用的状态，执行故障排查以及管理kubernetes中各种资源。\n10.1 部署Dashboard 下载yaml，并运行Dashboard 1# 下载yaml 2[root@k8s-master01 ~]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml 3 4# 修改kubernetes-dashboard的Service类型 5kind: Service 6apiVersion: v1 7metadata: 8 labels: 9 k8s-app: kubernetes-dashboard 10 name: kubernetes-dashboard 11 namespace: kubernetes-dashboard 12spec: 13 type: NodePort # 新增 14 ports: 15 - port: 443 16 targetPort: 8443 17 nodePort: 30009 # 新增 18 selector: 19 k8s-app: kubernetes-dashboard 20 21# 部署 22[root@k8s-master01 ~]# kubectl create -f recommended.yaml 23 24# 查看namespace下的kubernetes-dashboard下的资源 25[root@k8s-master01 ~]# kubectl get pod,svc -n kubernetes-dashboard 26NAME READY STATUS RESTARTS AGE 27pod/dashboard-metrics-scraper-c79c65bb7-zwfvw 1/1 Running 0 111s 28pod/kubernetes-dashboard-56484d4c5-z95z5 1/1 Running 0 111s 29 30NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE 31service/dashboard-metrics-scraper ClusterIP 10.96.89.218 \u0026lt;none\u0026gt; 8000/TCP 111s 32service/kubernetes-dashboard NodePort 10.104.178.171 \u0026lt;none\u0026gt; 443:30009/TCP 111s 2）创建访问账户，获取token\n1# 创建账号 2[root@k8s-master01-1 ~]# kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard 3 4# 授权 5[root@k8s-master01-1 ~]# kubectl create clusterrolebinding dashboard-admin-rb --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin 6 7# 获取账号token 8[root@k8s-master01 ~]# kubectl get secrets -n kubernetes-dashboard | grep dashboard-admin 9dashboard-admin-token-xbqhh kubernetes.io/service-account-token 3 2m35s 10 11[root@k8s-master01 ~]# kubectl describe secrets dashboard-admin-token-xbqhh -n kubernetes-dashboard 12Name: dashboard-admin-token-xbqhh 13Namespace: kubernetes-dashboard 14Labels: \u0026lt;none\u0026gt; 15Annotations: kubernetes.io/service-account.name: dashboard-admin 16 kubernetes.io/service-account.uid: 95d84d80-be7a-4d10-a2e0-68f90222d039 17 18Type: kubernetes.io/service-account-token 19 20Data 21==== 22namespace: 20 bytes 23token: eyJhbGciOiJSUzI1NiIsImtpZCI6ImJrYkF4bW5XcDhWcmNGUGJtek5NODFuSXl1aWptMmU2M3o4LTY5a2FKS2cifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4teGJxaGgiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiOTVkODRkODAtYmU3YS00ZDEwLWEyZTAtNjhmOTAyMjJkMDM5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.NAl7e8ZfWWdDoPxkqzJzTB46sK9E8iuJYnUI9vnBaY3Jts7T1g1msjsBnbxzQSYgAG--cV0WYxjndzJY_UWCwaGPrQrt_GunxmOK9AUnzURqm55GR2RXIZtjsWVP2EBatsDgHRmuUbQvTFOvdJB4x3nXcYLN2opAaMqg3rnU2rr-A8zCrIuX_eca12wIp_QiuP3SF-tzpdLpsyRfegTJZl6YnSGyaVkC9id-cxZRb307qdCfXPfCHR_2rt5FVfxARgg_C0e3eFHaaYQO7CitxsnIoIXpOFNAR8aUrmopJyODQIPqBWUehb7FhlU1DCduHnIIXVC_UICZ-MKYewBDLw 24ca.crt: 1025 bytes 3）通过浏览器访问Dashboard的UI\n在登录页面上输入上面的token\n出现下面的页面代表成功\n10.2 使用DashBoard 本章节以Deployment为例演示DashBoard的使用\n查看\n选择指定的命名空间dev，然后点击Deployments，查看dev空间下的所有deployment\n扩缩容\n在Deployment上点击规模，然后指定目标副本数量，点击确定\n编辑\n在Deployment上点击编辑，然后修改yaml文件，点击确定\n查看Pod\n点击Pods, 查看pods列表\n操作Pod\n选中某个Pod，可以对其执行日志（logs）、进入执行（exec）、编辑、删除操作\nDashboard提供了kubectl的绝大部分功能，这里不再一一演示\n","date":"2022-01-27","img":"","permalink":"/posts/387f5f40/","series":null,"tags":["k8s","教程"],"title":"Kubernetes学习记录"},{"categories":[["Go"],["源码"]],"content":"作为 Go 核心的数据结构和 Goroutine 之间的通信方式，Channel 是支撑 Go 语言高性能并发编程模型的重要结构本文会介绍管道 Channel 的设计原理、数据结构和常见操作，例如 Channel 的创建、发送、接收和关闭。\n特性 初始化 声明和初始化channel的方式主要有以下两种：\n变量声明 使用内置函数make() 变量声明 1var ch chan int 这种方式声明的管道，值为nil，并且每个管道只能存储一种类型数据。\n使用内置函数make() 使用内置函数make()可以创建无缓冲管道和带缓冲的管道\n1ch1 := make(chan int) //无缓冲的管道 2ch2 := make(chan int, 10) //缓冲区为10的管道 管道的操作 操作符 操作符\u0026lt;-表示数据的流向，管道在做表示向管道写入数据，管道在右表示从管道读取数据\n1ch := make(chan int, 10) //缓冲区为10的管道 2ch \u0026lt;- 1 //向管道写入数据 3num := \u0026lt;-ch // 从管道读取数据 4fmt.Println(num) 默认的管道为双向可读写，管道在函数间传递时可以使用操作符显示管道的读写，如下：\n1func OnlyRead(read \u0026lt;-chan int) { 2 // 只读 3 fmt.Println(\u0026lt;-read) 4} 5func OnlyWrite(write chan\u0026lt;- int) { 6 // 只写 7 write \u0026lt;- 1 8} 9func All(all chan int) { 10 // 可写 11 all \u0026lt;- 1 12 // 可读 13 fmt.Println(\u0026lt;-all) 14} 数据读写 管道中没有缓冲区时，从管道读取数据会阻塞，直到有协程向管道中写数据。类似地，向管道中写入数据也会阻塞，直到有协程从管道中读取数据。\n管道有缓冲区但是缓冲区没有数据时，从管道读取数据也会阻塞，直到有协程写入数据。类似地，向管道写入数据，如果缓冲区已满，那么也会阻塞，直到有协程从缓冲区中读取数据。\n对于值为nil的管道，无论读写都会阻塞，而且是永久阻塞。\n使用内置函数cloase()可以关闭管道，尝试向已经关闭的管道写数据会发生panic，但是关闭的管道仍然可以读。\n管道读取表达式最多可以给两个变量赋值，\n1ch := make(chan int, 10) //缓冲区为10的管道 2v1 := \u0026lt;-ch 3x, ok := \u0026lt;-ch 第一个变量表示读取出来的数据，第二个变量(bool)表示是否成功读取了数据，\n第二个变量不用于指示管道的关闭状态\n1ch := make(chan int, 10) //缓冲区为10的管道 2ch \u0026lt;- 1 // 写入数据 3ch \u0026lt;- 2 // 写入数据 4ch \u0026lt;- 3 // 写入数据 5close(ch) 6x, ok := \u0026lt;-ch 7fmt.Println(x, \u0026#34;\u0026#34;, ok) 8// 结果为1 true 第二个变量的值与管道的关闭状态有关，更确切地说跟管道缓冲区中是否有数据有关：\n一个已经关闭的管道有两种情况：\n缓冲区有数据 缓冲区没有数据 对于第一种情况，管道已经关闭而且还有数据，那么管道读取表达式返回的第一个变量读取到的数据，第二个变量的值为true\n对于第二种情况，管道已经关闭没有数据，那么管道读取表达式返回的第一个变量为相应类型的零值，第二个变量为false\n可以看到，只有管道已关闭并且缓冲区中没有数据时，管道读取表达式返回第二个变量才与管道关闭状态一致。\n可以使用len() cap()可以用来查询缓冲区数据个数以及缓冲区的大小\n总结 给一个 nil channel 发送/接收数据，造成永远阻塞 给一个已经关闭的 channel 发送数据，引起 panic 从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零值 无缓冲的channel是同步的，而有缓冲的channel是非同步的 实现原理 数据结构 源码包中src/runtime/chan.go:hchan定义了管道的数据结构\n1type hchan struct { 2 qcount uint // 当前队列中剩余元素的个数 3 dataqsiz uint // 环形队列的长度 4 buf unsafe.Pointer // 环形队列指针 5 elemsize uint16 // 每个元素的大小 6 closed uint32\t// 标识关闭的转态 7 elemtype *_type // 存放数据的类型 8 sendx uint // 队列的下标，指示元素写入时存放到循环队列中的位置 9 recvx uint // 下一个被读取的元素在队列中的位置 10 recvq waitq // 等待读消息的协程队列 11 sendq waitq // 等待写消息的协程队列 12 13 // lock protects all fields in hchan, as well as several 14 // fields in sudogs blocked on this channel. 15 // 16 // Do not change another G\u0026#39;s status while holding this lock 17 // (in particular, do not ready a G), as this can deadlock 18 // with stack shrinking. 19 lock mutex\t// 互斥锁，chan不允许并发 20} 从数据结构可以看出channel由队列、类型消息、协程等队列组成。\nqcount代表chan 中已经接收但还没被取走的元素的个数，函数 len 可以返回这个字段的值；\ndataqsiz和buf分别代表队列buffer的大小，cap函数可以返回这个字段的值以及队列buffer的指针，是一个定长的环形数组；\nelemtype 和 elemsiz表示chan 中元素的类型和 元素的大小；\nsendx：发送数据的指针在 buffer中的位置；\nrecvx：接收请求时的指针在 buffer 中的位置；\nrecvq和sendq分别表示等待接收数据的 goroutine 与等待发送数据的 goroutine；\nsendq和recvq的类型是waitq的结构体：\n1type waitq struct { 2\tfirst *sudog 3\tlast *sudog 4} waitq里面连接的是一个sudog双向链表，保存的是等待的goroutine 。整个chan的图例大概是这样：\n等待队列 从管道中读取数据时，如果管道缓冲区为空或者没有缓冲区，则当前的协程就会被阻塞，并且加入recvq队列中。向管道中写入数据时，如果管道缓冲区已满或者没有缓存区，则当前协程会被则色，并且加入sendq队列。\n处于等待队列中的协程会在其他协程操作管道时被唤醒：\n因读阻塞的协程会被向管道写入的协程唤醒 因写阻塞的协程会被向管道读取的协程唤醒 一般情况下recvq和sendq至少有一个为空。只有一个是例外，那就是同一个协程使用select语句向管道一边写入数据，一边读取读取数据，此时协程会分别位于两个等待队列中。\n管道操作 创建管道 创建管道时间上是初始化hchan结构，其中类型消息和缓冲区长度是由make()进行指定，buf的大小则是由元素大小和缓冲区长度共同决定\n创建管道的伪代码如下：\n1func makechan(t *chantype, size int) *hchan { 2 var c *hchan 3 c = new(hchan) 4 c.buf = malloc(元素类型大小 * size)\t// 申请空间 5 c.elemsize = 元素类型大小 6 c.elemtype = 元素类型 7 c.dataqsiz = size 8 return c 9} 向管道中写数据 向一个管道中写入数据的简单过程如下：\n如果缓冲区中有空余位置，则将数据写入缓冲区，结束发送过程 如果缓冲区中没有空余位置，则将当前协程加入sendq队列，进入睡眠并等待被读协程唤醒 实现时有一个小技巧，当前接受队列recvq不为空时，说明缓冲区中没有数据但有协程在等待数据，此时会把数据直接传递给recvq队列中第一个协程，而不必再写入缓冲区。\n简单流程如下：\n从管道读数据 从管道读取数据的简单过程如下：\n如果缓冲区中有数据，则从缓冲区取出数据，结束过程 如果缓冲区没有数据，则将当前协程加入recvq中，进入睡眠并等待被写协程唤醒 类似地，如果等待发送队列sendq不为空，且没有缓冲区，那么此时将直接从sendq队列的第一个协程总获取数据。\n简答流程如下：\n关闭管道 关闭管道时会把recq中的协程全部唤醒，这些协程获取的数据都为nil，同时会把sendq中的协程全部唤醒，这些协程触发panic\n除此之外，其他会触发panic的操作还有：\n关闭值为nil的管道 关闭已经关闭的管道 向已经关闭的管道写数据 常见用法 单向管道 上述已经介绍过\nselect 使用select可以监控多个管道，当其中某一个管道可操作时就触发相应的case分支\n一个简答是示例程序如下：\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;time\u0026#34; 6) 7 8func main() { 9 var ch1 = make(chan int, 10) 10 var ch2 = make(chan int, 10) 11 12 go addNumberToChan(ch1) 13 go addNumberToChan(ch2) 14 15 for { 16 select { 17 case e := \u0026lt;-ch1: 18 fmt.Printf(\u0026#34;Get element form ch1: %d\\n\u0026#34;, e) 19 case e := \u0026lt;-ch2: 20 fmt.Printf(\u0026#34;Get element form ch2: %d\\n\u0026#34;, e) 21 default: 22 fmt.Printf(\u0026#34;No element in ch1 and ch2\\n\u0026#34;) 23 time.Sleep(time.Second) 24 } 25 26 } 27} 运行结果如下：\n1No element in ch1 and ch2 2Get element form ch2: 1 3Get element form ch2: 1 4Get element form ch1: 1 5Get element form ch1: 1 6No element in ch1 and ch2 7No element in ch1 and ch2 8Get element form ch2: 1 9Get element form ch1: 1 10Get element form ch1: 1 11Get element form ch2: 1 12No element in ch1 and ch2 13No element in ch1 and ch2 14Get element form ch1: 1 15Get element form ch1: 1 16Get element form ch2: 1 17Get element form ch2: 1 18No element in ch1 and ch2 19No element in ch1 and ch2 20... 由输出可见，从管道中读出数据的顺序是随机的。事实上，select语句的多个case语句的执行顺序是随机的。\n通过这个例子可以看出，select的case语句读取管道时不会阻塞，尽管管道中没有数据。这是由于case语句编译后调用读取管道时会明确传入不阻塞的参数，读不到数据时不会将当前协程加入等待队列，而是直接返回。\nfor-range 通过for-range可以持续地从管道中出数据，好像在遍历一个数组一样，当管道中没有数据时会阻塞当前协程，与读管道是的阻塞机制一样，即使管道被关闭，for-range也可以优雅结束\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;time\u0026#34; 6) 7 8func main() { 9\tvar ch1 = make(chan int, 10) 10 11\tgo addNumberToChan(ch1) 12\tgo chanRange(ch1) 13\tfor { 14 15\t} 16 17} 18func addNumberToChan(ch chan int) { 19\t// 每隔 1 秒向chan中写入一次数据 20\tfor { 21\tch \u0026lt;- 1 22\tfmt.Printf(\u0026#34;Set element to chan: %d\\n\u0026#34;, 1) 23\ttime.Sleep(time.Second) 24\t} 25} 26func chanRange(ch \u0026lt;-chan int) { 27\tfor e := range ch { 28\tfmt.Printf(\u0026#34;Get element form chan: %d\\n\u0026#34;, e) 29\t} 30} 结果如下：\n1Set element to chan: 1 2Get element form chan: 1 3Set element to chan: 1 4Get element form chan: 1 5Set element to chan: 1 6Get element form chan: 1 7Set element to chan: 1 8Get element form chan: 1 9... 例子 实现互斥锁 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tvar ch = make(chan int, 1) 7\tWorker(ch) 8} 9 10func Worker(ch chan int) { 11\tch \u0026lt;- 1 12\t//操作 13\t{ 14\tfmt.Println(\u0026#34;操作\u0026#34;) 15\t} 16\t// 17\t\u0026lt;-ch 18} ","date":"2022-01-26","img":"","permalink":"/posts/fb1f55a9/","series":null,"tags":["Go"],"title":"Channel简介与实现原理"},{"categories":[["教程"],["Web"]],"content":"浏览器安全的基石是\u0026quot;同源政策\u0026quot;（same-origin policy）。\n本文介绍\u0026quot;同源政策\u0026quot;的各个方面\n1995年，同源政策由 Netscape 公司引入浏览器。目前，所有浏览器都实行这个政策。\n最初，它的含义是指，A网页设置的 Cookie，B网页不能打开，除非这两个网页\u0026quot;同源\u0026quot;。所谓\u0026quot;同源\u0026quot;指的是\u0026quot;三个相同\u0026quot;。\n协议相同 域名相同 端口相同 如果两个 URL 的 protocol port 和 host 都相同的话，则这两个 URL 是同源。这个方案也被称为“协议/主机/端口元组”，或者直接是 “元组”。（“元组” 是指一组项目构成的整体，双重/三重/四重/五重/等的通用形式）。\n举例来说，http://www.example.com/dir/page.html这个网址，协议是http://，域名是www.example.com，端口是80（默认端口可以省略）。它的同源情况如下。\nhttp://www.example.com/dir2/other.html：同源 http://example.com/dir/other.html：不同源（域名不同） http://v2.www.example.com/dir/other.html：不同源（域名不同） http://www.example.com:81/dir/other.html：不同源（端口不同） 比如我们打开bing主页\n目前我所在的域就是https://cn.bing.com),如果要向https://www.bing.com发请求，那么他们就不是同源，就会被拒绝。\n为什么会出现同源政策？ 同源政策的目的，是为了保证用户信息的安全，防止恶意的网站窃取数据。\n设想这样一种情况：A网站是一家银行，用户登录以后，又去浏览其他网站。如果其他网站可以读取A网站的 Cookie，会发生什么？\n很显然，如果 Cookie 包含隐私（比如存款总额），这些信息就会泄漏。更可怕的是，Cookie 往往用来保存用户的登录状态，如果用户没有退出登录，其他网站就可以冒充用户，为所欲为。因为浏览器同时还规定，提交表单不受同源政策的限制。\n由此可见，\u0026ldquo;同源政策\u0026quot;是必需的，否则 Cookie 可以共享，互联网就毫无安全可言了。\n同源政策限制什么？ 随着互联网的发展，\u0026ldquo;同源政策\u0026quot;越来越严格。目前，如果非同源，共有三种行为受到限制。\n（1） Cookie、LocalStorage 和 IndexDB 无法读取。\n（2） DOM 无法获得。\n（3） AJAX 请求不能发送。\n虽然这些限制是必要的，但是有时很不方便，合理的用途也受到影响。\n","date":"2022-01-22","img":"","permalink":"/posts/6658c08b/","series":null,"tags":["跨域"],"title":"浏览器同源政策"},{"categories":[["Go"],["教程"]],"content":"本文主要给大家介绍了Go语言中函数new与make的使用和区别，关于Go语言中new和make是内建的两个函数，主要用来创建分配类型内存。在我们定义生成变量的时候，可能会觉得有点迷惑，其实他们的规则很简单，下面我们就通过一些示例说明他们的区别和使用。\n变量的声明 1var i int 2var s string 变量的声明我们可以通过var关键字，然后就可以在程序中使用。当我们不指定变量的默认值时，这些变量的默认值是他们的零值，比如int类型的零值是0,string类型的零值是\u0026quot;\u0026quot;，引用类型的零值是nil。\n对于例子中的两种类型的声明，我们可以直接使用，对其进行赋值输出。但是如果我们换成指针类型呢？\ntest1.go\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5) 6 7func main() { 8 var i *int 9 *i=10 10 fmt.Println(*i) 11} 12$ go run test1.go 13panic: runtime error: invalid memory address or nil pointer dereference 14[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x4849df] 15 16goroutine 1 [running]: 17main.main() 18\t/home/itheima/go/src/golang_deeper/make_new/t 从这个提示中可以看出，对于引用类型的变量，我们不光要声明它，还要为它分配内容空间，否则我们的值放在哪里去呢？这就是上面错误提示的原因。\n对于值类型的声明不需要，是因为已经默认帮我们分配好了。\n要分配内存，就引出来今天的new和make。\nnew 对于上面的问题我们如何解决呢？既然我们知道了没有为其分配内存，那么我们使用new分配一个吧。\n1func main() { 2 3 var i *int 4 i=new(int) 5 *i=10 6 fmt.Println(*i) 7 8} 现在再运行程序，完美PASS，打印10。现在让我们看下new这个内置的函数。\n1// The new built-in function allocates memory. The first argument is a type, 2// not a value, and the value returned is a pointer to a newly 3// allocated zero value of that type. 4func new(Type) *Type 它只接受一个参数，这个参数是一个类型，分配好内存后，返回一个指向该类型内存地址的指针。同时请注意它同时把分配的内存置为零，也就是类型的零值。\n我们的例子中，如果没有*i=10，那么打印的就是0。这里体现不出来new函数这种内存置为零的好处，我们再看一个例子。\ntest2.go\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5) 6 7type user struct { 8 name string 9 age int 10} 11 12func main() { 13 14 u := new(user) //默认给u分配到内存全部为0 15 u.name = \u0026#34;张三\u0026#34; 16 17 fmt.Println(u) 18} 运行\n1$ go run test2.go 2\u0026amp;{张三 0} 示例中的user类型中的lock字段我不用初始化，直接可以拿来用，不会有无效内存引用异常，因为它已经被零值了。\n这就是new，它返回的永远是类型的指针，指向分配类型的内存地址。\nmake make也是用于内存分配的，但是和new不同。\n它只用于\nchan map slice 的内存创建，而且它返回的类型就是这三个类型本身，而不是他们的指针类型，因为这三种类型就是引用类型，所以就没有必要返回他们的指针了。\n注意，因为这三种类型是引用类型，所以必须得初始化，但是不是置为零值，这个和new是不一样的。\n1func make(t Type, size ...IntegerType) Type 从函数声明中可以看到，返回的还是该类型。\nmake与new的异同 相同\n堆空间分配 不同\nmake: 只用于slice、map以及channel的初始化， 无可替代\nnew: 用于类型内存分配(初始化值为0)， 不常用\nnew不常用\n所以有new这个内置函数，可以给我们分配一块内存让我们使用，但是现实的编码中，它是不常用的。我们通常都是采用短语句声明以及结构体的字面量达到我们的目的，比如：\n1i : =0 2u := user{} make 无可替代\n我们在使用slice、map以及channel的时候，还是要使用make进行初始化，然后才可以对他们进行操作。\n","date":"2022-01-18","img":"","permalink":"/posts/b7d0417a/","series":null,"tags":["教程"],"title":"Golang中的make和new"},{"categories":[["Go"],["教程"]],"content":"go语言编译器会自动决定把一个变量放在栈还是放在堆，编译器会做逃逸分析(escape analysis)，当发现变量的作用域没有跑出函数范围，就可以在栈上，反之则必须分配在堆。 go语言声称这样可以释放程序员关于内存的使用限制，更多的让程序员关注于程序功能逻辑本身。\n什么是堆？什么是栈？ 简单说：\n堆：一般来讲是人为手动进行管理，手动申请、分配、释放。一般所涉及的内存大小并不定，一般会存放较大的对象。另外其分配相对慢，涉及到的指令动作也相对多 栈：由编译器进行管理，自动申请、分配、释放。一般不会太大，我们常见的函数参数（不同平台允许存放的数量不同），局部变量等等都会存放在栈上 逃逸分析 逃逸分析是一种确定指针动态范围的方法，简单来说就是分析在程序的哪些地方可以访问到该指针。\n通俗地讲，逃逸分析就是确定一个变量要放堆上还是栈上，规则如下：\n是否有在其他地方（非局部）被引用。只要有可能被引用了，那么它一定分配到堆上。否则分配到栈上 即使没有被外部引用，但对象过大，无法存放在栈区上。依然有可能分配到堆上 对此你可以理解为，逃逸分析是编译器用于决定变量分配到堆上还是栈上的一种行为。\n为什么需要逃逸 其实就是为了尽可能在栈上分配内存，我们可以反过来想，如果变量都分配到堆上了会出现什么事情？例如：\n垃圾回收（GC）的压力不断增大 申请、分配、回收内存的系统开销增大（相对于栈） 动态分配产生一定量的内存碎片 其实总的来说，就是频繁申请、分配堆内存是有一定 “代价” 的。会影响应用程序运行的效率，间接影响到整体系统。因此 “按需分配” 最大限度的灵活利用资源，才是正确的治理之道。这就是为什么需要逃逸分析的原因。\nGolang编译器的逃逸分析 我们再看如下代码:\n1package main 2 3func foo(argVal int) *int { 4 5\tvar fooVal1 int = 11 6\tvar fooVal2 int = 12 7\tvar fooVal3 int = 13 8\tvar fooVal4 int = 14 9\tvar fooVal5 int = 15 10\t//此处循环是防止go编译器将foo优化成inline(内联函数) 11\t//如果是内联函数，main调用foo将是原地展开，所以foo_val1-5相当于main作用域的变量 12\t//即使foo_val3发生逃逸，地址与其他也是连续的 13\tfor i := 0; i \u0026lt; 5; i++ { 14\tprintln(\u0026amp;argVal, \u0026amp;fooVal1, \u0026amp;fooVal2, \u0026amp;fooVal3, \u0026amp;fooVal4, \u0026amp;fooVal5) 15\t} 16 17\t//返回foo_val3给main函数 18\treturn \u0026amp;fooVal3 19} 20 21func main() { 22\tmainVal := foo(666) 23 24\tprintln(*mainVal, mainVal) 25} 运行结果如下\n10xc000049f60 0xc000049f58 0xc000049f50 0xc000049f48 0xc000049f40 0xc000049f38 20xc000049f60 0xc000049f58 0xc000049f50 0xc000049f48 0xc000049f40 0xc000049f38 30xc000049f60 0xc000049f58 0xc000049f50 0xc000049f48 0xc000049f40 0xc000049f38 40xc000049f60 0xc000049f58 0xc000049f50 0xc000049f48 0xc000049f40 0xc000049f38 50xc000049f60 0xc000049f58 0xc000049f50 0xc000049f48 0xc000049f40 0xc000049f38 613 0xc000049f48 我们能看到foo_val3是返回给main的局部变量, 其中他的地址应该是0xc000049f48,很明显与其他的foo_val1、2、3、4不是连续的.\n我们用go tool compile测试一下\n1D:\\code\\go\\test\u0026gt;go tool compile -m main.go 2main.go:3:6: can inline foo 3main.go:21:6: can inline main 4main.go:22:16: inlining call to foo 5main.go:7:6: moved to heap: fooVal3 果然,在编译的时候, foo_val3具有被编译器判定为逃逸变量, 将foo_val3放在堆中开辟.\nnew的变量在栈还是堆? 那么对于new出来的变量,是一定在heap中开辟的吗,我们来看看\n1package main 2 3func foo(argVal int) *int { 4 5 var fooVal1 *int = new(int) 6 var fooVal2 *int = new(int) 7 var fooVal3 *int = new(int) 8 var fooVal4 *int = new(int) 9 var fooVal5 *int = new(int) 10 11 //此处循环是防止go编译器将foo优化成inline(内联函数) 12 //如果是内联函数，main调用foo将是原地展开，所以foo_val1-5相当于main作用域的变量 13 //即使foo_val3发生逃逸，地址与其他也是连续的 14 for i := 0; i \u0026lt; 5; i++ { 15 println(argVal, fooVal1, fooVal2, fooVal3, fooVal4, fooVal5) 16 } 17 18 //返回foo_val3给main函数 19 return fooVal3 20} 21 22func main() { 23 mainVal := foo(666) 24 25 println(*mainVal, mainVal) 26} 我们将foo_val1-5全部用new的方式来开辟, 编译运行看结果\n1666 0xc000049f40 0xc000049f68 0xc000049f60 0xc000049f58 0xc000049f50 2666 0xc000049f40 0xc000049f68 0xc000049f60 0xc000049f58 0xc000049f50 3666 0xc000049f40 0xc000049f68 0xc000049f60 0xc000049f58 0xc000049f50 4666 0xc000049f40 0xc000049f68 0xc000049f60 0xc000049f58 0xc000049f50 5666 0xc000049f40 0xc000049f68 0xc000049f60 0xc000049f58 0xc000049f50 60 0xc000049f60 很明显, foo_val3的地址0xc000049f60依然与其他的不是连续的. 依然具备逃逸行为.\n逃逸规则 我们其实都知道一个普遍的规则，就是如果变量需要使用堆空间，那么他就应该进行逃逸。但是实际上Golang并不仅仅把逃逸的规则如此泛泛。Golang会有很多场景具备出现逃逸的现象。\n一般我们给一个引用类对象中的引用类成员进行赋值，可能出现逃逸现象。可以理解为访问一个引用对象实际上底层就是通过一个指针来间接的访问了，但如果再访问里面的引用成员就会有第二次间接访问，这样操作这部分对象的话，极大可能会出现逃逸的现象。\nGo语言中的引用类型有func（函数类型），interface（接口类型），slice（切片类型），map（字典类型），channel（管道类型），*（指针类型）等。\n那么我们下面的一些操作场景是产生逃逸的。\n[]interface{}数据类型，通过[]赋值必定会出现逃逸。 1package main 2 3func main() { 4 data := []interface{}{100, 200} 5 data[0] = 100 6} 1D:\\code\\go\\test\u0026gt;go tool compile -m main.go 2main.go:3:6: can inline main 3main.go:4:23: []interface {}{...} does not escape 4main.go:4:24: 100 does not escape 5main.go:4:29: 200 does not escape 6main.go:5:10: 100 escapes to heap 我们能看到，data[0] = 100 发生了逃逸现象。\nmap[string]interface{}类型尝试通过赋值，必定会出现逃逸。 1package main 2 3func main() { 4 data := make(map[string]interface{}) 5 data[\u0026#34;key\u0026#34;] = 200 6} 1D:\\code\\go\\test\u0026gt;go tool compile -m main.go 2main.go:3:6: can inline main 3main.go:4:14: make(map[string]interface {}) does not escape 4main.go:5:14: 200 escapes to heap 我们能看到，data[\u0026quot;key\u0026quot;] = 200 发生了逃逸。\nmap[interface{}]interface{}类型尝试通过赋值，会导致key和value的赋值，出现逃逸。 1package main 2 3func main() { 4 data := make(map[interface{}]interface{}) 5 data[100] = \u0026#34;dddd\u0026#34; 6} 1D:\\code\\go\\test\u0026gt;go tool compile -m main.go 2main.go:3:6: can inline main 3main.go:4:14: make(map[interface {}]interface {}) does not escape 4main.go:5:6: 100 escapes to heap 5main.go:5:12: \u0026#34;dddd\u0026#34; escapes to heap 我们能看到，data[100] = \u0026quot;dddd\u0026quot; 中，100和\u0026quot;dddd\u0026quot;均发生了逃逸。\nmap[string][]string数据类型，赋值会发生[]string发生逃逸。 1package main 2 3func main() { 4 data := make(map[string][]string) 5 data[\u0026#34;key\u0026#34;] = []string{\u0026#34;value\u0026#34;} 6} 1D:\\code\\go\\test\u0026gt;go tool compile -m main.go 2main.go:3:6: can inline main 3main.go:4:14: make(map[string][]string) does not escape 4main.go:5:24: []string{...} escapes to heap 我们能看到，[]string{...}切片发生了逃逸。\n[]*int数据类型，赋值的右值会发生逃逸现象。 1package main 2 3func main() { 4 a := 10 5 data := []*int{nil} 6 data[0] = \u0026amp;a 7} 我们通过编译看看逃逸结果\n1go tool compile -m 5.go 25.go:3:6: can inline main 35.go:4:2: moved to heap: a 45.go:6:16: []*int{...} does not escape 其中 moved to heap: a，最终将变量a 移动到了堆上。\nfunc(*int)函数类型，进行函数赋值，会使传递的形参出现逃逸现象。 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func foo(a *int) { 6 return 7} 8 9func main() { 10 data := 10 11 f := foo 12 f(\u0026amp;data) 13 fmt.Println(data) 14} 我们通过编译看看逃逸结果\n1aceld:test ldb$ go tool compile -m 6.go 26.go:5:6: can inline foo 36.go:12:3: inlining call to foo 46.go:14:13: inlining call to fmt.Println 56.go:5:10: a does not escape 66.go:14:13: data escapes to heap 76.go:14:13: []interface {}{...} does not escape 8:1: .this does not escape 我们会看到data已经被逃逸到堆上。\nfunc([]string): 函数类型，进行[]string{\"value\"}赋值，会使传递的参数出现逃逸现象。 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func foo(a []string) { 6 return 7} 8 9func main() { 10 s := []string{\u0026#34;aceld\u0026#34;} 11 foo(s) 12 fmt.Println(s) 13} 我们通过编译看看逃逸结果\n1go tool compile -m 7.go 27.go:5:6: can inline foo 37.go:11:5: inlining call to foo 47.go:13:13: inlining call to fmt.Println 57.go:5:10: a does not escape 67.go:10:15: []string{...} escapes to heap 77.go:13:13: s escapes to heap 87.go:13:13: []interface {}{...} does not escape 9 :1: .this does not escape 我们看到 s escapes to heap，s被逃逸到堆上。\nchan []string数据类型，想当前channel中传输[]string{\"value\"}会发生逃逸现象。 1package main 2 3func main() { 4 ch := make(chan []string) 5 6 s := []string{\u0026#34;aceld\u0026#34;} 7 8 go func() { 9 ch \u0026lt;- s 10 }() 11} 我们通过编译看看逃逸结果\n1go tool compile -m 8.go 28.go:8:5: can inline main.func1 38.go:6:15: []string{...} escapes to heap 48.go:8:5: func literal escapes to heap 我们看到[]string{...} escapes to heap, s被逃逸到堆上。\n总结 我们得出了指针必然发生逃逸的三种情况\n在某个函数中new或字面量创建出的变量，将其指针作为函数返回值，则该变量一定发生逃逸（构造函数返回的指针变量一定逃逸）； 被已经逃逸的变量引用的指针，一定发生逃逸； 被指针类型的slice、map和chan引用的指针，一定发生逃逸； 同时我们也得出一些必然不会逃逸的情况：\n指针被未发生逃逸的变量引用； 仅仅在函数内对变量做取址操作，而未将指针传出； 参考 golang 逃逸分析与栈、堆分配分析_惜暮-CSDN博客_golang 堆栈分配\n3、Golang中逃逸现象, 变量“何时栈?何时堆?” · Golang修养之路 · 看云 (kancloud.cn)\ngolang 逃逸分析详解 - 知乎 (zhihu.com)\n","date":"2022-01-18","img":"","permalink":"/posts/427ffcfc/","series":null,"tags":["教程","逃逸分析"],"title":"Golang逃逸现象"},{"categories":[["Go"],["教程"]],"content":"垃圾回收(Garbage Collection，简称GC)是编程语言中提供的自动的内存管理机制，自动释放不需要的内存对象，让出存储器资源。GC过程中无需程序员手动执行。GC机制在现代很多编程语言都支持，GC能力的性能与优劣也是不同语言之间对比度指标之一。\nGolang在GC的演进过程中也经历了很多次变革，Go V1.3之前的标记-清除(mark and sweep)算法，Go V1.3之前的标记-清扫(mark and sweep)的缺点\nGo V1.5的三色并发标记法 Go V1.5的三色标记为什么需要STW Go V1.5的三色标记为什么需要屏障机制(“强-弱” 三色不变式、插入屏障、删除屏障 ) Go V1.8混合写屏障机制 Go V1.8混合写屏障机制的全场景分析 Go V1.3之前的标记-清除(mark and sweep)算法 接下来我们来看一下在Golang1.3之前的时候主要用的普通的标记-清除算法，此算法主要有两个主要的步骤：\n标记(Mark phase) 清除(Sweep phase) 标记清除算法的具体步骤 暂停程序业务逻辑, 分类出可达和不可达的对象，然后做上标记。\n图中表示是程序与对象的可达关系，目前程序的可达对象有对象1-2-3，对象4-7等五个对象。\n开始标记，程序找出它所有可达的对象，并做上标记。如下图所示：\n所以对象1-2-3、对象4-7等五个对象被做上标记。\n标记完了之后，然后开始清除未标记的对象. 结果如下。\n操作非常简单，但是有一点需要额外注意：mark and sweep算法在执行的时候，需要程序暂停！即 STW(stop the world)，STW的过程中，CPU不执行用户代码，全部用于垃圾回收，这个过程的影响很大，所以STW也是一些回收机制最大的难题和希望优化的点。所以在执行第三步的这段时间，程序会暂定停止任何工作，卡在那等待回收执行完毕。\n停止暂停，让程序继续跑。然后循环重复这个过程，直到process程序生命周期结束。\n以上便是标记-清除（mark and sweep）回收的算法。\n标记-清除(mark and sweep)的缺点 标记清除算法明了，过程鲜明干脆，但是也有非常严重的问题。\nSTW，stop the world；让程序暂停，程序出现卡顿 (重要问题)； 标记需要扫描整个heap； 清除数据会产生heap碎片。 Go V1.3版本之前就是以上来实施的, 在执行GC的基本流程就是首先启动STW暂停，然后执行标记，再执行数据回收，最后停止STW，如图所示。\n从上图来看，全部的GC时间都是包裹在STW范围之内的，这样貌似程序暂停的时间过长，影响程序的运行性能。所以Go V1.3 做了简单的优化,将STW的步骤提前, 减少STW暂停的时间范围.如下所示\n上图主要是将STW的步骤提前了异步，因为在Sweep清除的时候，可以不需要STW停止，因为这些对象已经是不可达对象了，不会出现回收写冲突等问题。\n但是无论怎么优化，Go V1.3都面临这个一个重要问题，就是mark-and-sweep 算法会暂停整个程序 。\nGo是如何面对并这个问题的呢？接下来G V1.5版本 就用三色并发标记法来优化这个问题.\nGo V1.5的三色并发标记法 Golang中的垃圾回收主要应用三色标记法，GC过程和其他用户goroutine可并发运行，但需要一定时间的STW(stop the world)，所谓三色标记法实际上就是通过三个阶段的标记来确定清楚的对象都有哪些？我们来看一下具体的过程。\n每次新创建的对象，默认的颜色都是标记为“白色”，如图所示。\n上图所示，我们的程序可抵达的内存对象关系如左图所示，右边的标记表，是用来记录目前每个对象的标记颜色分类。这里面需要注意的是，所谓“程序”，则是一些对象的跟节点集合。所以我们如果将“程序”展开，会得到类似如下的表现形式，如图所示。\n每次GC回收开始, 会从根节点开始遍历所有对象，把遍历到的对象从白色集合放入“灰色”集合如图所示。\n这里 要注意的是，本次遍历是一次遍历，非递归形式，是从程序抽次可抵达的对象遍历一层，如上图所示，当前可抵达的对象是对象1和对象4，那么自然本轮遍历结束，对象1和对象4就会被标记为灰色，灰色标记表就会多出这两个对象。\n遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合，如图所示。\n这一次遍历是只扫描灰色对象，将灰色对象的第一层遍历可抵达的对象由白色变为灰色，如：对象2、对象7. 而之前的灰色对象1和对象4则会被标记为黑色，同时由灰色标记表移动到黑色标记表中。\n重复第三步, 直到灰色中无任何对象，如图所示。\n当我们全部的可达对象都遍历完后，灰色标记表将不再存在灰色对象，目前全部内存的数据只有两种颜色，黑色和白色。那么黑色对象就是我们程序逻辑可达（需要的）对象，这些数据是目前支撑程序正常业务运行的，是合法的有用数据，不可删除，白色的对象是全部不可达对象，目前程序逻辑并不依赖他们，那么白色对象就是内存中目前的垃圾数据，需要被清除。\n回收所有的白色标记表的对象. 也就是回收垃圾，如图所示。\n以上我们将全部的白色对象进行删除回收，剩下的就是全部依赖的黑色对象。\n以上便是三色并发标记法，不难看出，我们上面已经清楚的体现三色的特性。但是这里面可能会有很多并发流程均会被扫描，执行并发流程的内存可能相互依赖，为了在GC过程中保证数据的安全，我们在开始三色标记之前就会加上STW，在扫描确定黑白对象之后再放开STW。但是很明显这样的GC扫描的性能实在是太低了。\n那么Go是如何解决标记-清除(mark and sweep)算法中的卡顿(stw，stop the world)问题的呢？\n没有STW的三色标记法 先抛砖引玉，我们加入如果没有STW，那么也就不会再存在性能上的问题，那么接下来我们假设如果三色标记法不加入STW会发生什么事情？ 我们还是基于上述的三色并发标记法来说, 他是一定要依赖STW的. 因为如果不暂停程序, 程序的逻辑改变对象引用关系, 这种动作如果在标记阶段做了修改，会影响标记结果的正确性，我们来看看一个场景，如果三色标记法, 标记过程不使用STW将会发生什么事情?\n我们把初始状态设置为已经经历了第一轮扫描，目前黑色的有对象1和对象4， 灰色的有对象2和对象7，其他的为白色对象，且对象2是通过指针p指向对象3的，如图所示。\n现在如何三色标记过程不启动STW，那么在GC扫描过程中，任意的对象均可能发生读写操作，如图所示，在还没有扫描到对象2的时候，已经标记为黑色的对象4，此时创建指针q，并且指向白色的对象3。\n与此同时灰色的对象2将指针p移除，那么白色的对象3实则就是被挂在了已经扫描完成的黑色的对象4下，如图所示。\n然后我们正常指向三色标记的算法逻辑，将所有灰色的对象标记为黑色，那么对象2和对象7就被标记成了黑色，如图所示。\n那么就执行了三色标记的最后一步，将所有白色对象当做垃圾进行回收，如图所示。\n但是最后我们才发现，本来是对象4合法引用的对象3，却被GC给“误杀”回收掉了。\n可以看出，有两种情况，在三色标记法中，是不希望被发生的。\n条件1: 一个白色对象被黑色对象引用**(白色被挂在黑色下)** 条件2: 灰色对象与它之间的可达关系的白色对象遭到破坏**(灰色同时丢了该白色)** 如果当以上两个条件同时满足时，就会出现对象丢失现象! 并且，如图所示的场景中，如果示例中的白色对象3还有很多下游对象的话, 也会一并都清理掉。\n为了防止这种现象的发生，最简单的方式就是STW，直接禁止掉其他用户程序对对象引用关系的干扰，但是STW的过程有明显的资源浪费，对所有的用户程序都有很大影响。那么是否可以在保证对象不丢失的情况下合理的尽可能的提高GC效率，减少STW时间呢？答案是可以的，我们只要使用一种机制，尝试去破坏上面的两个必要条件就可以了。\n屏障机制 我们让GC回收器，满足下面两种情况之一时，即可保对象不丢失。 这两种方式就是“强三色不变式”和“弱三色不变式”。\n强弱三色不变式 强三色不变式 不存在黑色对象引用到白色对象的指针。破坏条件1\n弱三色不变色实际上是强制性的不允许黑色对象引用白色对象，这样就不会出现有白色对象被误删的情况。\n弱三色不变式 所有被黑色对象引用的白色对象都处于灰色保护状态。破坏条件2\n弱三色不变式强调，黑色对象可以引用白色对象，但是这个白色对象必须存在其他灰色对象对它的引用，或者可达它的链路上游存在灰色对象。 这样实则是黑色对象引用白色对象，白色对象处于一个危险被删除的状态，但是上游灰色对象的引用，可以保护该白色对象，使其安全。\n为了遵循上述的两个方式，GC算法演进到两种屏障方式，他们“插入屏障”, “删除屏障”。\n插入屏障 具体操作: 在A对象引用B对象的时候，B对象被标记为灰色。(将B挂在A下游，B必须被标记为灰色)\n满足: 强三色不变式. (不存在黑色对象引用白色对象的情况了， 因为白色会强制变成灰色)\n伪码如下:\n1添加下游对象(当前下游对象slot, 新下游对象ptr) { 2 //1 3 标记灰色(新下游对象ptr) 4 //2 5 当前下游对象slot = 新下游对象ptr 6} 场景：\nA.添加下游对象(nil, B) //A 之前没有下游， 新添加一个下游对象B， B被标记为灰色 A.添加下游对象(C, B) //A 将下游对象C 更换为B， B被标记为灰色\n这段伪码逻辑就是写屏障,. 我们知道,黑色对象的内存槽有两种位置, 栈和堆. 栈空间的特点是容量小,但是要求相应速度快,因为函数调用弹出频繁使用, 所以“插入屏障”机制,在栈空间的对象操作中不使用. 而仅仅使用在堆空间对象的操作中.\n接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。\n但是如果栈不添加,当全部三色标记扫描之后,栈上有可能依然存在白色对象被引用的情况(如上图的对象9). 所以要对栈重新进行三色标记扫描, 但这次为了对象不丢失, 要对本次标记扫描启动STW暂停. 直到栈空间的三色标记结束.\n最后将栈和堆空间 扫描剩余的全部 白色节点清除. 这次STW大约的时间在10~100ms间.\n删除屏障 具体操作: 被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。\n满足: 弱三色不变式. (保护灰色对象到白色对象的路径不会断)\n伪代码：\n1添加下游对象(当前下游对象slot， 新下游对象ptr) { 2 //1 3 if (当前下游对象slot是灰色 || 当前下游对象slot是白色) { 4 标记灰色(当前下游对象slot) //slot为被删除对象， 标记为灰色 5 } 6 7 //2 8 当前下游对象slot = 新下游对象ptr 9} 场景：\nA.添加下游对象(B, nil) //A对象，删除B对象的引用。 B被A删除，被标记为灰(如果B之前为白) A.添加下游对象(B, C)\t//A对象，更换下游B变成C。 B被A删除，被标记为灰(如果B之前为白)\n接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。\n这种方式的回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清理掉。\nGo V1.8的混合写屏障(hybrid write barrier)机制 插入写屏障和删除写屏障的短板：\n插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活； 删除写屏障：回收精度低，GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。 Go V1.8版本引入了混合写屏障机制（hybrid write barrier），避免了对栈re-scan的过程，极大的减少了STW的时间。结合了两者的优点。\n混合写屏障规则 具体操作:\n1、GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)，\n2、GC期间，任何在栈上创建的新对象，均为黑色。\n3、被删除的对象标记为灰色。\n4、被添加的对象标记为灰色。\n满足: 变形的弱三色不变式（结合了插入、删除写屏障两者的优点）\n伪代码：\n1添加下游对象(当前下游对象slot, 新下游对象ptr) { 2 //1 3\t标记灰色(当前下游对象slot) //只要当前下游对象被移走，就标记灰色 4 5 //2 6 标记灰色(新下游对象ptr)\t// 强三色 7 8 //3 9 当前下游对象slot = 新下游对象ptr 10} 这里我们注意， 屏障技术是不在栈上应用的，因为要保证栈的运行效率。\n混合写屏障的具体场景分析 接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。\n注意混合写屏障是GC的一种屏障机制，所以只是当程序执行GC的时候，才会触发这种机制。\nGC开始：扫描栈区，将可达对象全部标记为黑\n栈上的全部标记为黑，就不会再次扫描了\n场景一： 对象被一个堆对象删除引用，成为栈对象的下游 伪代码 1//前提：堆对象4-\u0026gt;对象7 = 对象7； //对象7 被 对象4引用 2栈对象1-\u0026gt;对象7 = 堆对象7； //将堆对象7 挂在 栈对象1 下游 3堆对象4-\u0026gt;对象7 = null； //对象4 删除引用 对象7 4// 代码解释 5 6heap4.Next = obj7 7stack1.Next = heap7 8heap4.Next = nil 对象4删除对象7的引用关系\n对象7要被删除，对象7被标记为灰色\n对象4就删除了对象7的引用，\n此时对象7变为灰色，下一轮将被扫描，被保护\n场景二： 对象被一个栈对象删除引用，成为另一个栈对象的下游 伪代码 1new 栈对象9； 2对象9-\u0026gt;对象3 = 对象3； //将栈对象3 挂在 栈对象9 下游 3对象2-\u0026gt;对象3 = null； //对象2 删除引用 对象3 场景三：对象被一个堆对象删除引用，成为另一个堆对象的下游 伪代码 1堆对象10-\u0026gt;对象7 = 堆对象7； //将堆对象7 挂在 堆对象10 下游 2堆对象4-\u0026gt;对象7 = null； //对象4 删除引用 对象7 场景四：对象从一个栈对象删除引用，成为另一个堆对象的下游 伪代码 1堆对象10-\u0026gt;对象7 = 堆对象7； //将堆对象7 挂在 堆对象10 下游 2堆对象4-\u0026gt;对象7 = null； //对象4 删除引用 对象7 Golang中的混合写屏障满足弱三色不变式，结合了删除写屏障和插入写屏障的优点，只需要在开始时并发扫描各个goroutine的栈，使其变黑并一直保持，这个过程不需要STW，而标记结束后，因为栈在扫描后始终是黑色的，也无需再进行re-scan操作了，减少了STW的时间。\n参考 Golang中GC回收机制三色标记与混合写屏障_哔哩哔哩_bilibili\n","date":"2022-01-17","img":"","permalink":"/posts/c21b4284/","series":null,"tags":["教程","垃圾回收机制","混合写屏障","三色标记"],"title":"Golang中GC回收机制三色标记与混合写屏障"},{"categories":[["Go"],["教程"]],"content":"Go调度器调度11种场景过程全解析\n场景1 G1在运行中想要创建一个G （G3），GMP调度器会满足局部性，G1创建的G3最好位于同一个M中。\nG1和G3可能会共享内存资源和会话是一致的。\nG3优先加入到G1所在的本地队列。\n场景2 G1运行完成后(函数：goexit)，M上运行的goroutine切换为G0（每一个M都有一个G0），G0负责调度时协程的切换（函数：schedule）。\n这里的G0是M在创建时有一个结构体的指针指向G0\n由于本地队列中还有G，所以从P的本地队列取G2，从G0切换到G2，并开始运行G2(函数：execute)。实现了线程M1的复用。\n场景3 有这么一个场景，假设P1的本地队列最多只存4个G，现在G2创建了6个G，调度器该如何处理。\n首先G2会创建4个G将P1的本地队列填满\n接下来请看场景4\n场景4 G2在创建G7的时候，发现P1的本地队列已满，需要执行负载均衡(把P1中本地队列中前一半的G，还有新创建G转移到全局队列)，将G3G4打乱之后放在全局队列中，同时将新创建的G7也加入到全局队列中，这些G被转移到全局队列时，会被打乱顺序。所以G3,G4,G7被转移到全局队列。\n全局队列中的G大概率会被不同核运行，打乱顺序能降低不同核同时修改同一缓存行的概率\n场景5 G2创建G8时，P1的本地队列未满，所以G8会被加入到P1的本地队列。\nG8加入到P1点本地队列的原因还是因为P1此时在与M1绑定，而G2此时是M1在执行。所以G2创建的新的G会优先放置到自己的M绑定的P上。\n场景6 规定：在创建G时，运行的G会尝试唤醒其他空闲的P和M组合去执行。\n假定G2唤醒了M2，M2绑定了P2，并运行G0，但P2本地队列没有G，M2此时为自旋线程**（没有G但为运行状态的线程，不断寻找G）**。M2就会从先全局拿，如果全局队列中没有就去其他的本地队列去偷。\n自旋线程：如果线程被销毁会消耗大量的硬件资源，与其让它销毁，不会让它寻找执行。 自旋线程优先从全局队列中拿G\n场景7 M2尝试从全局队列(简称“GQ”)取一批G放到P2的本地队列（函数：findrunnable()）。M2从全局队列取的G数量符合下面的公式：\n1n = min(len(GQ) / GOMAXPROCS + 1, cap(LQ) / 2 ) 相关源码参考:\n1// 从全局队列中偷取，调用时必须锁住调度器 2func globrunqget(_p_ *p, max int32) *g { 3\t// 如果全局队列中没有 g 直接返回 4\tif sched.runqsize == 0 { 5\treturn nil 6\t} 7 8\t// per-P 的部分，如果只有一个 P 的全部取 9\tn := sched.runqsize/gomaxprocs + 1 10\tif n \u0026gt; sched.runqsize { 11\tn = sched.runqsize 12\t} 13 14\t// 不能超过取的最大个数 15\tif max \u0026gt; 0 \u0026amp;\u0026amp; n \u0026gt; max { 16\tn = max 17\t} 18 19\t// 计算能不能在本地队列中放下 n 个 20\tif n \u0026gt; int32(len(_p_.runq))/2 { 21\tn = int32(len(_p_.runq)) / 2 22\t} 23 24\t// 修改本地队列的剩余空间 25\tsched.runqsize -= n 26\t// 拿到全局队列队头 g 27\tgp := sched.runq.pop() 28\t// 计数 29\tn-- 30 31\t// 继续取剩下的 n-1 个全局队列放入本地队列 32\tfor ; n \u0026gt; 0; n-- { 33\tgp1 := sched.runq.pop() 34\trunqput(_p_, gp1, false) 35\t} 36\treturn gp 37} 至少从全局队列取1个g，但每次不要从全局队列移动太多的g到p本地队列，给其他p留点。这是从全局队列到P本地队列的负载均衡。\n场景8 假设G2一直在M1上运行，经过2轮后，M2已经把G7、G4从全局队列获取到了P2的本地队列并完成运行，全局队列和P2的本地队列都空了,如场景8图的左半部分。\n全局队列已经没有G，那m就要执行work stealing(偷取)：从其他有G的P哪里偷取一半G过来，放到自己的P本地队列。P2从P1的本地队列尾部取一半的G，本例中一半则只有1个G8，放到P2的本地队列并执行。\n场景9 G1本地队列G5、G6已经被其他M偷走并运行完成，当前M1和M2分别在运行G2和G8，M3和M4没有goroutine可以运行，M3和M4处于自旋状态，它们不断寻找goroutine。\n为什么要让m3和m4自旋，自旋本质是在运行，线程在运行却没有执行G，就变成了浪费CPU. 为什么不销毁现场，来节约CPU资源。因为创建和销毁CPU也会浪费时间，我们希望当有新goroutine创建时，立刻能有M运行它，如果销毁再新建就增加了时延，降低了效率。当然也考虑了过多的自旋线程是浪费CPU，所以系统中最多有GOMAXPROCS个自旋的线程(当前例子中的GOMAXPROCS=4，所以一共4个P)，多余的没事做线程会让他们休眠。\n场景10 假定当前除了M3和M4为自旋线程，还有M5和M6为空闲的线程(没有得到P的绑定，注意我们这里最多就只能够存在4个P，所以P的数量应该永远是M\u0026gt;=P, 大部分都是M在抢占需要运行的P)，G8创建了G9，G8进行了阻塞的系统调用，M2和P2立即解绑，P2会执行以下判断：如果P2本地队列有G、全局队列有G或有空闲的M，P2都会立马唤醒1个M和它绑定，否则P2则会加入到空闲P列表，等待M来获取可用的p。本场景中，P2本地队列有G9，可以和其他空闲的线程M5绑定。\n场景11 G8创建了G9，假如G8进行了非阻塞系统调用。\nM2和P2会解绑，但M2会记住P2，然后G8和M2进入系统调用状态。当G8和M2退出系统调用时，会尝试获取P2，如果无法获取，则获取空闲的P，如果依然没有，G8会被记为可运行状态，并加入到全局队列,M2因为没有P的绑定而变成休眠状态(长时间休眠等待GC回收销毁)。\n参考 Golang深入理解GPM模型_哔哩哔哩_bilibili\n","date":"2022-01-17","img":"","permalink":"/posts/cb818503/","series":null,"tags":["教程"],"title":"Go调度器GMP调度场景"},{"categories":[["教程"],["Go"]],"content":"本文介绍如何在Linux中配置Go语言的环境\n下载所需文件 在Downloads - The Go Programming Language中复制下载url\n然后用于curl检索 tarball，确保将突出显示的 URL 替换为您刚刚复制的 URL。该-O标志确保将其输出到文件，并且该L标志指示 HTTPS 重定向，因为此链接取自 Go 网站并将在文件下载之前重定向到此处：\n1root@Jimyag:~# curl -OL https://golang.google.cn/dl/go1.17.6.linux-amd64.tar.gz 2 % Total % Received % Xferd Average Speed Time Time Time Current 3 Dload Upload Total Spent Left Speed 4100 75 100 75 0 0 136 0 --:--:-- --:--:-- --:--:-- 135 5100 128M 100 128M 0 0 3042k 0 0:00:43 0:00:43 --:--:-- 3244k 要验证您下载的文件的完整性，请运行 sha256sum命令并将其作为参数传递给文件名：\n1root@Jimyag:~# sha256sum go1.17.6.linux-amd64.tar.gz 2231654bbf2dab3d86c1619ce799e77b03d96f9b50770297c8f4dff8836fc8ca2 go1.17.6.linux-amd64.tar.gz 如果校验和与下载页面上列出的校验和匹配，则您已正确完成此步骤。\n接下来，用于tar提取 tarball。此命令包括-C指示 tar 在执行任何其他操作之前更改到给定目录的标志。这意味着提取的文件将被写入/usr/local/目录，即安装 Go 的推荐位置..x标志告诉tar提取，v告诉它我们想要详细输出（被提取的文件的列表），并f告诉它我们将指定一个文件名：\n1root@Jimyag:~# sudo tar -C /usr/local -xvf go1.17.6.linux-amd64.tar.gz 虽然/usr/local/go是安装 Go 的推荐位置，但一些用户可能更喜欢或需要不同的路径。\n设置 Go 路径 在此步骤中，您将在您的环境中设置路径。\n首先，设置 Go 的 root 值，它告诉 Go 去哪里寻找它的文件。\n1root@Jimyag:~# vim ~/.profile 然后，将以下信息添加到文件末尾：\n1export PATH=$PATH:/usr/local/go/bin 接下来，通过运行以下命令刷新您的配置文件：\n1source ~/.profile 之后，检查是否可以go通过运行go version以下命令执行命令：\n1root@Jimyag:~# go version 2go version go1.17.6 linux/amd64 ","date":"2022-01-17","img":"","permalink":"/posts/c56e43df/","series":null,"tags":["教程","Go","Linux"],"title":"在Linux安装Go环境"},{"categories":[["Go"],["教程"]],"content":"Goroutine调度器的GMP模型的设计思想\nGMP模型 面对之前调度器的问题，Go设计了新的调度器。\n在新调度器中，出列M(thread)和G(goroutine)，又引进了P(Processor)。\nP:processor，处理goroutine协程它包含了运行goroutine的资源，如果线程想运行goroutine，必须先获取P，P中还包含了可运行的G队列。\nM:go语言层面实现的用户级线程，他们对应着底层OS内核级线程\n在Go中，线程是运行goroutine的实体，调度器的功能是把可运行的goroutine分配到工作线程上。\n全局队列（Global Queue）：存放等待运行的G。 P的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建G\u0026rsquo;时，G\u0026rsquo;优先加入到P的本地队列，如果队列满了，则会把本地队列中一半的G移动到全局队列。 P列表：所有的P都在程序启动时创建，并保存在数组中，最多有GOMAXPROCS(可配置)个。 M：当前操作系统分配到当前Go程序的内核线程数。线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M也会尝试从全局队列拿一批G放到P的本地队列，或从其他P的本地队列偷一半放到自己P的本地队列。M运行G，G执行之后，M会从P获取下一个G，不断重复下去。 Goroutine调度器和OS调度器是通过M结合起来的，每个M都代表了1个内核线程，OS调度器负责把内核线程分配到CPU的核上执行。\n有关P和M的个数问题 P的数量： 由启动时环境变量$GOMAXPROCS或者是由runtime的方法GOMAXPROCS()决定。这意味着在程序执行的任意时刻都只有$GOMAXPROCS个goroutine在同时运行。 M的数量: go语言本身的限制：go程序启动时，会设置M的最大数量，默认10000.但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug中的SetMaxThreads函数，设置M的最大数量 一个M阻塞了，会创建新的M。 如果有M空闲，那么就会回收或者睡眠 M与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所以，即使P的默认数量是1，也有可能会创建很多个M出来。\nP和M何时会被创建 1、P何时创建：在确定了P的最大数量n后，运行时系统会根据这个数量创建n个P。\n2、M何时创建：没有足够的M来关联P并运行其中的可运行的G。比如所有的M此时都阻塞住了，而P中还有很多就绪任务，就会去寻找空闲的M，而没有空闲的，就会去创建新的M。\n调度器设计策略 复用线程 避免频繁的创建、销毁线程，而是对线程的复用。\n1）work stealing机制\n当本线程无可运行的G时，尝试从其他线程绑定的P偷取G，而不是销毁线程。\n2）hand off机制\n当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行。\n如果G1还想继续执行，则G1还会加入到其他队列，如果G1不执行则M1可能会睡眠或者销毁。\n利用并行： GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个CPU上同时运行。GOMAXPROCS也限制了并发的程度，比如GOMAXPROCS = 核数/2，则最多利用了一半的CPU核进行并行。\n设置GOMAXPROCS的数量小于等于CPU核数，是为了避免进行切换进程，不会创建过多线程。P的和核数没有关系。\n抢占 在coroutine中要等待一个协程主动让出CPU才执行下一个协程，\n在Go中，一个goroutine最多占用CPU 10ms，\n防止其他goroutine被饿死，这就是goroutine不同于coroutine的一个地方。\n全局G队列 在新的调度器中依然有全局G队列，但功能已经被弱化了，\n当M执行work stealing从其他P偷不到G时，它可以从全局G队列获取G。\ngo func() 调度流程 从上图我们可以分析出几个结论：\n我们通过 go func()来创建一个goroutine；\n有两个存储G的队列，一个是局部调度器P的本地队列、一个是全局G队列。新创建的G会先保存在P的本地队列中，如果P的本地队列已经满了就会保存在全局的队列中；\nG只能运行在M中，一个M必须持有一个P，M与P是1：1的关系。M会从P的本地队列弹出一个可执行状态的G来执行，如果P的本地队列为空，就会想其他的MP组合偷取一个可执行的G来执行；\n一个M调度G执行的过程是一个循环机制；\n当M执行某一个G时候如果发生了syscall或则其余阻塞操作，M会阻塞，如果当前有一些G在执行，runtime(调度器)会把这个线程M从P中摘除分离(detach)，然后再创建一个新的操作系统的线程(如果有空闲的线程可用就复用空闲线程)来服务于这个P；\n当M系统调用结束时候，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程M变成休眠状态， 加入到空闲线程中，然后这个G会被放入全局队列中。\n调度器的⽣命周期 特殊的M0和G0 M0 M0是启动程序后的编号为0的主线程，这个M对应的实例会在全局变量runtime.m0中，不需要在heap上分配，M0负责执行初始化操作和启动第一个G， 在之后M0就和其他的M一样了。\nG0 G0是每次启动一个M都会第一个创建的goroutine，G0仅用于负责调度的G，G0不指向任何可执行的函数, 每个M都会有一个自己的G0。在调度或系统调用时会使用G0的栈空间, 全局变量的G0是M0的G0。\n我们来跟踪一段代码\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6 fmt.Println(\u0026#34;Hello world\u0026#34;) 7} 接下来我们来针对上面的代码对调度器里面的结构做一个分析。\n也会经历如上图所示的过程：\nruntime创建最初的线程m0和goroutine g0，并把2者关联。 调度器初始化：初始化m0、栈、垃圾回收，以及创建和初始化由GOMAXPROCS个P构成的P列表。 示例代码中的main函数是main.main，runtime中也有1个main函数——runtime.main，代码经过编译后，runtime.main会调用main.main，程序启动时会为runtime.main创建goroutine，称它为main goroutine吧，然后把main goroutine加入到P的本地队列。 启动m0，m0已经绑定了P，会从P的本地队列获取G，获取到main goroutine。 G拥有栈，M根据G中的栈信息和调度信息设置运行环境 M运行G G退出，再次回到M获取可运行的G，这样重复下去，直到main.main退出，runtime.main执行Defer和Panic处理，或调用runtime.exit退出程序。 调度器的生命周期几乎占满了一个Go程序的一生，runtime.main的goroutine执行之前都是为调度器做准备工作，runtime.main的goroutine运行，才是调度器的真正开始，直到runtime.main结束而结束。\n可视化GMP编程 有2种方式可以查看一个程序的GMP的数据。\ngo tool trace trace记录了运行时的信息，能提供可视化的Web页面。\n简单测试代码：main函数创建trace，trace会运行在单独的goroutine中，然后main打印\u0026quot;Hello World\u0026quot;退出。\nmain.go\n1package main 2 3import ( 4 \u0026#34;os\u0026#34; 5 \u0026#34;fmt\u0026#34; 6 \u0026#34;runtime/trace\u0026#34; 7) 8 9func main() { 10 11 //创建trace文件 12 f, err := os.Create(\u0026#34;trace.out\u0026#34;) 13 if err != nil { 14 panic(err) 15 } 16 17 defer f.Close() 18 19 //启动trace goroutine 20 err = trace.Start(f) 21 if err != nil { 22 panic(err) 23 } 24 defer trace.Stop() 25 26 //main 27 fmt.Println(\u0026#34;Hello World\u0026#34;) 28} 运行程序\n1$ go run main.go 2Hello World 会得到一个trace.out文件，然后我们可以用一个工具打开，来分析这个文件。\n1D:\\Computer\\Desktop\\gmp\u0026gt;go tool trace trace.out 22022/01/17 14:32:14 Parsing trace... 32022/01/17 14:32:14 Splitting trace... 42022/01/17 14:32:14 Opening browser. Trace viewer is listening on http://127.0.0.1:50359 我们可以通过浏览器打开http://127.0.0.1:50359网址，点击view trace 能够看见可视化的调度流程。\nG信息\n点击Goroutines那一行可视化的数据条，我们会看到一些详细的信息。\n一共有两个G在程序中，一个是特殊的G0，是每个M必须有的一个初始化的G，这个我们不必讨论。\n其中G1应该就是main goroutine(执行main函数的协程)，在一段时间内处于可运行和运行的状态。\nM信息\n点击Threads那一行可视化的数据条，我们会看到一些详细的信息。\n一共有两个M在程序中，一个是特殊的M0，用于初始化使用，这个我们不必讨论。\nP信息\nG1中调用了main.main，创建了trace goroutine g19。G1运行在P1上，G19运行在P0上。\n这里有两个P，我们知道，一个P必须绑定一个M才能调度G。\n我们在来看看上面的M信息。\n为了调度G19,P0又创建了一个M1来执行，我们会发现，确实G19在P0上被运行的时候，确实在Threads行多了一个M的数据，点击查看如下：\n多了一个M2应该就是P0为了执行G19而动态创建的M2.\nDebug trace trace.go\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;time\u0026#34; 6) 7 8func main() { 9 for i := 0; i \u0026lt; 5; i++ { 10 time.Sleep(time.Second) 11 fmt.Println(\u0026#34;Hello World\u0026#34;) 12 } 13} 编译\n1go build trace.go 通过Debug方式运行\n1root@Jimyag:/mnt/d/Computer/Desktop/gmp# GODEBUG=schedtrace=1000 ./trace 2SCHED 0ms: gomaxprocs=12 idleprocs=11 threads=2 spinningthreads=0 idlethreads=0 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0] 3Hello World 4SCHED 1010ms: gomaxprocs=12 idleprocs=12 threads=5 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0] 5Hello World 6SCHED 2015ms: gomaxprocs=12 idleprocs=12 threads=5 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0] 7Hello World 8SCHED 3022ms: gomaxprocs=12 idleprocs=12 threads=5 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0] 9Hello World 10SCHED 4029ms: gomaxprocs=12 idleprocs=12 threads=5 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0] 11Hello World SCHED：调试信息输出标志字符串，代表本行是goroutine调度器的输出； 0ms：即从程序启动到输出这行日志的时间； gomaxprocs: P的数量，本例有12个P, 因为默认的P的属性是和cpu核心数量默认一致，当然也可以通过GOMAXPROCS来设置； idleprocs: 处于idle状态的P的数量；通过gomaxprocs和idleprocs的差值，我们就可知道执行go代码的P的数量； threads: os threads/M的数量，包含scheduler使用的m数量，加上runtime自用的类似sysmon这样的thread的数量。包括M0，包括GODEBUG调试的线程； spinningthreads: 处于自旋状态的os thread数量； idlethread: 处于idle（空闲）状态的os thread的数量； runqueue=0： Scheduler全局队列中G的数量； [0 0 0 0 0 0 0 0 0 0 0 0]: 分别为12个P的local queue中的G的数量。 参考 Golang深入理解GPM模型_哔哩哔哩_bilibili\n","date":"2022-01-17","img":"","permalink":"/posts/61098f97/","series":null,"tags":["教程"],"title":"Goroutine调度器的GMP模型的设计思想"},{"categories":[["Go"],["教程"]],"content":"Golang调度器的由来\n单进程时代 我们知道，一切的软件都是跑在操作系统上，真正用来干活(计算)的是CPU。早期的操作系统每个程序就是一个进程，知道一个程序运行完，才能进行下一个进程，就是“单进程时代”\n一切的程序只能串行发生。\n早期的单进程操作系统，面临2个问题：\n1.单一的执行流程，计算机只能一个任务一个任务处理。\n2.进程阻塞所带来的CPU时间浪费。\n那么能不能有多个进程来宏观一起来执行多个任务呢？\n后来操作系统就具有了最早的并发能力：多进程并发，当一个进程阻塞的时候，切换到另外等待执行的进程，这样就能尽量把CPU利用起来，CPU就不浪费了。\n多进程/多线程 在多进程/多线程的操作系统中，就解决了阻塞的问题，因为一个进程阻塞cpu可以立刻切换到其他进程中去执行，而且调度cpu的算法可以保证在运行的进程都可以被分配到cpu的运行时间片。这样从宏观来看，似乎多个进程是在同时被运行。\n多进程/多线程解决了阻塞的问题，如果一个进程被阻塞时，时间片到了之后就能切换到另一个进程执行。\n但新的问题就又出现了，进程拥有太多的资源，进程的创建、切换、销毁，都会占用很长的时间，CPU虽然利用起来了，但如果进程过多，CPU有很大的一部分都被用来进行进程调度了。\n切换主要是把CPU寄存器里当前进程的数据保存到内存中，然后从内存中把另一个进程的数据加载到CPU中\n如果进程/线程的数量越多，切换成本越大，也就越浪费。\n看起来CPU100%运行，实际上只有60%执行程序，剩余的在切换\n怎么才能提高CPU的利用率呢？\n但是对于Linux操作系统来讲，cpu对进程的态度和线程的态度是一样的。\n很明显，CPU调度切换的是进程和线程。尽管线程看起来很美好，但实际上多线程开发设计会变得更加复杂，要考虑很多同步竞争等问题，如锁、竞争冲突等。\n协程来提高CPU利用率 多进程、多线程已经提高了系统的并发能力，但是在当今互联网高并发场景下，为每个任务都创建一个线程是不现实的，因为会消耗大量的内存(进程虚拟内存会占用4GB[32位操作系统], 而线程也要大约4MB)。\n大量的进程/线程出现了新的问题\n高内存占用 调度的高消耗CPU 好了，然后工程师们就发现，其实一个线程分为“内核态“线程和”用户态“线程。\n一个“用户态线程”必须要绑定一个“内核态线程”，但是CPU并不知道有“用户态线程”的存在，它只知道它运行的是一个“内核态线程”(Linux的PCB进程控制块)。\n这样，我们再去细化去分类一下，内核线程依然叫“线程(thread)”，用户线程叫“协程(co-routine)\u0026quot;.\n看到这里，我们就要开脑洞了，既然一个协程(co-routine)可以绑定一个线程(thread)，那么能不能多个协程(co-routine)绑定一个或者多个线程(thread)上呢。\n之后，我们就看到了有3中协程和线程的映射关系：\nN:1关系 N个协程绑定1个线程，优点就是协程在用户态线程即完成切换，不会陷入到内核态，这种切换非常的轻量快速。但也有很大的缺点，1个进程的所有协程都绑定在1个线程上\n缺点：\n某个程序用不了硬件的多核加速能力 一旦某协程阻塞，造成线程阻塞，本进程的其他协程都无法执行了，根本就没有并发的能力了。 1:1 关系 1个协程绑定1个线程，这种最容易实现。协程的调度都由CPU完成了，不存在N:1缺点，\n缺点：\n协程的创建、删除和切换的代价都由CPU完成，有点略显昂贵了。 M:N关系 M个协程绑定1个线程，是N:1和1:1类型的结合，克服了以上2种模型的缺点，但实现起来最为复杂。\n协程跟线程是有区别的，线程由CPU调度是抢占式的，协程由用户态调度是协作式的，一个协程让出CPU后，才执行下一个协程。\n调度器主要是协调线程消费协程，还有一些阻塞的协程的切换\n在M:N模型中所有的瓶颈都来自于协程调度器,如果协程调度器越好，则CPU利用率越来越高。\nGo的协程goroutine Go为了提供更容易使用的并发方法，使用了goroutine和channel。goroutine来自协程的概念，让一组可复用的函数运行在一组线程之上，即使有协程阻塞，该线程的其他协程也可以被runtime调度，转移到其他可运行的线程上。最关键的是，程序员看不到这些底层的细节，这就降低了编程的难度，提供了更容易的并发。\nGo中，协程被称为goroutine，它非常轻量，一个goroutine只占几KB，并且这几KB就足够goroutine运行完，这就能在有限的内存空间内支持大量goroutine，支持了更多的并发。虽然一个goroutine的栈只占几KB，但实际是可伸缩的，如果需要更多内容，runtime会自动为goroutine分配。\nGoroutine特点：\n占用内存更小（几kb） 调度更灵活(runtime调度) 被废弃的goroutine调度器 好了，既然我们知道了协程和线程的关系，那么最关键的一点就是调度协程的调度器的实现了。\nGo目前使用的调度器是2012年重新设计的，因为之前的调度器性能存在问题，所以使用4年就被废弃了，那么我们先来分析一下被废弃的调度器是如何运作的？\n大部分文章都是会用G来表示Goroutine，用M来表示线程，那么我们也会用这种表达的对应关系。\n下面我们来看看被废弃的golang调度器是如何实现的？\nM想要执行、放回G都必须访问全局G队列，并且M有多个，即多线程访问同一资源需要加锁进行保证互斥/同步，所以全局G队列是有互斥锁进行保护的。\n老调度器有几个缺点：\n创建、销毁、调度G都需要每个M获取锁，这就形成了激烈的锁竞争。 M转移G会造成延迟和额外的系统负载。比如当G中包含创建新协程的时候，M创建了G’，为了继续执行G，需要把G’交给M’执行，也造成了很差的局部性，因为G’和G是相关的，最好放在M上执行，而不是其他M\u0026rsquo;。 系统调用(CPU在M之间的切换)导致频繁的线程阻塞和取消阻塞操作增加了系统开销。 参考 Golang深入理解GPM模型_哔哩哔哩_bilibili\n","date":"2022-01-16","img":"","permalink":"/posts/46db0928/","series":null,"tags":["教程"],"title":"Golang调度器的由来"},{"categories":[["教程"],["Docker"],["Go"]],"content":"记录自己用dockers部署Go项目\nGo 项目文件结构如下\n首先实现一个测试demo main.go\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;github.com/gin-gonic/gin\u0026#34; 6\t\u0026#34;net/http\u0026#34; 7) 8 9func main() { 10\tfmt.Println(\u0026#34;service start\u0026#34;) 11\trouter := gin.Default() 12\trouter.GET(\u0026#34;/ping\u0026#34;, func(context *gin.Context) { 13\tcontext.JSON(http.StatusOK, gin.H{\u0026#34;message\u0026#34;: \u0026#34;pong\u0026#34;}) 14\tfmt.Println(\u0026#34;service healthy\u0026#34;) 15\t}) 16\trouter.Run(\u0026#34;:9999\u0026#34;) 17} Dockerfile 编写Dockerfile文件Dockerfile\n1FROM golang:1.17-alpine 2 3WORKDIR /app 4ADD * /app 5 6ENV GO111MODULE=on \\ 7 CGO_ENABLED=0 \\ 8 GOOS=linux \\ 9 GOARCH=amd64 \\ 10 GOPROXY=\u0026#34;https://goproxy.io,direct\u0026#34; 11RUN go mod download 12 13RUN go build -o test_go . 14 15EXPOSE 9999 16 17CMD ./test_go 编写启动构建和启动脚本 构建脚本docker_build.sh 1docker build -t my_test . 运行脚本 docker_run.sh 1docker run -p 9999:9999 --name gin_test my_test 执行构建脚本 1docker_build.sh 执行运行脚本 1docker_run.sh 测试 在ApiPost进行测试\n","date":"2022-01-10","img":"","permalink":"/posts/e6a3ea27/","series":null,"tags":["教程","Docker","Gin"],"title":"Docker部署Go项目"},{"categories":["基础"],"content":"query和params传参的区别\n通过 url 传递参数控制页面显示数据的两种方式\nquery 传统问号传参url 格式：xxx.com/product?id=123模板内获取数据，？之后的信息\nparams 动态路由匹配url 格式：xxx.com/product/123模板内获取数据，用冒号的形式标记参数可以继续拼接 /student/:id/:name/:age/:address他必须严格按照 url 的配置格式访问\n","date":"2022-01-09","img":"","permalink":"/posts/77535737/","series":null,"tags":["Web"],"title":"Query和params传参的区别"},{"categories":["LeetCode"],"content":"题目 LeetCode 设计了一款新式键盘，正在测试其可用性。测试人员将会点击一系列键（总计 n 个），每次一个。\n给你一个长度为 n 的字符串 keysPressed ，其中 keysPressed[i] 表示测试序列中第 i 个被按下的键。releaseTimes 是一个升序排列的列表，其中 releaseTimes[i] 表示松开第 i 个键的时间。字符串和数组的 下标都从 0 开始 。第 0 个键在时间为 0 时被按下，接下来每个键都 恰好 在前一个键松开时被按下。\n测试人员想要找出按键 持续时间最长 的键。第 i 次按键的持续时间为 releaseTimes[i] - releaseTimes[i - 1] ，第 0 次按键的持续时间为 releaseTimes[0] 。\n注意，测试期间，同一个键可以在不同时刻被多次按下，而每次的持续时间都可能不同。\n请返回按键 持续时间最长 的键，如果有多个这样的键，则返回 按字母顺序排列最大 的那个键。\n示例 示例 1 1输入：releaseTimes = [9,29,49,50], keysPressed = \u0026#34;cbcd\u0026#34; 2输出：\u0026#34;c\u0026#34; 3解释：按键顺序和持续时间如下： 4按下 \u0026#39;c\u0026#39; ，持续时间 9（时间 0 按下，时间 9 松开） 5按下 \u0026#39;b\u0026#39; ，持续时间 29 - 9 = 20（松开上一个键的时间 9 按下，时间 29 松开） 6按下 \u0026#39;c\u0026#39; ，持续时间 49 - 29 = 20（松开上一个键的时间 29 按下，时间 49 松开） 7按下 \u0026#39;d\u0026#39; ，持续时间 50 - 49 = 1（松开上一个键的时间 49 按下，时间 50 松开） 8按键持续时间最长的键是 \u0026#39;b\u0026#39; 和 \u0026#39;c\u0026#39;（第二次按下时），持续时间都是 20 9\u0026#39;c\u0026#39; 按字母顺序排列比 \u0026#39;b\u0026#39; 大，所以答案是 \u0026#39;c\u0026#39; 示例 2 1输入：releaseTimes = [12,23,36,46,62], keysPressed = \u0026#34;spuda\u0026#34; 2输出：\u0026#34;a\u0026#34; 3解释：按键顺序和持续时间如下： 4按下 \u0026#39;s\u0026#39; ，持续时间 12 5按下 \u0026#39;p\u0026#39; ，持续时间 23 - 12 = 11 6按下 \u0026#39;u\u0026#39; ，持续时间 36 - 23 = 13 7按下 \u0026#39;d\u0026#39; ，持续时间 46 - 36 = 10 8按下 \u0026#39;a\u0026#39; ，持续时间 62 - 46 = 16 9按键持续时间最长的键是 \u0026#39;a\u0026#39; ，持续时间 16 解答 模拟\n代码 1char slowestKey(vector\u0026lt;int\u0026gt;\u0026amp; releaseTimes, string keysPressed) { 2\tint timeDraution = releaseTimes[0]; 3 char a = keysPressed[0]; 4 for (int i = 1; i \u0026lt; releaseTimes.size(); i++) { 5 int temp = releaseTimes[i] - releaseTimes[i - 1]; 6 if (temp == timeDraution) { 7 if (keysPressed[i] \u0026gt;= a) { 8 timeDraution = temp; 9 a = keysPressed[i]; 10 } 11 } 12 if (temp \u0026gt; timeDraution) { 13 timeDraution = temp; 14 a = keysPressed[i]; 15 } 16 } 17 return a; 18} ","date":"2022-01-09","img":"","permalink":"/posts/81eca2cd/","series":["leetcode"],"tags":["简单"],"title":"LeetCode-1629-按键持续时间最长的键"},{"categories":["LeetCode"],"content":"双周赛太离谱了，签到完就溜。\n将标题首字母大写 给你一个字符串 title ，它由单个空格连接一个或多个单词组成，每个单词都只包含英文字母。请你按以下规则将每个单词的首字母 大写 ：\n如果单词的长度为 1 或者 2 ，所有字母变成小写。 否则，将单词首字母大写，剩余字母变成小写。 请你返回 大写后 的 title 。\n示例 示例 1 1输入：title = \u0026#34;capiTalIze tHe titLe\u0026#34; 2输出：\u0026#34;Capitalize The Title\u0026#34; 3解释： 4由于所有单词的长度都至少为 3 ，将每个单词首字母大写，剩余字母变为小写。 示例 2 1输入：title = \u0026#34;First leTTeR of EACH Word\u0026#34; 2输出：\u0026#34;First Letter of Each Word\u0026#34; 3解释： 4单词 \u0026#34;of\u0026#34; 长度为 2 ，所以它保持完全小写。 5其他单词长度都至少为 3 ，所以其他单词首字母大写，剩余字母小写。 示例 3 1输入：title = \u0026#34;i lOve leetcode\u0026#34; 2输出：\u0026#34;i Love Leetcode\u0026#34; 3解释： 4单词 \u0026#34;i\u0026#34; 长度为 1 ，所以它保留小写。 5其他单词长度都至少为 3 ，所以其他单词首字母大写，剩余字母小写。 解答 将字符串以空格进行分割，并把分割新字符串转换为小写。\n判断长度是否大于2，大于2的首字母大写\n代码 1string capitalizeTitle(string title) { 2 vector\u0026lt;string\u0026gt; s; 3 for (int i = 0; i \u0026lt; title.size(); i++) { 4 string temp = \u0026#34;\u0026#34;; 5 int j = i; 6 for (; j \u0026lt; title.size(); j++) { 7 if (title[j] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; title[j] \u0026lt;= \u0026#39;Z\u0026#39;) { 8 title[j] = tolower(title[j]); 9 } 10 if (title[j] != \u0026#39; \u0026#39;) { 11 temp = temp + title[j]; 12 } else { 13 break; 14 } 15 } 16 i = j; 17 s.emplace_back(temp); 18 } 19 string ans = \u0026#34;\u0026#34;; 20 for (string a: s) { 21 if (a.size() \u0026gt; 2) { 22 a[0] = toupper(a[0]); 23 } 24 ans += a + \u0026#39; \u0026#39;; 25 } 26 ans.pop_back(); 27 return ans; 28 } 链表最大孪生和 在一个大小为 n 且 n 为 偶数 的链表中，对于 0 \u0026lt;= i \u0026lt;= (n / 2) - 1 的 i ，第 i 个节点（下标从 0 开始）的孪生节点为第 (n-1-i) 个节点 。\n比方说，n = 4 那么节点 0 是节点 3 的孪生节点，节点 1 是节点 2 的孪生节点。这是长度为 n = 4 的链表中所有的孪生节点。 孪生和 定义为一个节点和它孪生节点两者值之和。\n给你一个长度为偶数的链表的头节点 head ，请你返回链表的 最大孪生和 。\n示例 示例 1： 1输入：head = [5,4,2,1] 2输出：6 3解释： 4节点 0 和节点 1 分别是节点 3 和 2 的孪生节点。孪生和都为 6 。 5链表中没有其他孪生节点。 6所以，链表的最大孪生和是 6 。 示例 2 1输入：head = [4,2,2,3] 2输出：7 3解释： 4链表中的孪生节点为： 5- 节点 0 是节点 3 的孪生节点，孪生和为 4 + 3 = 7 。 6- 节点 1 是节点 2 的孪生节点，孪生和为 2 + 2 = 4 。 7所以，最大孪生和为 max(7, 4) = 7 。 示例 3 1输入：head = [1,100000] 2输出：100001 3解释： 4链表中只有一对孪生节点，孪生和为 1 + 100000 = 100001 。 解答 按照题目要求模拟即可\n代码 1 int pairSum(ListNode* head) { 2 vector\u0026lt;int\u0026gt; val; 3 while (head != nullptr) { 4 val.emplace_back(head-\u0026gt;val); 5 head = head-\u0026gt;next; 6 } 7 if (val.size() == 2) { 8 return val[0] + val[1]; 9 } 10 int ans = 0; 11 for (int i = 0; i \u0026lt;= val.size() / 2 - 1; i++) { 12 int temp = val[i] + val[val.size() - i - 1]; 13 if (temp \u0026gt; ans) { 14 ans = temp; 15 } 16 } 17 return ans; 连接两字母单词得到的最长回文串 给你一个字符串数组 words 。words 中每个元素都是一个包含 两个 小写英文字母的单词。\n请你从 words 中选择一些元素并按 任意顺序 连接它们，并得到一个 尽可能长的回文串 。每个元素 至多 只能使用一次。\n请你返回你能得到的最长回文串的 长度 。如果没办法得到任何一个回文串，请你返回 0 。\n回文串 指的是从前往后和从后往前读一样的字符串。\n示例 示例 1 1输入：words = [\u0026#34;lc\u0026#34;,\u0026#34;cl\u0026#34;,\u0026#34;gg\u0026#34;] 2输出：6 3解释：一个最长的回文串为 \u0026#34;lc\u0026#34; + \u0026#34;gg\u0026#34; + \u0026#34;cl\u0026#34; = \u0026#34;lcggcl\u0026#34; ，长度为 6 。 4\u0026#34;clgglc\u0026#34; 是另一个可以得到的最长回文串。 示例 2 1输入：words = [\u0026#34;ab\u0026#34;,\u0026#34;ty\u0026#34;,\u0026#34;yt\u0026#34;,\u0026#34;lc\u0026#34;,\u0026#34;cl\u0026#34;,\u0026#34;ab\u0026#34;] 2输出：8 3解释：最长回文串是 \u0026#34;ty\u0026#34; + \u0026#34;lc\u0026#34; + \u0026#34;cl\u0026#34; + \u0026#34;yt\u0026#34; = \u0026#34;tylcclyt\u0026#34; ，长度为 8 。 4\u0026#34;lcyttycl\u0026#34; 是另一个可以得到的最长回文串。 示例 3 1输入：words = [\u0026#34;cc\u0026#34;,\u0026#34;ll\u0026#34;,\u0026#34;xx\u0026#34;] 2输出：2 3解释：最长回文串是 \u0026#34;cc\u0026#34; ，长度为 2 。 4\u0026#34;ll\u0026#34; 是另一个可以得到的最长回文串。\u0026#34;xx\u0026#34; 也是。 解答 只处理完了相反的字符，相同的字符没有处理\n代码 1bool isAllSame(string s) { 2 return s[0] == s[1]; 3} 4 5int longestPalindrome(vector\u0026lt;string\u0026gt; words) { 6 int ans = 0; 7 // 处理完可以两两相反的 8 for (int i = 0; i \u0026lt; words.size(); i++) { 9 for (int j = i; j \u0026lt; words.size(); j++) { 10 string *temp = new string(words[j]); 11 reverse(temp-\u0026gt;begin(), temp-\u0026gt;end()); 12 if (words[i] == *temp) { 13 ans += 4; 14 } 15 } 16 } 17 // 处理两两相同的， 18 // 如果两两相反的为空 19 // //找到两两相同的 20 return ans; ","date":"2022-01-08","img":"","permalink":"/posts/3087638f/","series":["leetcode"],"tags":["周赛"],"title":"LeetCode-第69场双周赛"},{"categories":["LeetCode"],"content":"题目 n 位格雷码序列 是一个由 2^n 个整数组成的序列，其中： 每个整数都在范围 [0, 2^n - 1] 内（含 0 和 2^n - 1） 第一个整数是 0 一个整数在序列中出现 不超过一次 每对 相邻 整数的二进制表示 恰好一位不同 ，且第一个 和 最后一个 整数的二进制表示 恰好一位不同 给你一个整数 n ，返回任一有效的 n 位格雷码序列 。\n示例 示例 1 1输入：n = 2 2输出：[0,1,3,2] 3解释： 4[0,1,3,2] 的二进制表示是 [00,01,11,10] 。 5- 00 和 01 有一位不同 6 7- 01 和 11 有一位不同 8 9- 11 和 10 有一位不同 10 11- 10 和 00 有一位不同 12 [0,2,3,1] 也是一个有效的格雷码序列，其二进制表示是 [00,10,11,01] 。 13 14- 00 和 10 有一位不同 15 16- 10 和 11 有一位不同 17 18- 11 和 01 有一位不同 19 20- 01 和 00 有一位不同 示例 2： 1输入：n = 1 2输出：[0,1] 解答 给一个整数n，返回任一有效的n位格雷码序列。\nn 位格雷码序列是一个由 2^n 个整数组成的序列，其中： 每个整数都在范围 [0, 2^n - 1] 内（含 0 和 2^n - 1）\n第一个整数是 0\n一个整数在序列中出现 不超过一次\n每对 相邻 整数的二进制表示 恰好一位不同 ，且\n第一个 和 最后一个 整数的二进制表示 恰好一位不同\n下表为0为、1位、2位、3位、4位格雷码的实例，我们可以发现这样一个规律。\n总结规律：\n1位格雷码有两个码字 (n+1)位格雷码中的前2^n个码字等于n位格雷码的码字，按顺序书写，加前缀0 (n+1)位格雷码中的后2^n个码字等于n位格雷码的码字，按逆序书写，加前缀1 n+1位格雷码的集合 = n位格雷码集合(顺序)加前缀0 + n位格雷码集合(逆序)加前缀1 代码 1vector\u0026lt;int\u0026gt; grayCode(int n) { 2 vector\u0026lt;int\u0026gt; result; 3 result.push_back(0); 4 if(n == 0) { 5 return result; 6 } 7 int first = 1; 8 for(int i = 0; i \u0026lt; n; i++){ 9 for(int j = result.size() - 1; j \u0026gt;= 0; j--){ 10 result.push_back(first + result[j]); 11 } 12 first = first \u0026lt;\u0026lt; 1; 13 } 14 return result; 15 } ","date":"2022-01-08","img":"","permalink":"/posts/b9635535/","series":["leetcode"],"tags":["中等"],"title":"LeetCode-89-格雷编码"},{"categories":["LeetCode"],"content":"题目 如果字符串满足以下条件之一，则可以称之为 有效括号字符串（valid parentheses string，可以简写为 VPS）：\n字符串是一个空字符串 \u0026ldquo;\u0026quot;，或者是一个不为 \u0026ldquo;(\u0026rdquo; 或 \u0026ldquo;)\u0026rdquo; 的单字符。 字符串可以写为 AB（A 与 B 字符串连接），其中 A 和 B 都是 有效括号字符串 。 字符串可以写为 (A)，其中 A 是一个 有效括号字符串 。 类似地，可以定义任何有效括号字符串 S 的 嵌套深度 depth(S)：\ndepth(\u0026rdquo;\u0026quot;) = 0 depth(C) = 0，其中 C 是单个字符的字符串，且该字符不是 \u0026ldquo;(\u0026rdquo; 或者 \u0026ldquo;)\u0026rdquo; depth(A + B) = max(depth(A), depth(B))，其中 A 和 B 都是 有效括号字符串 depth(\u0026quot;(\u0026quot; + A + \u0026ldquo;)\u0026rdquo;) = 1 + depth(A)，其中 A 是一个 有效括号字符串 例如：\u0026quot;\u0026quot;、\u0026quot;()()\u0026quot;、\u0026quot;()(()())\u0026quot; 都是 有效括号字符串（嵌套深度分别为 0、1、2），而 \u0026ldquo;)(\u0026rdquo; 、\u0026quot;(()\u0026quot; 都不是 有效括号字符串 。\n给你一个 有效括号字符串 s，返回该字符串的 s 嵌套深度 。\n示例 示例 1 1输入：s = \u0026#34;(1+(2*3)+((8)/4))+1\u0026#34; 2输出：3 3解释：数字 8 在嵌套的 3 层括号中。 示例 2 1输入：s = \u0026#34;(1)+((2))+(((3)))\u0026#34; 2输出：3 示例 3 1输入：s = \u0026#34;1+(2*3)/(2-1)\u0026#34; 2输出：1 示例 4 1输入：s = \u0026#34;1\u0026#34; 2输出：0 解答 如果遇到左括号深度+1，遇到有括号-1，统计dep的最大值\n代码 1int maxDepth(string s) { 2 int ans = 0; 3 int dep = 0; 4 for (char a: s) { 5 if (a == \u0026#39;(\u0026#39; || a == \u0026#39;[\u0026#39; || a == \u0026#39;{\u0026#39;) { 6 dep++; 7 } 8 if (a == \u0026#39;)\u0026#39; || a == \u0026#39;]\u0026#39; || a == \u0026#39;}\u0026#39;) { 9 dep--; 10 } 11 if (dep \u0026gt; ans) { 12 ans = dep; 13 } 14 } 15 return ans; 16} ","date":"2022-01-07","img":"","permalink":"/posts/965e3905/","series":["leetcode"],"tags":["模拟","简单"],"title":"LeetCode-1614-括号的最大嵌套深度"},{"categories":["LeetCode"],"content":"题目 给你一个字符串 path ，表示指向某一文件或目录的 Unix 风格 绝对路径 （以 \u0026lsquo;/\u0026rsquo; 开头），请你将其转化为更加简洁的规范路径。\n在 Unix 风格的文件系统中，一个点（.）表示当前目录本身；此外，两个点 （..） 表示将目录切换到上一级（指向父目录）；两者都可以是复杂相对路径的组成部分。任意多个连续的斜杠（即，\u0026rsquo;//\u0026rsquo;）都被视为单个斜杠 \u0026lsquo;/\u0026rsquo; 。 对于此问题，任何其他格式的点（例如，\u0026rsquo;\u0026hellip;\u0026rsquo;）均被视为文件/目录名称。\n请注意，返回的 规范路径 必须遵循下述格式：\n始终以斜杠 \u0026lsquo;/\u0026rsquo; 开头。 两个目录名之间必须只有一个斜杠 \u0026lsquo;/\u0026rsquo; 。 最后一个目录名（如果存在）不能 以 \u0026lsquo;/\u0026rsquo; 结尾。 此外，路径仅包含从根目录到目标文件或目录的路径上的目录（即，不含 \u0026lsquo;.\u0026rsquo; 或 \u0026lsquo;..\u0026rsquo;）。 返回简化后得到的 规范路径 。\n示例 示例 1 1输入：path = \u0026#34;/home/\u0026#34; 2输出：\u0026#34;/home\u0026#34; 3解释：注意，最后一个目录名后面没有斜杠。 示例 2 1输入：path = \u0026#34;//\u0026#34; 2输出：\u0026#34;/\u0026#34; 3解释：从根目录向上一级是不可行的，因为根目录是你可以到达的最高级。 示例 3 1输入：path = \u0026#34;/home//foo/\u0026#34; 2输出：\u0026#34;/home/foo\u0026#34; 3解释：在规范路径中，多个连续斜杠需要用一个斜杠替换。 示例 4 1输入：path = \u0026#34;/a/./b///c/\u0026#34; 2输出：\u0026#34;/c\u0026#34; 解答 模拟 ​\t题目中已经解释过Linux文件的结构规范，在学过编译原理之后，我们可以把它划分为三个操作\n\u0026ldquo;..\u0026rdquo; 后退上一级 \u0026ldquo;.\u0026ldquo;在当前目录 忽略 其他 进入下一目录 既然要有后退我们可以用栈来处理这个\n将path通过\u0026rsquo;/\u0026lsquo;分割为不同的操作，对应的进行处理就行\n处理完之后的栈就是层级的文件（名）,在每一个文件(名)前面加上\u0026rsquo;/\u0026lsquo;就是我们想要的结果了\n调包 goland的包\n代码 1string simplifyPath(string path) { 2 stack\u0026lt;string\u0026gt; file; 3 // 处理分割文件 4 for (int i = 0; i \u0026lt; path.size(); i++) { 5 if (path[i] == \u0026#39;/\u0026#39;) { 6 string temp = \u0026#34;\u0026#34;; 7 int j = i + 1; 8 for (; j \u0026lt; path.size(); j++) { 9 if (path[j] != \u0026#39;/\u0026#39;) { 10 temp = temp + path[j]; 11 } else { 12 break; 13 } 14 } 15 // 是否要后退 16 if (temp == \u0026#34;..\u0026#34; \u0026amp;\u0026amp; !file.empty()) { 17 file.pop(); 18 } 19 // 是否忽略 20 // if (temp==\u0026#34;.\u0026#34;){} 21 22 // 进入下一目录 23 if (temp != \u0026#34;..\u0026#34; \u0026amp;\u0026amp; temp != \u0026#34;.\u0026#34; \u0026amp;\u0026amp; temp != \u0026#34;\u0026#34;) { 24 file.push(temp); 25 } 26 i = j - 1; 27 } 28 } 29 string ans = \u0026#34;\u0026#34;; 30 int n = file.size(); 31 for (int i = 0; i \u0026lt; n; i++) { 32 ans = \u0026#34;/\u0026#34; + file.top() + ans; 33 file.pop(); 34 } 35 // file 为空就要返回/ 36 if(ans==\u0026#34;\u0026#34;){ 37 ans=\u0026#34;/\u0026#34;; 38 } 39 return ans; 40} 1func simplifyPath(path string) string { 2\treturn filepath.Clean(path) 3} ","date":"2022-01-06","img":"","permalink":"/posts/30245f9e/","series":["leetcode"],"tags":["Linux","中等"],"title":"LeetCode-71-简化路径"},{"categories":[["教程"],["Docker"]],"content":"Docker-配置文档的图片\n","date":"2022-01-06","img":"","permalink":"/posts/26f6376f/","series":null,"tags":["教程","Docker"],"title":"Docker-配置文档-图片"},{"categories":[["教程"],["Docker"]],"content":"哔哩哔哩【编程不良人】Docker\u0026amp;Docker-Compose 实战!_哔哩哔哩_bilibili的教程的文档总结\n官方文档地址:https://www.docker.com/get-started\n中文参考手册:https://docker_practice.gitee.io/zh-cn/\n1.什么是 Docker 1.1 官方定义 最新官网首页 1# 1.官方介绍 2- We have a complete container solution for you - no matter who you are and where you are on your containerization journey. 3- 翻译: 我们为你提供了一个完整的容器解决方案,不管你是谁,不管你在哪,你都可以开始容器的的旅程。 4- 官方定义: docker是一个容器技术。 1.2 Docker的起源 1Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。 2 3Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目 已经超过 5 万 7 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。 4 5Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 OverlayFS 类的 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。 2.为什么是Docker 在开发的时候，在本机测试环境可以跑，生产环境跑不起来\n这里我们拿java Web应用程序举例，我们一个java Web应用程序涉及很多东西，比如jdk、tomcat、mysql等软件环境。当这些其中某一项版本不一致的时候，可能就会导致应用程序跑不起来这种情况。Docker则将程序以及使用软件环境直接打包在一起，无论在那个机器上保证了环境一致。\n优势1: 一致的运行环境,更轻松的迁移\n服务器自己的程序挂了，结果发现是别人程序出了问题把内存吃完了，自己程序因为内存不够就挂了\n这种也是一种比较常见的情况，如果你的程序重要性不是特别高的话，公司基本上不可能让你的程序独享一台服务器的，这时候你的服务器就会跟公司其他人的程序共享一台服务器，所以不可避免地就会受到其他程序的干扰，导致自己的程序出现问题。Docker就很好解决了环境隔离的问题，别人程序不会影响到自己的程序。\n优势2：对进程进行封装隔离,容器与容器之间互不影响,更高效的利用系统资源\n公司要弄一个活动，可能会有大量的流量进来，公司需要再多部署几十台服务器\n在没有Docker的情况下，要在几天内部署几十台服务器，这对运维来说是一件非常折磨人的事，而且每台服务器的环境还不一定一样，就会出现各种问题，最后部署地头皮发麻。用Docker的话，我只需要将程序打包到镜像，你要多少台服务，我就给力跑多少容器，极大地提高了部署效率。\n优势3: 通过镜像复制N多个环境一致容器\n3.Docker和虚拟机区别 关于Docker与虚拟机的区别，我在网上找到的一张图，非常直观形象地展示出来，话不多说，直接上图。\n比较上面两张图，我们发现虚拟机是携带操作系统，本身很小的应用程序却因为携带了操作系统而变得非常大，很笨重。Docker是不携带操作系统的，所以Docker的应用就非常的轻巧。另外在调用宿主机的CPU、磁盘等等这些资源的时候，拿内存举例，虚拟机是利用Hypervisor去虚拟化内存，整个调用过程是虚拟内存-\u0026gt;虚拟物理内存-\u0026gt;真正物理内存，但是Docker是利用Docker Engine去调用宿主的的资源，这时候过程是虚拟内存-\u0026gt;真正物理内存。\n传统虚拟机 Docker容器 磁盘占用 几个GB到几十个GB左右 几十MB到几百MB左右 CPU内存占用 虚拟操作系统非常占用CPU和内存 Docker引擎占用极低 启动速度 （从开机到运行项目）几分钟 （从开启容器到运行项目）几秒 安装管理 需要专门的运维技术 安装、管理方便 应用部署 每次部署都费时费力 从第二次部署开始轻松简捷 耦合性 多个应用服务安装到一起，容易互相影响 每个应用服务一个容器，达成隔离 系统依赖 无 需求相同或相似的内核，目前推荐是Linux 4.Docker的安装 4.1 安装docker(centos7.x) 卸载原始docker\n1$ sudo yum remove docker \\ 2 docker-client \\ 3 docker-client-latest \\ 4 docker-common \\ 5 docker-latest \\ 6 docker-latest-logrotate \\ 7 docker-logrotate \\ 8 docker-engine 安装docker依赖\n1$ sudo yum install -y yum-utils \\ 2 device-mapper-persistent-data \\ 3 lvm2 设置docker的yum源\n1$ sudo yum-config-manager \\ 2 --add-repo \\ 3 https://download.docker.com/linux/centos/docker-ce.repo 安装最新版的docker\n1$ sudo yum install docker-ce docker-ce-cli containerd.io 指定版本安装docker\n1$ yum list docker-ce --showduplicates | sort -r 2$ sudo yum install docker-ce-\u0026lt;VERSION_STRING\u0026gt; docker-ce-cli-\u0026lt;VERSION_STRING\u0026gt; containerd.io 3$ sudo yum install docker-ce-18.09.5-3.el7 docker-ce-cli-18.09.5-3.el7 containerd.io 启动docker\n1$ sudo systemctl enable docker 2$ sudo systemctl start docker 关闭docker\n1$ sudo systemctl stop docker 测试docker安装\n1$ sudo docker run hello-world 4.2 bash安装(通用所有平台) 在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，CentOS 系统上可以使用这套脚本安装，另外可以通过 --mirror 选项使用国内源进行安装：执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker 的稳定(stable)版本安装在系统中。\n1$ curl -fsSL get.docker.com -o get-docker.sh 2$ sudo sh get-docker.sh --mirror Aliyun 启动docker\n1$ sudo systemctl enable docker 2$ sudo systemctl start docker 创建docker用户组\n1$ sudo groupadd docker 将当前用户加入docker组\n1$ sudo usermod -aG docker $USER 测试docker安装是否正确\n1$ docker run hello-world 5.Docker 的核心架构 镜像: 一个镜像代表一个应用环境,他是一个只读的文件,如 mysql镜像,tomcat镜像,nginx镜像等 容器: 镜像每次运行之后就是产生一个容器,就是正在运行的镜像,特点就是可读可写 仓库:用来存放镜像的位置,类似于maven仓库,也是镜像下载和上传的位置 dockerFile:docker生成镜像配置文件,用来书写自定义镜像的一些配置 tar:一个对镜像打包的文件,日后可以还原成镜像 6. Docker 配置阿里镜像加速服务 6.1 docker 运行流程 6.2 docker配置阿里云镜像加速 访问阿里云登录自己账号查看docker镜像加速服务 1sudo mkdir -p /etc/docker 2sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; 3{ 4 \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://lz2nib3q.mirror.aliyuncs.com\u0026#34;] 5} 6EOF 7sudo systemctl daemon-reload 8sudo systemctl restart docker 验证docker的镜像加速是否生效 1[root@localhost ~]# docker info 2\t.......... 3 127.0.0.0/8 4 Registry Mirrors: 5 \u0026#39;https://lz2nib3q.mirror.aliyuncs.com/\u0026#39; 6 Live Restore Enabled: false 7 Product License: Community Engine 7.Docker的入门应用 7.1 docker 的第一个程序 docker run hello-world\n1[root@localhost ~]# docker run hello-world 2 3Hello from Docker! 4This message shows that your installation appears to be working correctly. 5 6To generate this message, Docker took the following steps: 7 1. The Docker client contacted the Docker daemon. 8 2. The Docker daemon pulled the \u0026#34;hello-world\u0026#34; image from the Docker Hub. 9 (amd64) 10 3. The Docker daemon created a new container from that image which runs the 11 executable that produces the output you are currently reading. 12 4. The Docker daemon streamed that output to the Docker client, which sent it 13 to your terminal. 14 15To try something more ambitious, you can run an Ubuntu container with: 16 $ docker run -it ubuntu bash 17 18Share images, automate workflows, and more with a free Docker ID: 19 https://hub.docker.com/ 20 21For more examples and ideas, visit: 22 https://docs.docker.com/get-started/ 8.常用命令 6.1 辅助命令 1# 1.安装完成辅助命令 2\tdocker version\t--------------------------\t查看docker的信息 3\tdocker info\t--------------------------\t查看更详细的信息 4\tdocker --help\t--------------------------\t帮助命令 6.2 Images 镜像命令 1# 1.查看本机中所有镜像 2\tdocker images\t--------------------------\t列出本地所有镜像 3\t-a\t列出所有镜像（包含中间映像层） 4 -q\t只显示镜像id 5 6# 2.搜索镜像 7\tdocker search [options] 镜像名\t-------------------\t去dockerhub上查询当前镜像 8\t-s 指定值\t列出收藏数不少于指定值的镜像 9 --no-trunc\t显示完整的镜像信息 10 11# 3.从仓库下载镜像 12\tdocker pull 镜像名[:TAG|@DIGEST]\t----------------- 下载镜像 13 14# 4.删除镜像 15\tdocker rmi 镜像名\t-------------------------- 删除镜像 16\t-f\t强制删除 6.3 Contrainer 容器命令 1# 1.运行容器 2\tdocker run 镜像名\t--------------------------\t镜像名新建并启动容器 3 --name 别名为容器起一个名字 4 -d\t启动守护式容器（在后台启动容器） 5 -p 映射端口号：原始端口号\t指定端口号启动 6 7\t例：docker run -it --name myTomcat -p 8888:8080 tomcat 8 docker run -d --name myTomcat -P tomcat 9 10# 2.查看运行的容器 11\tdocker ps\t--------------------------\t列出所有正在运行的容器 12\t-a\t正在运行的和历史运行过的容器 13\t-q\t静默模式，只显示容器编号 14 15# 3.停止|关闭|重启容器 16\tdocker start 容器名字或者容器id --------------- 开启容器 17\tdocker restart 容器名或者容器id --------------- 重启容器 18\tdocker stop 容器名或者容器id ------------------ 正常停止容器运行 19\tdocker kill 容器名或者容器id ------------------ 立即停止容器运行 20 21# 4.删除容器 22\tdocker rm -f 容器id和容器名 23\tdocker rm -f $(docker ps -aq)\t--------------------------\t删除所有容器 24 25# 5.查看容器内进程 26\tdocker top 容器id或者容器名 ------------------ 查看容器内的进程 27 28# 6.查看查看容器内部细节 29\tdocker inspect 容器id ------------------ 查看容器内部细节 30 31# 7.查看容器的运行日志 32\tdocker logs [OPTIONS] 容器id或容器名\t------------------ 查看容器日志 33 -t\t加入时间戳 34 -f\t跟随最新的日志打印 35 --tail 数字\t显示最后多少条 36 37# 8.进入容器内部 38\tdocker exec [options] 容器id 容器内命令 ------------------ 进入容器执行命令 39\t-i\t以交互模式运行容器，通常与-t一起使用 40 -t\t分配一个伪终端 shell窗口 bash 41 42# 9.容器和宿主机之间复制文件 43\tdocker cp 文件|目录 容器id:容器路径 ----------------- 将宿主机复制到容器内部 44\tdocker cp 容器id:容器内资源路径 宿主机目录路径 ----------------- 将容器内资源拷贝到主机上 45 46# 10.数据卷(volum)实现与宿主机共享目录 47\tdocker run -v 宿主机的路径|任意别名:/容器内的路径 镜像名 48\t注意: 49\t1.如果是宿主机路径必须是绝对路径,宿主机目录会覆盖容器内目录内容 50\t2.如果是别名则会在docker运行容器时自动在宿主机中创建一个目录,并将容器目录文件复制到宿主机中 51 52# 11.打包镜像 53\tdocker save 镜像名 -o 名称.tar 54 55# 12.载入镜像 56\tdocker load -i 名称.tar 57 58# 13.容器打包成新的镜像 59\tdocker commit -m \u0026#34;描述信息\u0026#34; -a \u0026#34;作者信息\u0026#34; （容器id或者名称）打包的镜像名称:标签 7.docker的镜像原理 7.1 镜像是什么？ 镜像是一种轻量级的，可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时所需的库、环境变量和配置文件。\n7.2 为什么一个镜像会那么大？ 镜像就是花卷\nUnionFS（联合文件系统）:\nUnion文件系统是一种分层，轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。Union文件系统是Docker镜像的基础。这种文件系统特性:就是一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录 。\n7.3 Docker镜像原理 docker的镜像实际是由一层一层的文件系统组成。\nbootfs（boot file system）主要包含bootloader和kernel，bootloader主要是引导加载kernel，Linux刚启动时会加载bootfs文件系统。在docker镜像的最底层就是bootfs。这一层与Linux/Unix 系统是一样的，包含boot加载器（bootloader）和内核（kernel）。当boot加载完,后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时会卸载bootfs。\nrootfs（root file system），在bootfs之上，包含的就是典型的linux系统中的/dev，/proc，/bin，/etc等标准的目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu/CentOS等等。\n我们平时安装进虚拟机的centos都有1到几个GB，为什么docker这里才200MB？对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令，工具，和程序库就可以了，因为底层直接使用Host的Kernal，自己只需要提供rootfs就行了。由此可见不同的linux发行版，他们的bootfs是一致的，rootfs会有差别。因此不同的发行版可以共用bootfs。\n7.4 为什么docker镜像要采用这种分层结构呢? 最大的一个好处就是资源共享\n比如：有多个镜像都是从相同的base镜像构建而来的，那么宿主机只需在磁盘中保存一份base镜像。同时内存中也只需要加载一份base镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。Docker镜像都是只读的。当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称为容器层，容器层之下都叫镜像层。 8.Docker安装常用服务 8.1 安装mysql 1# 1.拉取mysql镜像到本地 2\tdocker pull mysql:tag (tag不加默认最新版本) 3\t4# 2.运行mysql服务 5\tdocker run --name mysql -e MYSQL_ROOT_PASSWORD=root -d mysql:tag --没有暴露外部端口外部不能连接 6\tdocker run --name mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:tag --没有暴露外部端口 7 8# 3.进入mysql容器 9\tdocker exec -it 容器名称|容器id bash 10 11# 4.外部查看mysql日志 12\tdocker logs 容器名称|容器id 13 14# 5.使用自定义配置参数 15\tdocker run --name mysql -v /root/mysql/conf.d:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=root -d mysql:tag 16 17# 6.将容器数据位置与宿主机位置挂载保证数据安全 18\tdocker run --name mysql -v /root/mysql/data:/var/lib/mysql -v /root/mysql/conf.d:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:tag 19 20# 7.通过其他客户端访问 如在window系统|macos系统使用客户端工具访问 21\t22# 8.将mysql数据库备份为sql文件 23\tdocker exec mysql|容器id sh -c \u0026#39;exec mysqldump --all-databases -uroot -p\u0026#34;$MYSQL_ROOT_PASSWORD\u0026#34;\u0026#39; \u0026gt; /root/all-databases.sql --导出全部数据 24\tdocker exec mysql sh -c \u0026#39;exec mysqldump --databases 库表 -uroot -p\u0026#34;$MYSQL_ROOT_PASSWORD\u0026#34;\u0026#39; \u0026gt; /root/all-databases.sql --导出指定库数据 25\tdocker exec mysql sh -c \u0026#39;exec mysqldump --no-data --databases 库表 -uroot -p\u0026#34;$MYSQL_ROOT_PASSWORD\u0026#34;\u0026#39; \u0026gt; /root/all-databases.sql --导出指定库数据不要数据 26 27# 9.执行sql文件到mysql中 28\tdocker exec -i mysql sh -c \u0026#39;exec mysql -uroot -p\u0026#34;$MYSQL_ROOT_PASSWORD\u0026#34;\u0026#39; \u0026lt; /root/xxx.sql 8.2 安装Redis服务 1# 1.在docker hub搜索redis镜像 2\tdocker search redis 3 4# 2.拉取redis镜像到本地 5\tdocker pull redis 6 7# 3.启动redis服务运行容器 8\tdocker run --name redis -d redis:tag (没有暴露外部端口) 9\tdocker run --name redis -p 6379:6379 -d redis:tag (暴露外部宿主机端口为6379进行连接) 10 11# 4.查看启动日志 12\tdocker logs -t -f 容器id|容器名称 13 14# 5.进入容器内部查看 15\tdocker exec -it 容器id|名称 bash 16 17# 6.加载外部自定义配置启动redis容器 18\t默认情况下redis官方镜像中没有redis.conf配置文件 需要去官网下载指定版本的配置文件 19\t1. wget http://download.redis.io/releases/redis-5.0.8.tar.gz 下载官方安装包 20\t2. 将官方安装包中配置文件进行复制到宿主机指定目录中如 /root/redis/redis.conf文件 21\t3. 修改需要自定义的配置 22\tbind 0.0.0.0 开启远程权限 23\tappenonly yes 开启aof持久化 24\t4. 加载配置启动 25\tdocker run --name redis -v /root/redis:/usr/local/etc/redis -p 6379:6379 -d redis redis-server /usr/local/etc/redis/redis.conf 26 27# 7.将数据目录挂在到本地保证数据安全 28\tdocker run --name redis -v /root/redis/data:/data -v /root/redis/redis.conf:/usr/local/etc/redis/redis.conf -p 6379:6379 -d redis redis-server /usr/local/etc/redis/redis.conf 8.3 安装Nginx 1# 1.在docker hub搜索nginx 2\tdocker search nginx 3 4# 2.拉取nginx镜像到本地 5\t[root@localhost ~]# docker pull nginx 6 Using default tag: latest 7 latest: Pulling from library/nginx 8 afb6ec6fdc1c: Pull complete 9 b90c53a0b692: Pull complete 10 11fa52a0fdc0: Pull complete 11 Digest: sha256:30dfa439718a17baafefadf16c5e7c9d0a1cde97b4fd84f63b69e13513be7097 12 Status: Downloaded newer image for nginx:latest 13 docker.io/library/nginx:latest 14 15# 3.启动nginx容器 16\tdocker run -p 80:80 --name nginx01 -d nginx 17 18# 4.进入容器 19\tdocker exec -it nginx01 /bin/bash 20\t查找目录: whereis nginx 21\t配置文件: /etc/nginx/nginx.conf 22 23# 5.复制配置文件到宿主机 24\tdocker cp nginx01(容器id|容器名称):/etc/nginx/nginx.conf 宿主机名录 25 26# 6.挂在nginx配置以及html到宿主机外部 27\tdocker run --name nginx02 -v /root/nginx/nginx.conf:/etc/nginx/nginx.conf -v /root/nginx/html:/usr/share/nginx/html -p 80:80 -d nginx\t8.4 安装Tomcat 1# 1.在docker hub搜索tomcat 2\tdocker search tomcat 3 4# 2.下载tomcat镜像 5\tdocker pull tomcat 6 7# 3.运行tomcat镜像 8\tdocker run -p 8080:8080 -d --name mytomcat tomcat 9 10# 4.进入tomcat容器 11\tdocker exec -it mytomcat /bin/bash 12 13# 5.将webapps目录挂载在外部 14\tdocker run -p 8080:8080 -v /root/webapps:/usr/local/tomcat/webapps -d --name mytomcat tomcat 8.5 安装MongoDB数据库 1# 1.运行mongDB 2\tdocker run -d -p 27017:27017 --name mymongo mongo ---无须权限 3\tdocker logs -f mymongo --查看mongo运行日志 4 5# 2.进入mongodb容器 6\tdocker exec -it mymongo /bin/bash 7\t直接执行mongo命令进行操作 8 9# 3.常见具有权限的容器 10\tdocker run --name mymongo -p 27017:27017 -d mongo --auth 11 12# 4.进入容器配置用户名密码 13\tmongo 14\tuse admin 选择admin库 15\tdb.createUser({user:\u0026#34;root\u0026#34;,pwd:\u0026#34;root\u0026#34;,roles:[{role:\u0026#39;root\u0026#39;,db:\u0026#39;admin\u0026#39;}]}) //创建用户,此用户创建成功,则后续操作都需要用户认证 16\texit 17 18# 5.将mongoDB中数据目录映射到宿主机中 19\tdocker run -d -p 27017:27017 -v /root/mongo/data:/data/db --name mymongo mongo 8.6 安装ElasticSearch 注意:调高JVM线程数限制数量 0.拉取镜像运行elasticsearch 1# 1.dockerhub 拉取镜像 2\tdocker pull elasticsearch:6.4.2 3# 2.查看docker镜像 4\tdocker images 5# 3.运行docker镜像 6\tdocker run -p 9200:9200 -p 9300:9300 elasticsearch:6.4.2 启动出现如下错误 1. 预先配置 1# 1.在centos虚拟机中，修改配置sysctl.conf 2\tvim /etc/sysctl.conf 3# 2.加入如下配置 4\tvm.max_map_count=262144 5# 3.启用配置 6\tsysctl -p 7\t注：这一步是为了防止启动容器时，报出如下错误： 8\tbootstrap checks failed max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 2.启动EleasticSearch容器 1# 0.复制容器中data目录到宿主机中 2\tdocker cp 容器id:/usr/share/share/elasticsearch/data /root/es 3# 1.运行ES容器 指定jvm内存大小并指定ik分词器位置 4\tdocker run -d --name es -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=\u0026#34;-Xms128m -Xmx128m\u0026#34; -v /root/es/plugins:/usr/share/elasticsearch/plugins -v /root/es/data:/usr/share/elasticsearch/data elasticsearch:6.4.2 3.安装IK分词器 1# 1.下载对应版本的IK分词器 2\twget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.4.2/elasticsearch-analysis-ik-6.4.2.zip 3 4# 2.解压到plugins文件夹中 5\tyum install -y unzip 6\tunzip -d ik elasticsearch-analysis-ik-6.4.2.zip 7 8# 3.添加自定义扩展词和停用词 9\tcd plugins/elasticsearch/config 10\tvim IKAnalyzer.cfg.xml 11\t\u0026lt;properties\u0026gt; 12\t\u0026lt;comment\u0026gt;IK Analyzer 扩展配置\u0026lt;/comment\u0026gt; 13\t\u0026lt;!--用户可以在这里配置自己的扩展字典 --\u0026gt; 14\t\u0026lt;entry key=\u0026#34;ext_dict\u0026#34;\u0026gt;ext_dict.dic\u0026lt;/entry\u0026gt; 15\t\u0026lt;!--用户可以在这里配置自己的扩展停止词字典--\u0026gt; 16\t\u0026lt;entry key=\u0026#34;ext_stopwords\u0026#34;\u0026gt;ext_stopwords.dic\u0026lt;/entry\u0026gt; 17\t\u0026lt;/properties\u0026gt; 18 19# 4.在ik分词器目录下config目录中创建ext_dict.dic文件 编码一定要为UTF-8才能生效 20\tvim ext_dict.dic 加入扩展词即可 21# 5. 在ik分词器目录下config目录中创建ext_stopword.dic文件 22\tvim ext_stopwords.dic 加入停用词即可 23 24# 6.重启容器生效 25\tdocker restart 容器id 26# 7.将此容器提交成为一个新的镜像 27\tdocker commit -a=\u0026#34;xiaochen\u0026#34; -m=\u0026#34;es with IKAnalyzer\u0026#34; 容器id xiaochen/elasticsearch:6.4.2 4. 安装Kibana 1# 1.下载kibana镜像到本地 2\tdocker pull kibana:6.4.2 3 4# 2.启动kibana容器 5\tdocker run -d --name kibana -e ELASTICSEARCH_URL=http://10.15.0.3:9200 -p 5601:5601 kibana:6.4.2 10.Docker中出现如下错误解决方案 1[root@localhost ~]# docker search mysql 或者 docker pull 这些命令无法使用 2Error response from daemon: Get https://index.docker.io/v1/search?q=mysql\u0026amp;n=25: x509: certificate has expired or is not yet valid 注意:这个错误的原因在于是系统的时间和docker hub时间不一致,需要做系统时间与网络时间同步 1# 1.安装时间同步 2\tsudo yum -y install ntp ntpdate 3# 2.同步时间 4\tsudo ntpdate cn.pool.ntp.org 5# 3.查看本机时间 6\tdate 7# 4.从新测试 9.Dockerfile 9.1 什么是Dockerfile Dockerfile可以认为是Docker镜像的描述文件，是由一系列命令和参数构成的脚本。主要作用是用来构建docker镜像的构建文件。\n通过架构图可以看出通过DockerFile可以直接构建镜像 9.2 Dockerfile解析过程 9.3 Dockerfile的保留命令 官方说明:https://docs.docker.com/engine/reference/builder/\n保留字 作用 FROM 当前镜像是基于哪个镜像的 第一个指令必须是FROM MAINTAINER 镜像维护者的姓名和邮箱地址 RUN 构建镜像时需要运行的指令 EXPOSE 当前容器对外暴露出的端口号 WORKDIR 指定在创建容器后，终端默认登录进来的工作目录，一个落脚点 ENV 用来在构建镜像过程中设置环境变量 ADD 将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar包 COPY 类似于ADD，拷贝文件和目录到镜像中将从构建上下文目录中\u0026lt;原路径\u0026gt;的文件/目录复制到新的一层的镜像内的\u0026lt;目标路径\u0026gt;位置 VOLUME 容器数据卷，用于数据保存和持久化工作 CMD 指定一个容器启动时要运行的命令Dockerfile中可以有多个CMD指令，但只有最后一个生效，CMD会被docker run之后的参数替换 ENTRYPOINT 指定一个容器启动时要运行的命令ENTRYPOINT的目的和CMD一样，都是在指定容器启动程序及其参数 9.3.1 FROM 命令 基于那个镜像进行构建新的镜像,在构建时会自动从docker hub拉取base镜像 必须作为Dockerfile的第一个指令出现\n语法:\n1FROM \u0026lt;image\u0026gt; 2FROM \u0026lt;image\u0026gt;[:\u0026lt;tag\u0026gt;] 使用版本不写为latest 3FROM \u0026lt;image\u0026gt;[@\u0026lt;digest\u0026gt;] 使用摘要 9.3.2 MAINTAINER 命令 镜像维护者的姓名和邮箱地址[废弃]\n语法:\n1MAINTAINER \u0026lt;name\u0026gt; 9.3.3 RUN 命令 RUN指令将在当前映像之上的新层中执行任何命令并提交结果。生成的提交映像将用于Dockerfile中的下一步\n语法:\n1RUN \u0026lt;command\u0026gt; (shell form, the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows) 2RUN echo hello 3 4RUN [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] (exec form) 5RUN [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;echo hello\u0026#34;] 9.3.4 EXPOSE 命令 用来指定构建的镜像在运行为容器时对外暴露的端口\n语法:\n1EXPOSE 80/tcp 如果没有显示指定则默认暴露都是tcp 2EXPOSE 80/udp 9.3.5 CMD 命令 用来为启动的容器指定执行的命令,在Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。\n注意: Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。\n语法:\n1CMD [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] (exec form, this is the preferred form) 2CMD [\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] (as default parameters to ENTRYPOINT) 3CMD command param1 param2 (shell form) 9.3.6 WORKDIR 命令 用来为Dockerfile中的任何RUN、CMD、ENTRYPOINT、COPY和ADD指令设置工作目录。如果WORKDIR不存在，即使它没有在任何后续Dockerfile指令中使用，它也将被创建。\n语法:\n1WORKDIR /path/to/workdir 2 3WORKDIR /a 4WORKDIR b 5WORKDIR c 6`注意:WORKDIR指令可以在Dockerfile中多次使用。如果提供了相对路径，则该路径将与先前WORKDIR指令的路径相对` 9.3.7 ENV 命令 用来为构建镜像设置环境变量。这个值将出现在构建阶段中所有后续指令的环境中。\n语法：\n1ENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; 2ENV \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... 9.3.8 ADD 命令 用来从context上下文复制新文件、目录或远程文件url，并将它们添加到位于指定路径的映像文件系统中。\n语法:\n1ADD hom* /mydir/ 通配符添加多个文件 2ADD hom?.txt /mydir/ 通配符添加 3ADD test.txt relativeDir/ 可以指定相对路径 4ADD test.txt /absoluteDir/ 也可以指定绝对路径 5ADD url 9.3.9 COPY 命令 用来将context目录中指定文件复制到镜像的指定目录中\n语法:\n1COPY src dest 2COPY [\u0026#34;\u0026lt;src\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;dest\u0026gt;\u0026#34;] 9.3.10 VOLUME 命令 用来定义容器运行时可以挂在到宿主机的目录\n语法:\n1VOLUME [\u0026#34;/data\u0026#34;] 9.3.11 ENTRYPOINT命令 用来指定容器启动时执行命令和CMD类似\n语法:\n1 [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] 2ENTRYPOINT command param1 param2 ENTRYPOINT指令，往往用于设置容器启动后的第一个命令，这对一个容器来说往往是固定的。 CMD指令，往往用于设置容器启动的第一个命令的默认参数，这对一个容器来说可以是变化的。\n9.3.11 ENTRYPOINT命令 9.4 Dockerfile构建springboot项目部署 1.准备springboot可运行项目 2.将可运行项目放入linux虚拟机中 3.编写Dockerfile 1FROM openjdk:8 2WORKDIR /ems 3ADD ems.jar /ems 4EXPOSE 8989 5ENTRYPOINT [\u0026#34;java\u0026#34;,\u0026#34;-jar\u0026#34;] 6CMD [\u0026#34;ems.jar\u0026#34;] 4.构建镜像 1[root@localhost ems]# docker build -t ems . 5.运行镜像 1[root@localhost ems]# docker run -p 8989:8989 ems 6.访问项目 1http://10.15.0.8:8989/ems/login.html 10.高级网络配置 10.1 说明 当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。\n同时，Docker 随机分配一个本地未占用的私有网段（在 RFC1918 中定义）中的一个地址给 docker0 接口。比如典型的 172.17.42.1，掩码为 255.255.0.0。此后启动的容器内的网口也会自动分配一个同一网段（172.17.0.0/16）的地址。\n当创建一个 Docker 容器的时候，同时会创建了一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头（例如 vethAQI2QT）。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络。\n10.2 查看网络信息 1# docker network ls 10.3 创建一个网桥 1# docker network create -d bridge 网桥名称 10.4 删除一个网桥 1# docker network rm 网桥名称 10.5 容器之前使用网络通信 1# 1.查询当前网络配置 2- docker network ls 1NETWORK ID NAME DRIVER SCOPE 28e424e5936b7 bridge bridge local 317d974db02da docker_gwbridge bridge local 4d6c326e433f7 host host local 1# 2.创建桥接网络 2- docker network create -d bridge info 1[root@centos ~]# docker network create -d bridge info 26e4aaebff79b1df43a064e0e8fdab08f52d64ce34db78dd5184ce7aaaf550a2f 3[root@centos ~]# docker network ls 4NETWORK ID NAME DRIVER SCOPE 58e424e5936b7 bridge bridge local 617d974db02da docker_gwbridge bridge local 7d6c326e433f7 host host local 86e4aaebff79b info bridge local 1# 3.启动容器指定使用网桥 2- docker run -d -p 8890:80 --name nginx001 --network info nginx 3- docker run -d -p 8891:80 --name nginx002 --network info nginx 4\t`注意:一旦指定网桥后--name指定名字就是主机名,多个容器指定在同一个网桥时,可以在任意一个容器中使用主机名与容器进行互通` 1[root@centos ~]# docker run -d -p 8890:80 --name nginx001 --network info nginx 2c315bcc94e9ddaa36eb6c6f16ca51592b1ac8bf1ecfe9d8f01d892f3f10825fe 3[root@centos ~]# docker run -d -p 8891:80 --name nginx002 --network info nginx 4f8682db35dd7fb4395f90edb38df7cad71bbfaba71b6a4c6e2a3a525cb73c2a5 5[root@centos ~]# docker ps 6CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7f8682db35dd7 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 seconds ago Up 2 seconds 0.0.0.0:8891-\u0026gt;80/tcp nginx002 8c315bcc94e9d nginx \u0026#34;/docker-entrypoint.…\u0026#34; 7 minutes ago Up 7 minutes 0.0.0.0:8890-\u0026gt;80/tcp nginx001 9b63169d43792 mysql:5.7.19 \u0026#34;docker-entrypoint.s…\u0026#34; 7 minutes ago Up 7 minutes 3306/tcp mysql_mysql.1.s75qe5kkpwwttyf0wrjvd2cda 10[root@centos ~]# docker exec -it f8682db35dd7 /bin/bash 11root@f8682db35dd7:/# curl http://nginx001 12\u0026lt;!DOCTYPE html\u0026gt; 13\u0026lt;html\u0026gt; 14\u0026lt;head\u0026gt; 15\u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; 16..... 11.高级数据卷配置 11.1 说明 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性：\n数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。\n11.2 创建数据卷 1[root@centos ~]# docker volume create my-vol 2my-vol 11.3 查看数据卷 1[root@centos ~]# docker volume inspect my-vol 2[ 3 { 4 \u0026#34;CreatedAt\u0026#34;: \u0026#34;2020-11-25T11:43:56+08:00\u0026#34;, 5 \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, 6 \u0026#34;Labels\u0026#34;: {}, 7 \u0026#34;Mountpoint\u0026#34;: \u0026#34;/var/lib/docker/volumes/my-vol/_data\u0026#34;, 8 \u0026#34;Name\u0026#34;: \u0026#34;my-vol\u0026#34;, 9 \u0026#34;Options\u0026#34;: {}, 10 \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34; 11 } 12] 11.4 挂载数据卷 1[root@centos ~]# docker run -d -P --name web -v my-vol:/usr/share/nginx/html nginx 2[root@centos ~]# docker inspect web 3\t\u0026#34;Mounts\u0026#34;: [ 4 { 5 \u0026#34;Type\u0026#34;: \u0026#34;volume\u0026#34;, 6 \u0026#34;Name\u0026#34;: \u0026#34;my-vol\u0026#34;, 7 \u0026#34;Source\u0026#34;: \u0026#34;/var/lib/docker/volumes/my-vol/_data\u0026#34;, 8 \u0026#34;Destination\u0026#34;: \u0026#34;/usr/share/nginx/html\u0026#34;, 9 \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, 10 \u0026#34;Mode\u0026#34;: \u0026#34;z\u0026#34;, 11 \u0026#34;RW\u0026#34;: true, 12 \u0026#34;Propagation\u0026#34;: \u0026#34;\u0026#34; 13 } 14 ], 11.5 删除数据卷 1docker volume rm my-vol 12.Docker Compose 12.1 简介 Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。\n其代码目前在 https://github.com/docker/compose 上开源。\nCompose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。\n通过第一部分中的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。\nCompose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。\nCompose 中有两个重要的概念：\n服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。\nCompose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。\n12.2 安装与卸载 1.linux 在 Linux 上的也安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。例如，在 Linux 64 位系统上直接下载对应的二进制包。 1$ sudo curl -L https://github.com/docker/compose/releases/download/1.25.5/docker-compose-`uname -s`-`uname -m` \u0026gt; /usr/local/bin/docker-compose 2$ sudo chmod +x /usr/local/bin/docker-compose 2.macos、window Compose 可以通过 Python 的包管理工具 pip 进行安装，也可以直接下载编译好的二进制文件使用，甚至能够直接在 Docker 容器中运行。Docker Desktop for Mac/Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。 3.bash命令补全 1$ curl -L https://raw.githubusercontent.com/docker/compose/1.25.5/contrib/completion/bash/docker-compose \u0026gt; /etc/bash_completion.d/docker-compose 4.卸载 如果是二进制包方式安装的，删除二进制文件即可。 1$ sudo rm /usr/local/bin/docker-compose 5.测试安装成功 1$ docker-compose --version 2 docker-compose version 1.25.5, build 4667896b 12.3 docker compose使用 1# 1.相关概念 首先介绍几个术语。\n服务 (service)：一个应用容器，实际上可以运行多个相同镜像的实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元。∂一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理。 1# 2.场景 最常见的项目是 web 网站，该项目应该包含 web 应用和缓存。\nspringboot应用 mysql服务 redis服务 elasticsearch服务 \u0026hellip;\u0026hellip;. 1# 3.docker-compose模板 2- 参考文档:https://docker_practice.gitee.io/zh-cn/compose/compose_file.html 1version: \u0026#34;3.0\u0026#34; 2services: 3 mysqldb: 4 image: mysql:5.7.19 5 container_name: mysql 6 ports: 7 - \u0026#34;3306:3306\u0026#34; 8 volumes: 9 - /root/mysql/conf:/etc/mysql/conf.d 10 - /root/mysql/logs:/logs 11 - /root/mysql/data:/var/lib/mysql 12 environment: 13 MYSQL_ROOT_PASSWORD: root 14 networks: 15 - ems 16 depends_on: 17 - redis 18 19 redis: 20 image: redis:4.0.14 21 container_name: redis 22 ports: 23 - \u0026#34;6379:6379\u0026#34; 24 networks: 25 - ems 26 volumes: 27 - /root/redis/data:/data 28 command: redis-server 29 30networks: 31 ems: 1# 4.通过docker-compose运行一组容器 2- 参考文档:https://docker_practice.gitee.io/zh-cn/compose/commands.html 1[root@centos ~]# docker-compose up //前台启动一组服务 2[root@centos ~]# docker-compose up -d //后台启动一组服务 12.4 docker-compose 模板文件 模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。\n默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。\n1version: \u0026#34;3\u0026#34; 2 3services: 4 webapp: 5 image: examples/web 6 ports: 7 - \u0026#34;80:80\u0026#34; 8 volumes: 9 - \u0026#34;/data\u0026#34; 注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。\n如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中重复设置。\n下面分别介绍各个指令的用法。\nbuild 指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。\n1version: \u0026#39;3\u0026#39; 2services: 3 4 webapp: 5 build: ./dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。\n使用 dockerfile 指令指定 Dockerfile 文件名。\n使用 arg 指令指定构建镜像时的变量。\n1version: \u0026#39;3\u0026#39; 2services: 3 4 webapp: 5 build: 6 context: ./dir 7 dockerfile: Dockerfile-alternate 8 args: 9 buildno: 1 command 覆盖容器启动后默认执行的命令。\n1command: echo \u0026#34;hello world\u0026#34; container_name 指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。\n1container_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。\ndepends_on 解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web\n1version: \u0026#39;3\u0026#39; 2 3services: 4 web: 5 build: . 6 depends_on: 7 - db 8 - redis 9 10 redis: 11 image: redis 12 13 db: 14 image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动。\nenv_file 从文件中获取环境变量，可以为单独的文件路径或列表。\n如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。\n如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。\n1env_file: .env 2 3env_file: 4 - ./common.env 5 - ./apps/web.env 6 - /opt/secrets.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。\n1# common.env: Set development environment 2PROG_ENV=development environment 设置环境变量。你可以使用数组或字典两种格式。\n只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。\n1environment: 2 RACK_ENV: development 3 SESSION_SECRET: 4 5environment: 6 - RACK_ENV=development 7 - SESSION_SECRET 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括\n1y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF healthcheck 通过命令检查容器是否健康运行。\n1healthcheck: 2 test: [\u0026#34;CMD\u0026#34;, \u0026#34;curl\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;http://localhost\u0026#34;] 3 interval: 1m30s 4 timeout: 10s 5 retries: 3 image 指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。\n1image: ubuntu 2image: orchardup/postgresql 3image: a4bc65fd networks 配置容器连接的网络。\n1version: \u0026#34;3\u0026#34; 2services: 3 4 some-service: 5 networks: 6 - some-network 7 - other-network 8 9networks: 10 some-network: 11 other-network: ports 暴露端口信息。\n使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。\n1ports: 2 - \u0026#34;3000\u0026#34; 3 - \u0026#34;8000:8000\u0026#34; 4 - \u0026#34;49100:22\u0026#34; 5 - \u0026#34;127.0.0.1:8001:8001\u0026#34; 注意：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。\nsysctls 配置容器内核参数。\n1sysctls: 2 net.core.somaxconn: 1024 3 net.ipv4.tcp_syncookies: 0 4 5sysctls: 6 - net.core.somaxconn=1024 7 - net.ipv4.tcp_syncookies=0 ulimits 指定容器的 ulimits 限制值。\n例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。\n1 ulimits: 2 nproc: 65535 3 nofile: 4 soft: 20000 5 hard: 40000 volumes 数据卷所挂载路径设置。可以设置为宿主机路径(HOST:CONTAINER)或者数据卷名称(VOLUME:CONTAINER)，并且可以设置访问模式 （HOST:CONTAINER:ro）。\n该指令中路径支持相对路径。\n1volumes: 2 - /var/lib/mysql 3 - cache/:/tmp/cache 4 - ~/configs:/etc/configs/:ro 如果路径为数据卷名称，必须在文件中配置数据卷。\n1version: \u0026#34;3\u0026#34; 2 3services: 4 my_src: 5 image: mysql:8.0 6 volumes: 7 - mysql_data:/var/lib/mysql 8 9volumes: 10 mysql_data: 12.5 docker-compose 常用命令 1. 命令对象与格式 对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。\n执行 docker-compose [COMMAND] --help 或者 docker-compose help [COMMAND] 可以查看具体某个命令的使用格式。\ndocker-compose 命令的基本的使用格式是\n1docker-compose [-f=\u0026lt;arg\u0026gt;...] [options] [COMMAND] [ARGS...] 2. 命令选项 -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。 --x-networking 使用 Docker 的可拔插网络后端特性 --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge --verbose 输出更多调试信息。 -v, --version 打印版本并退出。 3.命令使用说明 up 格式为 docker-compose up [options] [SERVICE...]。\n该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。\n链接的服务都将会被自动启动，除非已经处于运行状态。\n可以说，大部分时候都可以直接通过该命令来启动一个项目。\n默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。\n当通过 Ctrl-C 停止命令时，所有容器将会停止。\n如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。\n默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容\ndown 此命令将会停止 up 命令所启动的容器，并移除网络 exec 进入指定的容器。 ps 格式为 docker-compose ps [options] [SERVICE...]。\n列出项目中目前的所有容器。\n选项：\n-q 只打印容器的 ID 信息。 restart 格式为 docker-compose restart [options] [SERVICE...]。\n重启项目中的服务。\n选项：\n-t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 rm 格式为 docker-compose rm [options] [SERVICE...]。\n删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。\n选项：\n-f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷。 start 格式为 docker-compose start [SERVICE...]。\n启动已经存在的服务容器。\nstop 格式为 docker-compose stop [options] [SERVICE...]。\n停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。\n选项：\n-t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top 查看各个服务容器内运行的进程。\nunpause 格式为 docker-compose unpause [SERVICE...]。\n恢复处于暂停状态中的服务。\n13.docker可视化工具 13.1 安装Portainer 官方安装说明：https://www.portainer.io/installation/\n1[root@ubuntu1804 ~]#docker pull portainer/portainer 2 3[root@ubuntu1804 ~]#docker volume create portainer_data 4portainer_data 5[root@ubuntu1804 ~]#docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer 620db26b67b791648c2ef6aee444a5226a9c897ebcf0160050e722dbf4a4906e3 7[root@ubuntu1804 ~]#docker ps 8CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 920db26b67b79 portainer/portainer \u0026#34;/portainer\u0026#34; 5 seconds ago Up 4 seconds 0.0.0.0:8000-\u0026gt;8000/tcp, 0.0.0.0:9000-\u0026gt;9000/tcp portainer 13.2 登录和使用Portainer 用浏览器访问：http://localhost:9000\n","date":"2022-01-06","img":"","permalink":"/posts/ddeb9b11/","series":null,"tags":["教程","Docker"],"title":"Docker-配置文档"},{"categories":["LeetCode"],"content":"题目 给你一个仅包含小写英文字母和 \u0026lsquo;?\u0026rsquo; 字符的字符串 s，请你将所有的 \u0026lsquo;?\u0026rsquo; 转换为若干小写字母，使最终的字符串不包含任何 连续重复 的字符。\n注意：你 不能 修改非 ? 字符。\n题目测试用例保证 除 ? 字符 之外，不存在连续重复的字符。\n在完成所有转换（可能无需转换）后返回最终的字符串。如果有多个解决方案，请返回其中任何一个。可以证明，在给定的约束条件下，答案总是存在的。\n示例 示例 1 1输入：s = \u0026#34;?zs\u0026#34; 2输出：\u0026#34;azs\u0026#34; 3解释：该示例共有 25 种解决方案，从 \u0026#34;azs\u0026#34; 到 \u0026#34;yzs\u0026#34; 都是符合题目要求的。只有 \u0026#34;z\u0026#34; 是无效的修改，因为字符串 \u0026#34;zzs\u0026#34; 中有连续重复的两个 \u0026#39;z\u0026#39; 。 示例 2 1输入：s = \u0026#34;ubv?w\u0026#34; 2输出：\u0026#34;ubvaw\u0026#34; 3解释：该示例共有 24 种解决方案，只有替换成 \u0026#34;v\u0026#34; 和 \u0026#34;w\u0026#34; 不符合题目要求。因为 \u0026#34;ubvvw\u0026#34; 和 \u0026#34;ubvww\u0026#34; 都包含连续重复的字符。 示例 3 1输入：s = \u0026#34;j?qg??b\u0026#34; 2输出：\u0026#34;jaqgacb\u0026#34; 示例 4 1输入：s = \u0026#34;??yw?ipkj?\u0026#34; 2输出：\u0026#34;acywaipkja\u0026#34; 解答 根据题意进行模拟，尝试对每个 s[i] 进行替换，能够替换的前提是 s[i] 为 ?，且替换字符与前后字符（若存在）不同，由于只需要确保与前后字符不同，因此必然最多在 3 个字符内找到可替换的值。\n代码 1string modifyString(string s) { 2 s=\u0026#34; \u0026#34;+s+\u0026#34; \u0026#34;; 3 for(char\u0026amp; c:s){ 4 if(c==\u0026#39;?\u0026#39;){ 5 for(int i=\u0026#39;a\u0026#39;;i\u0026lt;=\u0026#39;c\u0026#39;;++i){ 6 if(i!=(\u0026amp;c)[-1] \u0026amp;\u0026amp; i!=(\u0026amp;c)[1]){ 7 c=i; 8 break; 9 } 10 } 11 } 12 } 13 return {s.begin()+1,s.end()-1}; 14 } 1string modifyString(string s) { 2 s=\u0026#34; \u0026#34;+s+\u0026#34; \u0026#34;; 3 for(char\u0026amp; c:s){ 4 if(c==\u0026#39;?\u0026#39;){ 5 for(int i=\u0026#39;a\u0026#39;;i\u0026lt;=\u0026#39;z\u0026#39;;++i){ 6 if(i!=(\u0026amp;c)[-1] \u0026amp;\u0026amp; i!=(\u0026amp;c)[1]){ 7 c=i; 8 break; 9 } 10 } 11 } 12 } 13 return {s.begin()+1,s.end()-1}; 14 } ","date":"2022-01-05","img":"","permalink":"/posts/68d43a4d/","series":["leetcode"],"tags":["模拟","简单"],"title":"LeetCode-1576-替换所有的问号"},{"categories":["LeetCode"],"content":"题目 两位玩家分别扮演猫和老鼠，在一张 无向 图上进行游戏，两人轮流行动。\n图的形式是：graph[a] 是一个列表，由满足 ab 是图中的一条边的所有节点 b 组成。\n老鼠从节点 1 开始，第一个出发；猫从节点 2 开始，第二个出发。在节点 0 处有一个洞。\n在每个玩家的行动中，他们 必须 沿着图中与所在当前位置连通的一条边移动。例如，如果老鼠在节点 1 ，那么它必须移动到 graph[1] 中的任一节点。\n此外，猫无法移动到洞中（节点 0）。\n然后，游戏在出现以下三种情形之一时结束：\n如果猫和老鼠出现在同一个节点，猫获胜。 如果老鼠到达洞中，老鼠获胜。 如果某一位置重复出现（即，玩家的位置和移动顺序都与上一次行动相同），游戏平局。 给你一张图 graph ，并假设两位玩家都都以最佳状态参与游戏：\n如果老鼠获胜，则返回 1； 如果猫获胜，则返回 2； 如果平局，则返回 0 。\n示例 示例1 1输入：graph = [[2,5],[3],[0,4,5],[1,4,5],[2,3],[0,2,3]] 2输出：0 示例2 1输入：graph = [[1,3],[0],[3],[0,2]] 2输出：1 解答 前言 这道题是博弈问题，猫和老鼠都按照最优策略参与游戏。\n在阐述具体解法之前，首先介绍博弈问题中的三个概念：必胜状态、必败状态与必和状态。\n对于特定状态，如果游戏已经结束，则根据结束时的状态决定必胜状态、必败状态与必和状态。\n如果分出胜负，则该特定状态对于获胜方为必胜状态，对于落败方为必败状态。 如果是平局，则该特定状态对于双方都为必和状态。 从特定状态开始，如果存在一种操作将状态变成必败状态，则当前玩家可以选择该操作，将必败状态留给对方玩家，因此该特定状态对于当前玩家为必胜状态。\n从特定状态开始，如果所有操作都会将状态变成必胜状态，则无论当前玩家选择哪种操作，都会将必胜状态留给对方玩家，因此该特定状态对于当前玩家为必败状态。\n从特定状态开始，如果任何操作都不能将状态变成必败状态，但是存在一种操作将状态变成必和状态，则当前玩家可以选择该操作，将必和状态留给对方玩家，因此该特定状态对于双方玩家都为必和状态。\n对于每个玩家，最优策略如下：\n争取将必胜状态留给自己，将必败状态留给对方玩家。 在自己无法到达必胜状态的情况下，争取将必和状态留给自己。 方法一：动态规划 博弈问题通常可以使用动态规划求解。\n使用三维数组 dp 表示状态，dp[mouse][cat][turns] 表示从老鼠位于节点 mouse、猫位于节点 cat、游戏已经进行了 turns 轮的状态开始，猫和老鼠都按照最优策略的情况下的游戏结果。假设图中的节点数是 n，则有 0≤mouse,cat\u0026lt;n。\n由于游戏的初始状态是老鼠位于节点 1，猫位于节点 2，因此 dp[1][2][0] 为从初始状态开始的游戏结果。\n动态规划的边界条件为可以直接得到游戏结果的状态，包括以下三种状态：\n如果 mouse=0，老鼠躲入洞里，则老鼠获胜，因此对于任意cat 和 turns 都有dp[0][cat][turns]=1，该状态为老鼠的必胜状态，猫的必败状态。\n如果 cat=mouse，猫和老鼠占据相同的节点，则猫获胜，因此当cat=mouse 时，对于任意 mouse、cat 和turns 都有dp[mouse][cat][turns]=2，该状态为老鼠的必败状态，猫的必胜状态。注意猫不能移动到节点 00，因此当 mouse=0 时，一定有 cat≠mouse\n如果 turns≥2n，则是平局，该状态为双方的必和状态。\n为什么当 turns≥2n 时，游戏结果是平局呢？\n如果游戏已经进行了2n 轮，但是仍然没有任何一方获胜，此时猫和老鼠各移动了 n次，该移动次数等于图中的节点数，因此一定存在一个老鼠到达过至少两次的节点，以及一定存在一个猫到达过至少两次的节点。\n对于老鼠而言，即使按照最优策略，也无法躲入洞内，而是只能回到一个已经到达过的节点。当老鼠回到一个在过去的某个回合已经到达过的节点时，猫可能回到在相同回合已经到达过的节点，也可能移动到一个更有利于猫获胜的节点，不可能移动到一个更有利于老鼠获胜的节点（否则猫就不是按照最优策略参与游戏）。如果猫回到在相同回合已经到达过的节点，则形成循环，因此是平局；如果猫移动到一个更有利于猫获胜的节点，则老鼠的获胜机会更小，因此老鼠无法获胜。\n同理可知，如果猫按照最优策略也只能回到一个已经到达过的节点，则猫无法获胜。\n因此当猫和老鼠分别回到一个已经到达过的节点时，猫和老鼠都无法获胜，游戏结果是平局。\n动态规划的状态转移需要考虑当前玩家所有可能的移动，选择最优策略的移动。\n由于老鼠先开始移动，猫后开始移动，因此可以根据游戏已经进行的轮数 turns 的奇偶性决定当前轮到的玩家，当 turns 是偶数时轮到老鼠移动，当 turns 是奇数时轮到猫移动。\n如果轮到老鼠移动，则对于老鼠从当前节点移动一次之后可能到达的每个节点，进行如下操作：\n如果存在一个节点，老鼠到达该节点之后，老鼠可以获胜，则老鼠到达该节点之后的状态为老鼠的必胜状态，猫的必败状态，因此在老鼠移动之前的当前状态为老鼠的必胜状态。 如果老鼠到达任何节点之后的状态都不是老鼠的必胜状态，但是存在一个节点，老鼠到达该节点之后，结果是平局，则老鼠到达该节点之后的状态为双方的必和状态，因此在老鼠移动之前的当前状态为双方的必和状态。 如果老鼠到达任何节点之后的状态都不是老鼠的必胜状态或必和状态，则老鼠到达任何节点之后的状态都为老鼠的必败状态，猫的必胜状态，因此在老鼠移动之前的当前状态为老鼠的必败状态。 如果轮到猫移动，则对于猫从当前节点移动一次之后可能到达的每个节点，进行如下操作：\n如果存在一个节点，猫到达该节点之后，猫可以获胜，则猫到达该节点之后的状态为猫的必胜状态，老鼠的必败状态，因此在猫移动之前的当前状态为猫的必胜状态。 如果猫到达任何节点之后的状态都不是猫的必胜状态，但是存在一个节点，猫到达该节点之后，结果是平局，则猫到达该节点之后的状态为双方的必和状态，因此在猫移动之前的当前状态为双方的必和状态。 如果猫到达任何节点之后的状态都不是猫的必胜状态或必和状态，则猫到达任何节点之后的状态都为猫的必败状态，老鼠的必胜状态，因此在猫移动之前的当前状态为猫的必败状态。 实现方面，由于双方移动的策略相似，因此可以使用一个函数实现移动策略，根据游戏已经进行的轮数的奇偶性决定当前轮到的玩家。对于特定玩家的移动，实现方法如下：\n如果当前玩家存在一种移动方法到达非必败状态，则用该状态更新游戏结果。 如果该移动方法到达必胜状态，则将当前状态（移动前的状态）设为必胜状态，结束遍历其他可能的移动。 如果该移动方法到达必和状态，则将当前状态（移动前的状态）设为必和状态，继续遍历其他可能的移动，因为可能存在到达必胜状态的移动方法。 如果当前玩家的任何移动方法都到达必败状态，则将当前状态（移动前的状态）设为必败状态。 特别地，如果当前玩家是猫，则不能移动到节点 0。\n代码\n1const int MOUSE_WIN = 1; 2const int CAT_WIN = 2; 3const int DRAW = 0; 4const int MAXN = 51; 5 6class Solution { 7public: 8 int n; 9 int dp[MAXN][MAXN][MAXN*2]; 10 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; graph; 11 12 int catMouseGame(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; graph) { 13 this-\u0026gt;n = graph.size(); 14 this-\u0026gt;graph = graph; 15 memset(dp, -1, sizeof(dp)); 16 return getResult(1, 2, 0); 17 } 18 19 int getResult(int mouse, int cat, int turns) { 20 if (turns == n * 2) { 21 return DRAW; 22 } 23 if (dp[mouse][cat][turns] \u0026lt; 0) { 24 if (mouse == 0) { 25 dp[mouse][cat][turns] = MOUSE_WIN; 26 } else if (cat == mouse) { 27 dp[mouse][cat][turns] = CAT_WIN; 28 } else { 29 getNextResult(mouse, cat, turns); 30 } 31 } 32 return dp[mouse][cat][turns]; 33 } 34 35 void getNextResult(int mouse, int cat, int turns) { 36 int curMove = turns % 2 == 0 ? mouse : cat; 37 int defaultResult = curMove == mouse ? CAT_WIN : MOUSE_WIN; 38 int result = defaultResult; 39 for (int next : graph[curMove]) { 40 if (curMove == cat \u0026amp;\u0026amp; next == 0) { 41 continue; 42 } 43 int nextMouse = curMove == mouse ? next : mouse; 44 int nextCat = curMove == cat ? next : cat; 45 int nextResult = getResult(nextMouse, nextCat, turns + 1); 46 if (nextResult != defaultResult) { 47 result = nextResult; 48 if (result != DRAW) { 49 break; 50 } 51 } 52 } 53 dp[mouse][cat][turns] = result; 54 } 55}; 1class Solution { 2 vector\u0026lt;vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026gt; dp; 3 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; g; 4 int n; 5public: 6 int dfs(int k, int x, int y){ 7 if(k == n * 2) return 0; 8 if(x == y) return dp[k][x][y] = 2; 9 if(x == 0) return dp[k][x][y] = 1; 10 if(dp[k][x][y] != -1) return dp[k][x][y]; 11 //轮到老鼠走 12 if(k % 2 == 0){ 13 bool flag = 1; //标记 14 for(int i = 0; i \u0026lt; g[x].size(); i ++){ //遍历当前老鼠可走的位置 15 int nx = g[x][i]; 16 int ne = dfs(k + 1, nx, y); 17 if(ne == 1){ 18 return dp[k][x][y] = 1; //如果可以走的通就返回1，老鼠赢 19 }else if(ne != 2){ //猫不赢 20 flag = 0; //标记有平局的情况 21 } 22 } 23 if(flag){ 24 return dp[k][x][y] = 2; //猫赢 25 }else{ 26 return dp[k][x][y] = 0; //平局 27 } 28 } 29 else{ //轮到猫走 30 bool flag = 1; 31 for(int i = 0; i \u0026lt; g[y].size(); i ++){ 32 int ny = g[y][i]; 33 if(ny == 0)continue; //如果当前位置为老鼠洞就不能走 34 int ne = dfs(k + 1, x, ny); 35 if(ne == 2){ 36 return dp[k][x][y] = 2; //猫赢 37 }else if(ne != 1){ 38 flag = 0; //标记有平局的情况 39 } 40 } 41 if(flag){ //没有平局情况 42 return dp[k][x][y] = 1; //鼠赢 43 }else{ 44 return dp[k][x][y] = 0; //平局 45 } 46 } 47 } 48 int catMouseGame(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; graph) { 49 n = graph.size(); 50 //状态定义，dp[k][i][j],走k步，老鼠在i位置，猫在j位置 51 //vector\u0026lt;vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026gt; dp(2 * n, vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(n, -1))); 52 dp = vector\u0026lt;vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026gt;(2 * n, vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(n, vector\u0026lt;int\u0026gt;(n, -1))); 53 g = graph; 54 return dfs(0, 1, 2); 55 } 56}; ","date":"2022-01-04","img":"","permalink":"/posts/e1f1048f/","series":["leetcode"],"tags":["困难","不会"],"title":"LeetCode-913-猫和老鼠"},{"categories":[["教程"],["Docker"]],"content":"Docker 是一个应用打包、分发、部署的工具 你也可以把它理解为一个轻量的虚拟机，它只虚拟你软件需要的运行环境，多余的一点都不要， 而普通虚拟机则是一个完整而庞大的系统，包含各种不管你要不要的软件。\nDocker的简介 与虚拟机对比 特性 普通虚拟机 Docker 跨平台 通常只能在桌面级系统运行，例如 Windows/Mac，无法在不带图形界面的服务器上运行 支持的系统非常多，各类 windows 和 Linux 都支持 性能 性能损耗大，内存占用高，因为是把整个完整系统都虚拟出来了 性能好，只虚拟软件所需运行环境，最大化减少没用的配置 自动化 需要手动安装所有东西 一个命令就可以自动部署好所需环境 稳定性 稳定性不高，不同系统差异大 稳定性好，不同系统都一样部署方式 打包、分发、部署 打包：就是把你软件运行所需的依赖、第三方库、软件打包到一起，变成一个安装包 分发：你可以把你打包好的“安装包”上传到一个镜像仓库，其他人可以非常方便的获取和安装 部署：拿着“安装包”就可以一个命令运行起来你的应用，自动模拟出一摸一样的运行环境，不管是在 Windows/Mac/Linux。 Docker 部署的优势 常规应用开发部署方式：自己在 Windows 上开发、测试 \u0026ndash;\u0026gt; 到 Linux 服务器配置运行环境部署。\n问题：我机器上跑都没问题，怎么到服务器就各种问题了\n用 Docker 开发部署流程：自己在 Windows 上开发、测试 \u0026ndash;\u0026gt; 打包为 Docker 镜像（可以理解为软件安装包） \u0026ndash;\u0026gt; 各种服务器上只需要一个命令部署好\n优点：确保了不同机器上跑都是一致的运行环境，不会出现我机器上跑正常，你机器跑就有问题的情况。\nDocker 通常用来做什么 应用分发、部署，方便传播给他人安装。特别是开源软件和提供私有部署的应用 快速安装测试/学习软件，用完就丢（类似小程序），不把时间浪费在安装软件上。例如 Redis / MongoDB / ElasticSearch / ELK 多个版本软件共存，不污染系统，例如 Python2、Python3，Redis4.0，Redis5.0 Windows 上体验/学习各种 Linux 系统 镜像、容器 镜像：可以理解为软件安装包，可以方便的进行传播和安装。 容器：软件安装后的状态，每个软件运行环境都是独立的、隔离的，称之为容器。\n安装 桌面版：https://www.docker.com/products/docker-desktop 服务器版：https://docs.docker.com/engine/install/#server\n根据自己系统选择对应的官网教程进行安装即可。\nWindows设置镜像加速源 镜像加速器 镜像加速器地址 Docker 中国官方镜像 https://registry.docker-cn.com DaoCloud 镜像站 http://f1361db2.m.daocloud.io Azure 中国镜像 https://dockerhub.azk8s.cn 科大镜像站 https://docker.mirrors.ustc.edu.cn 阿里云 https://\u0026lt;your_code\u0026gt;.mirror.aliyuncs.com 七牛云 https://reg-mirror.qiniu.com 网易云 https://hub-mirror.c.163.com 腾讯云 https://mirror.ccs.tencentyun.com 添加如下内容\n1\u0026#34;registry-mirrors\u0026#34;:[\u0026#34;https://registry.docker-cn.com\u0026#34;,\u0026#34;https://reg-mirror.qiniu.com\u0026#34;], 点击重启即可。\nDocker 快速安装软件 直接安装的缺点 安装麻烦，可能有各种依赖，运行报错。例如：WordPress，ElasticSearch，Redis，ELK 可能对 Windows 并不友好，运行有各种兼容问题，软件只支持 Linux 上跑 不方便安装多版本软件，不能共存。 电脑安装了一堆软件，拖慢电脑速度。 不同系统和硬件，安装方式不一样 Docker 安装的优点 一个命令就可以安装好，快速方便 有大量的镜像，可直接使用 没有系统兼容问题，Linux 专享软件也照样跑 支持软件多版本共存 用完就丢，不拖慢电脑速度 不同系统和硬件，只要安装好 Docker 其他都一样了，一个命令搞定所有 演示 Docker 安装 Redis Redis 官网：https://redis.io/\n官网下载安装教程只有源码安装方式，没有 Windows 版本。想要自己安装 windows 版本需要去找别人编译好的安装包。\n在Redis官网我们没有找到Windows的安装方式，那么我们想要在在Windows下安装只能自己编译，配置起来很麻烦。\n所以，我们选择用Docker进行安装。\n在Docker官方镜像仓库找到Redis https://hub.docker.com/\n一条命令运行Redis 在终端执行以下命令\n1docker run -d -p 6379:6379 --name redis redis:latest Docker命令参数可以查看官网文档docker run | Docker Documentation\n终端中显示如下信息表示成功安装\n1C:\\Users\\jimyag\u0026gt;docker run -d -p 6379:6379 --name redis redis:latest 2Unable to find image \u0026#39;redis:latest\u0026#39; locally 3latest: Pulling from library/redis 4a2abf6c4d29d: Pull complete 5c7a4e4382001: Pull complete 64044b9ba67c9: Pull complete 7c8388a79482f: Pull complete 8413c8bb60be2: Pull complete 91abfd3011519: Pull complete 10Digest: sha256:db485f2e245b5b3329fdc7eff4eb00f913e09d8feb9ca720788059fdc2ed8339 11Status: Downloaded newer image for redis:latest 123b5a6af571d0d5117c4c339925e5fc30ce513ee17a06eb9475a2d372888380f2 其中里面的hash值不同。\n我们可以在桌面版Docker中看到redis的运行情况\n我们也可以进行Redis的终端进行测试\n参考 Docker 1小时快速上手教程，无废话纯干货_哔哩哔哩_bilibili\n","date":"2022-01-03","img":"","permalink":"/posts/8b63f587/","series":null,"tags":["教程","Docker"],"title":"Docker基础入门"},{"categories":["LeetCode"],"content":"题目 给你一个日期，请你设计一个算法来判断它是对应一周中的哪一天。\n输入为三个整数：day、month 和 year，分别表示日、月、年。\n您返回的结果必须是这几个值中的一个 {\u0026ldquo;Sunday\u0026rdquo;, \u0026ldquo;Monday\u0026rdquo;, \u0026ldquo;Tuesday\u0026rdquo;, \u0026ldquo;Wednesday\u0026rdquo;, \u0026ldquo;Thursday\u0026rdquo;, \u0026ldquo;Friday\u0026rdquo;, \u0026ldquo;Saturday\u0026rdquo;}。\n示例 示例 1 1输入：day = 31, month = 8, year = 2019 2输出：\u0026#34;Saturday\u0026#34; 示例 2 1输入：day = 18, month = 7, year = 1999 2输出：\u0026#34;Sunday\u0026#34; 示例 3 1输入：day = 15, month = 8, year = 1993 2输出：\u0026#34;Sunday\u0026#34; 解答 题目规定输入的日期一定是在 19711971 到 21002100 年之间的有效日期，即在 19711971 年 11 月 11 日，到 21002100 年 1212 月 3131 日之间。通过查询日历可知，19701970 年 1212 月 3131 日是星期四，我们只需要算出输入的日期距离 19701970 年 1212 月 3131 日有几天，再加上 33 后对 77 求余，即可得到输入日期是一周中的第几天。\n求输入的日期距离 19701970 年 1212 月 3131 日的天数，可以分为三部分分别计算后求和：\n输入年份之前的年份的天数贡献；\n输入年份中，输入月份之前的月份的天数贡献；\n输入月份中的天数贡献。\n例如，如果输入是 21002100 年 1212 月 3131 日，即可分为三部分分别计算后求和：\n19711971 年 11 月 11 到 20992099 年 1212 月 3131 日之间所有的天数； 21002100 年 11 月 11 日到 21002100 年 1111 月 3131 日之间所有的天数； 21002100 年 1212 月 11 日到 21002100 年 1212 月 3131 日之间所有的天数。 其中（1）和（2）部分的计算需要考虑到闰年的影响。当年份是 400400 的倍数或者是 44 的倍数且不是 100100 的倍数时，该年会在二月份多出一天。\n代码 1string dayOfTheWeek(int day, int month, int year) { 2 vector\u0026lt;string\u0026gt; week = {\u0026#34;Monday\u0026#34;, \u0026#34;Tuesday\u0026#34;, \u0026#34;Wednesday\u0026#34;, \u0026#34;Thursday\u0026#34;, \u0026#34;Friday\u0026#34;, \u0026#34;Saturday\u0026#34;, \u0026#34;Sunday\u0026#34;}; 3 vector\u0026lt;int\u0026gt; monthDays = {31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30}; 4 /* 输入年份之前的年份的天数贡献 */ 5 int days = 365 * (year - 1971) + (year - 1969) / 4; 6 /* 输入年份中，输入月份之前的月份的天数贡献 */ 7 for (int i = 0; i \u0026lt; month - 1; ++i) { 8 days += monthDays[i]; 9 } 10 if ((year % 400 == 0 || (year % 4 == 0 \u0026amp;\u0026amp; year % 100 != 0)) \u0026amp;\u0026amp; month \u0026gt;= 3) { 11 days += 1; 12 } 13 /* 输入月份中的天数贡献 */ 14 days += day; 15 return week[(days + 3) % 7]; 16 } 1string dayOfTheWeek(int day, int month, int year) { 2 string res[] = {\u0026#34;Monday\u0026#34;, \u0026#34;Tuesday\u0026#34;, \u0026#34;Wednesday\u0026#34;, \u0026#34;Thursday\u0026#34;, \u0026#34;Friday\u0026#34;, \u0026#34;Saturday\u0026#34;, \u0026#34;Sunday\u0026#34;}; 3 if (month == 1 || month == 2) { 4 month = month + 12; 5 year--; 6 } 7 int index = 0; 8 //基姆拉尔森计算公式 9 index = (day + 2 * month + 3 * (month + 1) / 5 + year + year / 4 - year / 100 + year / 400) % 7; 10 return res[index]; 11} ","date":"2022-01-03","img":"","permalink":"/posts/95bcecc9/","series":["leetcode"],"tags":["模拟","简单"],"title":"LeetCode-1185-一周中的第几天"},{"categories":["LeetCode"],"content":"第一次参加LeetCode的周赛，记录一下自己AC的三道简单题。\n5967. 检查是否所有 A 都在 B 之前 题目 给你一个 仅 由字符 \u0026lsquo;a\u0026rsquo; 和 \u0026lsquo;b\u0026rsquo; 组成的字符串 s 。如果字符串中 每个 \u0026lsquo;a\u0026rsquo; 都出现在 每个 \u0026lsquo;b\u0026rsquo; 之前，返回 true ；否则，返回 false 。\n示例 示例1 1输入：s = \u0026#34;aaabbb\u0026#34; 2输出：true 3解释： 4\u0026#39;a\u0026#39; 位于下标 0、1 和 2 ；而 \u0026#39;b\u0026#39; 位于下标 3、4 和 5 。 5因此，每个 \u0026#39;a\u0026#39; 都出现在每个 \u0026#39;b\u0026#39; 之前，所以返回 true 。 示例2 1输入：s = \u0026#34;abab\u0026#34; 2输出：false 3解释： 4存在一个 \u0026#39;a\u0026#39; 位于下标 2 ，而一个 \u0026#39;b\u0026#39; 位于下标 1 。 5因此，不能满足每个 \u0026#39;a\u0026#39; 都出现在每个 \u0026#39;b\u0026#39; 之前，所以返回 false 。 示例3 1输入：s = \u0026#34;bbb\u0026#34; 2输出：true 3解释： 4不存在 \u0026#39;a\u0026#39; ，因此可以视作每个 \u0026#39;a\u0026#39; 都出现在每个 \u0026#39;b\u0026#39; 之前，所以返回 true 。 解答 找到第一个出现的b，如果出现的a的下标比b大，返回false即可。\n代码 1bool checkString(string s) { 2 int index_b = -1; 3 for (int i = 0; i \u0026lt; s.size(); i++) { 4 // 找到第一个出现的b 5 if (index_b == -1 \u0026amp;\u0026amp; s[i] == \u0026#39;b\u0026#39;) { 6 index_b = i; 7 } 8 // 如果出现的a的下标比b大 返回false 9 if (s[i] == \u0026#39;a\u0026#39; \u0026amp;\u0026amp; index_b != -1 \u0026amp;\u0026amp; index_b \u0026lt; i) { 10 return false; 11 } 12 } 13 return true; 14 } 5968. 银行中的激光束数量 题目 银行内部的防盗安全装置已经激活。给你一个下标从 0 开始的二进制字符串数组 bank ，表示银行的平面图，这是一个大小为 m x n 的二维矩阵。 bank[i] 表示第 i 行的设备分布，由若干 \u0026lsquo;0\u0026rsquo; 和若干 \u0026lsquo;1\u0026rsquo; 组成。\u0026lsquo;0\u0026rsquo; 表示单元格是空的，而 \u0026lsquo;1\u0026rsquo; 表示单元格有一个安全设备。\n对任意两个安全设备而言，如果同时 满足下面两个条件，则二者之间存在 一个 激光束：\n两个设备位于两个 不同行 ：r1 和 r2 ，其中 r1 \u0026lt; r2 。 满足 r1 \u0026lt; i \u0026lt; r2 的 所有 行 i ，都 没有安全设备 。 激光束是独立的，也就是说，一个激光束既不会干扰另一个激光束，也不会与另一个激光束合并成一束。\n返回银行中激光束的总数量。\n示例 示例1 1输入：bank = [\u0026#34;011001\u0026#34;,\u0026#34;000000\u0026#34;,\u0026#34;010100\u0026#34;,\u0026#34;001000\u0026#34;] 2输出：8 3解释：在下面每组设备对之间，存在一条激光束。总共是 8 条激光束： 4 * bank[0][1] -- bank[2][1] 5 * bank[0][1] -- bank[2][3] 6 * bank[0][2] -- bank[2][1] 7 * bank[0][2] -- bank[2][3] 8 * bank[0][5] -- bank[2][1] 9 * bank[0][5] -- bank[2][3] 10 * bank[2][1] -- bank[3][2] 11 * bank[2][3] -- bank[3][2] 12注意，第 0 行和第 3 行上的设备之间不存在激光束。 13这是因为第 2 行存在安全设备，这不满足第 2 个条件。 示例2 1输入：bank = [\u0026#34;000\u0026#34;,\u0026#34;111\u0026#34;,\u0026#34;000\u0026#34;] 2输出：0 3解释：不存在两个位于不同行的设备 解答 统计每一行的设备的个数，根据相隔两行的设备个数求出总共的激光束。\n如果出现类似示例1的情况，要进行特殊处理。前一行的设备不为0，这一行的为0，那么这样行的设备书就是上一行的设备数。\n代码 1int numberOfBeams(vector\u0026lt;string\u0026gt;\u0026amp; bank) { 2 vector\u0026lt;int\u0026gt; counts; 3 for (const string\u0026amp; s: bank) { 4 int c = 0; 5 for (char i: s) { 6 if (i == \u0026#39;1\u0026#39;) { 7 c += 1; 8 } 9 } 10 counts.emplace_back(c); 11 } 12 int ans = 0; 13 for (int i = 0; i \u0026lt; counts.size() - 1; i++) { 14 // 示例1的情况特殊处理 15 if(i\u0026gt;0\u0026amp;\u0026amp;counts[i]==0\u0026amp;\u0026amp;counts[i-1]!=0){ 16 counts[i] = counts[i-1]; 17 } 18 ans += counts[i] * counts[i + 1]; 19 } 20 return ans; 21 } 5969. 摧毁小行星 题目 给你一个整数 mass ，它表示一颗行星的初始质量。再给你一个整数数组 asteroids ，其中 asteroids[i] 是第 i 颗小行星的质量。\n你可以按 任意顺序 重新安排小行星的顺序，然后让行星跟它们发生碰撞。如果行星碰撞时的质量 大于等于 小行星的质量，那么小行星被 摧毁 ，并且行星会 获得 这颗小行星的质量。否则，行星将被摧毁。\n如果所有小行星 都 能被摧毁，请返回 true ，否则返回 false 。\n示例 示例 1 1输入：mass = 10, asteroids = [3,9,19,5,21] 2输出：true 3解释：一种安排小行星的方式为 [9,19,5,3,21] ： 4 5- 行星与质量为 9 的小行星碰撞。新的行星质量为：10 + 9 = 19 6- 行星与质量为 19 的小行星碰撞。新的行星质量为：19 + 19 = 38 7- 行星与质量为 5 的小行星碰撞。新的行星质量为：38 + 5 = 43 8- 行星与质量为 3 的小行星碰撞。新的行星质量为：43 + 3 = 46 9- 行星与质量为 21 的小行星碰撞。新的行星质量为：46 + 21 = 67 10 所有小行星都被摧毁。 示例2 1输入：mass = 5, asteroids = [4,9,23,4] 2输出：false 3解释： 4行星无论如何没法获得足够质量去摧毁质量为 23 的小行星。 5行星把别的小行星摧毁后，质量为 5 + 4 + 9 + 4 = 22 。 6它比 23 小，所以无法摧毁最后一颗小行星。 解答 题目中说了可以自由安排小行星的顺序，我们对小行星重新排序即可。\n注意是否越界。\n代码 1bool asteroidsDestroyed(int mass, vector\u0026lt;int\u0026gt;\u0026amp; asteroids) { 2 sort(asteroids.begin(), asteroids.end()); 3 long long res = mass; 4 for(int i:asteroids){ 5 if(res\u0026gt;=i){ 6 res+=i; 7 }else{ 8 return false; 9 } 10 } 11 return true; 12 } 总结 第一次参加周赛还行，前三题都有思路，因为做题开始的时间比较晚，三十分钟做了三道题还行。第三题提交的时候已经十二点了，超过时间了，没有提交上去。\n下周继续吧！\n","date":"2022-01-02","img":"","permalink":"/posts/43ef6653/","series":["leetcode"],"tags":["中等","简单","周赛"],"title":"LeetCode-第274场周赛"},{"categories":["LeetCode"],"content":"题目 给定一个从1 到 n 排序的整数列表。 首先，从左到右，从第一个数字开始，每隔一个数字进行删除，直到列表的末尾。 第二步，在剩下的数字中，从右到左，从倒数第一个数字开始，每隔一个数字进行删除，直到列表开头。 我们不断重复这两步，从左到右和从右到左交替进行，直到只剩下一个数字。 返回长度为 n 的列表中，最后剩下的数字。\n示例 1输入: 2n = 9, 31 2 3 4 5 6 7 8 9 42 4 6 8 52 6 66 7 8输出: 96 解答 暴力模拟超时，看了一下别人的思路。\n通过观察用例，我们可以得到以下规律：\n经历的回合数应该是 $$\\lfloor \\log_2n \\rfloor + 1$$ arr数组永远是一个等差数列 arr数组的数目，每次减少一半（向下取整） 公差每次翻倍 我们知道一个等差数列可以由a0（首项）, d（公差）, n（数列元素个数）三个参数来定义。\n综合以上规律，我们知道每次删除后，以上三个参数每次应该这样变化\nd → 2d n → n/2 a0→a0 或者a0→a0+d 大体上来说这道题目就是这样，其它细节可以看代码。\n如何决定a0的变化？当删除数字时，存在以下四种情况：\n从左向右删除，总共有奇数个数字（第一位要删掉，最后一位要删掉） 从左向右删除，总共有偶数个数字（第一位要删掉，最后一位不用删掉） 从右向左删除，总共有奇数个数字（第一位要删掉，最后一位要删掉） 从右向左删除，总共有偶数个数字（第一位不用删掉，最后一位要删掉） 只有情况4才会出现a0→a0，其余都是a0→a0+d\n代码 1int lastRemaining(int n) { 2 int num_amount = n; 3 int loop_cnt = 0; 4 int a0 = 1, d = 1; 5 while (num_amount != 1) { 6 // 奇数个数字 7 if (num_amount % 2 == 1) { 8 a0 = a0 + d; 9 } 10 // 偶数个数字 11 else if (num_amount % 2 == 0) { 12 bool left_to_right = (loop_cnt % 2 == 0); 13 if (left_to_right) { 14 a0 = a0 + d; 15 } else 16 a0 = a0; 17 } 18 loop_cnt++; 19 d *= 2; 20 num_amount /= 2; 21 } 22 return a0; 23} 参考文章 C++ 数学+找规律 - 消除游戏 - 力扣（LeetCode） (leetcode-cn.com)\n","date":"2022-01-02","img":"","permalink":"/posts/297384ed/","series":["leetcode"],"tags":["数学","中等"],"title":"LeetCode-390-消除游戏"},{"categories":["教程"],"content":"搜索引擎能搜索到网站的前提是它抓取了网站的内容，并对其建立了索引，其实也就是爬虫爬取 + 插入数据库。虽然大部分搜索引擎都是自动抓取网络上的所有链接，并尝试爬取以及入库，但通常会比较缓慢。所以更加推荐由我们站长主动出击，直接告诉它我们的网站地址。\n为了让更多人能阅读到网站内容，本文介绍如何配置Hexo被Google、bing、Baidu收录。\n上图就是搜索引擎的爬虫服务爬取我的网站。\n配置Hexo 安装插件 1npm install hexo-generator-sitemap --save 添加设置 在根目录_config.yml中添加如下内容\n1sitemap: 2 path: sitemap.xml 3 # template: ./sitemap_template.xml 4 rel: true 5 tags: false 6 categories: false 生成站点地图 执行以下命令\n1hexo g -d 在浏览器中输入自己域名/sitemap.xml可以看到插件替我们生成的站点地图。\n配置网站收录 Google Google 官网给了详细的文档，可以看这篇 新手入门指南\n而对我们来说，主要分三个步骤：注册 Search Console，验证网站所有权，提交站点地图\n注册 Search Console 注册的过程非常简单，进入 GSC 官网，用谷歌账号登录即可\n验证网站所有权 登录之后，就需要添加我们的网站了\n这里共有5种方法，我使用域名提供商验证的方式进行\n我们将Google提供给我们的解析值添加到DNS的解析中，这里以腾讯云为例，\n添加一条@记录，记录类型为txt，记录值为刚刚生成的记录值，保存即可。\n检验Google是否收录 我们进入GSC 官网，在添加网站处输入自己的域名看到一下内容，代表Google已经收录我们的网站。\nBing 进入Bing Webmaster Tools - Bing Webmaster Tools主页，选择使用GSC导入网站\n登陆自己的注册GSC的Google账户即可，同意授权即可完成。\n提交站点地图 按照如图操作添加自己域名即可\nBaidu 登陆 用百度账号登录百度搜索资源平台，找到普通收录\n选择sitemap\n填写你的域名域名/sitemap.xml提交信息。\n验证 提交以后，Baidu会生成一条CNAME的记录（这里我忘记保存截图了），让你将你的某个二级域名CNAME到Baidu的资源。\n参考资料 Hexo 配置主流搜索引擎收录流程记录 | 乐园 (ywang-wnlo.github.io)\n","date":"2022-01-02","img":"","permalink":"/posts/e058fe03/","series":null,"tags":["Hexo"],"title":"Hexo配置主流搜索引擎收录"},{"categories":["LeetCode"],"content":"题目 给你一个下标从 0 开始的一维整数数组 original 和两个整数 m 和 n 。你需要使用 original 中 所有 元素创建一个 m 行 n 列的二维数组。\noriginal 中下标从 0 到 n - 1 （都 包含 ）的元素构成二维数组的第一行，下标从 n 到 2 * n - 1 （都 包含 ）的元素构成二维数组的第二行，依此类推。\n请你根据上述过程返回一个 m x n 的二维数组。如果无法构成这样的二维数组，请你返回一个空的二维数组。\n示例 示例1 1输入：original = [1,2,3,4], m = 2, n = 2 2输出：[[1,2],[3,4]] 3解释： 4构造出的二维数组应该包含 2 行 2 列。 5original 中第一个 n=2 的部分为 [1,2] ，构成二维数组的第一行。 6original 中第二个 n=2 的部分为 [3,4] ，构成二维数组的第二行。 示例2 1输入：original = [1,2,3], m = 1, n = 3 2输出：[[1,2,3]] 3解释： 4构造出的二维数组应该包含 1 行 3 列。 5将 original 中所有三个元素放入第一行中，构成要求的二维数组。 示例3 1输入：original = [1,2], m = 1, n = 1 2输出：[] 3解释： 4original 中有 2 个元素。 5无法将 2 个元素放入到一个 1x1 的二维数组中，所以返回一个空的二维数组。 示例4 1输入：original = [3], m = 1, n = 2 2输出：[] 3解释： 4original 中只有 1 个元素。 5无法将 1 个元素放满一个 1x2 的二维数组，所以返回一个空的二维数组。 解答 根据题意进行模拟即可\n代码 1vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; construct2DArray(vector\u0026lt;int\u0026gt; \u0026amp;original, int m, int n) { 2 if (original.size() != m * n) { 3 return vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;{}; 4 } 5 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ans; 6 for (int i = 0; i \u0026lt; m; i++) { 7 vector\u0026lt;int\u0026gt; temp; 8 for (int j = 0; j \u0026lt; n; j++) { 9 temp.emplace_back(original[i * n + j]); 10 } 11 ans.emplace_back(temp); 12 } 13 return ans; 14 } ","date":"2022-01-01","img":"","permalink":"/posts/9806fff7/","series":["leetcode"],"tags":["简单","模拟"],"title":"LeetCode-2022-将一维数组转变成二维数组"},{"categories":["LeetCode"],"content":"题目 对于一个 正整数，如果它和除了它自身以外的所有 正因子 之和相等，我们称它为 「完美数」。\n给定一个 整数 n， 如果是完美数，返回 true，否则返回 false\n示例 1输入：num = 28 2输出：true 3解释：28 = 1 + 2 + 4 + 7 + 14 41, 2, 4, 7, 和 14 是 28 的所有正因子。 1输入：num = 6 2输出：true 1输入：num = 496 2输出：true 1输入：num = 8128 2输出：true 1输入：num = 2 2输出：false 解答 枚举因子\n代码 1bool checkPerfectNumber(int num) { 2 set\u0026lt;int\u0026gt; s; 3 int ans = 0; 4 for (int i = 1; i \u0026lt; num / 2; i++) { 5 if (num % i == 0) { 6 s.insert(i); 7 s.insert(num / i); 8 } 9 } 10 for (const auto \u0026amp;item: s) { 11 cout \u0026lt;\u0026lt; item \u0026lt;\u0026lt; endl; 12 ans += item; 13 } 14 ans = ans - num; 15 return ans == num; 16} 1bool checkPerfectNumber(int num) { 2 if (num == 1) return false; 3 int ans = 1; 4 for (int i = 2; i \u0026lt;= num / i; i++) { 5 if (num % i == 0) ans += i + num / i; 6 } 7 return ans == num; 8 } ","date":"2021-12-31","img":"","permalink":"/posts/9c98d12/","series":["leetcode"],"tags":["简单","数学"],"title":"LeetCode-507-完美数"},{"categories":["LeetCode"],"content":"题目 Alice 手中有一把牌，她想要重新排列这些牌，分成若干组，使每一组的牌数都是 groupSize ，并且由 groupSize 张连续的牌组成。\n给你一个整数数组 hand 其中 hand[i] 是写在第 i 张牌，和一个整数 groupSize 。如果她可能重新排列这些牌，返回 true ；否则，返回 false 。\n示例 1输入：hand = [1,2,3,6,2,3,4,7,8], groupSize = 3 2输出：true 3解释：Alice 手中的牌可以被重新排列为 [1,2,3]，[2,3,4]，[6,7,8]。 1输入：hand = [1,2,3,4,5], groupSize = 4 2输出：false 3解释：Alice 手中的牌无法被重新排列成几个大小为 4 的组。 解答 题目的意思是给出一组牌，判断能否组成n个连子。统计牌的个数之后，每次取最小的一个牌组成连子，如果最小的牌的张数没了，那么久继续挑选下一个小的牌，最小的牌存在。\n代码 1bool isNStraightHand(vector\u0026lt;int\u0026gt; \u0026amp;hand, int groupSize) { 2 // 不能整除直接返回 3 if (hand.size() % groupSize != 0) { 4 return false; 5 } 6 // 统计每张牌的个数 7 map\u0026lt;int, int\u0026gt; nums; 8 // 最小的牌 9 priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;\u0026gt;\u0026gt; p_q; 10 for (int temp: hand) { 11 p_q.push(temp); 12 nums[temp]++; 13 } 14 for (int i = 0; i \u0026lt; (hand.size() / groupSize); i++) { 15 int pre; 16 // 找一组牌是否连续 17 for (int j = 0; j \u0026lt; groupSize; j++) { 18 // 找到第一个小的牌 19 if (j == 0) { 20 do { 21 pre = p_q.top(); 22 p_q.pop(); 23 // 如果这个牌已经被用完了，就把重新选一张牌当做最小的牌 24 } while (nums.find(pre) == nums.end() || nums[pre] \u0026lt; 1); 25 // 找到最小牌之后就把这个牌数减小 26 nums[pre]--; 27 continue; 28 } 29 int current = pre+1; 30 if (nums.find(current) == nums.end() || nums[current] \u0026lt; 1) { 31 return false; 32 } 33 nums[current]--; 34 pre =current; 35 } 36 } 37 return true; 38} ","date":"2021-12-30","img":"","permalink":"/posts/111b38ee/","series":["leetcode"],"tags":["中等","优先队列","模拟"],"title":"LeetCode-846-一手顺子"},{"categories":["LeetCode"],"content":"题目 给你一个 下标从 0 开始 的整数数组 nums ，返回满足下述条件的 不同 四元组 (a, b, c, d) 的 数目 ：\nnums[a] + nums[b] + nums[c] == nums[d] ，且 a \u0026lt; b \u0026lt; c \u0026lt; d\n示例 1输入：nums = [1,2,3,6] 2输出：1 3解释：满足要求的唯一一个四元组是 (0, 1, 2, 3) 因为 1 + 2 + 3 == 6 。 1输入：nums = [3,3,6,4,5] 2输出：0 3解释：[3,3,6,4,5] 中不存在满足要求的四元组。 1输入：nums = [1,1,1,3,5] 2输出：4 3解释：满足要求的 4 个四元组如下： 4- (0, 1, 2, 3): 1 + 1 + 1 == 3 5- (0, 1, 3, 4): 1 + 1 + 3 == 5 6- (0, 2, 3, 4): 1 + 1 + 3 == 5 7- (1, 2, 3, 4): 1 + 1 + 3 == 5 解答 思路1 暴力枚举，结果通过了？？\n思路2 来自三叶姐姐的解题思路,利用等式关系 nums[a] + nums[b] + nums[c] = nums[d]nums[a]+nums[b]+nums[c]=nums[d]，具有明确的「数值」和「个数」关系，可将问题抽象为组合优化问题求方案数。\n限制组合个数的维度有两个，均为「恰好」限制，转换为「二维费用背包问题求方案数」问题。\n定义 f[i][j][k]为考虑前 i 个物品（下标从 1 开始），凑成数值恰好 j，使用个数恰好为 k 的方案数。\n最终答案为 $$\\sum_{i = 3}^{n - 1}(f[i][nums[i]][3])$$起始状态 f[0][0][0]=1 代表不考虑任何物品时，所用个数为 0，凑成数值为 0 的方案数为 1。\n不失一般性考虑 $$f[i][j][k]$$ 该如何转移，根据 $$nums[i - 1]$$ 是否参与组合进行分情况讨论：\nnums[i - 1] 不参与组成，此时有：$$f[i - 1][j][k]$$ nums[i - 1] 参与组成，此时有：$$f[i - 1][j - t][k - 1]$$ 最终 $$f[i][j][k]$$为上述两种情况之和，最终统计 $$\\sum_{i = 3}^{n - 1}(f[i][nums[i]][3])$$即是答案。\n代码 1int countQuadruplets(vector\u0026lt;int\u0026gt; \u0026amp;nums) { 2 int ans = 0; 3 for (int i = 0; i \u0026lt; nums.size() - 3; i++) { 4 for (int j = i + 1; j \u0026lt; nums.size() - 2; j++) { 5 for (int k = j + 1; k \u0026lt; nums.size() - 1; k++) { 6 for (int m = k + 1; m \u0026lt; nums.size(); m++) { 7 if (nums[i] + nums[j] + nums[k] == nums[m]) { 8 ans += 1; 9 } 10 } 11 } 12 } 13 } 14 return ans; 15} 1int dp[55][105][4] = {0};// dp[i][j][k] 表示 前 i 个元素 中选择 k 个元素 构成大小 j 的方案数 2 int countQuadruplets(vector\u0026lt;int\u0026gt;\u0026amp; nums) { 3 int n = nums.size(); 4 int res = 0; 5 dp[0][0][0] = 1; 6 for(int i = 1;i \u0026lt;= n;i ++) { 7 int v = nums[i - 1]; 8 dp[i][0][0] = 1; 9 for(int j = 1;j \u0026lt; 105;j ++) { 10 for(int k = 1;k \u0026lt; 4;k ++) { 11 dp[i][j][k] += dp[i - 1][j][k]; 12 if(j - v \u0026gt;= 0 \u0026amp;\u0026amp; k - 1 \u0026gt;= 0) dp[i][j][k] += dp[i - 1][j - v][k - 1]; 13 } 14 } 15 } 16 for(int i = 3;i \u0026lt; n;i ++) { 17 res += dp[i][nums[i]][3]; 18 } 19 return res; 20 } ","date":"2021-12-29","img":"","permalink":"/posts/ace15a6d/","series":["leetcode"],"tags":["简单","暴力","动态规划"],"title":"LeetCode-1995-统计特殊四元组"},{"categories":["LeetCode"],"content":"题目 给你一个 不含重复 单词的字符串数组 words ，请你找出并返回 words 中的所有 连接词 。\n连接词 定义为：一个完全由给定数组中的至少两个较短单词组成的字符串。\n示例 1输入：words = [\u0026#34;cat\u0026#34;,\u0026#34;cats\u0026#34;,\u0026#34;catsdogcats\u0026#34;,\u0026#34;dog\u0026#34;,\u0026#34;dogcatsdog\u0026#34;,\u0026#34;hippopotamuses\u0026#34;,\u0026#34;rat\u0026#34;,\u0026#34;ratcatdogcat\u0026#34;] 2输出：[\u0026#34;catsdogcats\u0026#34;,\u0026#34;dogcatsdog\u0026#34;,\u0026#34;ratcatdogcat\u0026#34;] 3解释：\u0026#34;catsdogcats\u0026#34; 由 \u0026#34;cats\u0026#34;, \u0026#34;dog\u0026#34; 和 \u0026#34;cats\u0026#34; 组成; 4 \u0026#34;dogcatsdog\u0026#34; 由 \u0026#34;dog\u0026#34;, \u0026#34;cats\u0026#34; 和 \u0026#34;dog\u0026#34; 组成; 5 \u0026#34;ratcatdogcat\u0026#34; 由 \u0026#34;rat\u0026#34;, \u0026#34;cat\u0026#34;, \u0026#34;dog\u0026#34; 和 \u0026#34;cat\u0026#34; 组成。 1输入：words = [\u0026#34;cat\u0026#34;,\u0026#34;dog\u0026#34;,\u0026#34;catdog\u0026#34;] 2输出：[\u0026#34;catdog\u0026#34;] 解答 代码","date":"2021-12-28","img":"","permalink":"/posts/a9eb621/","series":["leetcode"],"tags":["困难"],"title":"LeetCode-472-连接词"},{"categories":["LeetCode"],"content":"题目 在社交媒体网站上有 n 个用户。给你一个整数数组 ages ，其中 ages[i] 是第 i 个用户的年龄。\n如果下述任意一个条件为真，那么用户 x 将不会向用户 y（x != y）发送好友请求：\nage[y] \u0026lt;= 0.5 * age[x] + 7 age[y] \u0026gt; age[x] age[y] \u0026gt; 100 \u0026amp;\u0026amp; age[x] \u0026lt; 100 否则，x 将会向 y 发送一条好友请求。\n注意，如果 x 向 y 发送一条好友请求，y 不必也向 x 发送一条好友请求。另外，用户不会向自己发送好友请求。\n返回在该社交媒体网站上产生的好友请求总数。\n示例 1输入：ages = [16,16] 2输出：2 3解释：2 人互发好友请求。 1输入：ages = [16,17,18] 2输出：2 3解释：产生的好友请求为 17 -\u0026gt; 16 ，18 -\u0026gt; 17 。 1输入：ages = [20,30,100,110,120] 2输出：3 3解释：产生的好友请求为 110 -\u0026gt; 100 ，120 -\u0026gt; 110 ，120 -\u0026gt; 100 。 解答 要想x给y发送一条好友请求，那么就要满足：\nage[y]\u0026gt; 0.5 * age[x] + 7 age[y] \u0026lt;= age[x] age[y] \u0026lt;= 100 || age[x] \u0026gt;= 100 在条件2和3中，条件2包含了条件3。x给y发送一条好友请求、可以化简为。\n0.5 * age[x] + 7 \u0026lt;age[y]\u0026lt;=age[x]\n在这种条件下x可以给y发消息，那么对于每一个y只要找到给他发消息的x就行。\n代码 1int numFriendRequests(vector\u0026lt;int\u0026gt; \u0026amp;ages) { 2 sort(ages.begin(), ages.end()); 3 int ans = 0; 4 int left_x = 0; 5 int right_x = 0; 6 7 for (int y_index = 0; y_index \u0026lt; ages.size(); y_index++) { 8 // 对于每一个y找到比他年龄小的的满足范围的人 9 // 从0开始找到最后一个不满的要求的人 10 while (left_x \u0026lt; y_index \u0026amp;\u0026amp; !isSend(ages[left_x], ages[y_index])) left_x++; 11 // 右边的比y要大 12 if (right_x \u0026lt; y_index) right_x = y_index; 13 // 找到满足要求的最后一个人 14 while (right_x \u0026lt; ages.size() \u0026amp;\u0026amp; isSend(ages[right_x], ages[y_index])) right_x++; 15 // 减去自己 16 if (right_x \u0026gt; left_x) { 17 ans += right_x - left_x - 1; 18 } 19 } 20 return ans; 21 22} 23 24bool isSend(int x_age, int y_age) { 25 if (0.5 * x_age + 7 \u0026gt;= y_age)return false; 26 if (x_age \u0026lt; y_age) return false; 27 if (x_age \u0026lt; 100 \u0026amp;\u0026amp; y_age \u0026gt; 100) return false; 28 return true; 29} ","date":"2021-12-27","img":"","permalink":"/posts/69e04ce/","series":["leetcode"],"tags":["中等"],"title":"LeetCode-825-适龄的朋友"},{"categories":["LeetCode"],"content":"题目 给出第一个词 first 和第二个词 second，考虑在某些文本 text 中可能以 \u0026ldquo;first second third\u0026rdquo; 形式出现的情况，其中 second 紧随 first 出现，third 紧随 second 出现。\n对于每种这样的情况，将第三个词 \u0026ldquo;third\u0026rdquo; 添加到答案中，并返回答案。\n示例 1 2输入：text = \u0026#34;alice is a good girl she is a good student\u0026#34;, first = \u0026#34;a\u0026#34;, second = \u0026#34;good\u0026#34; 3输出：[\u0026#34;girl\u0026#34;,\u0026#34;student\u0026#34;] 1输入：text = \u0026#34;we will we will rock you\u0026#34;, first = \u0026#34;we\u0026#34;, second = \u0026#34;will\u0026#34; 2输出：[\u0026#34;we\u0026#34;,\u0026#34;rock\u0026#34;] 解答 根据题意进行模拟\n代码 1vector\u0026lt;string\u0026gt; findOcurrences(string text, string first, string second) { 2 vector\u0026lt;string\u0026gt; words; 3 int s = 0, e = 0, len = text.length(); 4 while (true) { 5 while (s \u0026lt; len \u0026amp;\u0026amp; text[s] == \u0026#39; \u0026#39;) { 6 s++; 7 } 8 if (s \u0026gt;= len) { 9 break; 10 } 11 e = s + 1; 12 while (e \u0026lt; len \u0026amp;\u0026amp; text[e] != \u0026#39; \u0026#39;) { 13 e++; 14 } 15 words.push_back(text.substr(s, e - s)); 16 s = e + 1; 17 } 18 vector\u0026lt;string\u0026gt; ret; 19 for (int i = 2; i \u0026lt; words.size(); i++) { 20 if (words[i - 2] == first \u0026amp;\u0026amp; words[i - 1] == second) { 21 ret.push_back(words[i]); 22 } 23 } 24 return ret; 25 } 1 vector\u0026lt;string\u0026gt; findOcurrences(string text, string first, string second) { 2 stringstream ss(text); 3 string str; 4 vector\u0026lt;string\u0026gt; strs; 5 while (ss \u0026gt;\u0026gt; str) { 6 strs.push_back(str); 7 } 8 9 vector\u0026lt;string\u0026gt; ans; 10 for (int i = 0; i + 2 \u0026lt; strs.size(); i ++) { 11 if (strs[i] == first \u0026amp;\u0026amp; strs[i + 1] == second) { 12 ans.push_back(strs[i + 2]); 13 } 14 } 15 return ans; 16 } ","date":"2021-12-26","img":"","permalink":"/posts/e0d1a0/","series":["leetcode"],"tags":["简单"],"title":"LeetCode-1078-Bigram-分词"},{"categories":["LeetCode"],"content":"题目 如果一棵二叉树满足下述几个条件，则可以称为 奇偶树 ：\n二叉树根节点所在层下标为 0 ，根的子节点所在层下标为 1 ，根的孙节点所在层下标为 2 ，依此类推。 偶数下标 层上的所有节点的值都是 奇 整数，从左到右按顺序 严格递增 奇数下标 层上的所有节点的值都是 偶 整数，从左到右按顺序 严格递减 给你二叉树的根节点，如果二叉树为 奇偶树 ，则返回 true ，否则返回 false 。\n示例 1输入：root = [1,10,4,3,null,7,9,12,8,6,null,null,2] 2输出：true 3解释：每一层的节点值分别是： 40 层：[1] 51 层：[10,4] 62 层：[3,7,9] 73 层：[12,8,6,2] 8由于 0 层和 2 层上的节点值都是奇数且严格递增，而 1 层和 3 层上的节点值都是偶数且严格递减，因此这是一棵奇偶树。 1输入：root = [5,4,2,3,3,7] 2输出：false 3解释：每一层的节点值分别是： 40 层：[5] 51 层：[4,2] 62 层：[3,3,7] 72 层上的节点值不满足严格递增的条件，所以这不是一棵奇偶树。 1输入：root = [5,9,1,3,5,7] 2输出：false 3解释：1 层上的节点值应为偶数。 1示例 4： 2 3输入：root = [1] 4输出：true 5示例 5： 6 7输入：root = [11,8,6,1,3,9,11,30,20,18,16,12,10,4,2,17] 8输出：true 解答 刚开始想法是用广度优先遍历每一层，把每一层的值存起来，每一层遍历完成之后，根据数的深度判断降序或者升序。\n题目中的条件比较多，既要判断层深度的值是否是奇偶、还要判断这一层是否是降序、升序。\n官方给的判断方式非常巧妙，value % 2 == level % 2就可以判断层数与对应值奇偶类型相同\n代码 1bool isEvenOddTree(TreeNode *root) { 2 queue\u0026lt;TreeNode *\u0026gt; q; 3 q.push(root); 4 int level = 0; 5 while (!q.empty()) { 6 // 层数是偶数，就要升序，用最小值比 7 // 层数是奇数、降序，用最大值来比 8 int prev = level % 2 == 0 ? INT_MIN : INT_MAX; 9 int q_len = q.size(); 10 for (int i = 0; i \u0026lt; q_len; i++) { 11 TreeNode *temp = q.front(); 12 q.pop(); 13 int value = temp-\u0026gt;val; 14 //判断层数和对应的值的类型是否不同 15 if (value % 2 == level % 2) { 16 return false; 17 } 18 // 偶数层升序，奇数层降序 19 if (level % 2 == 0 \u0026amp;\u0026amp; value \u0026lt;= prev || level % 2 == 1 \u0026amp;\u0026amp; value \u0026gt;= prev) { 20 return false; 21 } 22 prev = value; 23 if (temp-\u0026gt;left != nullptr) { 24 q.push(temp-\u0026gt;left); 25 } 26 if (temp-\u0026gt;right != nullptr) { 27 q.push(temp-\u0026gt;right); 28 } 29 } 30 level++; 31 } 32 return true; 33} ","date":"2021-12-25","img":"","permalink":"/posts/1c05b892/","series":["leetcode"],"tags":["中等","BFS"],"title":"LeetCode-1609-奇偶树"},{"categories":["LeetCode"],"content":"题目 有一棵特殊的苹果树，一连 n 天，每天都可以长出若干个苹果。在第 i 天，树上会长出 apples[i] 个苹果，这些苹果将会在 days[i] 天后（也就是说，第 i + days[i] 天时）腐烂，变得无法食用。也可能有那么几天，树上不会长出新的苹果，此时用 apples[i] == 0 且 days[i] == 0 表示。\n你打算每天 最多 吃一个苹果来保证营养均衡。注意，你可以在这 n 天之后继续吃苹果。\n给你两个长度为 n 的整数数组 days 和 apples ，返回你可以吃掉的苹果的最大数目。\n示例 1输入：apples = [1,2,3,5,2], days = [3,2,1,4,2] 2输出：7 3解释：你可以吃掉 7 个苹果： 4- 第一天，你吃掉第一天长出来的苹果。 5- 第二天，你吃掉一个第二天长出来的苹果。 6- 第三天，你吃掉一个第二天长出来的苹果。过了这一天，第三天长出来的苹果就已经腐烂了。 7- 第四天到第七天，你吃的都是第四天长出来的苹果。 1输入：apples = [3,0,0,0,0,2], days = [3,0,0,0,0,2] 2输出：5 3解释：你可以吃掉 5 个苹果： 4- 第一天到第三天，你吃的都是第一天长出来的苹果。 5- 第四天和第五天不吃苹果。 6- 第六天和第七天，你吃的都是第六天长出来的苹果。 解答 代码","date":"2021-12-24","img":"","permalink":"/posts/48cf338b/","series":["leetcode"],"tags":["中等"],"title":"LeetCode-1705-吃苹果的最大数目"},{"categories":["LeetCode"],"content":"题目 给你一个字符串 s ，考虑其所有 重复子串 ：即，s 的连续子串，在 s 中出现 2 次或更多次。这些出现之间可能存在重叠。\n返回 任意一个 可能具有最长长度的重复子串。如果 s 不含重复子串，那么答案为 \u0026quot;\u0026quot; 。\n示例 1输入：s = \u0026#34;banana\u0026#34; 2输出：\u0026#34;ana\u0026#34; 1输入：s = \u0026#34;abcd\u0026#34; 2输出：\u0026#34;\u0026#34; 解答 代码 1class SuffixArray { 2public: 3 using size_type = unsigned; 4 using pointer = size_type*; 5 using const_pointer = const size_type*; 6 const_pointer sa, rk, ht; 7 8private: 9 std::unique_ptr\u0026lt;size_type[]\u0026gt; data; 10 11private: 12 template\u0026lt;typename S\u0026gt; 13 inline static bool substring_equal(const S\u0026amp; s, size_type p1, size_type p2, size_type len) { 14 for (size_type i = 0;i \u0026lt; len;++i) 15 if (s[p1 + i] != s[p2 + i]) 16 return false; 17 return true; 18 } 19 20 template\u0026lt;typename S\u0026gt; 21 inline static void induced_sort( 22 const S\u0026amp; s, 23 pointer sa, 24 bool* type, 25 pointer pos, 26 pointer lbuk, 27 pointer sbuk, 28 size_type n, 29 size_type m, 30 size_type n0) { 31 std::fill_n(sa, n, 0); 32 lbuk[0] = 0; 33 for (size_type i = 1;i \u0026lt; m;++i) 34 lbuk[i] = sbuk[i - 1]; 35 for (size_type i = n0;i-- \u0026gt; 0;) 36 sa[--sbuk[s[pos[i]]]] = pos[i]; 37 sbuk[m - 1] = n; 38 for (size_type i = 1;i \u0026lt; m;++i) 39 sbuk[i - 1] = lbuk[i]; 40 sa[lbuk[s[n - 1]]++] = n - 1; 41 for (size_type i = 0;i \u0026lt; n;++i) 42 if (sa[i] \u0026gt; 0 \u0026amp;\u0026amp; !type[sa[i] - 1]) 43 sa[lbuk[s[sa[i] - 1]]++] = sa[i] - 1; 44 lbuk[0] = 0; 45 for (size_type i = 1;i \u0026lt; m;++i) 46 lbuk[i] = sbuk[i - 1]; 47 for (size_type i = n;i-- \u0026gt; 0;) 48 if (sa[i] \u0026gt; 0 \u0026amp;\u0026amp; type[sa[i] - 1]) 49 sa[--sbuk[s[sa[i] - 1]]] = sa[i] - 1; 50 } 51 52 template\u0026lt;typename S\u0026gt; 53 static void sais( 54 const S\u0026amp; s, 55 pointer sa, 56 bool* type, 57 pointer len, 58 pointer pos, 59 pointer lbuk, 60 pointer sbuk, 61 size_type n, 62 size_type m) { 63 type[n - 1] = false; 64 for (size_type i = n - 1;i-- \u0026gt; 0;) 65 type[i] = s[i] != s[i + 1] ? s[i] \u0026lt; s[i + 1] : type[i + 1]; 66 size_type n0 = 0; 67 for (size_type i = 1;i \u0026lt; n;++i) 68 if (!type[i - 1] \u0026amp;\u0026amp; type[i]) 69 pos[n0++] = i; 70 std::fill_n(len, n, 0); 71 for (size_type p = n - 1, i = n0;i-- \u0026gt; 0;p = pos[i]) 72 len[pos[i]] = p - pos[i] + 1; 73 std::fill_n(sbuk, m, 0); 74 for (size_type i = 0;i \u0026lt; n;++i) 75 ++sbuk[s[i]]; 76 for (size_type i = 1;i \u0026lt; m;++i) 77 sbuk[i] += sbuk[i - 1]; 78 induced_sort(s, sa, type, pos, lbuk, sbuk, n, m, n0); 79 sbuk[m - 1] = n; 80 for (size_type i = 1;i \u0026lt; m;++i) 81 sbuk[i - 1] = lbuk[i]; 82 size_type m0 = -1; 83 size_type ppos = -1, plen = 0; 84 for (size_type i = 0;i \u0026lt; n;++i) { 85 if (len[sa[i]] == 0) continue; 86 if (len[sa[i]] != plen || !substring_equal(s, sa[i], ppos, plen)) ++m0; 87 plen = len[sa[i]]; 88 len[sa[i]] = m0; 89 ppos = sa[i]; 90 } 91 pointer s0 = sa; 92 pointer sa0 = sa + n0; 93 for (size_type i = 0;i \u0026lt; n0;++i) 94 s0[i] = len[pos[i]]; 95 if (++m0 \u0026lt; n0) 96 sais(s0, sa0, type + n, len, pos + n0, lbuk, lbuk + n0, n0, m0); 97 else for (size_type i = 0;i \u0026lt; n0;++i) 98 sa0[s0[i]] = i; 99 for (size_type i = 0;i \u0026lt; n0;++i) 100 pos[i + n0] = pos[sa0[i]]; 101 induced_sort(s, sa, type, pos + n0, lbuk, sbuk, n, m, n0); 102 } 103 104public: 105 template\u0026lt;typename S\u0026gt; 106 SuffixArray(const S\u0026amp; s, size_type n, size_type m) 107 : data(std::make_unique\u0026lt;size_type[]\u0026gt;(3 * n)) { 108 const auto type = std::make_unique\u0026lt;bool[]\u0026gt;(2 * n); 109 const auto lbuk = std::make_unique\u0026lt;size_type[]\u0026gt;(std::max(n, m)); 110 const auto sbuk = std::make_unique\u0026lt;size_type[]\u0026gt;(m); 111 pointer sa = data.get(), rk = sa + n, ht = rk + n; 112 sais(s, sa, type.get(), rk, ht, lbuk.get(), sbuk.get(), n, m); 113 for (size_type i = 0;i \u0026lt; n;++i) 114 rk[sa[i]] = i; 115 for (size_type k = 0, i = 0;i \u0026lt; n;++i) { 116 if (rk[i] == 0) continue; 117 if (k \u0026gt; 0) --k; 118 for (size_type j = sa[rk[i] - 1], l = n - std::max(i, j);k \u0026lt; l;++k) 119 if (s[i + k] != s[j + k]) break; 120 ht[rk[i]] = k; 121 } 122 this-\u0026gt;sa = sa; 123 this-\u0026gt;rk = rk; 124 this-\u0026gt;ht = ht; 125 } 126 127 inline size_type suffix(size_type p) const { 128 return sa[p]; 129 } 130 131 inline size_type rank(size_type p) const { 132 return rk[p]; 133 } 134 135 inline size_type height(size_type p) const { 136 return ht[p]; 137 } 138}; 139 140class Solution { 141public: 142 string longestDupSubstring(string s) { 143 const int n = s.size(); 144 SuffixArray sa(s, n, 128); 145 int len = 0, pos = -1; 146 for (int i = 1;i \u0026lt; n;++i) { 147 if (sa.ht[i] \u0026gt; len) { 148 len = sa.ht[i]; 149 pos = sa.sa[i]; 150 } 151 } 152 return pos == -1 ? \u0026#34;\u0026#34; : s.substr(pos, len); 153 } 154}; ","date":"2021-12-23","img":"","permalink":"/posts/8669609e/","series":["leetcode"],"tags":["困难"],"title":"LeetCode-1044-最长重复子串"},{"categories":["教程"],"content":"项目中使用到了postgres的枚举类型，但是使用GORM自动迁移表的时候出现了\n1 CREATE TABLE \u0026#34;user\u0026#34; (\u0026#34;id\u0026#34; bigserial, 2 \u0026#34;created_at\u0026#34; timestamptz, 3 \u0026#34;updated_at\u0026#34; timestamptz, 4 \u0026#34;deleted_at\u0026#34; timestamptz, 5 \u0026#34;username\u0026#34; varchar(20),unique, 6 \u0026#34;password\u0026#34; varchar(20), 7 \u0026#34;email\u0026#34; varchar(32),unique, 8 \u0026#34;authority\u0026#34; enum(\u0026#39;root\u0026#39;, \u0026#39;one\u0026#39;, \u0026#39;two\u0026#39;, \u0026#39;three\u0026#39;, \u0026#39;four\u0026#39;),default:\u0026#39;one\u0026#39;, 9 PRIMARY KEY (\u0026#34;id\u0026#34;)) 10错误: 语法错误 在 \u0026#34;,\u0026#34; 或附近的 (SQLSTATE 42601) 在gorm/issues中找到了解决方案\n在pg中创建自定义类型 1CREATE TYPE authority AS ENUM ( 2 \u0026#39;root\u0026#39;, 3 \u0026#39;one\u0026#39;, 4 \u0026#39;two\u0026#39;, 5 \u0026#39;three\u0026#39;, 6 \u0026#39;four\u0026#39;); 定义自定义的数据类型的model 1import ( 2\t\u0026#34;database/sql/driver\u0026#34; 3) 4type Authority string 5// \u0026#39;root\u0026#39;, \u0026#39;one\u0026#39;, \u0026#39;two\u0026#39;, \u0026#39;three\u0026#39;, \u0026#39;four\u0026#39; 6const ( 7\troot Authority = \u0026#34;root\u0026#34; 8\tone Authority = \u0026#34;one\u0026#34; 9\ttwo Authority = \u0026#34;two\u0026#34; 10\tthree Authority = \u0026#34;three\u0026#34; 11\tfour Authority = \u0026#34;four\u0026#34; 12) 13func (p *Authority) Scan(value interface{}) error { 14\t*p = Authority(value.([]byte)) 15\treturn nil 16} 17func (p Authority) Value() (driver.Value, error) { 18\treturn string(p), nil 19} 定义一个要使用的Model 1type User struct { 2\tglobal.Model 3\tUsername string `gorm:\u0026#34;type:varchar(20)\u0026#34; json:\u0026#34;username\u0026#34; ` 4\tPassword string `gorm:\u0026#34;type:varchar(20)\u0026#34; json:\u0026#34;password\u0026#34;` 5\tEmail string `gorm:\u0026#34;type:varchar(32)\u0026#34; json:\u0026#34;email\u0026#34; ` 6\tAuthority string `gorm:\u0026#34;type:authority\u0026#34; json:\u0026#34;authority\u0026#34;` 7} 现在你就可以使用GORM的AutoMigrate()自动迁移表了\n1err = DB.AutoMigrate(\u0026amp;User{}) 2\tif err != nil { 3\tfmt.Println(\u0026#34;数据库创建失败\u0026#34;, err) 4\treturn nil 5} ","date":"2021-12-22","img":"","permalink":"/posts/1fb2f937/","series":null,"tags":["GORM","Postgres"],"title":"在GORM中使用Postgres自定义数据类型"},{"categories":["LeetCode"],"content":"题目 给定两个字符串 a 和 b，寻找重复叠加字符串 a 的最小次数，使得字符串 b 成为叠加后的字符串 a 的子串，如果不存在则返回 -1。\n注意：字符串 \u0026ldquo;abc\u0026rdquo; 重复叠加 0 次是 \u0026ldquo;\u0026quot;，重复叠加 1 次是 \u0026ldquo;abc\u0026rdquo;，重复叠加 2 次是 \u0026ldquo;abcabc\u0026rdquo;。\n示例 1输入：a = \u0026#34;abcd\u0026#34;, b = \u0026#34;cdabcdab\u0026#34; 2输出：3 3解释：a 重复叠加三遍后为 \u0026#34;abcdabcdabcd\u0026#34;, 此时 b 是其子串。 1输入：a = \u0026#34;a\u0026#34;, b = \u0026#34;aa\u0026#34; 2输出：2 1输入：a = \u0026#34;a\u0026#34;, b = \u0026#34;a\u0026#34; 2输出：1 1输入：a = \u0026#34;abc\u0026#34;, b = \u0026#34;wxyz\u0026#34; 2输出：-1 解答 根据题意进行模拟，如果a的长度小于b的长度，newA = newA+a，直到newA.size()\u0026gt;=b.size()结束，在此期间记录加了几次a，然后判断b是否是newA的子串。如果不是子串还要判断newA.size()是否等于b.size()，就像示例1一样，虽然a叠加两边之后和b的size一样，b不是a的子串，但是再叠加一次，b就是a的子串了。\n代码 1int repeatedStringMatch(string a, string b) { 2 string newA = a; 3 int ans = 1; 4 while (newA.size() \u0026lt; b.size()) { 5 ans++; 6 cout \u0026lt;\u0026lt; \u0026#34;newA.size() = \u0026#34; \u0026lt;\u0026lt; newA.size() \u0026lt;\u0026lt; endl; 7 newA = newA + a; 8 } 9 string::size_type sizeType = newA.find(b); 10 if (sizeType == string::npos) { 11 newA += a; 12 sizeType = newA.find(b); 13 if (sizeType == string::npos) { 14 return -1; 15 } else { 16 return ans + 1; 17 } 18 } 19 20 return ans; 21 } ","date":"2021-12-22","img":"","permalink":"/posts/cb644e85/","series":["leetcode"],"tags":["中等","模拟","字符串"],"title":"LeetCode-686-重复叠加字符串匹配"},{"categories":["LeetCode"],"content":"题目 给你一个字符串 date ，按 YYYY-MM-DD 格式表示一个 现行公元纪年法 日期。请你计算并返回该日期是当年的第几天。\n通常情况下，我们认为 1 月 1 日是每年的第 1 天，1 月 2 日是每年的第 2 天，依此类推。每个月的天数与现行公元纪年法（格里高利历）一致。\n示例 1输入：date = \u0026#34;2019-01-09\u0026#34; 2输出：9 1输入：date = \u0026#34;2019-02-10\u0026#34; 2输出：41 1输入：date = \u0026#34;2003-03-01\u0026#34; 2输出：60 1输入：date = \u0026#34;2004-03-01\u0026#34; 2输出：61 解答 按照题目意思进行模拟即可，在模拟过程中不能加上本月的时间，2月10号就是31+10。\n代码 1int dayOfYear(string date) { 2 vector\u0026lt;string\u0026gt; result = split(date, \u0026#34;-\u0026#34;); 3 int year = stoi(result[0]); 4 int month = stoi(result[1]); 5 int day = stoi(result[2]); 6 vector\u0026lt;int\u0026gt; days = {31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31}; 7 int ans = 0; 8 if (year % 400 == 0 || (year % 4 == 0 \u0026amp;\u0026amp; year % 100 != 0)) { 9 days[1] = 29; 10 } 11 for (int i = 0; i \u0026lt; month - 1; i++) { 12 ans += days[i]; 13 } 14 ans += day; 15 return ans; 16} 17 18vector\u0026lt;string\u0026gt; split(const string \u0026amp;s, const string \u0026amp;seperator) { 19 vector\u0026lt;string\u0026gt; result; 20 typedef string::size_type string_size; 21 string_size i = 0; 22 23 while (i != s.size()) { 24 //找到字符串中首个不等于分隔符的字母； 25 int flag = 0; 26 while (i != s.size() \u0026amp;\u0026amp; flag == 0) { 27 flag = 1; 28 for (char x: seperator) { 29 if (s[i] == x) { 30 ++i; 31 flag = 0; 32 break; 33 34 } 35 } 36 } 37 38 //找到又一个分隔符，将两个分隔符之间的字符串取出； 39 flag = 0; 40 string_size j = i; 41 while (j != s.size() \u0026amp;\u0026amp; flag == 0) { 42 for (char x: seperator) { 43 if (s[j] == x) { 44 flag = 1; 45 break; 46 } 47 } 48 if (flag == 0) 49 ++j; 50 } 51 if (i != j) { 52 result.push_back(s.substr(i, j - i)); 53 i = j; 54 } 55 } 56 return result; 57} ","date":"2021-12-21","img":"","permalink":"/posts/bd5751e9/","series":["leetcode"],"tags":["简单"],"title":"LeetCode-1154-一年中的第几天"},{"categories":["LeetCode"],"content":"题目 冬季已经来临。 你的任务是设计一个有固定加热半径的供暖器向所有房屋供暖。\n在加热器的加热半径范围内的每个房屋都可以获得供暖。\n现在，给出位于一条水平线上的房屋 houses 和供暖器 heaters 的位置，请你找出并返回可以覆盖所有房屋的最小加热半径。\n说明：所有供暖器都遵循你的半径标准，加热的半径也一样。\n示例 1输入: houses = [1,2,3], heaters = [2] 2输出: 1 3解释: 仅在位置2上有一个供暖器。如果我们将加热半径设为1，那么所有房屋就都能得到供暖。 1输入: houses = [1,2,3,4], heaters = [1,4] 2输出: 1 3解释: 在位置1, 4上有两个供暖器。我们需要将加热半径设为1，这样所有房屋就都能得到供暖。 1输入：houses = [1,5], heaters = [2] 2输出：3 解答 对于每个房屋，要么用前面的暖气，要么用后面的，二者取近的，得到距离； 对于所有的房屋，选择最大的上述距离。 代码 1int findRadius(vector\u0026lt;int\u0026gt; \u0026amp;houses, vector\u0026lt;int\u0026gt; \u0026amp;heaters) { 2 sort(heaters.begin(), heaters.end()); 3 sort(houses.begin(), houses.end()); 4 int ans = 0; 5 for (int house: houses) { 6 // 找到比该房间右边的第一个暖气的索引 7 int currentRightHeater = upper_bound(heaters.begin(), heaters.end(), house) - heaters.begin(); 8 int currentLeftHeater = currentRightHeater - 1; 9 int rightDistance = currentRightHeater \u0026gt;= heaters.size() ? INT_MAX : heaters[currentRightHeater] - house; 10 int leftDistance = currentLeftHeater \u0026lt; 0 ? INT_MAX : house - heaters[currentLeftHeater]; 11 // 他要用最近的一个这样才能保证最小， 12 int curDistance = min(leftDistance, rightDistance); 13 // 在所有的房屋都要满足要求，则要取最大的一个 14 ans = max(ans, curDistance); 15 } 16 return ans; 17} ","date":"2021-12-20","img":"","permalink":"/posts/e63dcfe3/","series":["leetcode"],"tags":["中等"],"title":"LeetCode-475-供暖器"},{"categories":["LeetCode"],"content":"题目 在一个小镇里，按从 1 到 n 为 n 个人进行编号。传言称，这些人中有一个是小镇上的秘密法官。\n如果小镇的法官真的存在，那么：\n小镇的法官不相信任何人。 每个人（除了小镇法官外）都信任小镇的法官。 只有一个人同时满足条件 1 和条件 2 。 给定数组 trust，该数组由信任对 trust[i] = [a, b] 组成，表示编号为 a 的人信任编号为 b 的人。\n如果小镇存在秘密法官并且可以确定他的身份，请返回该法官的编号。否则，返回 -1。\n示例 1输入：n = 2, trust = [[1,2]] 2输出：2 1输入：n = 3, trust = [[1,3],[2,3]] 2输出：3 1输入：n = 3, trust = [[1,3],[2,3],[3,1]] 2输出：-1 1输入：n = 3, trust = [[1,2],[2,3]] 2输出：-1 1输入：n = 4, trust = [[1,3],[1,4],[2,3],[2,4],[4,3]] 2输出：3 解答 和题目LeetCode-851-喧闹和富有)是有些共同特征的，在这个题目中，信任是不能传递的，我们也不能使用DFS去找到他们都信任的人。只有法官一个人是不相信任何人的，而剩下的n-1个人都相信法官，用题目中给的信任关系，构建一个有向图，我们要找到是，出度为0，入度为n-1的节点。由于法官不会相信其他人，如果有人相信i那么v[edge[1]]++，i相信别人就v[edge[1]]--\n代码 1int findJudge(int n, vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; trust) { 2 vector\u0026lt;int\u0026gt; v(n + 1); 3 for (auto\u0026amp; edge : trust) { 4 v[edge[0]]--; 5 v[edge[1]]++; 6 } 7 for (int i = 1; i \u0026lt;= n; ++i) { 8 if (v[i]== n-1) { 9 return i; 10 } 11 } 12 return -1; 13} 1int findJudge(int n, vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; trust) { 2\tvector\u0026lt;int\u0026gt; inDegrees(n + 1); 3 vector\u0026lt;int\u0026gt; outDegrees(n + 1); 4 for (auto\u0026amp; edge : trust) { 5 int x = edge[0], y = edge[1]; 6 ++inDegrees[y]; 7 ++outDegrees[x]; 8 } 9 for (int i = 1; i \u0026lt;= n; ++i) { 10 if (inDegrees[i] == n - 1 \u0026amp;\u0026amp; outDegrees[i] == 0) { 11 return i; 12 } 13 } 14 return -1; 15} ","date":"2021-12-19","img":"","permalink":"/posts/e18d9e0d/","series":["leetcode"],"tags":["简单"],"title":"LeetCode-997-找到小镇的法官"},{"categories":[["教程"],["Go"]],"content":"​\tCasbin努力成为与编程语言无关的，解耦的权限框架！致力于多种语言一致体验，直白来说，就是一套规则框架，在各种编程语言中稍微改动就可以与业务系统结合使用，使其成为与语言、语言框架无关且通用的权限管理系统。\n我们可以理解为Casbin做的是3A(认证、授权、审计)之中的授权这一步，也是主旨！\nCasbin模型 Casbin有四个元模型\n它的思路是这样的，我定义一个策略(policy)、一个匹配规则(matcher)，通过请求(request)过来的参数与策略通过规则进行匹配，匹配可以获得一个影响(effect)，拿到影响的结果，返回一个bool值。\n在Casbin官网中有在线编辑器，我们可以试一下。\n我们先将这个例子做简单解释，如果刚开始不懂没关系，可以返回来继续看。\nmodel中的文件如下\n1# 请求的定义 2[request_definition] 3r = sub, obj, act 4# 策略定义 5[policy_definition] 6p = sub, obj, act 7# 策略的影响 8[policy_effect] 9e = some(where (p.eft == allow)) 10# 用户组 11[role_definition] 12g = _,_ 13# 匹配验证方法 14[matchers] 15m = g(r.sub, p.sub) \u0026amp;\u0026amp; keyMatch2(r.obj, p.obj) \u0026amp;\u0026amp; regexMatch(r.act, p.act) policy中，请求的策略定义\np代表他是一个策略，admin访问的主体，/alice_data/:resource访问的对象，GET，访问的方式 g代表用户组，后面表示tom继承自admin，tom拥有admin角色的所有权限 1p, admin, /alice_data/:resource, GET 2p, admin, /alice_data2/:id/using/:resId, GET 3 4g, tom,admin 5g, alice,user request\ntom通过使用GET的方式访问/alice_data/hello资源（对象） 1tom, /alice_data/hello, GET 2tom, /alice_data2/2/using/1, GET 3tom, /alice_data2/2/using/1, POST result\ntom使用POST方法访问资源的时候，就不会通过 1true 2true 3false 下面我将通过这个例子简要介绍Casbin\nsubject（sub 访问实体）、object（obj 访问的资源）、action（act 访问的方法）、effect（eft 策略结果，一般为空，默认指定为 allow，还可以定义为deny，只有这两种情况）\nRequest 定义请求参数。基本请求是一个元组对象，至少需要主题(访问实体)、对象(访问资源) 和动作(访问方式)。\nr={sub,obj,act}它实际上定义了我们应该提供访问控制匹配功能的参数名称和顺序。\n这就如同至尊宝例子中至尊宝对门说芝麻开门，\n这条“规则”指明一次请求至少需要提供三个参数：请求主体、要访问的资源和请求方式，即前端访问API时提供当前请求的用户、要访问的url和请求方式(GET\u0026hellip;)\n定义至尊宝的访问请求\n至尊宝 /api/v1/door/open POST Policy 实际上Policy和Request在很多情况下都是相同的，是由Policy来决定Request的，从官方给的在线示例代码中，我们也可以看出来。\n定义一个至尊宝的Policy\n至尊宝 /api/v1/door/open `POST Matcher 匹配器 1m = g(r.sub, p.sub) \u0026amp;\u0026amp; keyMatch2(r.obj, p.obj) \u0026amp;\u0026amp; regexMatch(r.act, p.act) 这个简单和常见的匹配规则意味着如果请求的参数(访问实体，访问资源和访问方式)匹配， 如果可以在策略中找到资源和方法，那么策略结果（p.eft）便会返回。 策略的结果将保存在 p.eft 中。\ng使用角色管理 keyMatch2()使用自己写的验证方法，返回bool值，如何编写会在下面的实战中介绍 regexMatch()使用正则表达式进行验证，返回bool值，如何编写会在下面的实战中介绍 定义一个至尊宝匹配器\nm = r.sub == p.sub \u0026amp;\u0026amp; r.act == p.act \u0026amp;\u0026amp; r.obj == p.obj Effect 它可以被理解为一种模型，在这种模型中，对匹配结果再次作出逻辑组合判断。\n例如： e = some (where (p.eft == allow))\n这句话意味着，如果匹配的策略结果有一些是允许的，那么最终结果为真。\n让我们看看另一个示例： e = some (where (p.eft == allow)) \u0026amp;\u0026amp; !some(where (p.eft == deny) 此示例组合的逻辑含义是：如果有符合允许结果的策略且没有符合拒绝结果的策略， 结果是为真。 换言之，当匹配策略均为允许（没有任何否认）是为真（更简单的是，既允许又同时否认，拒绝就具有优先地位)。\n定义至尊宝的eft\ne = some (where (p.eft == allow)) Role [role_definition] 是RBAC角色继承关系的定义。 Casbin 支持 RBAC 系统的多个实例, 例如, 用户可以具有角色及其继承关系, 资源也可以具有角色及其继承关系。 这两个 RBAC 系统不会互相干扰。\n此部分是可选的。 如果在模型中不使用 RBAC 角色, 则省略此部分。\n1[role_definition] 2g = _, _ 3g2 = _, _ 上述角色定义表明, g 是一个 RBAC系统, g2 是另一个 RBAC 系统。 _, _表示角色继承关系的前项和后项，即前项继承后项角色的权限。 一般来讲，如果您需要进行角色和用户的绑定，直接使用g 即可。 当您需要表示角色（或者组）与用户和资源的绑定关系时，可以使用g 和 g2 这样的表现形式。 请参见 rbac_model 和 rbac_model_with_resource_roles 的示例。\nCasbin 只存储用户角色的映射关系。 Cabin 没有验证用户是否是有效的用户，或者角色是一个有效的角色。 这应该通过认证来解决。 RBAC 系统中的用户名称和角色名称不应相同。因为Casbin将用户名和角色识别为字符串， 所以当前语境下Casbin无法得出这个字面量到底指代用户 alice 还是角色 alice。 这时，使用明确的 role_alice ，问题便可迎刃而解。 假设A具有角色 B，B 具有角色 C，并且 A 有角色 C。 这种传递性在当前版本会造成死循环。 实战 在上面介绍了Casbin的基础模型，下面将说明如何在编写测试代码\nmain.go\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;github.com/casbin/casbin/v2\u0026#34; 6\txormadapter \u0026#34;github.com/casbin/xorm-adapter/v2\u0026#34; 7\t_ \u0026#34;github.com/lib/pq\u0026#34; 8\t\u0026#34;log\u0026#34; 9) 10 11func main() { 12\t// 初始化 Xorm 适配器并在 Casbin 执行器中使用它： 13\t// 适配器将使用名为\u0026#34;casbin\u0026#34;的 Postgres 数据库。 14\t// 如果它不存在，适配器将自动创建它。 15\ta, err := xormadapter.NewAdapter(\u0026#34;postgres\u0026#34;, \u0026#34;dbname=casbin user=postgres_name password=postgres_passwd host=127.0.0.1 port=5432 sslmode=disable\u0026#34;, true) // Your driver and data source. 16\tif err != nil { 17\tlog.Fatal(err) 18\treturn 19\t} 20 // 初始化执行者 21\te, err := casbin.NewEnforcer(\u0026#34;to/model.conf\u0026#34;, a) 22\tif err != nil { 23\tlog.Fatal(\u0026#34;err,\u0026#34;, err) 24\treturn 25\t} 26 27\t// Load the policy from DB. 28\terr = e.LoadPolicy() 29\tif err != nil { 30\tlog.Fatal(e) 31\treturn 32\t} 33\t// AddPolicy 将授权规则添加到当前策略。 34\t// 如果规则已存在，则该函数返回 false，并且不会添加该规则。 35\t// 否则，该函数通过添加新规则返回 true。 36\t_, err = e.AddPolicy(\u0026#34;admin\u0026#34;, \u0026#34;/alice_data/:resource\u0026#34;, \u0026#34;GET\u0026#34;) 37\t_, err = e.AddPolicy(\u0026#34;admin\u0026#34;, \u0026#34;/alice_data2/:id/using/:resId\u0026#34;, \u0026#34;GET\u0026#34;) 38\tif err != nil { 39\treturn 40\t} 41\t_, err = e.AddGroupingPolicy(\u0026#34;tom\u0026#34;, \u0026#34;admin\u0026#34;) 42\t_, err = e.AddGroupingPolicy(\u0026#34;alice\u0026#34;, \u0026#34;user\u0026#34;) 43 44\tif err != nil { 45\tlog.Fatal(err) 46\treturn 47\t} 48\t// Check the permission. 49\ttest(\u0026#34;tom\u0026#34;, \u0026#34;/alice_data/hello\u0026#34;, \u0026#34;GET\u0026#34;, e) 50\ttest(\u0026#34;tom\u0026#34;, \u0026#34;/alice_data2/2/using/1\u0026#34;, \u0026#34;GET\u0026#34;, e) 51\ttest(\u0026#34;tom\u0026#34;, \u0026#34;/alice_data2/2/using/1\u0026#34;, \u0026#34;POST\u0026#34;, e) 52\ttest(\u0026#34;alice\u0026#34;, \u0026#34;/alice_data2/2/using/1\u0026#34;, \u0026#34;POST\u0026#34;, e) 53 54\t// Save the policy back to DB. 55\terr = e.SavePolicy() 56\tif err != nil { 57\treturn 58\t} 59} 60 61func test(sub string, obj string, act string, e *casbin.Enforcer) { 62\tenforce, err := e.Enforce(sub, obj, act) 63\tif err != nil { 64\treturn 65\t} 66\tif enforce { 67\tfmt.Printf(\u0026#34;sub:%s obj:%s act:%s 通过了\\n\u0026#34;, sub, obj, act) 68\t} else { 69\tfmt.Printf(\u0026#34;sub:%s obj:%s act:%s 不通过\\n\u0026#34;, sub, obj, act) 70\t} 71} to/model.conf\n1# 请求的定义 2[request_definition] 3r = sub, obj, act 4# 策略定义 5[policy_definition] 6p = sub, obj, act 7# 策略的影响 8[policy_effect] 9e = some(where (p.eft == allow)) 10# 用户组 11[role_definition] 12g = _,_ 13# 匹配验证方法 14[matchers] 15m = g(r.sub, p.sub) \u0026amp;\u0026amp; keyMatch2(r.obj, p.obj) \u0026amp;\u0026amp; regexMatch(r.act, p.act) keyMatch2() 和regexMatch() 是Casbin的内置函数\n运行结果如下\n1sub:tom obj:/alice_data/hello act:GET 通过了 2sub:tom obj:/alice_data2/2/using/1 act:GET 通过了 3sub:tom obj:/alice_data2/2/using/1 act:POST 不通过 4sub:alice obj:/alice_data2/2/using/1 act:POST 不通过 运行完之后就会发现数据库中多了几条数据。\n我们已经将添加的策略保存到数据库中。\nAdapter 在Casbin中，策略存储作为adapter(Casbin的中间件) 实现。 Casbin用户可以使用adapter从存储中加载策略规则 (aka LoadPolicy()) 或者将策略规则保存到其中 (aka SavePolicy())。\n上面的小示例中我们从一个postgres数据库读取policy，使用数据库更方便管理，对于巨量策略条目性能也更高！Casbin官方提供了完整的适配器列表供选择，包含了各种主流编程语言以及各种主流数据库、云及文件如csv等的支持，有官方的也有第三方的具体请参照官网。\n以上实例我们创建了xorm类型adapter，它使用Postgres作为policy存储容器，并使用默认生成的数据库casbin中的casbin_rule表存储具体的policy，返回*Adapter与err对象，然后调用NewEnforcer()方法加载模型文件model.conf与适配器a，对tom,alice鉴权。在此，我们需要知道并记住的是，**Casbin默认将policy(策略)加载到内存中，如果改变了存储容器内的策略数据需要执行LoadPolicy()方法重载策略到内存才能生效！**方便的是，我们在官方提供的API中不需要手动去调用，这些方法底层已实现，除非特别说明！由此指出，如果我们自己实现某些会改变策略方法的话需要实现这个方法，否则就要手动调用或重启，常见的问题有程序在运行时，手动往数据表插入一条策略去测试并未生效！查询等不涉及改变数据表数据的操作不需要有此操作！\n自定义Matcher方法 在小例子中，我们使用了内置的比较方法keyMatch2() 和regexMatch()现在我们自己写一个比较的方法。\n首先准备您的函数。 它接受一些参数，然后返回一个布尔类型：\n1func KeyMatch(key1 string, key2 string) bool { 2\treturn key1 == key2 3} 然后用 interface{} 类型的接口包装它：\n1func KeyMatchFunc(args ...interface{}) (interface{}, error) { 2 name1 := args[0].(string) 3 name2 := args[1].(string) 4 return (bool)(KeyMatch(name1, name2)), nil 5} 最后，在Casbin的执行者(enforcer)中注册这个函数：\n注：要在NewEnforcer()之后执行它\n1e.AddFunction(\u0026#34;my_func\u0026#34;, KeyMatchFunc) 现在，您可以在您的模型CONF中像这样使用这个函数：\n1m = g(r.sub, p.sub) \u0026amp;\u0026amp; keyMatch2(r.obj, p.obj) \u0026amp;\u0026amp; my_func(r.act, p.act) 通过修改小示例，继续运行,还是一样的结果\n1sub:tom obj:/alice_data/hello act:GET 通过了 2sub:tom obj:/alice_data2/2/using/1 act:GET 通过了 3sub:tom obj:/alice_data2/2/using/1 act:POST 不通过 4sub:alice obj:/alice_data2/2/using/1 act:POST 不通过 Gin框架结合 项目的结构如下\n1├─api 2│ └─v1 #存放API目录 3├─config # 存放配置文件目录 4├─docs # 存放文档 5├─global #存放全局变量 6├─initiate # 初始化项目 7├─log # 存放log文件 8├─middleware # 存放中间件 9├─model# 存放实体 10├─routes # 存放路由 11└─utils 12 ├─load #加载配置文件 13 └─response # 响应封装 代码在jimyag/gin-casbin-demo (github.com)\n程序运行的逻辑为：初始化配置文件，初始化数据库、初始化Casbin、初始化路由，路由分为公共的路由和私有需要认证和授权的。我们使用JWT进行认证，使用Casbin进行授权，同时还用了logrus做日志处理。在授权中，我只对获取用户信息的接口进行授权。\ncasbin的model如下\n1# 请求的定义 2[request_definition] 3r = sub, obj, act 4# 策略定义 5[policy_definition] 6p = sub, obj, act 7# 策略的影响 8[policy_effect] 9e = some(where (p.eft == allow)) 10# 用户组 11[role_definition] 12g = _,_ 13# 匹配验证方法 14[matchers] 15m = g(r.sub, p.sub) \u0026amp;\u0026amp; regexMatch(r.obj, p.obj) \u0026amp;\u0026amp; r.act==p.act ||r.sub==\u0026#34;1\u0026#34; 其中r.sub==\u0026quot;1\u0026quot;表示如果是超级管理员用户的话，就直接放行\n","date":"2021-12-18","img":"","permalink":"/posts/112bfef3/","series":null,"tags":["Casbin","GIN"],"title":"Casbin-入门demo"},{"categories":["教程"],"content":"由于自己不会配置如何按照每一篇博客在hexo中打包博客中的图片，所以想要自己搭建一个图床，总体效果很满意。\n将配置过程记录，方便之后重新配置。\n这是搭建好的效果图\n我们可以随时访问自己博客中的图片。\n安装Nginx 使用下面命令安装nginx\n1yum install nginx -y 显示以下信息表示安装完成\n1Loaded plugins: fastestmirror, langpacks 2Determining fastest mirrors 3Resolving Dependencies 4......... 5Installed: 6 nginx.x86_64 1:1.20.1-9.el7 7 8Dependency Installed: 9 gperftools-libs.x86_64 0:2.6.1-1.el7 nginx-filesystem.noarch 1:1.20.1-9.el7 openssl11-libs.x86_64 1:1.1.1k-2.el7 10 11Complete! 启动nginx\n1nginx 在地址栏中输入服务器ip可以看到下面信息表示安装成功。\n安装Docker 安装一些必要的系统工具： 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 显示以下信息\n1Loaded plugins: fastestmirror, langpacks 2Loading mirror speeds from cached hostfile 3Package yum-utils-1.1.31-54.el7_8.noarch already installed and latest version 4Package device-mapper-persistent-data-0.8.5-3.el7_9.2.x86_64 already installed and latest version 5Package 7:lvm2-2.02.187-6.el7_9.5.x86_64 already installed and latest version 6Nothing to do 添加软件源信息： 1sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 显示以下信息\n1[root@VM-0-15-centos ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 2Loaded plugins: fastestmirror, langpacks 3adding repo from: http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 4grabbing file http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo to /etc/yum.repos.d/docker-ce.repo 5repo saved to /etc/yum.repos.d/docker-ce.repo 更新yum缓存 1sudo yum makecache fast 安装docker-ce 1sudo yum -y install docker-ce 显示以下信息\n1Loaded plugins: fastestmirror, langpacks 2Loading mirror speeds from cached hostfile 3Resolving Dependencies 4--\u0026gt; Running transaction check 5---\u0026gt; Package docker-ce.x86_64 3:20.10.12-3.el7 will be installed 6--\u0026gt; Processing Dependency: container-selinux \u0026gt;= 2:2.74 for package: 3:docker-ce-20.10.12-3.el7.x86_64 7--\u0026gt; Processing Dependency: containerd.io \u0026gt;= 1.4.1 for package: 3:docker-ce-20.10.12-3.el7.x86_64 8--\u0026gt; Processing Dependency: docker-ce-cli for package: 3:docker-ce-20.10.12-3.el7.x86_64 9--\u0026gt; Processing Dependency: docker-ce-rootless-extras for package: 3:docker-ce-20.10.12-3.el7.x86_64 10--\u0026gt; Processing Dependency: libcgroup for package: 3:docker-ce-20.10.12-3.el7.x86_64 11........ 12Complete! 启动docke后台服务 1sudo systemctl start docker 查看docker 版本\n1[root@VM-0-15-centos ~]# docker -v 2Docker version 20.10.12, build e91ed57 docker配置MinIo 拉取MinIo 我们这里选择拉取旧的版本，新版本在访问文件时有访问已被取消的问题\n目前这个问题没有解决，所以我选择一个旧版本安装。\n1[root@VM-0-15-centos ~]# docker pull minio/minio:RELEASE.2021-06-17T00-10-46Z 创建存放minio的文件夹 1mkdir -p /mnt/minio/{data,cofig} 关闭防火墙 docker中容器需要用到很多端口，在没有配置nginx之前，可以先将防火墙关闭\n1systemctl stop firewalld.service 启动MinIO -d 表示在后台挂起\n-p 指定端口 MinIO的默认端口为9000\nMINIO_ACCESS_KEY=admin 设置用户名为admin\nMINIO_SECRET_KEY=12345678 设置密码为12345678\n1[root@VM-0-15-centos conf.d]# docker run -d -p 9000:9000 --name minio -e \u0026#34;MINIO_ACCESS_KEY=admin\u0026#34; 2-e \u0026#34;MINIO_SECRET_KEY=12345678\u0026#34; -v /mnt/minio/data:/data -v /mnt/minio/config:/root/.minio minio/minio:RELEASE.2021-06-17T00-10-46Z server /data 进入控制台 在浏览器中输入ip:9000 即可进入MinIO的控制台\n新建一个bucket叫 test 添加权限 给这个桶添加public权限\n上传文件 访问上传的图片 在浏览器中输入ip:9000/刚刚创建的bucket名称/上传的图片名称\nhttp://1.116.169.34:9000/test/image-20211014225210485.png\n配置nginx代理 在etc/nginx/cof.d中新建一个配置文件minio.conf写入\n1server { 2 listen 80; 3 4 location / { 5 proxy_pass http://172.17.0.15:9000; //172.17.0.15为内网的本机ip 6 } 7} 查看配置文件是的正确\n1[root@VM-0-15-centos conf.d]# nginx -t 2nginx: the configuration file /etc/nginx/nginx.conf syntax is ok 3nginx: configuration file /etc/nginx/nginx.conf test is successful 重新加载nginx配置文件\n1nginx -s reload 再次访问文件\n","date":"2021-12-18","img":"","permalink":"/posts/f0e09e13/","series":null,"tags":["CentOS","MinIO","Nginx"],"title":"Centos+minio+nginx搭建自己的图床"},{"categories":["LeetCode"],"content":"题目 给你一个大小为 m x n 的矩阵 board 表示甲板，其中，每个单元格可以是一艘战舰 \u0026lsquo;X\u0026rsquo; 或者是一个空位 \u0026lsquo;.\u0026rsquo; ，返回在甲板 board 上放置的 战舰 的数量。\n战舰 只能水平或者垂直放置在 board 上。换句话说，战舰只能按 1 x k（1 行，k 列）或 k x 1（k 行，1 列）的形状建造，其中 k 可以是任意大小。两艘战舰之间至少有一个水平或垂直的空位分隔 （即没有相邻的战舰）。\n示例 1输入：board = [[\u0026#34;.\u0026#34;]] 2输出：0 解答 方法1 题目的意思是只要横竖连在一块的X都算是一个战舰，找出有多少个战舰就行。\n那么就对有战舰的地方进行对row和column进行深度优先搜索，就可以找到当前战舰的一部分，既然是这个战舰的一部分，可以消除这个\u0026rsquo;X\u0026rsquo;以免在后面中被重复计算到。\n方法2 题目进阶要求一次扫描算法，只使用 O(1)O(1) 额外空间，并且不修改甲板的值。因为题目中给定的两艘战舰之间至少有一个水平或垂直的空位分隔，任意两个战舰之间是不相邻的，因此我们可以通过枚举每个战舰的左上顶点即可统计战舰的个数。假设矩阵的行数为 row，矩阵的列数col，矩阵中的位置[i][j]为战舰的左上顶点，需满足以下条件：\n满足当前位置所在的值 board[i][j] =X；\n满足当前位置的左则为空位，即board[i][j-1] =.\n满足当前位置的上方为空位，即board[i-1][j] =.\n我们统计出所有战舰的左上顶点的个数即为所有战舰的个数。\n代码 方法1 1int countBattleships(vector\u0026lt;vector\u0026lt;char\u0026gt;\u0026gt; \u0026amp;board) { 2 int ans = 0; 3 for (int row = 0; row \u0026lt; board.size(); row++) { 4 for (int column = 0; column \u0026lt; board[row].size(); ++column) { 5 if (board[row][column] == \u0026#39;X\u0026#39;) { 6 dfs(board, row, column); 7 ans++; 8 } 9 } 10 } 11 return ans; 12 13} 14 15 16void dfs(vector\u0026lt;vector\u0026lt;char\u0026gt;\u0026gt; \u0026amp;board, int row, int column) { 17 if (row \u0026gt;= board.size() || column \u0026gt;= board[row].size() || board[row][column] == \u0026#39;.\u0026#39;) { 18 return; 19 } 20 board[row][column] = \u0026#39;.\u0026#39;; 21 dfs(board, row, column + 1); 22 dfs(board, row + 1, column); 23} 方法2 1int countBattleships(vector\u0026lt;vector\u0026lt;char\u0026gt;\u0026gt;\u0026amp; board) { 2 int row = board.size(); 3 int col = board[0].size(); 4 int ans = 0; 5 for (int i = 0; i \u0026lt; row; ++i) { 6 for (int j = 0; j \u0026lt; col; ++j) { 7 if (board[i][j] == \u0026#39;X\u0026#39;) { 8 if (i \u0026gt; 0 \u0026amp;\u0026amp; board[i - 1][j] == \u0026#39;X\u0026#39;) { 9 continue; 10 } 11 if (j \u0026gt; 0 \u0026amp;\u0026amp; board[i][j - 1] == \u0026#39;X\u0026#39;) { 12 continue; 13 } 14 ans++; 15 } 16 } 17 } 18 return ans; 19 } ","date":"2021-12-18","img":"","permalink":"/posts/aa19f9bb/","series":["leetcode"],"tags":["中等","DFS"],"title":"LeetCode-419-甲板上的战舰"},{"categories":["LeetCode"],"content":"题目 小区便利店正在促销，用 numExchange 个空酒瓶可以兑换一瓶新酒。你购入了 numBottles 瓶酒。\n如果喝掉了酒瓶中的酒，那么酒瓶就会变成空的。\n请你计算 最多 能喝到多少瓶酒。\n示例 解答 根据题目进行模拟，要注意的是，已经换来的酒还可以继续换酒\n1int numWaterBottles(int numBottles, int numExchange) { 2 //numExchange 多少个瓶子可以换一瓶酒 3 // numBottles 买了多少瓶酒 4 // 最终能喝多少酒 5 int ans = numBottles; 6 // 如果剩下的酒瓶还可以兑换 7 while (numBottles \u0026gt;= numExchange) { 8 // 计算可以换几瓶酒 9 int change = numBottles / numExchange; 10 // 喝酒 11 ans += change; 12 // 计算换完酒之后还有多少瓶子 13 numBottles -= change * numExchange; 14 // 把喝完酒的瓶子也算上 15 numBottles += change; 16 } 17 return ans; 18} ","date":"2021-12-17","img":"","permalink":"/posts/656c6fd2/","series":["leetcode"],"tags":["简单"],"title":"LeetCode-1518-换酒问题"},{"categories":["LeetCode"],"content":"题目 给你一个点数组 points 和一个表示角度的整数 angle ，你的位置是 location ，其中 location = [posx, posy] 且 points[i] = [xi, yi] 都表示 X-Y 平面上的整数坐标。\n最开始，你面向东方进行观测。你 不能 进行移动改变位置，但可以通过 自转 调整观测角度。换句话说，posx 和 posy 不能改变。你的视野范围的角度用 angle 表示， 这决定了你观测任意方向时可以多宽。设 d 为你逆时针自转旋转的度数，那么你的视野就是角度范围 [d - angle/2, d + angle/2] 所指示的那片区域。\n对于每个点，如果由该点、你的位置以及从你的位置直接向东的方向形成的角度 位于你的视野中 ，那么你就可以看到它。\n同一个坐标上可以有多个点。你所在的位置也可能存在一些点，但不管你的怎么旋转，总是可以看到这些点。同时，点不会阻碍你看到其他点。\n返回你能看到的点的最大数目。\n示例 1输入：points = [[2,1],[2,2],[3,3]], angle = 90, location = [1,1] 2输出：3 3解释：阴影区域代表你的视野。在你的视野中，所有的点都清晰可见，尽管 [2,2] 和 [3,3]在同一条直线上，你仍然可以看到 [3,3] 。 1输入：points = [[2,1],[2,2],[3,4],[1,1]], angle = 90, location = [1,1] 2输出：4 3解释：在你的视野中，所有的点都清晰可见，包括你所在位置的那个点。 1输入：points = [[1,0],[2,1]], angle = 13, location = [1,1] 2输出：1 3解释：如图所示，你只能看到两点之一。 解答 好难嗷\nupdate：2021.12.18\n你的视野范围是有限的只能看到angle范围内的东西，给你一个位置和许多东西，你可以通过旋转来看这些东西，但是你必须站在这个位置不能移动。\n将所给的点全部转换为以location为原点的坐标，这样一来就很方便可以知道可以看到的点的位置了。\n但是有一个很坑的地方就是location和points中的point可能会重合，所以我们要对与location重合的点进行重新判断，这些点肯定是能看到的。\n剩下计算两个points中point的点位于location的极角，在这里又有一个很坑的地方，我们使用的方法atan2方法返回的极角范围如下\n当我们旋转到超过PI时，就不行了。这里可以将所有的极角同时+360°，这样可以保证极角是单调的。\n最后用窗口为angle来找到最终的结果\n代码 1int test(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; \u0026amp;points, int angle, vector\u0026lt;int\u0026gt; \u0026amp;location){ 2 // 与location重合的点个数 3 int sameCnt = 0; 4 vector\u0026lt;double\u0026gt; polarDegrees; 5 for (auto \u0026amp; point : points) { 6 if (point[0] == location[0] \u0026amp;\u0026amp; point[1] == location[1]) { 7 sameCnt++; 8 continue; 9 } 10 double degree = atan2(point[1] - location[1], point[0] - location[0]); 11 polarDegrees.emplace_back(degree); 12 } 13 // 将计算的极角排序 14 sort(polarDegrees.begin(), polarDegrees.end()); 15 16 int m = polarDegrees.size(); 17 for (int i = 0; i \u0026lt; m; ++i) { 18 polarDegrees.emplace_back(polarDegrees[i] + 2 * M_PI); 19 } 20 21 int maxCnt = 0; 22 int right = 0; 23 double degree = angle * M_PI / 180; 24 for (int i = 0; i \u0026lt; m; ++i) { 25 while (right \u0026lt; polarDegrees.size() \u0026amp;\u0026amp; polarDegrees[right] \u0026lt;= polarDegrees[i] + degree) { 26 right++; 27 } 28 maxCnt = max(maxCnt, right - i); 29 } 30 return maxCnt + sameCnt; 31 32} ","date":"2021-12-16","img":"","permalink":"/posts/5a04344/","series":["leetcode"],"tags":["困难","数学"],"title":"LeetCode-1610-可见点的最大数目"},{"categories":["LeetCode"],"content":"题目 有一组 n 个人作为实验对象，从 0 到 n - 1 编号，其中每个人都有不同数目的钱，以及不同程度的安静值（quietness）。为了方便起见，我们将编号为 x 的人简称为 \u0026ldquo;person x \u0026ldquo;。\n给你一个数组 richer ，其中 richer[i] = [ai, bi] 表示 person ai 比 person bi 更有钱。另给你一个整数数组 quiet ，其中 quiet[i] 是 person i 的安静值。richer 中所给出的数据 逻辑自洽（也就是说，在 person x 比 person y 更有钱的同时，不会出现 person y 比 person x 更有钱的情况 ）。\n现在，返回一个整数数组 answer 作为答案，其中 answer[x] = y 的前提是，在所有拥有的钱肯定不少于 person x 的人中，person y 是最安静的人（也就是安静值 quiet[y] 最小的人）。\n示例 1输入：richer = [[1,0],[2,1],[3,1],[3,7],[4,3],[5,3],[6,3]], quiet = [3,2,5,4,6,1,7,0] 2输出：[5,5,2,5,4,5,6,7] 3解释： 4answer[0] = 5， 5person 5 比 person 3 有更多的钱，person 3 比 person 1 有更多的钱，person 1 比 person 0 有更多的钱。 6唯一较为安静（有较低的安静值 quiet[x]）的人是 person 7， 7但是目前还不清楚他是否比 person 0 更有钱。 8answer[7] = 7， 9在所有拥有的钱肯定不少于 person 7 的人中（这可能包括 person 3，4，5，6 以及 7）， 10最安静（有较低安静值 quiet[x]）的人是 person 7。 11其他的答案也可以用类似的推理来解释。 1输入：richer = [], quiet = [0] 2输出：[0] 解答 在题目中，两个人之间有一个金钱高低的比较，并且每个人都有一定的安静值，我们可以这样来理解有人比你穷有人比你穷，无论他们穷还是富，都有一种特征低调（安静值）,题目给出两个人之间的贫富关系，你让找出一个人，他比x人富或一样富，但是他最低调（安静值最低）。\n根据题目给出的示例我们可以换出一张有向图，节点表示人的编号，节点的值表示这个人的低调程度，箭头指向的是比这个人穷的人。以示例1为例。\n比0富有的有0,1,2,3,4,5,6，其中最低调的是5\n比2富有的只有2，最低调也是2\n有了上述的模拟思路，我们只要将题目中给的信息转换为上图，然后对于每一个人，找到比他富的人中最低调就行。\n我们用邻接矩阵来保存上述信息moreRicher[i]表示比i富的人，用一个数组保存结果。只需要对每一个人进行深度遍历就行。\n1vector\u0026lt;int\u0026gt; loudAndRich(vector\u0026lt;vector\u0026lt;int\u0026gt; \u0026gt; richer, vector\u0026lt;int\u0026gt; quiet) { 2 // 构造一个领接矩阵来存比某个人更富有 3 // moreRicher[0] = {1,2} 4 // 就是1,2比0号更富有 5 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; moreRicer(quiet.size()); 6 //初始化 把所有比他富有的人构造出来 7 for (int i = 0; i \u0026lt; richer.size(); i++) { 8 // richer[i][1]是穷的一个 9 moreRicer[richer[i][1]].emplace_back(richer[i][0]); 10 } 11 vector\u0026lt;int\u0026gt; ans(quiet.size(), -1); 12 13 function\u0026lt;int(int)\u0026gt; dfs = [\u0026amp;](int x) { 14 // 如果这个人的符合题意要求已经找到 15 if (ans[x] != -1) { 16 return ans[x]; 17 } 18 // 起始和自己相比较 19 ans[x] = x; 20 for (int i = 0; i \u0026lt; moreRicer[x].size(); i++) { 21 int id = dfs(moreRicer[x][i]); 22 if (quiet[id] \u0026lt; quiet[ans[x]]) { 23 ans[x] = id; 24 } 25 } 26 return ans[x]; 27 }; 28 // 先处理没有人比他更富的人 29 30 for (int i = 0; i \u0026lt; quiet.size(); i++) { 31 // 如果没有比他更富的，结果就是他自己 32 if (moreRicer[i].empty()) { 33 ans[i] = i; 34 continue; 35 } 36 dfs(i); 37 } 38 return ans; 39} ","date":"2021-12-15","img":"","permalink":"/posts/3f29dc95/","series":["leetcode"],"tags":["中等","DFS"],"title":"LeetCode-851-喧闹和富有"},{"categories":["LeetCode"],"content":"题目 这里有 n 门不同的在线课程，按从 1 到 n 编号。给你一个数组 courses ，其中 courses[i] = [durationi, lastDayi] 表示第 i 门课将会 持续 上 durationi 天课，并且必须在不晚于 lastDayi 的时候完成。\n你的学期从第 1 天开始。且不能同时修读两门及两门以上的课程。\n返回你最多可以修读的课程数目。\n示例 1输入：courses = [[100, 200], [200, 1300], [1000, 1250], [2000, 3200]] 2输出：3 3解释： 4这里一共有 4 门课程，但是你最多可以修 3 门： 5首先，修第 1 门课，耗费 100 天，在第 100 天完成，在第 101 天开始下门课。 6第二，修第 3 门课，耗费 1000 天，在第 1100 天完成，在第 1101 天开始下门课程。 7第三，修第 2 门课，耗时 200 天，在第 1300 天完成。 8第 4 门课现在不能修，因为将会在第 3300 天完成它，这已经超出了关闭日期。 1输入：courses = [[1,2]] 2输出：1 1输入：courses = [[3,2],[4,3]] 2输出：0 解答 要尽可能多的课程被选择，我们优先选择结束时间最早的课程，这样才能保证前面的课程是能被选择的，光靠这个进行选择是不行的。例如：[1,2] 、[3, 4]、[2, 5]这三门课的时候，如果按照上述方法进行选择，那么结果是：选择第一个课程，在选择第二个课程时候截止时间到了，不行，只能选择第三号课程。我们观察可以发现，其实可以先选三号课程，在选择2号课程。也就是在上述条件的基础上，优先选择**学习时长更短(duration)**的课程。使用大根堆可以满足我们的要求，我们在选择课程的时候做一判断：\n如果总学习时间+当前课程的学习时间\u0026lt;该课程的结束时间，那么这个课可以选择； 如果不满足条件1，但是满足，在已经选择的课程中，最长的课程时间\u0026gt;当前的课程持续时间，那么就选择当前的课程，并把之前选择的最长的课程取消选择。 代码 1// 贪心，按照结束时间的进行升序排列 2sort(courses.begin(), courses.end(), [](const auto \u0026amp;c0, const auto \u0026amp;c1) { 3 return c0[1] \u0026lt; c1[1]; 4}); 5// 最长的持续时间在前面 6priority_queue\u0026lt;int\u0026gt; maxHeap; 7// 优先队列中所有课程的总时间 8int hadLearnedTime = 0; 9 10for (const auto \u0026amp;course: courses) { 11 int currentCourseDuration = course[0], currentCourseLastDay = course[1]; 12 //如果总时长不会超过截止时间，那么，当前这门课程可以选择，直接入堆 13 if (hadLearnedTime + currentCourseDuration \u0026lt;= currentCourseLastDay) { 14 hadLearnedTime += currentCourseDuration; 15 maxHeap.push(currentCourseDuration); 16 } else if (!maxHeap.empty() \u0026amp;\u0026amp; maxHeap.top() \u0026gt; currentCourseDuration) { 17 // 出现冲突，优先选择学习时长更短的课程 18 hadLearnedTime = hadLearnedTime - maxHeap.top() + currentCourseDuration; 19 maxHeap.pop(); 20 maxHeap.push(currentCourseDuration); 21 } 22} 23return maxHeap.size(); ","date":"2021-12-14","img":"","permalink":"/posts/52f591e7/","series":["leetcode"],"tags":["困难","贪心"],"title":"LeetCode-630-课程表3"},{"categories":["LeetCode"],"content":"题目 给你一座由 n x n 个街区组成的城市，每个街区都包含一座立方体建筑。给你一个下标从 0 开始的 n x n 整数矩阵 grid ，其中 grid[r][c] 表示坐落于 r 行 c 列的建筑物的 高度 。\n城市的 天际线 是从远处观察城市时，所有建筑物形成的外部轮廓。从东、南、西、北四个主要方向观测到的 天际线 可能不同。\n我们被允许为 任意数量的建筑物 的高度增加 任意增量（不同建筑物的增量可能不同） 。 高度为 0 的建筑物的高度也可以增加。然而，增加的建筑物高度 不能影响 从任何主要方向观察城市得到的 天际线 。\n在 不改变 从任何主要方向观测到的城市 天际线 的前提下，返回建筑物可以增加的 最大高度增量总和 。\n示例 1输入：grid = [[3,0,8,4],[2,4,5,7],[9,2,6,3],[0,3,1,0]] 2输出：35 3解释：建筑物的高度如上图中心所示。 4用红色绘制从不同方向观看得到的天际线。 5在不影响天际线的情况下，增加建筑物的高度： 6gridNew = [ [8, 4, 8, 7], 7 [7, 4, 7, 7], 8 [9, 4, 8, 7], 9 [3, 3, 3, 3] ] 1输入：grid = [[0,0,0],[0,0,0],[0,0,0]] 2输出：0 3解释：增加任何建筑物的高度都会导致天际线的变化。 解答 根据官方给的例子我们可以发现，从某个方位看过去的样子和这一个方位最低的没有关系，如示例1：我们从西边看过去是【8，7，9，3】\n题目的意思是：在不改变每一个方位看到的样子的前提下，尽可能多的给“楼层”增加高度，从东西看到的形状是“相同”的，从南北看到的形状是“相同”的。所以我们在添加楼层的时候受限制的就是每一行和每一列的最大值中的最小的一个。\n比如在grid[0][0]这个位置，这一行最高的是8，这一列最高的是9，那么他最高只能为8,如果为9，就会影响从东西看到的形状。\n我们只要找到每一行和每一列对应的最大值，之后对应位置的值为，这一行、这一列的最大值中的最小的一个。\n代码 1int maxIncreaseKeepingSkyline(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; \u0026amp;grid) { 2 int n = grid.size(); 3 vector\u0026lt;int\u0026gt; maxColumn; 4 vector\u0026lt;int\u0026gt; maxRow; 5 for (int i = 0; i \u0026lt; n; i++) { 6 int max = -1; 7 for (int j = 0; j \u0026lt; n; j++) { 8 if (grid[i][j] \u0026gt; max) { 9 max = grid[i][j]; 10 } 11 } 12 maxRow.emplace_back(max); 13 } 14 15 for (int i = 0; i \u0026lt; n; i++) { 16 int max = -1; 17 for (int j = 0; j \u0026lt; n; j++) { 18 if (grid[j][i] \u0026gt; max) { 19 max = grid[j][i]; 20 } 21 } 22 maxColumn.emplace_back(max); 23 } 24 int res = 0; 25 for (int i = 0; i \u0026lt; n; i++) { 26 for (int j = 0; j \u0026lt; n; j++) { 27 if (maxRow[i] \u0026lt; maxColumn[j]) { 28 res += (maxRow[i] - grid[i][j]); 29 } else { 30 res += (maxColumn[j] - grid[i][j]); 31 } 32 } 33 } 34 return res; 35 } 上面代码和下面代码的时间复杂度是一样的，但是能用一个循环解决。\n1int maxIncreaseKeepingSkyline(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; \u0026amp;grid) { 2 int n = grid.size(); 3 vector\u0026lt;int\u0026gt; maxColumn; 4 vector\u0026lt;int\u0026gt; maxRow; 5 for (int i = 0; i \u0026lt; n; i++) { 6 int maxRowTemp = -1; 7 int maxColumnTemp = -1; 8 for (int j = 0; j \u0026lt; n; j++) { 9 if (grid[i][j] \u0026gt; maxRowTemp) { 10 maxRowTemp = grid[i][j]; 11 } 12 if (grid[j][i] \u0026gt; maxColumnTemp) { 13 maxColumnTemp = grid[j][i]; 14 } 15 } 16 maxColumn.emplace_back(maxColumnTemp); 17 maxRow.emplace_back(maxRowTemp); 18 } 19 int res = 0; 20 for (int i = 0; i \u0026lt; n; i++) { 21 for (int j = 0; j \u0026lt; n; j++) { 22 if (maxRow[i] \u0026lt; maxColumn[j]) { 23 res += (maxRow[i] - grid[i][j]); 24 } else { 25 res += (maxColumn[j] - grid[i][j]); 26 } 27 } 28 } 29 return res; 30 } ","date":"2021-12-13","img":"","permalink":"/posts/9457eaea/","series":["leetcode"],"tags":["中等"],"title":"LeetCode-807-保持城市天际线"},{"categories":["计算机网络"],"content":"根据老师提供的范围整理的计算机网络原理的复习资料\n第一章 1-1计算机网络向用户可以提供哪些服务？ 信息交互服务 资源共享服务。 1-2试简述分组交换的要点。 采用存储转发技术 发送数据不在源和目的之间先建立一条物理的通路， 将要发送的报文分割为较小的数据段 将控制信息作为首部加在每个数据段前面（构成分组）一起发送给分组交换机。 每一个分组的首部都含有目的地址等控制信息。 分组交换网中的分组交换机根据分组首部中的控制信息，把分组转发到下一个分组交换机。 用这种存储转发方式将分组转发到达最终目的地 1-3试从建立连接、何时需要地址、是否独占链路、网络拥塞、数据是否会失序、端到 端时延的确定性、适用的数据传输类型等多个方面比较分组交换与电路交换的特点 1-7 小写和大写开头的英文名字 internet 和 Internet 在意思上有何重要区别？ 以小写字母i开始的 internet（互联网或互连网）是一个通用名词，它泛指由多个 计算机网络互连而成的网络。在这些网络之间的通信协议可以是任意的。 以大写字母 I 开始的 Internet（因特网）则是一个专用名词，它指当前全球最大的、开放 的、由众多网络相互连接而成的特定计算机网络，它采用 TCP/IP 协议族作为通信的规则。 1-13 计算机网络有哪些常用的性能指标？ 速率、带宽、吞吐量、时延、利用率\n1-14 收发两端之间的传输距离为1000 km，信号在媒体上的传播速率为2*10^8 m/s。试 计算以下两种情况的发送时延和传播时延。 （1）数据长度为 10^7bit，数据发送速率为 100 kbit/s;\n（2）数据长度为 10^3bit，数据发送速率为 1 Gbit/s。\n解答：(1) 发送时延为 100 s，传播时延为 5 ms。发送时延远大于传播时延。 (2) 发送时延为 1 µs，传播时延为 5 ms。发送时延远小于传播时延\n1-17 试述具有五层协议的网络体系结构的要点，包括各层的主要功能。 物理层：在物理媒体上传送比特流。具体包括：与物理媒体的接口、比特的表示与 同步、数据率、线路配置、物理拓扑等。\n数据链路层：在两个相邻结点间（主机和路由器或路由器和路由器之间）的链路上 传送以帧为单位的数据。具体包括：组帧、差错控制、物理编址、接入控制、流量控制等。\n网络层：负责将分组从源主机（按照合适的路由）通过中间若干路由器的转发传送 到目的主机。核心功能是逻辑编址、路由选择和分组转发。\n运输层：负责主机中两个进程之间的逻辑通信（端到端通信）。具体包括：复用与分用、可靠数据传输、流量控制、拥塞控制等。\n应用层：通过应用进程间的交互来实现特定网络应用，直接为用户或应用进程提供特定的应用服务，如文件传输、电子邮件等\n1-18 试解释以下名词：协议栈、实体、对等层、协议数据单元、客户、服务器、客户-服务器方式。 协议栈：指网络中各层协议的总和，其形象的反映了一个网络中文件传输的过程，由上层协议到底层协议，再由底层协议到上层协议。 实体：表示任何可发送或接收信息的硬件或软件进程。 对等层：通信双方实现同样功能的层。协议定义的就是对等层间的通信规则。 协议数据单元：OSI 参考模型把对等层次之间传送的数据单位称为该层的协议数据单元 （PDU）。 客户：在计算机网络中进行通信的应用进程中的服务请求方。 服务器：在计算机网络中进行通信的应用进程中的服务提供方。 客户-服务器方式：网络应用程序的工作方式。描述的是进程之间服务和被服务的关系。服务器总是 一直运行并被动等待通信，而客户总是主动发起通信。服务器可以同时处理多个客户的请求， 而客户程序之间不直接进行通信。 第二章 2-1 物理层要解决哪些问题？物理层协议的主要任务是什么？ 物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体。 因此物理层要考虑如何用电磁信号表示“1”或“0”； 考虑所采用的传输媒体的类型，如双绞线、同轴电缆、光缆等； 考虑与物理媒体之间接口，如插头的引脚数 目和排列等； 考虑每秒发送的比特数目，即数据率。 物理层协议的主要任务就是确定与传输媒体的接口有关的一些特性，即机械特性、电气特性、功能特性和过程特性。 2-4 试给出数据通信系统的模型并说明其主要组成构件的作用。 一个数据通信系统可划分为三大部分，即源系统（或发送端、发送方）、传输系统（或传输网络）和目的系统（或接收端、接收方）\n源系统一般包括以下两个部分\n源点：源点设备产生要传输的数据，例如，从 PC 的键盘输入汉字，PC 产生输出的数字 比特流。 发送器：通常源点生成的数字比特流要通过发送器编码后才能够在传输系统中进行传输。 典型的发送器就是调制器。 目的系统一般也包括以下两个部分：\n接收器：接收传输系统传送过来的信号，并把它转换为能够被目的设备处理的信息。典 型的接收器就是解调器，它把来自传输线路上的模拟信号进行解调，提取出在发送端置入的 消息，还原出发送端产生的数字比特流。 终点：终点设备从接收器获取传送来的数字比特流，然后进行信息输出。 2-5 请画出数据流 1 0 1 0 0 0 1 1 的不归零编码、曼彻斯特编码和差分曼彻斯特编码的波 形（从高电平开始）。 曼彻斯特编码：在中间都会发生跳变想下跳变表示1，向上跳变表示0\n查分曼彻斯特编码：码元的开始和上个码元的结束不同表示0,和上次码元一样表示1，中间时刻，信号都会发生跳变。\n2-7 假定某信道受奈氏准则限制的最高码元速率为 20000 码元/秒。如果采用幅移键控， 把码元的振幅划分为 16 个不同等级来传送，那么可以获得多高的数据率（b/s）？ 奈式准则：每赫带宽的理想低道通信的最高码元传输速率位每秒2个码元，每赫带宽的带通信道的最高码元传输速率位每秒1个码元。 ​\t16 个等级可以表达 4 位二进制数，每个码元可以表示 4 个比特，因此，可以获得 4*20000 b/s 的数据率。\n​\t8个等级可以表达 3 位二进制数，每个码元可以表示 3个比特，因此，可以获得 3*20000 b/s 的数据率。\n2-8 假定用 3 kHz 带宽的电话信道传送 64 kb/s 的数据，试问这个信道应具有多高的信噪比？ 香农公式： 信道的极限信息传输速率C = Wlog2(1+ S/N) 。\nW是信道宽度(单位：Hz) S：信道内所传信号的平均功率 N：信道内部的高斯噪声功率 S/N :信噪比 信噪比 = 2^(C/W)-1\n2-10 常用的传输媒体有哪几种？各有何特点？ 双绞线，用两根绝缘铜线扭在一起的通信媒体，绞合在一起是为了减少相邻导线的电磁 干扰。双绞线价格便宜，布线方便，主要用于电话用户线和局域网中。 同轴电缆，由内导体铜质芯线、绝缘层、网状编织的外导体屏蔽层以及保护塑料外层所 组成。比双绞线带宽高和更好的抗干扰特性。用在有线电视网的居民小区中。 光纤，是利用光导纤维传递光脉冲信号来进行通信，由于可见光的频率非常高（108MHz）， 因此一个光纤通信系统的传输带宽远远大于目前其他传输媒体的带宽。光纤通信容量大，传输损耗小，抗干扰和保密性能好。光纤通常用在主干网络中和高速局域网中。 无线传输媒体，即利用自由空间传播电磁波。当通信距离很远，或跨越复杂地理环境时， 铺设电缆既昂贵又费时，利用无线电波在自由空间传播，可以实现多种通信。无线传输所使用的频段很广。无线 传输媒体的最大缺点就是容易被干扰，保密性差。 2-11 为什么要使用信道复用技术？常用的信道复用技术有哪些？ 许多用户可以通过复用技术共同使用一个共享的信道来进行通信。当网络中传输 媒体的传输容量大于单一信道传输的通信量时，可利用复用技术在一条物理线路上建立多条通信信道来充分利用传输媒体的带宽。 常用的复用技术包括：频分复用、时分复用、波分复用、码分复用。 2-12 试写出下列英文缩写的全文，并进行简单的解释。 FDM，TDM，STDM，WDM，DWDM，CDMA，SONET，SDH，STM-1，OC-48 FDM(Frequency Division Multiplexing)频分复用，将传输线路的可用频带分割为若干条较窄的子频带，每一条子频带传输一路信号，从而实现在同一条线路上传输多路信号。\nTDM(Time Division Multiplexing)时分复用，将一条物理线路的传输时间分成若干个时间 片（时隙），按一定的次序轮流给各个信号源使用，从而实现在同一条线路上传输多路信号。\nSTDM(Statistic TDM)统计时分复用，又称为异步时分复用，将线路的传输时间按需动态 地分配给各个信号源，而不是给每个信号源分配固定的时隙。\nWDM(Wavelength Division Multiplexing)波分复用，就是光的频分复用，将不同波长的光 信号复用到同一根光纤上。\nDWDM(Dense WDM)密集波分复用，最初，人们只能在一根光纤上复用两路光载波信号。 这种复用方式称为波分复用 WDM。随着技术的发展，在一根光纤上复用的光载波信号的路 数越来越多。现在已能做到在一根光纤上复用几十路或更多路数的光载波信号。于是就使用 了密集波分复用 DWDM 这一名词。DWDM 的波长间隔很小，不到 2 nm。\nCDMA(Code Division Multiplex Access)码分多址，给每个用户分配一个唯一的正交码， 在发送端，不同用户的数据用该正交码编码后复用到同一信道进行传输；在接收端，用同一 正交码解码进行分用。CDMA 主要用于无线通信，具有很强的抗干扰能力。\nSONET(Synchronous Optical Network)同步光纤网，美国在 1988 年首先推出的一个在光 纤传输基础上的数字传输标准。整个同步网络的各级时钟都来自一个非常精确的主时钟。 SONET 为光纤传输系统定义了同步传输的线路速率等级结构，其传输速率以 51.84 Mbit/s 为基础。\nSDH(Synchronous Digital Hierarchy)同步数字系列，ITU-T 以美国标准 SONET 为基础制 定的国际标准，SDH 的基本速率为 155.52 Mbit/s。\nSTM-1(Synchronous Transfer Module-1)第 1 级同步传递模块，是 SDH 的一系列传输标准 之一，规定了 SDH 的基本速率为 155.52 Mbit/s。\nOC-48(Optical Carrier-48) 第 48 级光载波，是 SONET 的一系列传输标准之一，其速率是 SONET 第 1 级光载波 OC-1 速率（51.84 Mbit/s）的 48 倍，即 2488.32 Mbit/s。\n2-14 共有 4 个用户进行 CDMA 通信。 这 4 个用户的码片序列为：\nA: (–1 –1 –1 +1 +1 –1 +1 +1)； B: (–1 –1 +1 –1 +1 +1 +1 –1) C: (–1 +1 –1 +1 +1 +1 –1 –1)； D: (–1 +1 –1 –1 –1 –1 +1 –1) 现收到码片序列：(–1 +1 –3 +1 –1 –3 +1 +1)。问是哪些用户发送了数据？发送的是 1 还 是 0？\n(–1 +1 –3 +1 –1 –3 +1 +1)(–1 –1 –1 +1 +1 –1 +1 +1)/8:A 的内积为 1，\nB 的内积为–1，C 的内积为 0，D 的内积为 1。因此，A 和 D 发送 的是 1，B 发送的是 0，而 C 未发送数据。\n第三章 3-2 数据链路层包括哪些主要功能？试讨论数据链路层做成可靠的链路层有哪些优点和缺点。 主要功能包括：封装成帧、透明传输和差错检测，可选功能包括可靠传输、流量控制等。 优点是通过点到点的差错检测和重传能及时纠正相邻结点间传输数据的差错。 若在数据链路层不实现可靠传输由高层如运输层通过端到端的差错检测和重传来纠正这些差错会产生很大的重传时延。 但是在数据链路层实现可靠传输并不能保证端到端数据传输的可靠，如由于网络拥塞导 致路由器丢弃分组等。因此，即使数据链路层是可靠的，在高层如运输层仍然有必要实现端到端可靠传输。如果相邻结点间传输数据的差错率非常低，则在数据链路层重复实现可靠传 输就会给各结点增加过多不必要的负担。 3-3 网络适配器的作用是什么？网络适配器工作在哪一层？ 网络适配器的作用就是实现数据链路层和物理层的功能。 网络适配器工作在物理层和数据链路层。 适配器接收和发送各种帧时不使用计算机的 CPU。这时 CPU 可以处理其他任务。当适配器收到有差错的帧时，就把这个帧丢弃而不必通知计算机。 当适配器收到正确的帧时，它就使用中断来通知该计算机 并交付给协议栈中的网络层。 3-5 要发送的数据为 1101011011。采用 CRC 的生成多项式是 P(X) = X^4 + X +1 。 试求应 添加在数据后面的余数。 数据在传输过程中最后一个 1 变成了 0，问接收端能否发现？ 若数据在传输过程中最后两个 1 都变成了 0，问接收端能否发现？ 采用 CRC 检验后，数据链路层的传输是否就变成了可靠的传输？ 多项式告诉我们除数为多少、在原数据后面添几个0(最高项次数是几就添几个0)接下来做除法即可。\n根据 CRC 生成多项式，除数 P=10011。用 11010110110000，模 2 除 P，余数即CRC 检验序列为 1110。添加检验序列后为 11010110111110。\n数据（注意是数据，不包括检验序列）在传输过程 中最后一个 1 变成了 0，则接收方收到的数据为 11010110101110。除 P 得到的余数不为零 （0011），发现差错。\n若数据在传输过程中最后两个 1 都变成了 0，则接收方收到的数据为 11010110001110。 除 P 得到的余数也不为零（0101），发现差错。\n采用 CRC 检验仅能发现数据在传输过程中出现差错但并不能纠正差错，因此并不能实现可靠传输。\n3-14 一条链路传输带宽为 2 Mbps，长度为 10000 km，信号传播速率为 2.0 × 10^5 km/s， 分组大小为 100 B，忽略应答帧大小。如果采用停止等待协议，问最大吞吐率（实际可达的最高平均数据速率）是多少？信道利用率是多少？如果采用滑动窗口协议，要想达到最高吞吐率，发送窗口最小是多少？ 停止等待协议 传播时延 = 信道长度/信号传播速率 = 10000km/2*10^5km/s\n发送(传输)时延 = 数据大小/传输带宽 = 100B/2Mbit/s\n发送的一个周期的时间 = 2*传播时延+发送时延 = 100.4ms\n平均的最高速率 = 数据量/时间 = 100B/100.4ms = 7968bit/s\n信道利用率 = 实际数据速率/带宽频率 = 7968bit/s / 2 Mbps = 0.3984%\n滑动窗口 个数 = (周期长度)/(分组发送时间)=100.4ms/0.4ms=251。 所以，发送窗口最小为 251。\n3-15 假定卫星信道的数据率为 100 kbps，卫星信道的单程（即从发送方通过卫星到达接 收方）传输时延为 250 ms，每个数据帧长均为 2000 b，忽略误码、确认字长、首部和处理时间等开销，为达到传输的最大效率，帧的序号至少多少位？此时信道最高利用率是多少？ RTT=250×2ms=0.5s\n1 个帧的发送时间=2000b/100kbps= 20 × 10−3s。\n1 个帧发送完后经过 1 个单程延迟到达接收方，再经过 1 个单程延迟发送方收到应答， 从而可以继续发送，理想的情况是此时窗口信息刚发送完或还没有发送完。\n假设窗口值等于 x，令(2000bit×x)/(100kb/s)= 20 × 10−3s+RTT= 20 × 10−3s+0.5s=0.52s。 得 x=26。 若要取得最大信道利用率，窗口值是 26 即可。\n在此条件下，可以不间断地发送帧，所以 发送率保持在 100kbps。 由于 16\u0026lt;26\u0026lt;32，帧的顺序号应为 5 位。在使用后退 N 帧协议的情况下，最大窗口值是 31，大于 26，可以不间断地发送帧，此时信道利用率是 100%\n3-17 PPP 协议的主要特点是什么？为什么 PPP 不使用帧的编号？PPP 适用于什么情况？ 为什么 PPP 协议不能使数据链路层实现可靠传输？ PPP 协议的主要特点如下\n简单，数据链路层的 PPP 协议非常简单，具有封装成帧、透明传输和差错检测功能， 但向上不提供可靠传输服务。 支持多种网络层协议，PPP 协议能够在在同一条物理链路上同时支持多种网络层协议， 如 IP 和 IPX 等。 支持多种类型链路，PPP 协议能够在多种类型的链路上运行。例如，串行的或并行的， 同步的或异步的，低速的或高速的，电的或光的点对点链路。 检测连接状态，PPP 协议具有一种机制能够及时（不超过几分钟）自动检测出链路是 否处于正常工作状态。 网络层地址协商，PPP 协议提供了一种机制使通信的两个网络层（例如，两个 IP 层） 的实体能够通过协商知道或能够配置彼此的网络层地址。 帧的编号是可靠数据传输的基本机制，PPP 不使用帧的编号是因为 PPP 不实现可靠数据传输。\n由于 PPP 没有编号和确认机制因此不能实现可靠数据传输，适用于线路质量较好的情况。\n3-18 一个 PPP 帧的数据部分（用十六进制写出）是 7D 5E FE 27 7D 5D 7D 5D 65 7D 5E。 试问真正的数据是什么（用十六进制写出）？ 解答：转义符为 7D，7D 5E 还原为 7E，7D 5D 还原为 7D，真正的数据为：7E FE 27 7D 7D 65 7E\n3-19 PPP 协议使用同步传输技术传送比特串 0110111111111100。试问经过零比特填充后 变成怎样的比特串？若接收端收到的 PPP 帧的数据部分是 0001110111110111110110，问删除 发送端加入的零比特后变成怎样的比特串？ 比特填充法的具体做法是：在发送端，当一串比特流尚未加上标志字段时，先用硬件扫描整个帧。只要发现5个连续1，则立即填入一个0。因此经过这种零比特填充后的数据，就可以保证不会出现6个连续1。在接收一个帧时，先找到F字段以确定帧的边界。接着再用硬件对其中的比特流进行扫描。每当发现5个连续1时，就将这5个连续1后的一个0删除，以还原成原来的比特流。\n解答：填充比特后为 011011111[0]11111[0]00（[]中是填充的比特）。删除比特后为 000111011111[0]11111[0]110（[]中是删除的比特）\n3-27 假定 1 km 长的 CSMA/CD 网络的数据率为 1 Gbit/s。设信号在网络上的传播速率为 200000 km/s。求能够使用此协议的最短帧长。 最小帧长 = 争用期*数据传输速率\n争用期 ：发送放到接收方再从接收方到发送方所经历的时间\n解答：端到端往返时延为(2 km) / (200000 km/s) = 10 µs，\n因此只有发送时延大于该往返时延才能保证检测出所有可能的碰撞。即，最短帧长为(1 Gbit/s)× (10 µs) = 10000 bit，即 1250 字节。\n3-39 以太网交换机有何特点？用它怎样组成虚拟局域网？ 特点 以太网交换机实质上就是一个多接口网桥，和工作在物理层的转发器和集线器有很大的差别。\n以太网交换机的每个接口通常都直接与一个单个主机或另一个交换机相连，并且一般都工作在全双工方式。当主机需要通信时，交换机能同时连通许多对的接口， 使每一对相互通信的主机都能像独占通信媒体那样，无碰撞地传输数据。\n是一种即插即用设备，其内部的帧转发表也是通过自学习算法自动地逐渐建立起来的，能够隔离碰撞但转发所有的广播帧。\n以太网交换机由于使用了专用的交换结构芯片，其交换速率就较高。\n组成虚拟局域网 虚拟局域网 VLAN 是由一些局域网网段构成的与物理位置无关的逻辑组。利用以太网交换机可以很方便地实现虚拟局域网 VLAN，连接到同一交换机的不同主机可以被划分到不同 的 VLAN 中（最常用的技术是根据交换机的端口来划分 VLAN），这些 VLAN 在逻辑上看起 来就像一些独立的 LAN，互相不能直接通信。当 VLAN 跨越多个交换机时，需要在以太网 的帧格式中插入一个 4 字节的标识符，称为 VLAN 标记(tag)，指明发送该帧的主机属于哪 一个 VLAN。\n3-40 网桥的工作原理和特点是什么？网桥与转发器以及以太网交换机有何异同？ 网桥工作在数据链路层，根据 MAC 帧的目的地址向目的主机所连接的端口进行转发，采用存储转发方式，转发时在接口执行 CSMA/CD 协议。网桥能隔离碰撞域，但转发所有的广播帧。\n网桥与转发器最大的区别就是工作的层次不同。网桥工作在数据链路层，根据 MAC 帧 的目的 MAC 地址进行转发；而转发器工作在物理层，用于连接电缆扩大网络覆盖范围，转 发器仅仅将一个端口输入的信号放大整形转发到另一个端口，并不识别帧，也不执行 CSMA/CD 协议。 以太网交换机实质上就是一个多接口网桥，通常直接与主机或另一个交换机相连，并且 一般都工作在全双工方式。而网桥通常用于将两个独立的局域网网段连接成一个局域网。\n3-41 下图表示有五个站分别连接在三个局域网上，并且用网桥 B1 和 B2 连接起来。 每一个网桥都有两个接口（1 和 2）。在一开始，两个网桥中的转发表都是空的。以后有以下 各站向其他的站发送了数据帧：A 发送给 E，C 发送给 B，D 发送给 C，B 发送给 A。试把有 关数据填写在表 3-3 中。\n解答\n3-45 无线局域网的 MAC 协议有哪些特点？为什么在无线局域网中不能使用 CSMA/CD 协议而必须使用 CSMA/CA 协议？结合隐蔽站问题说明 RTS 帧和 CTS 帧的作用。\n无线局域网的 MAC 协议是 CSMA/CA（载波监听多点接入/碰撞避免）。\n不使用 CSMA/CD 的原因是：\n要实现碰撞检测，就必须在发送信号的同时接收也接收信号。这 对于有线网络是很容易的事，但在无线网络中，接收信号的强度会远远小于发送信号的强度， 因此实现碰撞检测的代价较大。 另一方面，即使实现了碰撞检测，但由于隐蔽站问题发 送站也无法检测到所有的碰撞。因此，无线局域网不使用 CSMA/CD 协议而是使用 CSMA/CA 协议，尽可能减少碰撞。由于不可能避免所有的碰撞，CSMA/CA 通过确认机制实现可靠数 据传输。 无线局域网的 MAC 协议的特点是：\n由于不实现碰撞检测，要尽可能减少碰撞。因此 在监听信道时，若信道忙要执行退避算法，而不是像 CSMA/CD 一直坚持监听直到信道空闲。 由于不可能避免所有的碰撞，同时无线信道误码率比较高，无线局域网的 MAC 协议采用 停止等待协议，保证数据链路层数据传输的可靠性。 为进一步减少碰撞的概率，还采用 了虚拟载波监听机制，让源站把它要占用信道的时间（包括目的站发回确认帧所需的时间） 及时通知给所有其他站，以便使其他所有站在这一段时间都停止发送数据，这样就大大减少 了碰撞的机会。 标准规定了不同长度的帧间间隔。高优先级帧需要等待的时间较短，低优先级帧等待的时间较长。若低优先级帧还没来得及发送而其他站的高优先级帧已发送到媒 体，则媒体变为忙态因而低优先级帧就只能再推迟发送了。这样就减少了发生碰撞的机会。 隐蔽站问题如下图所示，站 A 和 C 同时向 B 发送数据。但 A 和 C 相距较远，彼此都接 收不到对方发送的信号。当 A 和 C 都检测不到对方的无线信号时，就认为现在无线信道是 空闲的，因而都向 B 发送数据。结果 B 同时收到 A 和 C 发来的数据，发生了碰撞。可见， 在无线局域网中，即使在发送数据前未检测到传输媒体上有信号，也不能保证数据能够发送 成功。为了更好地解决隐蔽站带来的碰撞问题，802.11 允许要发送数据的站对信道进行预约。 源站（如 A）争取到信道后在发送数据帧之前先发送一个短的控制帧，叫做请求发送 RTS （Request To Send），它包括源地址、目的地址和这次通信（包括相应的确认帧）所需的持续 时间。若目的站（如 B）正确收到源站发来的 RTS 帧，且媒体空闲，就发送一个响应控制 帧，叫做允许发送 CTS (Clear To Send)，它也包括这次通信所需的持续时间（从 RTS 帧中将 此持续时间复制到 CTS 帧中）。源站收到 CTS 帧后，再等待一段时间 SIFS 后发送其数据帧。 若目的站正确收到了源站发来的数据帧，在等待时间 SIFS 后，就向源站发送确认帧 ACK。 在 A 的作用范围内的所有其他站监听到 RTS 后，执行虚拟载波监听，在 A 和 B 通信期间不 会发送数据。在 A 的作用范围外，但在 B 的作用范围内的其他站（如 C），虽然收不到 A 的 RTS，但能收到 B 的 CTS，因此 C 知道 A 和 B 将要通信，并在 A 和 B 通信期间也不会发送 数据。 第四章 4-1 网络层向上提供的服务有哪两种？试比较其优缺点 提供的服务：面向连接的虚电路服务和无连接的数据报服务。\n对比的方面 虚电路服务 数据报服务 思路 可靠通信应当由网络来保证 可靠通信应当由用户主机来保证 连接的建立 必须有 不需要 终点地址 仅在连接建立阶段使用，每个 分组使用短的虚电路号 每个分组都有终点的完整地址 分组的转发 属于同一条虚电路的分组均按 照同一路由进行转发 每个分组独立选择路由进行转发 当结点出故障时 所有通过出故障的结点的虚电路均不能工作 出故障的结点可能会丢失分组，一些路由可能会发生变化 分组的顺序 总是按发送顺序到达终点 到达终点时不一定按发送顺序 端到端的差错处理和流量控制 可以由网络负责，也可以由用 户主机负责 由用户主机负责 4-6 作为中间设备，转发器、网桥、路由器和网关有何区别？ 物理层使用的中间设备叫做转发器(repeater)。 数据链路层使用的中间设备叫做网桥或桥接器(bridge)。 网络层使用的中间设备叫做路由器(router)。 在网络层以上使用的中间设备叫做网关(gateway)。用网关连接两个不兼容的系 统需要在高层进行协议的转换。 4-7 试简单说明下列协议的作用： IP, ARP 和 ICMP。\n网际协议 IP 用于互连异构网络，运行在主机和互连异构网络的路由器上，使这些 互连的异构网络在网络层上看起来好像是一个统一的网络。 地址解析协议 ARP 用来把一个机器的 IP 地址解析为相应的物理地址。 互联网控制报文协议 ICMP 允许主机或路由器报告差错情况和提供有关异常情况的报告。 4-9 分类 IP 地址分为哪几类？各如何表示？IP 地址的主要特点是什么？ IP 地址分为五类：\nA 类地址：网络号前 8 位，第 1 位为 0； [0-127] B 类地址：网络号前 16 位，前 2 位为 10； [128-191] C 类地址：网络号前 24 位，前 3 位为 110； [192-223] D 类地址：网络号前 32位，多播地址、前 4 位为 1110； [224-239] E 类地址：网络号前 32位，保留为今后使用、前 4 位为 1111。 [240-255] IP 地址具有以下一些重要特点：\n每一个 IP 地址都由网络号和主机号两部分组成。从这个意义上说，IP 地址是一种分 等级的地址结构。 实际上 IP 地址是标志一个主机（或路由器）和一条链路的接口。 按照因特网的观点，一个网络是指具有相同网络号 net-id 的主机的集合，因此，用 转发器或网桥连接起来的若干个局域网仍为一个网络，因为这些局域网都具有同样的网络号。 具有不同网络号的局域网必须使用路由器进行互连。 在 IP 地址中，所有分配到网络号的网络(不管是范围很小的局域网，还是可能覆盖很大地理范围的广域网)都是平等的。 4-10 对于分类编址方式，分别计算 A、B、C 三类网络各自可容纳的主机数量。 A:16777214; B:65534; C:254 4-12 试辨认分类编址方式中以下 IP 地址的网络类别。 (1) 128.36.199.3\n(2) 21.12.240.17\n(3) 183.194.76.253\n(4) 192.12.69.248\n(5) 89.3.0.1\n(6) 200.3.6.2\n(2)和(5)是 A 类，(1)和(3)是 B 类，(4)和(6)是 C 类。\n4-21 某单位分配到地址块 129.250.0.0/20。该单位有 4000 台机器，平均分布在 16 个不 同的地点。试给每一个地点分配一个网络地址和子网掩码，并算出每个地点能分配给主机的 IP 地址的最小值和最大值。 给每一个地点分配子网掩码 255.255.255.0，每个子网有 254 个可分配地址。4000 多台计算机分布在 16 不同地点，所以每个地点最多 254 台电脑。每个地点的网络前缀和主机 IP 地址的最小值和最大值为: 129.250.0.0/24: 129.250.0.1~129.250.0.254\n129.250.1.0/24: 129.250.1.1~129.250.1.254\n129.250.2.0/24: 129.250.2.1~129.250.2.254\n129.250.3.0/24: 129.250.3.1~129.250.3.254\n…………………………………\n129.250.15.0/24: 129.250.15.1~129.250.15.25\n4-25 有如下的 4 个/24 地址块，试进行最大可能的聚合。 212.56.132.0/24 212.56.133.0/24 212.56.134.0/24 212.56.135.0/24 共同的前缀有 22 位，即：11010100 00111000 1000001。 聚合的 CIDR 地址块是：212.56.132.0/22\n4-26 某主机的 IP 地址是 227.82.157.177/20。试问该主机所连接的网络的网络前缀是什 么？该网络的网络地址是什么？主机号占多少位？主机号的二进制表示是什么？ 网络前缀是：11100011 01010010 1001，或用十进制表示为：227.82.144.0/20。\n网络地址是：11100011 01010010 10010000 00000000，或用十进制表示为：227.82.144.0。\n主机号占 12 位，其二进制这表示是：1101 10110001。\n4-27 设某路由器建立了如表 4-8 所示的路由表（这三列分别是目的网络、子网掩码和下 一跳路由器，若直接交付则最后一列表示应当从哪一个接口转发出去） 现共收到 5 个分组，其目的站 IP 地址分别为：\n(1) 128.96.39.10\n(2) 128.96.40.12\n(3) 128.96.40.151\n(4) 192.4.153.17\n(5) 192.4.153.90\n试分别计算这些分组转发的下一跳。\n用目的站和子网掩码做与运算，如果结果为对应的目的网络，那么下一跳就是那一个。\n注意：第3小问\n(1)接口 0; (2) R2; (3) R4; (4) R3; (5) R4。\n4-28 考虑某路由器具有下列路由表项: 网络前缀 下一跳 142.150.64.0/24 A 142.150.71.128/28 B 142.150.71.128/30 C 142.150.0.0/16 D （1）假设路由器接收到一个目的地址为 142.150.71.132 的 IP 分组，请确定该路由器为该 IP 分组选择的下一跳，并解释说明。\n（2）在上面的路由表中增加一条路由表项，该路由表项使以 142.150.71.132 为目的地址 的 IP 分组选择“A”作为下一跳，而不影响其他目的地址的 IP 分组转发。\n（3）在上面的路由表中增加一条路由表项，使所有目的地址与该路由表中路由表项 都不匹配的 IP 分组被转发到下一跳“E”。\n（4）将 142.150.64.0/24 划分为 4 个规模尽可能大的等长子网，给出子网掩码及每个子网 的主机 IP 地址范围。\n解答：\n（1）B；与上一题相同\n（2）\u0026lt;142.150.71.132/32, A\u0026gt;；唯一确定这个ip就是在哪\n（3）\u0026lt;0.0.0.0/0, E\u0026gt;； 默认路由\n（4）子网掩码 255.255.255.192，\n142.150.64.1~142.150.64.62,\n142.150.64.65~142.150.64.126,\n142.150.64.129~142.150.64.190,\n142.150.64.193~142.150.64.254\n4-29 如图 4-57 所示，某单位有两个局域网（各有 120 台计算机），通过路由器 R2 连接 到因特网，现获得地址块 108.112.1.0/24，为这两个局域网分配 CIDR 地址块，并为路由器 R2 的接口 1、接口 2 分配地址（分配最小地址）。配置 R2 的路由表（目的地址，子网掩码， 下一跳），在 R1 的路由表中增加一条项目使该单位的网络获得正确路由。 解答：\nLAN1: 108.112.1.0/25;\nLAN2: 108.112.1.128/25;\n接口 1: 108.112.1.1;\n接口 2: 108.112.1.129（或 LAN1，LAN2 互换） 不会\n4-31 已知某地址块中的一个地址是 140.120.84.24/20。试问该地址块中的第一个地址是 什么？这个地址块共包含有多少个地址？最后一个地址是什么？ 解答：第一个地址：140.120.80.0。地址块中的地址数是 4096 个。最后一个地址： 140.120.95.255。\n4-32 某主机的 IP 地址为 140.252.20.68，子网掩码为 255.255.255.224，计算该主机所在 子网的网络前缀（采用 CIDR 地址表示法 a.b.c.d/x），该子网的地址空间大小和地址范围（含 特殊地址）。 解答：140.252.20.64/27，32, 140.252.20.64 至 140.252.20.95\n4-33 某组织分配到一个地址块，其中的第一个地址是 14.24.74.0/24。这个组织需要划分为 11 个子网。具体要求是：具有 64 个地址的子网 2 个；具有 32 个地址的子网 2 个；具有 16 个地址的子网 3 个；具有 4 个地址的子网 4 个（这里的地址都包含全 1 和全 0 的主机号）。 试设计这些子网。分配结束后还剩下多少个地址？ 具有 64 个地址的子网是：14.24.74.0/26，14.24.74.64/26。\n具有 32 个地址的子网是：14.24.74.128/27，14.24.74.160/27。\n具有 16 个地址的子网是：14.24.74.192/28，14.24.74.208/28，14.24.74.224/28。\n具有 4 个地址的子网是：14.24.74.240/30，14.24.74.244/30，14.24.74.248/30，14.24.74.252/30。\n全部 256 个地址已经分配完毕，没有剩下的地址。\n4-34 以下地址中的哪一个和 86.32/12 匹配？请说明理由。 (1) 86.33.224.123; (2) 86.79.65.216; (3) 86.58.119.74; (4) 86.68.206.154。\n只需要判断网络位是否大于 86.32即可。\n解答：只有(1)是匹配的。\n4-35 以下的地址前缀中的哪一个地址和 2.52.90.140 匹配？请说明理由。 (1) 0/4; (2) 32/4; (3) 4/6; (4) 80/4。\n只有(1)是匹配的\n4-37 考虑 RIP，假定网络中的路由器 B 的路由表有如下的项目（目的网络、距离、下 一跳） N1 7 A N2 2 C N6 8 F N8 4 E N9 4 F 现在 B 收到从 C 发来的路由信息（目的网络、距离）: (N2, 4)、(N3, 8)、(N6, 4)、(N8, 3)、 (N9, 5)，试求路由器 B 更新后的路由表（详细说明每项的原因。\n更新原则：\n添加没有的路由 替换距离长的路由 更新过时的路由 解答：\n写出收到的C的通告信息\nN2 4 C N3 8 C N6 4 C N8 3 C N9 5 C 看C的通告和原来B的路由表。\nN1新的，增加\nN2下一跳相同（一定要+1因为B到C还有一跳），更新\nN3新的，增加\nN6下一跳不同，但是距离更短，替换（+1跳）\nN8 距离相同，不更新\nN9新的距离更大，不更新\nN1 7 A 无新信息，不变 N2 5 C 相同下一跳，更新 N3 9 C 新项目，增加 N6 5 C 不同下一跳，距离更短，更 N8 4 E 不同下一跳，距离一样，不变 N9 4 F 不同下一跳，距离更大，不变 4-38 考虑 RIP，假定网络中的路由器 A 的路由表有如下的项目（目的网络、距离、下 一跳） N1 4 B N2 2 C N3 1 F N4 5 G 现在 A 收到从 C 发来的路由信息（目的网络、距离）: (N1, 2)、(N2, 1)、(N3, 3)、(N4, 7)， 试求路由器 A 更新后的路由表（详细说明每项的原因）。\n解答：\nN1 4 B 不同下一跳，距离更短，更新 N2 2 C 相同下一跳，距离一样，不变 N3 1 F 不同下一跳，距离更大，不变 N4 5 G 不同下一跳，距离更大，不变 第五章 5-1 试说明运输层在协议栈中的地位和作用。运输层的通信和网络层的通信有什么重要区别？ 从通信和信息处理的角度看，运输层向它上面的应用层提供端到端通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最低层。\n当位于网络边缘部分的两台主 机使用网络核心部分的功能进行端到端的通信时，只有主机的协议栈才有运输层，而网络核 心部分中的路由器在转发分组时都只用到下三层的功能。\n虽然网络层实现了主机到主机的逻辑通信，但严格地讲，通信的真正端点并不是主机而 是主机中的进程。\n因此，运输层在网络层之上提供应用进程间的逻辑通信。\n5-2 当应用程序使用面向连接的 TCP 和无连接的 IP 时，这种传输是面向连接的还是无 连接的？ 从网络层看是无连接的，但从运输层看是面向连接的。\n5-3 接收方收到有差错的 UDP 用户数据报时应如何处理？ 解答：丢弃且不通知发送方。\n5-4 在“滑动窗口”概念中，“发送窗口”和“接收窗口”的作用是什么？如果接收方 的接收能力不断地发生变化，则采取何种措施可以提高协议的效率。 “发送窗口”作用是限制发送方连续发送数据的数量，即控制发送方发送数据的 平均速率。“接收窗口”反映了接收方当前接收缓存的大小，即接收方接收能力的大小。\n当接 收方的接收能力不断地发生变化时，可以将接收窗口的大小发送给发送方，调节发送方的发 送速率，避免因发送方发送速率太大或太小而导致接收缓存的溢出或带宽的浪费，从而提高 协议的效率。\n5-5 简述 TCP 和 UDP 的主要区别。 TCP 提供的是面向连接、可靠字的字节流服务，并且有流量控制和拥塞控制功能。 UDP 提供的是无连接、不可靠的数据报服务，无流量控制和拥塞控制。\n5-9 试用具体例子说明为什么在运输连接建立时要使用三次联络。说明如不这样做可能 会出现什么情况。 这主要是为了防止已失效的连接请求报文段突然又传送到了 TCP 服务器，导致建 立错误的连接而浪费资源，如图所示。\n5-15 设 TCP 使用的最大窗口为 64 KB，即 64 × 1024 字节，而传输信道的带宽可认为是 不受限制的。若报文段的平均往返时延为 20 ms，问所能得到的最大吞量是多少？ (64×1024×8)/(20×10^-3 ) = 26.2×10^6 = 26.2 Mbit/s。\n5-32 简述 TCP 流量控制和拥塞控制的不同。 流量控制解决因发送方发送数据太快而导致接收方来不及接收使接收方缓存溢出 的问题。\n流量控制的基本方法就接收方根据自己的接收能力控制发送方的发送速率。\nTCP 采 用接收方控制发送方发送窗口大小的方法来实现在 TCP 连接上的流量控制。 拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过 载。\nTCP 的发送方维持一个叫做拥塞窗口的状态变量。拥塞窗口的大小取决于网络的拥塞程 度，当网络拥塞时减小拥塞窗口的大小，控制 TCP 发送方的发送速率。\nTCP 发送方的发送窗 口大小取接收窗口和拥塞窗口的最小值。\n5-33 在 TCP 的拥塞控制中，什么是慢开始、拥塞避免、快速重传和快速恢复算法？这 里每一种算法各起什么作用？“加性增”和“乘性减”各用在什么情况下？ 慢开始就是当主机刚开始发送数据时完全不知到网络的拥塞情况，将拥塞窗口设 为很小，当收到确认时，由小到大逐渐增大发送方的拥塞窗口数值。\n在慢开始阶段发送速率以指数方式迅速增长，若持续以该速度增长发送速率必然导致网 络很快进入拥塞状态。因此需要设置一个状态变量，即慢开始门限 ssthresh，当拥塞窗口大于 该门限时，进入拥塞避免阶段，降低发送速率的增长速率（以线性方式增长），避免网络拥塞。\n快速重传就是当发送方收到 3 个冗余确认时，就认为现在可能是网络出现了拥塞造成分 组丢失，就立即重传确认号指示的报文段，而不必继续等待超时。\n快速恢复就是，当发送方收到连续三个重复的 ACK 时，虽然有可能丢失了一些分组， 但这连续的三个重复 ACK 同时又表明丢失分组以外的另外三个分组已经被接收方接收了。 因此，与发生超时事件的情况不同，网络还有一定的分组交付能力，拥塞情况并不严重，直 接执行拥塞避免算法。\n采用快速恢复算法的情况下，长时间的 TCP 连接在稳定的时候通常处于下面描述的重复 状态。经过慢启动发送方迅速进入拥塞避免阶段，在该阶段，使拥塞窗口呈线性增长，即“加 性增”，发送速率缓慢增长，以防止网络过早出现拥塞。当流量逐渐超过网络可用带宽时会出 现拥塞，但由于发送速率增长缓慢，通常仅导致少量分组丢失。这种情况下发送方会收到 3 个重复 ACK 并将拥塞窗口减半，即“乘性减”，然后再继续执行“加性增”缓慢增长发送速 率，如此重复下去。\n第六章 6-1 简述应用层协议定义的内容。 (1)交换的报文类型，如请求报文和响应报文；\n(2)各种报文类型的语法，如报文中的各个字段及其详细描述；\n(3)字段的语义，即包含在字段中的信息的含义；\n(4)进程何时，如何发送报文及对报文进行响应。\n6-2 因特网的域名结构是怎样的？这样的结构有什么优点？ 因特网采用层次树状结构的命名方法，任何一个连接在因特网上的主机或路由器， 都有一个唯一的层次结构的名字，即域名(domain name)。这里，“域”（domain)是名字空间中 一个可被管理的划分。域还可以继续划分为子域，如二级域、三级域等等。域名的结构由若 干个分量组成，各分量之间用点（请注意，是小数点的点）隔开。各分量分别代表不同级别 的域名。每一级的域名都由英文字母和数字组成（不超过 63 个字符，并且不区分大小写字母）， 级别最低的域名写在最左边，而级别最高的顶级域名则写在最右边。\n因特网域名的层次结构便于管理，等级的命名方法便于维护名字的唯一性。同时针对层 次结构容易设计出高效的域名查询机制。\n6-6 DNS 有哪两种域名解析方式，简述这两种方式区别和特点。 递归查询: 被请求的域名服务器负责域名的解析，当被请求者自己无法解析时， 代替请求者查询，服务器负担重。\n迭代查询: 被请求的服务器不能解析时仅返回另一个服务器的域名和地址，让请求者自 己重新查询，即回答“我不知道这个名字, 请问这个服务器吧！”。请求这负担重。\n6-10 解释以下名词。各英文缩写词的原文是什么？ WWW (World Wide Web)是万维网的英文缩写。万维网并非某种特殊的计算机网络。万 维网是一个大规模的、联机式的信息储藏所，现在经常只用一个英文字 Web 来表示万维网。 万维网利用网页之间的链接（或称为超链接，即到另一个网页的指针）将不同网站的网页链 接成一张逻辑上的信息网，从而用户可以方便地从因特网上的一个站点访问另一个站点，主动地按需获取丰富的信息。\nURL (Uniform Resource Locator)是统一资源定位符的英文缩写。万维网使用 URL 来标志 万维网上的各种文档，并使每一个文档在整个因特网的范围内具有唯一的标识符 URL。\nHTTP (HyperText Transfer Protocol) 是超文本传送协议的英文缩写。HTTP 是浏览器与万 维网服务器之间的交互所遵守的协议。HTTP 是一个应用层协议，它使用 TCP 连接进行可靠 的传送。\nHTML (HyperText Markup Language)是超文本标记语言的英文缩写。使得万维网页面的 制作者可以很方便地用超链接从本页面的某处链接到因特网上的任何一个万万维网页面，并 且制作出来页面能够在任何浏览器的窗口中显示。\n浏览器是在万维网客户程序，用来向 Web 服务器请求页面，并向用户显示从 Web 服务 器请求的页面。\n超文本由多个信息源链接成，而这些信息源的数目实际上是不受限制的。利用一个链接 可使用户找到另一个文档，而这又可链接到其他的文档（依次类推）。这些文档可以位于世界 上任何一个接在因特网上的超文本系统中。超文本是万维网的基础。\n超媒体与超文本的区别是文档内容不同。超文本文档仅包含文本信息，而超媒体文档还 包含其他多媒体对象，如图形、图像、声音、动画，甚至活动视频图像。\n超链就是超文本的链接，超链是隐藏在页面文字或图片后面的 URL，该 URL 指向另一 个页面或文件，通常与超链关联文字是用特殊方式显示的（例如用不同的颜色，或添加了下 划线），而当我们将鼠标移动到这些地方时，鼠标的箭头就变成了一只手的形状。\n页面就是显示在浏览器中的万维网文档，也称为网页。\n动态文档是指文档的内容是在浏览器访问万维网服务器时才由应用程序动态创建的。\n活动文档是一种能提供页面连续变化而无需不断请求服务器的技术。实际上一个活动文 档就是一段程序或嵌入了程序脚本的 HTML 文档。活动文档中的程序可以在浏览器运行，从 而产生页面的变化（例如弹出下拉菜单或显示动画等）\n6-20 试简述 SMTP 通信的三个阶段的过程。 连接建立。发件人的邮件送到发送方邮件服务器的邮件缓存后，SMTP 客户就每隔一 定时间对邮件缓存扫描一次。如发现有邮件，就使用 SMTP 的熟知端口号码(25)与接收方邮 件服务器的 SMTP 服务器建立 TCP 连接。 邮件传送。邮件的传送从 MAIL 命令开始。MAIL 命令后面有发件人的地址。下面跟 着一个或多个 RCPT 命令，取决于把同一个邮件发送给一个或多个收件人。RCPT 命令的作 用就是：先弄清接收方系统是否已做好接收邮件的准备，然后才发送邮件。再下面就是 DATA 命令，表示要开始传送邮件的内容了。 连接释放。邮件发送完毕后，SMTP 客户应发送 QUIT 命令。SMTP 若同意释放 TCP 连接，邮件传送的全部过程即结束。 6-21 试述邮局协议 POP 的工作过程。在电子邮件中，为什么必须使用 POP 和 SMTP 这 两个协议？IMAP 与 POP 有何区别？ 由于 SMTP 是一种“推”协议，不能用来完成读取邮件这样“拉”的任务，发送 邮件是客户主动将邮件“推送”到邮件服务器的过程，而接收邮件是客户主动从邮件服务器 “拉取”邮件的过程。因此 SMTP 协议用来发送电子邮件，而 POP 协议用来读取电子邮件。\n邮局协议 POP 是一个非常简单、但功能有限的邮件读取协议。当用户需要从邮件服务器 的邮箱中下载电子邮件时，客户就开始读取邮件。客户（用户代理）在 TCP 端口 110 打开到 服务器的连接。它然后发送用户名和口令，访问邮箱。用户可以列出邮箱中的邮件清单，并 逐个读取邮件文件。\nPOP3 有两种工作方式：下载并删除方式和下载并保留方式。下载并删除方式就是在每 一次读取邮件后就把邮箱中的这个邮件删除。保存方式就是在读取邮件后仍然在邮箱中保存 这个邮件。删除方式通常用在用户使用固定计算机工作的情况，用户在本地计算机中保存和 管理所收到的邮件。下载并保留方式允许在不同的计算机上多次读取同一邮件。\n虽然 POP3 提供了下载并保留方式，但它不允许用户在服务器上管理他的邮件，例如创 建文件夹，对邮件进行分类管理等。因此 POP3 用户代理采用的主要模式是将所有邮件下载 到本地进行管理。这种方式对于经常使用不同计算机上网的移动用户来说是非常不方便的。\n另一个读取邮件的协议是因特网报文存取协议 IMAP。在使用 IMAP 时，在用户的 PC 上运行 IMAP 客户程序，然后与接收方的邮件服务器上的 IMAP 服务器程序建立 TCP 连接。 用户在自己的 PC 上就可以操纵邮件服务器的邮箱，就像在本地操纵一样，因此 IMAP 是一 个联机协议。用户可以根据需要为自己的邮箱创建便于分类管理的层次式的邮箱文件夹，并 且能够将存放的邮件从某一个文件夹中移动到另一个文件夹中。用户也可按某种条件对邮件 进行查找。在用户未发出删除邮件的命令之前，IMAP 服务器邮箱中的邮件一直保存着。这 样就省去了用户 PC 硬盘上的大量存储空间。\nIMAP 最大的好处就是用户可以在不同的地方使用不同的计算机（例如，使用办公室的 计算机、或家中的计算机，或在外地使用笔记本计算机）随时上网阅读和处理自己的邮件。\n6-27 文件传送协议 FTP 的主要工作过程是怎样的？主进程和从属进程各起什么作用？ FTP 基于客户/服务器体系结构。一个 FTP 服务器进程可同时为多个客户进程提供 服务。FTP 的服务器进程由两大部分组成：一个主进程，负责接受新的请求；另外有若干个 从属进程，负责处理单个请求。 主进程的工作步骤如下：\n打开熟知端口（端口号为 21），使客户进程能够连接上。 等待客户进程发出连接请求。 启动从属进程来处理客户进程发来的请求。从属进程对客户进程的请求处理完毕后即 终止，但从属进程在运行期间根据需要还可能创建其他一些子进程。 回到等待状态，继续接受其他客户进程发来的请求。主进程与从属进程的处理是并发 地进行。 ","date":"2021-12-12","img":"","permalink":"/posts/6e1fe6f1/","series":null,"tags":["复习资料","基础"],"title":"Sit-计算机网络原理-复习"},{"categories":["LeetCode"],"content":"题目： 给你一个字符串 s ，将该字符串中的大写字母转换成相同的小写字母，返回新的字符串。\n示例 示例 1： 1输出：\u0026#34;hello\u0026#34; 2输入：s = \u0026#34;Hello\u0026#34; 示例 2： 1输入：s = \u0026#34;here\u0026#34; 2输出：\u0026#34;here\u0026#34; 示例 3： 1输入：s = \u0026#34;LOVELY\u0026#34; 2输出：\u0026#34;lovely\u0026#34; 解答 位运算的由来 在计算机里面，任何数据最终都是用数字来表示的（不管是我们平时用的软件，看的图片，视频，还是文字）。 并且计算机运算单元只认识高低电位，转化成我们认识的逻辑，也就是 0 1 。\n这就是导致计算机里面任何数据最终都是用二进制（0 1）来保存的数字。只是我们平时看到的图片、文字、软件都只从二进行数字转化而来的。\n位运算符号 常用位操作 判断奇偶\n(x \u0026amp; 1) == 1 \u0026mdash;等价\u0026mdash;\u0026gt; (x % 2 == 1)\n(x \u0026amp; 1) == 0 \u0026mdash;等价\u0026mdash;\u0026gt; (x % 2 == 0)\nx / 2 \u0026mdash;等价\u0026mdash;\u0026gt; x \u0026raquo; 1\nx \u0026amp;= (x - 1) \u0026mdash;\u0026mdash;\u0026gt; 把x最低位的二进制1给去掉\nx \u0026amp; -x \u0026mdash;\u0026ndash;\u0026gt; 得到最低位的1\nx \u0026amp; ~x \u0026mdash;\u0026ndash;\u0026gt; 0\n指定位置的位运算 将X最右边的n位清零：x \u0026amp; (~0 \u0026laquo; n) 获取x的第n位值：(x \u0026raquo; n) \u0026amp; 1 获取x的第n位的幂值：x \u0026amp; (1 \u0026laquo; n) 仅将第n位置为1：x | (1 \u0026laquo; n) 仅将第n位置为0：x \u0026amp; (~(1 \u0026laquo; n)) 将x最高位至第n位（含）清零：x \u0026amp; ((1 \u0026laquo; n) - 1) 将第n位至第0位（含）清零：x \u0026amp; (~((1 \u0026laquo; (n + 1)) - 1)) 异或结合律 x ^ 0 = x, x ^ x = 0\nx ^ (~0) = ~x, x ^ (~x) = ~0\na ^ b = c, a ^ c = b, b ^ c = a\n注：(有没有点乘法结合律的意思) 字母表示：(a ^ b) ^ c = a ^ (b ^ c) 图形表示：(☆ ^ ◇) ^ △ = ☆ ^ (◇ ^ △)\n字母位运算技巧 大写变小写、小写变大写：字符 ^= 32 （大写 ^= 32 相当于 +32，小写 ^= 32 相当于 -32） 大写变小写、小写变小写：字符 |= 32 （大写 |= 32 就相当于+32，小写 |= 32 不变） 大写变大写、小写变大写：字符 \u0026amp;= -33 （大写 \u0026amp;= -33 不变，小写 \u0026amp;= -33 相当于 -32） 原因 把字母当成 8 个bit 位来看，我把大小字母对应的后 4 位圈出来了。大家有没有发现 A-a B-b \u0026hellip; Z-z 26个字母之间的大小写的后 4 位是完全一样的！！！\n（重要知识点1：对应大小字母的 后4位二进制是一样的，后4位二进制是一样的，后4位二进制是一样的）再来看一下头 4位。对应大小字母之间就第 3位 的 bit 值不一样！！！\n（重要知识点2：对应大小字母的前4位中，只有第3位bit值不一样，只有第3位bit值不一样，只有第3位bit值不一样） 把不一样的bit位单独取出来，其它位补 0，也就是 0b0010 0000，对应的十进制数就是 32 ！！！\n通过观察，我们发现对应的大小写字母之间，只有第3个bit位的值不一样，已此来做的区分。 那么上面提到的技巧的应用：\n字母 ^= 32 其是：字母 ^= 0b10 0000 字母 |= 32 其是：字母 |= 0b10 0000 字母 \u0026amp;= -33 其是：字母 ^= 0b1101 1111 都是针对第3位bit值做的操作，从而可以不用提前知道原字母大小，通过位操作来达到大小写切换。\n只有26字母，为什么大小之间的ASCII差值是32，而不是26？ （其实有了上面的了解，再来看这件事就更容易理解了。）\n因为字母大小之间的切换是一个很高频的行为，在设计ASCII表时，出于效率的考量，把大小之间的转换需要的 算力 压缩到最小。（关健词：算力） 也就是只需要对一个bit位操作就可以实现大小写之间的切换。\n如何压缩算力 如：\n1int n = 0b100; 2n ^= 0b011; n 最终等于 0b111。虽然只进行了一次 异或 操作，但是对于最底层的 异或 逻辑，是需要对各个bit分别进行一次 异或运算 最终把 3次 的异或累加返回。\n同样的逻辑，对应到字母大小之间的切换，每次只需要 1次位操作 就可以得做到大小写切换。（关键词：1次） 从而把大小之间转换的代价压缩到最小。\n代码 1 string toLowerCase(string s) { 2 int dis = \u0026#39;a\u0026#39; - \u0026#39;A\u0026#39;; 3 for (int i = 0; i \u0026lt; s.size(); i++) { 4 if (s[i] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; s[i] \u0026lt;= \u0026#39;Z\u0026#39;) { 5 s[i] = s[i] +dis; 6 } 7 } 8 return s; 9 } 10 11 12string toLowerCase(string s) { 13 for (char\u0026amp; ch: s) { 14 ch = tolower(ch); 15 } 16 return s; 17} 5种解法，你应该背下的位操作知识 - 2 的幂 - 力扣（LeetCode） (leetcode-cn.com)\n","date":"2021-12-12","img":"","permalink":"/posts/1af266db/","series":["leetcode"],"tags":["简单","模拟"],"title":"LeetCode-709-转换成小写字母"},{"categories":["LeetCode"],"content":"题目 给你两个整数数组 persons 和 times 。在选举中，第 i 张票是在时刻为 times[i] 时投给候选人 persons[i] 的。\n对于发生在时刻 t 的每个查询，需要找出在 t 时刻在选举中领先的候选人的编号。\n在 t 时刻投出的选票也将被计入我们的查询之中。在平局的情况下，最近获得投票的候选人将会获胜。\n实现 TopVotedCandidate 类：\nTopVotedCandidate(int[] persons, int[] times) 使用 persons 和 times 数组初始化对象。 int q(int t) 根据前面描述的规则，返回在时刻 t 在选举中领先的候选人的编号。\n示例 1输入： 2[\u0026#34;TopVotedCandidate\u0026#34;, \u0026#34;q\u0026#34;, \u0026#34;q\u0026#34;, \u0026#34;q\u0026#34;, \u0026#34;q\u0026#34;, \u0026#34;q\u0026#34;, \u0026#34;q\u0026#34;] 3[[[0, 1, 1, 0, 0, 1, 0], [0, 5, 10, 15, 20, 25, 30]], [3], [12], [25], [15], [24], [8]] 4输出： 5[null, 0, 1, 1, 0, 0, 1] 6 7解释： 8TopVotedCandidate topVotedCandidate = new TopVotedCandidate([0, 1, 1, 0, 0, 1, 0], [0, 5, 10, 15, 20, 25, 30]); 9topVotedCandidate.q(3); // 返回 0 ，在时刻 3 ，票数分布为 [0] ，编号为 0 的候选人领先。 10topVotedCandidate.q(12); // 返回 1 ，在时刻 12 ，票数分布为 [0,1,1] ，编号为 1 的候选人领先。 11topVotedCandidate.q(25); // 返回 1 ，在时刻 25 ，票数分布为 [0,1,1,0,0,1] ，编号为 1 的候选人领先。（在平局的情况下，1 是最近获得投票的候选人）。 12topVotedCandidate.q(15); // 返回 0 13topVotedCandidate.q(24); // 返回 0 14topVotedCandidate.q(8); // 返回 1 解释 对于给的示例进行解释，\n首先初始化投票信息。\n投给的候选人 时间 当前0候选人票数 当前1候选人票数 当前时间段领先的候选人 0号 0 1票 0票 0号 1号 5 1票 1票（最近被投的） 1号（最近被投的领先） 1号 10 1票 2票 1号（1\u0026lt;2票） 0号 15 2票（最近被投的） 2票 0号（2==2）（最近被投的） 0号 20 3票 2票 0号（3\u0026gt;2） 1号 25 3票 3票（最近被投的） 1号(3==3)（最近被投的） 0号 30 4票 3票 0号(4\u0026gt;3) 我们可以在初始化的时候进行预处理，构造一个某个时间段领先的候选人的表。如下\n时间 领先的候选人 0 0 5 1 10 1 15 0 20 0 25 1 30 0 如果给定一个时间t我们只需要找到比t小的最大的时间所对应的候选人是谁。\n如给定时间t=12找到比12小的中最大的是10，此时对应领先的1号。\n如给定时间t=15找到比15小的中最大的是15（比15\u0026lt;=15），此时对应领先的0号。\n注意：题目给的persons的取值范围，不是仅仅两个人\n1class TopVotedCandidate { 2public: 3 vector\u0026lt;int\u0026gt; tops; 4 vector\u0026lt;int\u0026gt; times; 5 6 TopVotedCandidate(vector\u0026lt;int\u0026gt;\u0026amp; persons, vector\u0026lt;int\u0026gt;\u0026amp; times) { 7 unordered_map\u0026lt;int, int\u0026gt; voteCounts; 8 voteCounts[-1] = -1; 9 int top = -1; 10 for (auto \u0026amp; p : persons) { 11 voteCounts[p]++; 12 if (voteCounts[p] \u0026gt;= voteCounts[top]) { 13 top = p; 14 } 15 tops.emplace_back(top); 16 } 17 this-\u0026gt;times = times; 18 } 19 20 int q(int t) { 21 // 找出比目标元素大的第一个元素 22 int pos = upper_bound(times.begin(), times.end(), t) - times.begin() - 1; 23 return tops[pos]; 24 } 25}; tops就是我们所构造的表。\n备注： unordered_map:\n简介 unordered_map是一个将key和value关联起来的容器，它可以高效的根据单个key值查找对应的value。 key值应该是唯一的，key和value的数据类型可以不相同。 unordered_map存储元素时是没有顺序的，只是根据key的哈希值，将元素存在指定位置，所以根据key查找单个value时非常高效，平均可以在常数时间内完成。 unordered_map查询单个key的时候效率比map高，但是要查询某一范围内的key值时比map效率低。 可以使用[]操作符来访问key值对应的value值。 map与unordered_map的区别 运行效率方面：unordered_map最高，而map效率较低但 提供了稳定效率和有序的序列。 占用内存方面：map内存占用略低，unordered_map内存占用略高,而且是线性成比例的。 map: #include \u0026lt; map \u0026gt; unordered_map: #include \u0026lt; unordered_map \u0026gt; 成员函数 迭代器 方法 说明 begin 返回指向容器起始位置的迭代器（iterator） end 返回指向容器末尾位置的迭代器 cbegin 返回指向容器起始位置的常迭代器（const_iterator） cend 返回指向容器末尾位置的常迭代器 size 返回 unordered_map 支持的最大元素个数 empty 判断是否为空 operator[] 访问元素 at 访问元素 insert 插入元素 erase 删除元素 swap 交换内容 clear 清空内容 emplace 构造及插入一个元素 emplace_hint 按提示构造及插入一个元素 find 通过给定主键查找元素,没找到：返回unordered_map::end count 返回匹配给定主键的元素的个数 equal_range 返回值匹配给定搜索值的元素组成的范围 bucket_count 返回槽（Bucket）数 max_bucket_count 返回最大槽数 bucket_size 返回槽大小 bucket 返回元素所在槽的序号 load_factor 返回载入因子，即一个元素槽（Bucket）的最大元素数 max_load_factor 返回或设置最大载入因子 rehash 设置槽数 reserve 请求改变容器容量 upper_bound\n简介 1//查找[first, last)区域中第一个大于 val 的元素。 2ForwardIterator upper_bound (ForwardIterator first, ForwardIterator last,const T\u0026amp; val); 3 4//查找[first, last)区域中第一个不符合 comp 规则的元素 5ForwardIterator upper_bound (ForwardIterator first, ForwardIterator last,const T\u0026amp; val, Compare comp); 1#include \u0026lt;iostream\u0026gt; // std::cout 2#include \u0026lt;algorithm\u0026gt; // std::upper_bound 3#include \u0026lt;vector\u0026gt; // std::vector 4using namespace std; 5//以普通函数的方式定义查找规则 6bool mycomp(int i, int j) { return i \u0026gt; j; } 7//以函数对象的形式定义查找规则 8class mycomp2 { 9public: 10 bool operator()(const int\u0026amp; i, const int\u0026amp; j) { 11 return i \u0026gt; j; 12 } 13}; 14int main() { 15 int a[5] = { 1,2,3,4,5 }; 16 //从 a 数组中找到第一个大于 3 的元素 17 int *p = upper_bound(a, a + 5, 3); 18 cout \u0026lt;\u0026lt; \u0026#34;*p = \u0026#34; \u0026lt;\u0026lt; *p \u0026lt;\u0026lt; endl; 19 vector\u0026lt;int\u0026gt; myvector{ 4,5,3,1,2 }; 20 //根据 mycomp2 规则，从 myvector 容器中找到第一个违背 mycomp2 规则的元素 21 vector\u0026lt;int\u0026gt;::iterator iter = upper_bound(myvector.begin(), myvector.end(), 3, mycomp2()); 22 cout \u0026lt;\u0026lt; \u0026#34;*iter = \u0026#34; \u0026lt;\u0026lt; *iter; 23 return 0; 24} 结果\n1*p = 4 2*iter = 1 ","date":"2021-12-11","img":"","permalink":"/posts/acd85fa1/","series":["leetcode"],"tags":["中等"],"title":"LeetCode-911-在线选举"},{"categories":["设计模式"],"content":"在现实生活中常常遇到实现某种目标存在多种策略可供选择的情况，例如，出行旅游可以乘坐飞机、乘坐火车、骑自行车或自己开私家车等，超市促销可以釆用打折、送商品、送积分等方法。\n1struct Order{} 2order Order = 订单信息 3if payType == 微信支付{ 4 微信支付流程 5} else if payType == 支付宝{ 6 支付宝支付流程 7} else if payType == 银行卡{ 8 银行卡支付流程 9} else { 10 暂不支持的支付方式 11} 如上代码，虽然写起来简单，但违反了面向对象的 2 个基本原则：\n单一职责原则：一个类只有1个发生变化的原因 之后修改任何逻辑，当前方法都会被修改 开闭原则：对扩展开放，对修改关闭 当我们需要增加、减少某种支付方式(积分支付/组合支付)，或者增加优惠券等功能时，不可避免的要修改该段代码 特别是当 if-else 块中的代码量比较大时，后续的扩展和维护会变得非常复杂且容易出错。在阿里《Java开发手册》中，有这样的规则：超过3层的 if-else 的逻辑判断代码可以使用卫语句、策略模式、状态模式等来实现。\n策略模式是解决过多 if-else（或者 switch-case） 代码块的方法之一，提高代码的可维护性、可扩展性和可读性。\n定义 该模式定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。策略模式属于对象行为模式，它通过对算法进行封装，把使用算法的责任和算法的实现分割开来，并委派给不同的对象对这些算法进行管理。\n理解 策略，也就是计策的意思。刘备每到关键时刻就可以打开一个(封装的)锦囊，得到一个战胜敌人的策略(火攻、水攻等等)；再例如我们想去黄山旅游，我们可以选择不同的策略(飞机、火车、开车)，不管是使用哪种策略，不会影响我们抵达黄山游览，只是耗时长短的问题。\n代码 这里我们用最容易理解的计算器为例。计算器支持加、减、乘、除等等计算方法(策略)。只要我们输入两数字，使用其中一个策略即可得到一个结果。对于计算器使用者来说，无需关心实际的算法运算过程，只需要输入数字即可。而对于算法的实现者来说，新的算法策略只要能接受两个参数入参进行运算，即可对接到计算器中，扩展了计算器的功能。\n这里我们先定义一个通用的计算策略Calc，接收两个参数a和b\n1type Strategy interface{ 2 Calc(a,b int) int 3} 加法策略 1//AddStrategy 加法策略 2type AddStrategy struct { 3} 4 5func (t AddStrategy) Calc(a, b int) int { 6 return a + b 7} 实现减法策略 1//SubStrategy 减法策略 2type SubStrategy struct { 3} 4 5func (t SubStrategy) Calc(a, b int) int { 6 return a - b 7} 将策略对接到实际的计算器中 1//Calculator 计算器 2type Calculator struct { 3 s Strategy 4} 5 6func (t *Calculator) setStrategy(s Strategy) { 7 t.s = s 8} 9func (t Calculator) GetResult(a, b int) int { 10 return t.s.Calc(a, b) 11} 对于计算器来说，他只需要使用setStrategy设置不同的计算策略，通过GetResult函数获取结果。\n开始使用计算器计算\n1func main() { 2 add := AddStrategy{} //加法策略 3 sub := SubStrategy{} //减法策略 4 //计算器通过setStrategy设置不同策略，解耦了计算器和算法实现类 5 cal := \u0026amp;Calculator{} 6 cal.setStrategy(add) 7 fmt.Println(\u0026#34;加法策略结果:\u0026#34;, cal.GetResult(1, 1)) 8 cal.setStrategy(sub) 9 fmt.Println(\u0026#34;减法策略结果:\u0026#34;, cal.GetResult(1, 1)) 10} 输出结果\n1加法策略结果: 2 2减法策略结果: 0 总结 策略模式的重点在于策略的设定，以及普通类Calculator与策略Strategy的对接。通过更换实现同一个接口Strategy的不同策略类AddStrategy和SubStrategy。降低了Calculator的维护成本，解耦和计算器和算法实现，符合设计模式的开放闭合原则。\n完整代码如下 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5//这里以计算器为例，包含两种功能 （加法、减法） 6/* 7//这种代码优点，如果只有这两种计算方法，编写简单容易理解。如果后续计算器包含很多计算方法(乘法、除法) Cal 结构体就需要不同的修改。违背了代码放开闭合原则。好的代码，应该是支持扩展，减少对原有代码修改，可以快速满足不同用户的需求。 8type Cal struct{ 9 10} 11 12func (t Cal)Add(a,b int) int{ 13\treturn a+b 14} 15 16func (t Cal)Sub(a,b int)int{ 17\treturn a-b 18} 19*/ 20 21//Strategy 定义策略接口 22type Strategy interface { 23\tCalc(a, b int) int 24} 25 26//AddStrategy 加法策略 27type AddStrategy struct { 28} 29 30func (t AddStrategy) Calc(a, b int) int { 31\treturn a + b 32} 33 34//SubStrategy 减法策略 35type SubStrategy struct { 36} 37 38func (t SubStrategy) Calc(a, b int) int { 39\treturn a - b 40} 41 42//Calculator 计算器 43type Calculator struct { 44\ts Strategy 45} 46 47func (t *Calculator) setStrategy(s Strategy) { 48\tt.s = s 49} 50func (t Calculator) GetResult(a, b int) int { 51\treturn t.s.Calc(a, b) 52} 53func main() { 54\tadd := AddStrategy{} 55\tsub := SubStrategy{} 56\t//计算器通过setStrategy设置不同策略，解耦了计算器和算法实现类 57\tcal := \u0026amp;Calculator{} 58\tcal.setStrategy(add) 59\tfmt.Println(\u0026#34;加法策略结果:\u0026#34;, cal.GetResult(1, 1)) 60\tcal.setStrategy(sub) 61\tfmt.Println(\u0026#34;减法策略结果:\u0026#34;, cal.GetResult(1, 1)) 62} ","date":"2021-12-11","img":"","permalink":"/posts/72e3b671/","series":null,"tags":["策略模式"],"title":"策略模式"},{"categories":["编译原理"],"content":"有限自动机是对语言有穷描述的一种方法，下面将介绍确定有限自动机、非确定有限自动机和他们之间的转化以及确定有限自动机的最小化。\n确定有限自动机 确定有限状态自动机A是由\n一个非空有限的状态集合Q 一个输入字母表（非空有限的字符集合） 一个转移函数 唯一开始状态 一个接受状态的集合(终止状态集合) 组成的五元组。\n转换函数 f(0,a) = 1\n处于状态0时输入字符状态迁移为1\n转换矩阵 状态\\输入符号 a b 0 1 2 1 3 2 状态为0时输入字符a状态迁移为1\n状态为1时输入字符a状态迁移为3\n状态转换图 从起点状态1开始，如果输入字符0或1状态迁移为2；在状态2输入字符1时状态转移为3。\n两个圆圈的为终止状态。\n非确定有限自动机 在确定有限自动状态机上稍加修改，使其在某状态下输入一个字符的转换状态不是唯一的，而允许转换为多个状态，并允许不扫描字符就可以转换状态。\n非确定有限状态自动机A是由\n一个非空有限的状态集合Q 一个输入字母表（非空有限的字符集合） 转移函数 开始状态集合 一个接受状态的集合(终止状态集合) 组成的五元组。\n与确定有限状态机区别 状态转换函数是一个子集，一个状态结点出发可以有不止一条同一标记的弧 不处理任何符号就可以转换 初态不止一个 DFA是NFA的特例 转换函数 f(0,a) = {0，1，2，3}\n处于状态0时输入字符状态迁移为0，1，2，3\n转换矩阵 状态\\输入符号 a b 0 1，2 2，5 1 3，4 2，3 状态为0时输入字符a状态迁移为1，2\n状态为1时输入字符a状态迁移为3，4\nNFA转DFA 对于任何一个NFA，都存在一个DFA，使其等价。\n思路 根据NFA和DFA的不同构造DFA\nNFA DFA 初始状态 不唯一 唯一 弧上的标记 单字符、ε 字符 转换关系 非确定 确定 消除初始状态不同 引进初态结点X和终态结点Y，从X到原来的初态各连接一条ε弧，从原所有来终态各引出一条ε弧到终态Y。现在只有一个唯一的初态，唯一的终态。\n状态替换 i\u0026ndash;AB\u0026ndash;\u0026gt;j 代之为 i\u0026ndash;A\u0026ndash;k\u0026ndash;B\u0026ndash;\u0026gt;j。引入新状态k 子集法 ε-闭包 I是状态集的一个子集，I的ε-闭包为：\nε-closure(I) = I∪{s1 | 从某个s∈I 出发经过任意条ε弧能达到S1}\n设a是字符集中一个字符，定义\n$$I_a = ε-closure(J)$$\n其中，J为I中的某个状态出发经过一条a弧而到达的状态集合。也就是说经过任意(0-n)个ε弧到a再经过任意(0-n)个ε弧到达的状态的集合就是I_a。\n例题 要求I_a,则要求J，J = {5，4，3}\nI_a = ε-closure(J) = {5,4,3,6,2,7,8}\n确定化 不失一般性，设字母表只含两个字符a、b，构造计算状态集的转化表\nI I_a I_b 置第一行第一列为ε-closure(X)，求这一列的I_a,I_b 检查这两个 I_a,I_b是否在表中出现过，把没有出现的在填在空行的第一列。 直到所有的I_a,I_b全部出现过。 ","date":"2021-10-14","img":"","permalink":"/posts/12879185/","series":null,"tags":["复习资料"],"title":"编译原理 有限自动机"},{"categories":["编译原理"],"content":"编译原理-文法和语言\n文法和语言 字母表和符号串 字母表 元素非空的又穷集合，包含了语言中允许出现的全部符号\n字母表上的符号串 有字母表Σ中的符号所组成的任何有穷序列。无任何符号的符号产称为空符号串，记作ε\n符号串的长度 符号串中符号的个数。字符串\u0026quot;110011\u0026quot;的长度 = |110011| = 6 ,空串ε的长度为0\n符号串的字串 设w是一个符号串，把从w的尾部删除0个或若干个符号后剩余之后的部分称为w的前缀。同理后缀\n从一个符号串总删去他的一个前缀和一个后缀之后剩余的部分称为该符号串的字符号串或字串\n符号串的方幂 设w是某字母表上的符号串，把w自身连接n次得到的符号串即v = www...ww(n个w)，称v是w的n次幂\nw^0 = ε\n集合的闭包 设A是一个集合，A的正闭包记作A^+ 定义为:\nA^+ = A^1 ∪ A^2 ∪\u0026hellip;∪ A^n∪\u0026hellip;\nA^* 定义为A的自反闭包，显然有:\nA^* = A^0 ∪A^1 ∪ A^2 ∪\u0026hellip;∪ A^n∪\u0026hellip;\n文法和语言的形式化定义 文法 一部文法G是一个四元组\nG = (V_N,V_T,S,P)\nV_N:非空有限的非终结符集合\nV_T:非空有限的终结符集合\nS:文法的开始符号,S属于V_N\nP:产生式集合。产生式是按一定格式书写的定义原发范畴的文法规则\nA、B、C等大写字母表示非终结符\na,b,c等小写字母表示终结符\nα，β，γ等希腊字母表示文法符号串。文法符号串是由终结符和非终结符组成的符号串\n直接推导 文法G=(V_N,V_T,S,P)。ζ，γ∈(V_N∪V_T)^* ,若S=*\u0026gt;ζαγ，且存在a-\u0026gt;β，则称ζαγ直接推导出ζβγ，记作ζαγ=\u0026gt;ζβγ，与之相应，称ζβγ直接规约到ζαγ。\n直接推导序列 设有文法G=(V_N,V_T,S,P)，若存在ω = α0=\u0026gt;α1=\u0026gt;\u0026hellip;αn-1=\u0026gt;αn = υ\n句型 如果 S⇒* α，α∈(VT∪VN)*，则称α是G的一个句型 (sentential form)。\n一个句型中既可以包含终结符，又可以包含非终结符，也可能是空串。\n句子 如果 S⇒* w，w ∈VT*，则称w是G的一个句子(sentence)。\n句子是不包含非终结符的句型。\n最左(右)推导 在每一步推导过程中，总是对字符串中最左(右)边的非终结符进行替换\n语法分析树和文法二义性 语法分析树 语法分析树来表示经推导而产生的句子结构，有助于理解句子的语法结构层次。\n根由开始符号所标记； 每个叶子由一个终结符、非终结符或 ε 标记； 每个内部节点都是非终结符； 若 A 是某节点的内部标记，且 X1、X2\u0026hellip;Xn 是该节点从左到右的所有孩子的标记。则：A→X1X2\u0026hellip;Xn 是一个产生式。若 A→ε，则标记为 A 的节点可以仅有一个标记为 ε 的孩子。若 A→ε ，则标记为 A 的节点可以仅有一个标记为 ε 的孩子。 二义文法 一个句子可能对应多于一棵语法树。\n这种问题由\u0026quot;句子产生过程中的某些推导有多于一种选择\u0026quot;引起。\n","date":"2021-10-14","img":"","permalink":"/posts/b68db71a/","series":null,"tags":["复习资料"],"title":"文法和语言"},{"categories":["编译原理"],"content":"课上不努力、课后徒伤悲。好好听网课，好好学习！\nFIRST集合 定义 FIRST(X)是X所有可能推导的开头终结符号或可能推导的ε所构成的集合。\n构造FIRST集合 对于每个非终结符或终结符X连续使用以下规则，直至每个X的FIRST集合不再增大为止\n若左边第一个符号是终结符或者是ε，将其放在FIRST(X)中; 若左边第一个符号是非终结符，将其FIRST集合中非ε元素加入FIRST(X)中; 若左边第一个符号是非终结符而且紧随其后有很多非终结符，要注意是否有ε; 若第i个非终结符的FIRST集中有ε，则把第i+1个非终结符的FIRST集合除ε的元素加入FRIST(X); 若所有非终结符的FIRST集中都有ε，则把ε加入FIRST(X); 重复使用以上规则，直至每个X的FIRST集合不再增大为止。\n例题 对于文法G(E):\n$$E-\u0026gt; TE^{\\prime} $$\n$$E^{\\prime}-\u0026gt; +TE^{\\prime} |ε $$\n$$T-\u0026gt;FT^{\\prime}$$\n$$T^{\\prime}-\u0026gt;*FT^{\\prime}|ε$$\n$$F-\u0026gt;(E)|i$$\n构造每个非终结符的FIRST集合\n我们使用上述规则进行构造\n第一轮 E-\u003e TE1 左边第一个是非终结符、紧随其后的也是终结符符合2,3规则，但是他们的FISRT集合都为空。\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ E1-\u003e +TE1|ε 规则 1：左边第一个是终结符和ε，将他们放进FIRST{E1}集中\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ +，ε T-\u003eFT1 规则2: 将FIRSR{F}中的非ε元素加入FIRST(T)，FIRST{T}为空\n规则3:FIRST{T}和FIRST{F1}为空\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ +，ε T1-\u003e*FT1|ε 规则1:将 *，ε加入FIRST{T1}\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ +，ε *，ε F-\u003e(E)|i 规则1:将 （，i加入FIRST{F}\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ +，ε *，ε （，i FIRST集合还在增大所以继续下一轮\n第二轮 E-\u003e TE1 规则2: FISRT{T}为空\n规则3: FISRT{T}为空\n不变\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ +，ε *，ε （，i E1-\u003e +TE1|ε 规则 1：左边第一个是终结符和ε，将他们放进FIRST{E1}集中。不变\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ +，ε *，ε （，i T-\u003eFT1 规则2: 将FIRSR{F}中的非ε元素加入FIRST(T) 变化了。\n规则3:FIRST{F}没有ε，不用考虑了。不变\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ +，ε （，i *，ε （，i T1-\u003e*FT1|ε 规则1:将 *，ε加入FIRST{T1}。不变\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ +，ε （，i *，ε （，i F-\u003e(E)|i 规则1:将 （，i加入FIRST{F}不变\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ +，ε （，i *，ε （，i 有变化，继续从头开始扫描\n第三轮 E-\u003e TE1 规则2: 把FISRT{T}放入FISRT{E}中 有变化\n规则3: FISRT{T}中没有ε，不用管\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ （，i +，ε （，i *，ε （，i E1-\u003e +TE1|ε 规则 1：左边第一个是终结符和ε，将他们放进FIRST{E1}集中。不变\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ （，i +，ε （，i *，ε （，i T-\u003eFT1 规则2: 将FIRSR{F}中的非ε元素加入FIRST(T)。已经放过了\n规则3:FIRST{F}没有ε，不用考虑了。不变\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ （，i +，ε （，i *，ε （，i T1-\u003e*FT1|ε 规则1:将 *，ε加入FIRST{T1}。不变\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ （，i +，ε （，i *，ε （，i F-\u003e(E)|i 规则1:将 （，i加入FIRST{F}不变\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ （，i +，ε （，i *，ε （，i 有变化，继续从头开始扫描\n第四轮 E-\u003e TE1 规则2: 把FISRT{T}放入FISRT{E}中 。没有增大\n规则3: FISRT{T}中没有ε，不用管\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ （，i +，ε （，i *，ε （，i E1-\u003e +TE1|ε 规则 1：左边第一个是终结符和ε，将他们放进FIRST{E1}集中。没有增大\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ （，i +，ε （，i *，ε （，i T-\u003eFT1 规则2: 将FIRSR{F}中的非ε元素加入FIRST(T)。没有增大\n规则3:FIRST{F}没有ε，不用考虑了。不变\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ （，i +，ε （，i *，ε （，i T1-\u003e*FT1|ε 规则1:将 *，ε加入FIRST{T1}。没有增大\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ （，i +，ε （，i *，ε （，i F-\u003e(E)|i 规则1:将 （，i加入FIRST{F} 没有增大\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ （，i +，ε （，i *，ε （，i 没有增大 结束。\n最终结果为：\n$$FIRST{E}$$ $$FIRST{E^{\\prime}}$$ $$FIRST{T}$$ $$FIRST{T^{\\prime}}$$ $$FIRST{F}$$ （，i +，ε （，i *，ε （，i FOLLOW集合 定义 FOLLOW(A)是所有矩形中出现在紧接A之后的终结符或#所构成的集合\n构造FOLLOW集合、 对于每个非终结符A，连续使用以下规则，直至每个FOLLOW集合不再增大\n对于文法的开始符号S，置#于FOLLOW(S)中 若A-\u0026gt; αBβ是一个产生式，则把FISRT{β}中非ε元素放入FOLLOW{B}中 若 A-\u0026gt; αB 或 A-\u0026gt; αBβ 【ε∈FISRT{B}】则把FOLLOW{A}中的元素放入FOLLOW{B}。 αβ是由终结符和非终结符构成的\n例题 对于文法G(E):\n$$E-\u0026gt; TE^{\\prime} $$\n$$E^{\\prime}-\u0026gt; +TE^{\\prime} |ε $$\n$$T-\u0026gt;FT^{\\prime}$$\n$$T^{\\prime}-\u0026gt;*FT^{\\prime}|ε$$\n$$F-\u0026gt;(E)|i$$\n构造每个非终结符的FOLLOW集合\n根据规则1将# 放入FOLLOW{E}中\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃ 第一轮 E-\u003e TE1 规则２：α为空，B为T，E１为β。将FISRT{E１}中非ε元素放入FOLLOW{T}中\n规则３：α为T，B为E１　FOLLOW{E}中的元素放入FOLLOW{Ｅ１}。\n规则３：α为空，B为T，E１为β，FISRT{E１}中有ε，将FOLLOW{E}中的元素放入FOLLOW{T}。\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃ ＃ +，＃ E1-\u003e +TE1|ε 规则２：α为＋，B为T，β为E１，将FISRT{E１}中非ε元素放入FOLLOW{T}中　规则３：α为＋T，B为E１　FOLLOW{E}中的元素放入FOLLOW{Ｅ１}。\n规则３：α为空，B为T，E１为β，FISRT{E１}中有ε，将FOLLOW{E}中的元素放入FOLLOW{T}。\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃ ＃ +，＃ T-\u003eFT1 规则２：α为空，B为F，T１为β。将FISRT{T１}中非ε元素放入FOLLOW{F}中\n规则３：α为F，B为T１　FOLLOW{T}中的元素放入FOLLOW{T１}。\n规则３：α为空，B为F，T１为β，FISRT{T１}中有ε，将FOLLOW{T}中的元素放入FOLLOW{F}。\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃ ＃ +，＃ +，＃ *，+，＃ T1-\u003e*FT1|ε 规则２：α为＊，B为F，T１为β。将FISRT{T１}中非ε元素放入FOLLOW{F}中\n规则３：α为＊F，B为T１　FOLLOW{T１}中的元素放入FOLLOW{T１}。不变\n规则３：α为＊，B为F，T１为β，FISRT{T１}中有ε，将FOLLOW{T１}中的元素放入FOLLOW{F}。不变\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃ ＃ +，＃ +，＃ *，+，＃ F-\u003e(E)|i 规则２：α为（，B为E，）为β。将FISRT{）}中非ε元素放入FOLLOW{E}中\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃，） ＃ +，＃ +，＃ * 第二轮 E-\u003e TE1 规则２：α为空，B为T，E１为β。将FISRT{E１}中非ε元素放入FOLLOW{T}中。已经放过\n规则３：α为T，B为E１　FOLLOW{E}中的元素放入FOLLOW{Ｅ１}。\n规则３：α为空，B为T，E１为β，FISRT{E１}中有ε，将FOLLOW{E}中的元素放入FOLLOW{T}。已经放过\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃，） ＃，） +，＃ +，＃ *，+，＃ E1-\u003e +TE1|ε 规则２：α为＋，B为T，β为E１，将FISRT{E１}中非ε元素放入FOLLOW{T}中\n规则３：α为＋T，B为E１　FOLLOW{E}中的元素放入FOLLOW{Ｅ１}。没变\n规则３：α为空，B为T，E１为β，FISRT{E１}中有ε，将FOLLOW{E}中的元素放入FOLLOW{T}。没变\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃，） ＃，） +，＃，） +，＃ *，+，＃ T-\u003eFT1 规则２：α为空，B为F，T１为β。将FISRT{T１}中非ε元素放入FOLLOW{F}中。没变\n规则３：α为F，B为T１　FOLLOW{T}中的元素放入FOLLOW{T１}。变了\n规则３：α为空，B为F，T１为β，FISRT{T１}中有ε，将FOLLOW{T}中的元素放入FOLLOW{F}。变了\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃，） ＃，） +，＃，） +，＃，） *，+，＃，） T1-\u003e*FT1|ε 规则２：α为＊，B为F，T１为β。将FISRT{T１}中非ε元素放入FOLLOW{F}中。已经放过\n规则３：α为＊F，B为T１　FOLLOW{T１}中的元素放入FOLLOW{T１}。不变\n规则３：α为＊，B为F，T１为β，FISRT{T１}中有ε，将FOLLOW{T１}中的元素放入FOLLOW{F}。不变\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃，） ＃，） +，＃，） +，＃，） *，+，＃，） F-\u003e(E)|i 规则２：α为（，B为E，）为β。将FISRT{）}中非ε元素放入FOLLOW{E}中。不变\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃，） ＃，） +，＃，） +，＃，） *，+，＃，） 第三轮 E-\u003e TE1 规则２：α为空，B为T，E１为β。将FISRT{E１}中非ε元素放入FOLLOW{T}中。已经放过\n规则３：α为T，B为E１　FOLLOW{E}中的元素放入FOLLOW{Ｅ１}。没变\n规则３：α为空，B为T，E１为β，FISRT{E１}中有ε，将FOLLOW{E}中的元素放入FOLLOW{T}。已经放过\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃，） ＃，） +，＃ +，＃ *，+，＃ E1-\u003e +TE1|ε 规则２：α为＋，B为T，β为E１，将FISRT{E１}中非ε元素放入FOLLOW{T}中。已经放过\n规则３：α为＋T，B为E１　FOLLOW{E}中的元素放入FOLLOW{Ｅ１}。没变\n规则３：α为空，B为T，E１为β，FISRT{E１}中有ε，将FOLLOW{E}中的元素放入FOLLOW{T}。没变\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃，） ＃，） +，＃，） +，＃ *，+，＃ T-\u003eFT1 规则２：α为空，B为F，T１为β。将FISRT{T１}中非ε元素放入FOLLOW{F}中。已经放过\n规则３：α为F，B为T１　FOLLOW{T}中的元素放入FOLLOW{T１}。没变\n规则３：α为空，B为F，T１为β，FISRT{T１}中有ε，将FOLLOW{T}中的元素放入FOLLOW{F}。没变\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃，） ＃，） +，＃，） +，＃，） *，+，＃，） T1-\u003e*FT1|ε 规则２：α为＊，B为F，T１为β。将FISRT{T１}中非ε元素放入FOLLOW{F}中。已经放过\n规则３：α为＊F，B为T１　FOLLOW{T１}中的元素放入FOLLOW{T１}。不变\n规则３：α为＊，B为F，T１为β，FISRT{T１}中有ε，将FOLLOW{T１}中的元素放入FOLLOW{F}。不变\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃，） ＃，） +，＃，） +，＃，） *，+，＃，） F-\u003e(E)|i 规则２：α为（，B为E，）为β。将FISRT{）}中非ε元素放入FOLLOW{E}中。不变\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃，） ＃，） +，＃，） +，＃，） *，+，＃，） 所有的FOLLOW已经没在变化了，这时候已经计算完了。\n最后的结果为：\n$$FOLLOW{E}$$ $$FOLLOW{E^{\\prime}}$$ $$FOLLOW{T}$$ $$FOLLOW{T^{\\prime}}$$ $$FOLLOW{F}$$ ＃，） ＃，） +，＃，） +，＃，） *，+，＃，） 消除左递归 法一 将左递归变为右递归\nP-\u0026gt;Pα|β\n变为\nP-\u0026gt;βP1\nP1-\u0026gt;αP1|ε\n对于文法P-\u0026gt;Pα|β我们可以推导出他能识别的串，它是以β开头后面接着0-n个α的串；βαααααα\u0026hellip;.\n法二 条件 不含以ε为右部的产生式 不含回路（p-\u0026gt;p） 方法 对非终结符进行排列P1\u0026hellip;..Pn 从P1到Pn遍历,把Pi改为α|Pi+1|Pi+2|...|Pn 从j=1 到j=i-1把形如Pi-\u0026gt;Pjγ的改写为Pi-\u0026gt;ζ1γ|ζ2γ|...|ζkγ 其中Pj-\u0026gt;ζ1|ζ2|...|ζk。此时就可以得到形如 Pi-\u0026gt;α|Pi|Pi|...|Pi+k|... 使用直接消除Pi使用方法一 化简2，去除从开始符号出发永远无法到达的非终结符产生规则 例题 考虑文法G[S]\nS-\u0026gt;(T)|a+S|a\nT-\u0026gt;T，S|S\n消除左递归\n第一步 只有两个非终结符，按照一定顺序排序，按照T，S的顺序排列\n第二步 先处理T\nT-\u0026gt;T，S|S\n由于T在前面，S在后面，所以S不处理(2.1)。由于本身有左递归，使用方法一直接消除左递归\nT-\u0026gt;ST1\nT1-\u0026gt; ,ST1|ε\n处理S\nS-\u0026gt;(T)|a+S|a\n由于T在S的前面，所以要将T处理掉。T又有（T-\u0026gt;ST1）进行替换\nS-\u0026gt;(ST1)|a+S|a\n不含有左递归，处理结束\n化简\nS-\u0026gt;(ST1)|a+S|a\nT-\u0026gt;ST1\nT1-\u0026gt; ,ST1|ε\n从开始符号都可以到达，所以不用去掉\n结果为 S-\u0026gt;(ST1)|a+S|a\nT-\u0026gt;ST1\nT1-\u0026gt; ,ST1|ε\n提取左公共因子 对于规则S\nS -\u0026gt; aB1|aB2|aB3|aB4|\u0026hellip;|aBn|y\n可以改写为\nS-\u0026gt; aS1|y S1 -\u0026gt; B1|B2|B3\u0026hellip;|Bn\nFISRTVT集合 方法 A-\u0026gt;a\u0026hellip;.. 则将a加入FIRSTVT(A)中 A-\u0026gt;B\u0026hellip;. 将FIRSTVT(B)加入到FIRSTVT(A)中 A-\u0026gt;Ba\u0026hellip; 例题 已给文法：\nG[S]: S→a|b|(B) A→S, A|S B→A\n求非终结符的FISRTVT集合\n求FIRSTVT(S) S→a|b|(B)\n根据规则1可得\nFIRSTVT(S)= {a,b,(}\n求FIRSTVT(A) A→S, A|S\n根据规则2可得，应该FISRTVT(S)中的放入FIRSTVT(A)中\nFIRSTVT(A) = {a,b,(}\n根据规则3，应该把,放入FIRSTVT(A)中\nFIRSTVT(A) = {a,b,(,逗号}\n求FIRSTVT(B) B→A\n根据规则3，应该FISRTVT(A)中的放入FIRSTVT(B)中\nFIRSTVT(B) = {a,b,(,逗号}\nFISRTVT S {a,b,(} A {a,b,(,逗号} B {a,b,(,逗号} LASTVT集合 方法 A-\u0026gt;\u0026hellip;..a 把a加入LASTVT(A)中 A-\u0026gt;\u0026hellip;..B 把LASTVT(B)加入LASTVT(A)中 A-\u0026gt;\u0026hellip;.aB 把a加入LASTVT(A)中 例题 已给文法：\nG[S]: S→a|b|(B) A→S, A|S B→A\n求非终结符的LASTVT集合\n求LASTVT(S) S→a|b|(B)\n根据规则1可得\nLASTVT(S)= {a,b,)}\n求LASTVT(A) A→S, A|S\n根据规则2可得，应该LASTVT(S)中的放入LASTVT(A)中\nLASTVT(A) = {a,b,)}\n根据规则3，应该把,放入LASTVT(A)中\nLASTVT(A) = {a,b,),逗号}\n求LASTVT(B) B→A\n根据规则3，应该LASTVT(A)中的放入LASTVT(B)中\nFIRSTVT(B) = {a,b,),逗号}\nLASTVT S {a,b,)} A {a,b,),逗号} B {a,b,),逗号} 算符优先文法OPG的条件 OPG文法条件 无S-\u0026gt;\u0026hellip;AB\u0026hellip; 无ε产生式 两两终结符间至多一种优先关系 判断算符优先级 方法一 找出所有非终结符，画出一下表格\na b c \u0026hellip; n a b c \u0026hellip; n ＝ 找aQb形式的，a=b，横排找a，竖排找b\n\u0026lt; 找aQ形式的，a与FISRSTVT(Q)的每个元素交叉处填\u0026lt;，a为横排元素\n\u0026gt; 找Qa形式的，在竖排中找到a，在横排中找到LASTVT(Q)中的元素，相交处填\u0026gt;\n# \u0026lt; FIRSTVT(A)\nLASTVT(A)\u0026gt;#\n例题 已给文法：\nG[S]: S→a|b|(B) A→S, A|S B→A\n判断算符优先级\n根据上面我们已经求出非终结符的FIRSTVT和LASTVT集合。列表\na b （ ） ， a b （ ） ， = 我们可以找到(B)是符合要求的，则 a b （ ） ， a b （ = ） ， \u0026lt; 我们找到aQ形式的，有(B,,A 则从横排找(,在竖排中找到FIRSTVT(B)，在交叉处填上\u0026lt;。在横排中找到，在竖排中国找到FIRSTVT(A)中的元素，在交叉处填上\u0026lt; a b （ ） ， a b （ \u0026lt; \u0026lt; \u0026lt; = \u0026lt; ） ， \u0026lt; \u0026lt; \u0026lt; \u0026lt; \u0026gt; 我们找到Qa形式的，有B),S, ，在竖排中找到),在横排中找到LASTVT(B)中的元素，在交叉处填上\u0026gt;, 在竖排找到, 在横排找到LASTVT(S)，在交叉处填上\u0026gt;\na b （ ） ， a \u0026gt; \u0026gt; b \u0026gt; \u0026gt; （ \u0026lt; \u0026lt; \u0026lt; = \u0026lt; ） \u0026gt; \u0026gt; ， \u0026lt; \u0026lt; \u0026lt; \u0026gt; \u0026lt; # \u0026lt; FIRSTVT(A) 横纵额外添加一列(行)#\na b （ ） ， # a \u0026gt; \u0026gt; \u0026gt; b \u0026gt; \u0026gt; \u0026gt; （ \u0026lt; \u0026lt; \u0026lt; = \u0026lt; ） \u0026gt; \u0026gt; \u0026gt; ， \u0026lt; \u0026lt; \u0026lt; \u0026gt; \u0026lt; # \u0026lt; \u0026lt; \u0026lt; \u0026lt; \u0026gt; # \u0026lt; FIRSTVT(S)\n# \u0026lt; FIRSTVT(A)\n# \u0026lt; FIRSTVT(B)\nLASTVTVT(A)\u0026gt;#\nLASTVTVT(S)\u0026gt;#\nLASTVTVT(A)\u0026gt;#\nLASTVTVT(B)\u0026gt;#\n结果如下 a b （ ） ， # a \u0026gt; \u0026gt; \u0026gt; b \u0026gt; \u0026gt; \u0026gt; （ \u0026lt; \u0026lt; \u0026lt; = \u0026lt; ） \u0026gt; \u0026gt; \u0026gt; ， \u0026lt; \u0026lt; \u0026lt; \u0026gt; \u0026lt; # \u0026lt; \u0026lt; \u0026lt; \u0026lt; \u0026gt; 方法二 对于文法的开始符号S，增加拓广文法S1-\u0026gt;#S#\n找出所有非终结符，画出一下表格\na b c \u0026hellip; n # a b c \u0026hellip; n # ＝ 找aQb形式的，a=b，横排找a，竖排找b\n\u0026lt; 找aQ形式的，a与FISRSTVT(Q)的每个元素交叉处填\u0026lt;，a为横排元素\n\u0026gt; 找Qa形式的，在竖排中找到a，在横排中找到LASTVT(Q)中的元素，相交处填\u0026gt;\n此方法不用额外判断#的优先级，在与其他的处理过程中，会一同处理\n","date":"2021-10-06","img":"","permalink":"/posts/29dc6b0/","series":null,"tags":["复习资料"],"title":"编译原理-作业"},{"categories":["计算机基础"],"content":"在做leetcode时发现自己对二进制的相关知识不太了解，将自己所找资料进行总结。\n基础概念 机器数 一个数在计算机中的二进制表示形式、叫做这个数的机器数。机器数带符号，最高位表示符号位，正数为0，复数为1.\n真值 由于第一位是符号位，所以机器数的形式值不等于真实的数值。为了区别起见，将带符号位的机器数对应的真正数值成为机器的真值。\n例：0000 0001的真值 = +000 0001 = +1，1000 0001的真值 = –000 0001 = –1\n原码 原码就是在符号位上加上真正的绝对值，即第一位表示符号，其余为表示值。比如8位二进制：\n[正数1]~原码~ = 0000 0001\n[负数1]~原码~ = 1000 0001\n则8位二进制数的取值范围就是:\n[1111 1111,0111 1111]\n[-127,+127]\n反码 正数的反码是其本身\n负数的反码是在原码基础上，符号位不变，其余各个位取反\n[+1] = [0000 0001]~原码~ = [0000 0001]~反码~\n[-1] = [1000 0001]~原码~ = [1111 1110]~反码~\n补码 正数的补码就是其本身\n负数的补码在其原码的基础上，符号位不变，其余各位取反，最后+1。【即在反码的基础上+1】\n[+1] = [0000 0001]~原码~ = [0000 0001]~反码~ = [0000 0001]~补码~\n[-1] = [1000 0001]~原码~ = [1111 1110]~反码~ = [1111 1111]~补码~\n为什么要用原码、反码、补码 计算机有三种编码方式表示一个数，对于正数，三种编码格式的结果都是一样的\n[+1] = [0000 0001]~原码~ = [0000 0001]~反码~ = [0000 0001]~补码~\n对于负数\n[-1] = [1000 0001]~原码~ = [1111 1110]~反码~ = [1111 1111]~补码~\n可见，负数的原码、补码和反码都是不同的，原码是让人看的表示方式，为何会有反码和补码呢？\n首先，人脑知道第一位是符号位，在计算的时候根据符号位，选择对真值区进行加减。但是对于计算机，加减乘除已经是最基本的运算，要设计的尽量简单，计算机辨别“符号位”显然会让计算机的基础电路变得十分复杂！于是人们想出了将符号位也参与运算的方法，根据运算法则，减去一个正数等于加上一个负数，所以机器可以只有加法而没有减法，这样计算机的设计就更简单了。于是人们探索将符号位参与运算，并且只保留加法的方法。\n首先来看原码计算十进制的：1-1=0\n1 - 1 = 1 + (-1) = [0000 0001]~原码~+[1000 0001]~原码~ = [1000 0010]~原码~ = 2~十进制~\n用原码表示，让符号位也参与运算，结果是不对的。\n为了解决原码做减法的问题，出现了反码\n1 - 1 = 1 + (-1) = [0000 0001]~反码~+[1111 1110]~反码~ = [1111 1111]~反码~ = [1000 0000]~原码~ = -0~十进制~\n结果貌似是对的，-0也是0，但是[0000 0000]~原码~也表示0 ，这样一来，0会有两种编码表示。\n于是补码出现了，解决了0的符号问题\n1 - 1 = 1 + (-1) = [0000 0001]~补码~+[1111 1111]~补码~ = [0000 0000]~补码~ = [0000 0000]~原码~ = 0~十进制~\n这样0可以用[0000 0000]~补码~ 唯一表示，而且可以用[1000 0000]~补码~来表示-128，\n在用补码运算的结果中, [1000 0000]补 就是-128。但是注意因为实际上是使用以前的-0的补码来表示-128, 所以-128并没有原码和反码表示.(对-128的补码表示[1000 0000]补算出来的原码是[0000 0000]原, 这是不正确的)\n使用了补码，不仅仅修复了0的符号以及存在两个编码的问题，而且还能够多表示一个最低数，这就是为什么8位二进制，使用原码或反码表示的范围为[-127, +127], 而使用补码表示的范围为[-128, 127]。\n原码、补码、反码再深入 计算机巧妙地把符号位参与运算, 并且将减法变成了加法, 背后蕴含了怎样的数学原理呢?\n将钟表想象成是一个1位的12进制数. 如果当前时间是6点, 我希望将时间设置成4点, 需要怎么做呢?我们可以:\n往后拨2个小时: 6 - 2 = 4\n向前前拨10个小时: (6 + 10) mod 12 = 4\n向前拨10+12=22个小时: (6+22) mod 12 =4\n2、3方法中的mod是指取模操作, 16 mod 12 =4 即用16除以12后的余数是4。\n所以钟表往后拨(减法)的结果可以用向前拨(加法)替代！\n如何使用一个正数来\u0026quot;代替\u0026quot;负数呢？\n同余 两个整数a、b，若他们除以整数m所得的余数相等，则称a、b对与模m同余\n记作 a ≡ b (mod m)\n读作 a 与 b 关于模 m 同余。\nmod运算的数学定义\n$$ x \\quad mod \\quad y \\quad = \\quad x -y\\lfloor x/y \\rfloor $$\n-3 mod 2\n= -3 - 2*($\\lfloor -3/2 \\rfloor$)\n= -3 -2*2\n= 1\n开始证明 回拨2小时 = 前拨10小时\n回拨4小时 = 前拨8小时\n回拨5小时= 前拨7小时\n结合上面学到的同余的概念.实际上:\n(-2) mod 12 = 10\n10 mod 12 = 10\n(-4) mod 12 = 8\n8 mod 12 = 8\n-2与10是同余的，-4与8是同余的。\n对于mod的线性运算定理\n若a ≡ b (mod m)，c ≡ d (mod m) 那么:\n(1)a ± c ≡ b ± d (mod m)\n(2)a * c ≡ b * d (mod m)\n举个例子\n7 ≡ 7 (mod 12)\n(-2) ≡ 10 (mod 12)\n7 -2 ≡ 7 + 10 (mod 12)\n现在我们为一个负数, 找到了它的正数同余数. 但是并不是7-2 = 7+10, 而是 7 -2 ≡ 7 + 10 (mod 12) , 即计算结果的余数相等。\n接下来回到二进制的问题上, 看一下: 2-1=1的问题。\n2-1=2+(-1) = [0000 0010]~原~ + [1000 0001]~原~= [0000 0010]~反~ + [1111 1110]~反~\n先到这一步, -1的反码表示是[1111 1110]。 如果这里将[1111 1110]认为是原码, 则[1111 1110]原 = -126, 这里将符号位除去, 即认为是126。\n发现有如下规律：\n(-1) mod 127 = 126\n126 mod 127 = 126\n即有\n(-1) ≡ 126 (mod 127)\n2-1 ≡ 2+126 (mod 127)\n2-1 与 2+126的余数结果是相同的! 而这个余数, 正式我们的期望的计算结果: 2-1=1\n所以说一个数的反码，实际上是这个数对于一个模的同余数，而这个模并不是我们的二进制，二十所能表示的最大值！这样就和钟表一样，转了一圈后总能找到在可表示范围内的一个正确数值。而2+126相当于钟表转过了一轮，因为符号位也是参与计算的，正好和溢出的最高位形成正确的运算结果。\n既然反码可以将减法变成加法, 那么现在计算机使用的补码呢? 为什么在反码的基础上加1, 还能得到正确的结果?\n2-1=2+(-1) = [0000 0010]~原~ + [1000 0001]~原~ = [0000 0010]~补~ + [1111 1111]~补~\n如果把[1111 1111]当成原码, 去除符号位, 则：\n[0111 1111]~原~ = 127\n其实, 在反码的基础上+1, 只是相当于增加了模的值:\n(-1) mod 128 = 127\n127 mod 128 = 127\n2-1 ≡ 2+127 (mod 128)\n此时, 表盘相当于每128个刻度转一轮. 所以用补码表示的运算结果最小值和最大值应该是[-128, 128]，但是由于0的特殊情况, 没有办法表示128, 所以补码的取值范围是[-128, 127]。\n","date":"2021-10-02","img":"","permalink":"/posts/c14b5b33/","series":null,"tags":["二进制"],"title":"二进制引发的思考"},{"categories":["随笔"],"content":"人生当中成功只是一时的，失败却是主旋律。但是如何面对失败，却把人分成了不同的样子，有的人会被失败击垮，有的人能不断的爬起来继续向前\u0026hellip;我想真正的成熟应该并不是追求完美，而是直面自己的缺憾，这才是生活的本质。罗曼罗兰说过，这个世上只有一种真正的英雄主义，那就是，认清生活的真相，并且仍然热爱她。\n","date":"2021-09-15","img":"","permalink":"/posts/c8d9f0a8/","series":null,"tags":null,"title":"9.15随笔"},{"categories":["YOLOV5"],"content":"由于项目需要目标追踪，之前打算是用OpenCV提供的算法进行追踪，但实测下来效果不是很理想，了解到使用YOLOv5与DeepSort相结合的方式可以进行多物体追踪，在跑通作者提供的track示例后，将目标检测和目标追踪分别进行封装，方便以后在项目中使用。\n原始track介绍 我们阅读track.py中代码，从中可以看出来代码包含以下部分\n参数配置（YOLOv5和DeepSort） 初始化DeepSort（DeepSort） 加载检测model（YOLOv5） 进行推理，获得相关信息（YOLOv5） 进行追踪（DeepSort） 结果显示的处理（YOLOv5和DeepSort） 按照上述流程我们可以对检测和追踪分别进行封装。\n参数配置 主方法中关于parser的所有语句都是加载命令行参数【219-241行】，我们如果要应用到项目中很少会用到命令行提供参数，所以我们需要写一个能提供参数的方法或类。\ndetect方法中刚开始就是对YOLOv5和DeepSort的相关参数进行配置【47-55行】\n初始化DeepSort 【54-62行】是获得DeepSort的配置文件，并构造deepsort对象\n加载检测model 【77-104行】加载相关的model\n进行推理 对以及打包的原始图像进行处理【91-95行】（对图片信息打包）【113-118行】（对图片进行浮点数、归一化处理），然后进行推理，之后进行非极大抑制，对所得的结果进行处理【129-150行】\n进行追踪 调用update方法进行追踪。【154】\n注意！ 追踪更新的返回 结果都是tensor\n最终展示结果处理 对获得的物体的ID、类别名称（cls）、置信度（confidence）、boundingboxes（xyxy）进行最终处理【157-167】\n！ 对于保存视频、文件等相关代码本文未讲述到。\n如何运行 克隆此项目\n1git clone https://github.com/jimyag/YOLOv5-DeepSort.git 安装依赖\n在终端执行以下语句安装依赖包\n1pip install -r requirements.txt requirements默认安装torch-cpu，如需安装pytorch-gup请移步至pytorch下载选择相应版本进行下载\n下载权重文件\n下载DeepSort权重\n点击下载，并将下载好的权重文件放在deep_sort_pytorch/deep_sort/deep/checkpoint下。\n如果要使用其他权重，需要修改deep_sort_pytorch/configs/deep_sort.yaml中REID_CKPT: \u0026quot;deep_sort_pytorch/deep_sort/deep/checkpoint/ckpt.t7\u0026quot;的配置文件\n下载YOLOv5权重\n点击下载，并将下载好的权重文件放在yolov5/weights,并修改my_detect.py中self.yolo_weights = 'yolov5/weights/basketball_robot.pt'\n更改源文件\n在my_detect.py中修改self.source = 'basketball.mp4'\n运行test.py\n","date":"2021-08-04","img":"","permalink":"/posts/5306f355/","series":null,"tags":["YOLOV5","DeepSort"],"title":"基于YOLOv5-DeepSort的目标追踪器的封装"},{"categories":["YOLOV5"],"content":"检测精度 混淆矩阵（confusion matrix） confusion matrix是用来总结一个分类器（classifier）结果的矩阵。对于k元分类，其实它就是一个k x k的表格，用来记录分类器的预测结果。\n对于最常见的二元分类来说，我们的模型最终需要判断样本的结果是0还是1，或者说是positive还是negative。我们通过样本的采集，能够直接知道真实情况下，哪些数据结果是positive，哪些结果是negative。同时，我们通过用样本数据跑出分类型模型的结果，也可以知道模型认为这些数据哪些是positive，哪些是negative。\n我们可以得到四个数据：\n真实值是positive，模型认为是positive的数量（True Positive=TP，第一位True表示预测的结果是正确的，第二位Positive表示结果为positive） 真实值是positive，模型认为是negative的数量（False Negative=FN）：这就是统计学上的第二类错误（Type II Error） 真实值是negative，模型认为是positive的数量（False Positive=FP）：这就是统计学上的第一类错误（Type I Error） 真实值是negative，模型认为是negative的数量（True Negative=TN） 将这四个数据（指标）呈现在表格中，可以得到如下的矩阵\nPrecision精确率 在模型预测是positive的所有结果中，预测正确的比重。用你预测出来的正确的数量除以所有实际样本的数量。\n​\t$$ precision = \\frac {TP}{TP+FP}$$\nRecall召回率（sensitivity 敏感度） 在真实值是positive的所有结果中，预测正确的比重。就是用你预测出来的正确的数量除以所有实际正确的数量。评估模型预测的全不全。\n$$ recall = \\frac {TP}{TP+FN}$$\nAccuracy正确率 $$Accuracy = \\frac {TP+TN}{TP+FN+FP+TN}$$\n分类模型中所有判断正确的结果占总观测值的比重。\nF1-Score $$F1-Score = \\frac{2}{(\\frac{1}{Precision}+\\frac{1}{Recall})}= \\frac{2PrecisionRecall}{Precision+Recall}$$\nF1-Score选择了调和平均数算法进行计算\nF1-Score是对精确率与召回率进行平均的一个结果,指标综合了Precision与Recall的产出的结果。F1-Score的取值范围从0到1的，1代表模型的输出最好，0代表模型的输出结果最差。\nIoU(Intersection over Union)交并比 蓝色的框表示Ground True（GT），在目标检测中表示标注的框。 橙色的框表示Precision，表示模型预测的框。 Iou为1则表示predicated和GT的bounding boxes完全重合。\n在实际检测中我们可以设置一个IoU的阈值（threshold）来判断检测是有效的。\n我们设置IoU为0.5\n如果IoU\u0026gt;=0.5则分类就是TP 如果IoU\u0026lt;0.5则分类是FP 如果图片中有GT但是网络没有预测出来就是FN 对于图片中没有预测的种类，模型也没有预测出来就是TN。这个指标在目标检测中没有用处，我们可以忽略他。 AP（Average　Precision）　And　ｍAP AP衡量学习出来的模型在每一个类别上的好坏。\nｍAP衡量的是学习出来的模型在所有类别上的好坏，mAP是取所有类别上AP的平均值。\nAP计算，假设我们的数据集中共有五个待检测的物体，我们的模型给出了10个候选框，我们按照模型给出的置信度（confidence）由高到低对候选框进行排序。第二列表示预测是否正确，如果他与GT匹配且IoU\u0026gt;=0.5，则是正确的。FN在是有几个物体没有被检测出来\nRank Correct? TP FP FN Precision Recall 1 True 1 0 4 $\\frac{TP}{TP+FP} = \\frac{1}{1+0} = 1$ $\\frac{TP}{TP+FN} = \\frac{1}{1+4} = 0.2$ 2 True 2 0 3 $\\frac{TP}{TP+FP} = \\frac{2}{2+0} = 1$ $\\frac{TP}{TP+FN} = \\frac{2}{2+3} = 0.4$ 3 False 2 1 3 $\\frac{TP}{TP+FP} = \\frac{2}{2+1} = 0.67$ $\\frac{TP}{TP+FN} = \\frac{2}{2+3} = 0.4$ 4 False 2 2 3 $\\frac{TP}{TP+FP} = \\frac{2}{2+2} = 0.5$ $\\frac{TP}{TP+FN} = \\frac{2}{2+3} = 0.4$ 5 False 2 3 3 $\\frac{TP}{TP+FP} = \\frac{2}{2+3} = 0.4$ $\\frac{TP}{TP+FN} = \\frac{2}{2+3} = 0.4$ 6 True 3 3 2 $\\frac{TP}{TP+FP} = \\frac{3}{3+3} = 0.5$ $\\frac{TP}{TP+FN} = \\frac{3}{3+2} = 0.6$ 7 True 4 3 1 $\\frac{TP}{TP+FP} = \\frac{4}{4+3} = 0.57$ $\\frac{TP}{TP+FN} = \\frac{4}{4+1} = 0.8$ 8 False 4 4 1 $\\frac{TP}{TP+FP} = \\frac{4}{4+4} = 0.5$ $\\frac{TP}{TP+FN} = \\frac{4}{4+1} = 0.8$ 9 False 4 5 1 $\\frac{TP}{TP+FP} = \\frac{4}{4+5} = 0.44$ $\\frac{TP}{TP+FN} = \\frac{4}{4+1} = 0.8$ 10 True 5 5 0 $\\frac{TP}{TP+FP} = \\frac{5}{5+5} = 0.5$ $\\frac{TP}{TP+FN} = \\frac{5}{5+0} =1$ 我们可以看到：随着预测的增多Recall越来越大，Percision会上下波动\nP-R（precision-recall）曲线\n我们当然希望检测的结果P越高越好，R也越高越好，但事实上这两者在某些情况下是矛盾的。比如极端情况下，我们只检测出了一个结果，且是准确的，那么Precision就是$\\frac{1}{1+0} = 100%$，但是Recall = $\\frac{1}{所有真正的结果}$就很低；而如果我们把所有结果都返回，那么必然Recall必然很大，但是Precision很低。\n因此在不同的场合中需要自己判断希望P比较高还是R比较高。如果是做实验研究，可以绘制Precision-Recall曲线来帮助分析。\n通过上述的数据我们可以得到P-R曲线\nAP计算\nAP就是平均精准度，简单来说就是对PR曲线上的Precision值求均值。对于pr曲线来说，我们使用积分来进行计算。Recall从0-1对p(r)进行积分\n$$AP = \\int_{0}^{1}p(r)dr$$\n在实际应用中，我们并不直接对该PR曲线进行计算，而是对PR曲线进行平滑处理。即对PR曲线上的每个点，Precision的值取该点右侧最大的Precision的值。经过处理我们可以得到如下图像\n)\nInterplolated AP（Pascal Voc 2008 的AP计算方式-“11点法”，2010年之前的计算方式）\nPascal VOC 2008中设置IoU的threshold为0.5，如果一个目标被重复检测，则confidence最高的为正样本，另一个为负样本。在平滑处理的PR曲线上，取横轴0-1的10等分点（包括断点共11个点）的Precision的值，计算其平均值为最终AP的值\n$$AP = \\frac{1}{11}*\\sum_{0,0.1,\\cdots,1}^{} P_{smooth}(i)$$\n​\t在我们的例子里$AP = \\frac{1}{11}(50.1+40.57+20.5) = 0.753$\nArea under curve（AUC）\n上述方法有两个缺陷，\n第一个是使用11个采样点在精度方面会有损失。 第二个是，在比较两个AP值较小的模型时，很难体现出两者的差别。 所以这种方法在2009年的Pascalvoc之后便不再采用了。在Pascal voc 2010之后，便开始采用这种精度更高的方式。绘制出平滑后的PR曲线后，用积分的方式计算平滑曲线下方的面积作为最终的AP值。求出被分割所有阶梯块的面积之和就是AP。\n","date":"2021-08-03","img":"","permalink":"/posts/d9d2de90/","series":null,"tags":["YOLOV5"],"title":"目标检测评估指标"},{"categories":["Web"],"content":"在使用next主题的过程中，碰到写的markdown中有LaTeX公式不显示的问题，遂查找资料解决。\n更换Hexo默认渲染引擎\nHexo默认的渲染引擎是 marked，但是 marked 不支持 MathJax。所以需要更换Hexo的markdown渲染引擎为hexo-renderer-kramed引擎，后者支持MathJax公式输出。\n1npm uninstall hexo-renderer-marked --save 2npm install hexo-renderer-kramed --save 激活MathJax\n在/blog/themes/next/config.yml中找到# MathJax Support修改为\n1mathjax: 2 enable: true 3 per_page: true 修改kramed语法解释\n在/blog/node_modules/kramed/lib/rules/inline.js 将\n1 escape: /^\\\\([\\\\`*{}\\[\\]()#$+\\-.!_\u0026gt;])/, 2 autolink: /^\u0026lt;([^ \u0026gt;]+(@|:\\/)[^ \u0026gt;]+)\u0026gt;/, 3 url: noop, 4 html: /^\u0026lt;!--[\\s\\S]*?--\u0026gt;|^\u0026lt;(\\w+(?!:\\/|[^\\w\\s@]*@)\\b)*?(?:\u0026#34;[^\u0026#34;]*\u0026#34;|\u0026#39;[^\u0026#39;]*\u0026#39;|[^\u0026#39;\u0026#34;\u0026gt;])*?\u0026gt;([\\s\\S]*?)?\u0026lt;\\/\\1\u0026gt;|^\u0026lt;(\\w+(?!:\\/|[^\\w\\s@]*@)\\b)(?:\u0026#34;[^\u0026#34;]*\u0026#34;|\u0026#39;[^\u0026#39;]*\u0026#39;|[^\u0026#39;\u0026#34;\u0026gt;])*?\u0026gt;/, 5 link: /^!?\\[(inside)\\]\\(href\\)/, 6 reflink: /^!?\\[(inside)\\]\\s*\\[([^\\]]*)\\]/, 7 nolink: /^!?\\[((?:\\[[^\\]]*\\]|[^\\[\\]])*)\\]/, 8 reffn: /^!?\\[\\^(inside)\\]/, 9 strong: /^__([\\s\\S]+?)__(?!_)|^\\*\\*([\\s\\S]+?)\\*\\*(?!\\*)/, 10 em: /^\\b_((?:__|[\\s\\S])+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, 11 code: /^(`+)\\s*([\\s\\S]*?[^`])\\s*\\1(?!`)/, 12 br: /^ {2,}\\n(?!\\s*$)/, 13 del: noop, 14 text: /^[\\s\\S]+?(?=[\\\\\u0026lt;!\\[_*`$]| {2,}\\n|$)/, 15 math: /^\\$\\$\\s*([\\s\\S]*?[^\\$])\\s*\\$\\$(?!\\$)/, 替换为\n1 escape: /^\\\\([`*\\[\\]()#$+\\-.!_\u0026gt;])/, 2 autolink: /^\u0026lt;([^ \u0026gt;]+(@|:\\/)[^ \u0026gt;]+)\u0026gt;/, 3 url: noop, 4 html: /^\u0026lt;!--[\\s\\S]*?--\u0026gt;|^\u0026lt;(\\w+(?!:\\/|[^\\w\\s@]*@)\\b)*?(?:\u0026#34;[^\u0026#34;]*\u0026#34;|\u0026#39;[^\u0026#39;]*\u0026#39;|[^\u0026#39;\u0026#34;\u0026gt;])*?\u0026gt;([\\s\\S]*?)?\u0026lt;\\/\\1\u0026gt;|^\u0026lt;(\\w+(?!:\\/|[^\\w\\s@]*@)\\b)(?:\u0026#34;[^\u0026#34;]*\u0026#34;|\u0026#39;[^\u0026#39;]*\u0026#39;|[^\u0026#39;\u0026#34;\u0026gt;])*?\u0026gt;/, 5 link: /^!?\\[(inside)\\]\\(href\\)/, 6 reflink: /^!?\\[(inside)\\]\\s*\\[([^\\]]*)\\]/, 7 nolink: /^!?\\[((?:\\[[^\\]]*\\]|[^\\[\\]])*)\\]/, 8 reffn: /^!?\\[\\^(inside)\\]/, 9 strong: /^__([\\s\\S]+?)__(?!_)|^\\*\\*([\\s\\S]+?)\\*\\*(?!\\*)/, 10 em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, 在markdown开头添加语句\n1mathjax: true 测试\n$$1 = \\frac{2}{2}$$\n在HEXO博客中使用LaTeX公式的简单方法_Loy Fan-CSDN博客\n","date":"2021-08-03","img":"","permalink":"/posts/37cab689/","series":null,"tags":["Web","教程"],"title":"Hexo-NexT使用LaTeX公式"},{"categories":["Web"],"content":"去年在好友 晚风吹行舟 的帮助下购买了腾讯云的主机以及域名，但这些在很长时间内都是闲置状态。 暑期这段时间收到了腾讯云服务电话，域名备案需要更新，顺便将自己网站进行完善。\n环境准备 Git安装及配置 安装Git 选择最新版本，或者其他版本进行下载，双击可执行文件并一路点击Next安装Git下载 在终端执行 1git --version 查看git版本，如出现下面提示则Git安装成功 1git version 2.28.0.windows.1 配置Git 打开Git Bash（在任意地方右击，点击Git Bash Here） 配置用户名。在终端中使用下面的命令可以设置git自己的名字和电子邮件。这是因为Git是分布式版本控制系统，所以，每个机器都必须自报家门：你的名字和Email地址。 1git config --global user.name \u0026#34;name\u0026#34; # (name:你的名字) 配置邮箱 1git config --global user.email \u0026#34;xxx@xxx.com\u0026#34; # 邮箱， 生成ssh的Key 1 ssh-keygen -t rsa -C \u0026#39;github邮箱号\u0026#39; -f ~/.ssh/id_rsa_github ​\t这时会在用户目录(C:Users\\xxx.ssh)下生成以下文件\nid_rsa_github id_rsa_github.pub 登陆Github，在Settings \u0026gt; SSH and GPG keys 找到New SSH key 输入Title名，在Key中填入id_rsa_github.pub的内容，点击Add SSH key。 至此，Git已经配置完成\nNode.js安装 选择最新版本，或者其他版本进行下载，双击可执行文件并一路点击Next进行安装。Node.js下载 在终端输入以下命令，如出现版本号代表安装完成。 1node -v 2npm -v npm换源(可选) 1npm config set registry https://registry.npm.taobao.org Hexo配置 Hexo安装，执行以下命令，等待安装完成 1npm install -g hexo-cli 生成Hexo。 执行以下命令，生成一个博客，安装过程中，他会自动生成一个文件夹，这个文件夹就是Hexo的配置文件。 “blog”是你要生成博客的文件夹名称，可以根据自己的喜好来取名。 1hexo init blog 进入刚刚生成的配置文件夹，执行以下命令启动Hexo 1cd blog 2hexo server 在浏览器中地址栏中输入\u0026quot;127.0.0.1:4000\u0026quot;即可看到Hexo的“Hello World”界面 Hexo部署至腾讯云 部署环境准备 环境 本地Windows10 腾讯云CentOS7.6 准备 已准备好的Hexo本地博客 用于连接服务器的工具MobaXterm 服务器配置Git 安装Git 1sudo yum install -y git 创建Git用户并且修改权限 1adduser username 2passwd username 3chmod 740 /etc/sudoers 4vim /etc/sudoers ​\t修改内容如下\n1root ALL=(ALL) ALL 2username ALL=(ALL) ALL 本地Win10创建密匙 1ssh-keygen -t rsa 在服务器中切换Git用户，并将Win10中\u0026quot;id_rsa.pub\u0026quot;文件复制到服务器中\u0026rsquo;~/.ssh/authorized_keys' 1su username 2mkdir ~/.ssh 3vim ~/.ssh/authorized_keys 服务器网站配置 创建网站目录并且设置权限 1su root 2mkdir /home/hexo 3chown username:username -R /home/hexo 安装Nginx，并启动服务 1yum install -y nginx 2systemctl start nginx.service #启动服务 修改Nginx配置文件 1vim /etc/nginx/nginx.conf 2server { 3 listen 80 default_server; 4 listen [::]:80 default_server; 5 server_name jimyag.cn; #你的域名 6 root /home/hexo; #网站目录 7} 重启Nginx 1systemctl restart nginx.service 建立Git仓库 1su root 2cd /home/username 3git init --bare blog.git 4chown username:username -R blog.git 同步网站根目录 1vim blog.git/hooks/post-receive 2 3#!/bin/sh 4git --work-tree=/home/hexo --git-dir=/home/username/blog.git checkout -f 修改权限 1chmod +x /home/username/blog.git/hooks/post-receive 在Win10本地Hexo目录修改_config.yml文件 1deploy: 2 type: git 3 repository: username@ip:/home/username/blog.git #用户名@服务器Ip:git仓库位置 4 branch: master 在Win10GitBash部署 1hexo clean 2hexo g -d 网站配置 个性化配置参考教程 B站 参考博客 Hexo换主题乱码\nCentOS修改主机名\nDeployer not found\nnginx跳转到https\n主题博客个性化配置\n主题侧边栏日志\n增加备案号 添加文章更新时间\nnpm换源\n设置博客目录\n","date":"2021-07-31","img":"","permalink":"/posts/19323af8/","series":null,"tags":["Web","教程"],"title":"首次部署网站-Hexo-Nginx"},{"categories":null,"content":"我目前大三在读。 写过Golang的小项目，了解过目标检测、ROS。我也对具有良好理论成分的更多应用问题感兴趣。 这是我的简历（上次更新于 2022 年 7 月 3 日）\n专业技能 熟悉 Go，了解 C++、Java，有良好的编程风格 掌握基础数据结构和算法的基本原理 了解Go的GC、GMP模型 了解Casbin的权限控制思想 了解Docker部署项目 项目经历 学校 - \u0026ldquo;资助星\u0026quot;小程序 - 独立开发 - 2021.08- 2021.10 用户查询学校的资助公告、勤工助学部门，同学可以完成线上申请面试，管理员进行面试；学生加入勤助部门、线上签到、查看值班表、工作记录。 后端使用Go开发，有JWT认证、Casbin授权、Gin框架、日志分割、Git版本控制、RESTful的API、易读的文档。小程序使用原生框架来模仿微信的界面。 资助星的后端 资助星小程序 学校 - \u0026ldquo;云服务器管理平台\u0026rdquo; - 负责后端、前端开发 - 2021.12 用户购买多个云服务器并可以在网页进行ssh连接，管理员服务器服务器套餐信息、用户信息 通过使用Casbin实现动态控制某个用户某个接口能否使用。 后端使用Go开发，在网页中ssh连接服务器用户感觉不到延迟，使用了websocket保持ssh的连接，除了“资助星”项目中的后端技术还包含websocket的鉴权。前端使用Vue框架，使用路由守卫控制权限、使用canvas实现验证码组件。 学校 - “购物平台” - 负责后端开发 - 2022.03 - 04 此项目采用分层的微服务架构开发，后端分为两部分，第一部分是用gin来接收前端的请求，并获取发送过来的数据，然后将获取到的数据通过gRPC协议传输到gRPC服务端中进行数据的处理。对于库存扣减的gRPC服务使用Redis实现分布式锁，保证库存正常扣减。对于售卖接口，使用RocketMQ的半消息和延时消息来保证商品的正常售卖和超时归还。 项目使用consul实现服务注册、服务发现和配置中心的功能。使用jaeger实现链路追踪。 jimyag/shop: 商城(github.com) 实习 - “存储” 2022.06 - 至今 经历 TODO 为什么写博客 我在这里的大部分知识来自许多其他人共享的免费资源。在这里分享我的知识可以作为对互联网的贡献并帮助其他人。 我的博客服务器作为公共笔记，这样当我想查看某个主题的具体细节时，我可以通过搜索引擎轻松找到它。 您可以通过电子邮件i@jimyag.cn与我联系。\n","date":"0001-01-01","img":"","permalink":"/about/","series":null,"tags":null,"title":"About"},{"categories":null,"content":"收集的觉得不错的资料\nGo package testify stretchr/testify go的测试包，不用写if err!=nil进行测试\njwt-go dgrijalva/jwt-go 认证的包\nPASETO o1egl/paseto 基于token的认证库，比JWT更安全\nsite dbdiagram dbdiagram.io可以在线设计数据库关系图(database relationship diagram)且可以导出DDL SQL的工具。\nExcalidraw Excalidraw一个高颜值的绘图网站\nGo Playground Go Playground展示go代码片段\nonemodel.app https://www.onemodel.app/ 高颜值画架构图\nutils loov/lensm https://github.com/loov/lensm 查看汇编和源代码对应的工具\nmultipass https://github.com/canonical/multipass 可以启动多个 ubuntu 的实例\nchaos-mesh https://github.com/chaos-mesh/chaos-mesh 一个混沌工程的工具，可以模拟各种环境\nblog https://tonybai.com/\nhttps://eng.uber.com/\nhttps://xargin.com/\nhttps://www.yuque.com/aceld\nhttps://draveness.me/\nhttps://thinkerou.com/\nhttps://geektutu.com/\n","date":"0001-01-01","img":"","permalink":"/data/","series":null,"tags":null,"title":"整理的资料"}]