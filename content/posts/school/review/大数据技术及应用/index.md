---
title: "大数据技术及应用-复习资料"
date: 2022-04-24T22:50:12+08:00
draft: false
slug: 77d147b1
tags: ["复习资料"]
categories: []
featured: false 
comment: false 
toc: true 
diagram: true 
series: [ ] 
pinned: false
weight: 100
---

大数据技术及应用的复习资料。

<!--more-->

## 大数据概述

### 大数据概念

指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应海量、高增长率和多样化的信息资产。

### 大数据特性

1. 海量性
2. 多样性
3. 真实性
4. 价值密度低
5. 高速性
6. 可变性

![img](index/wps1.jpg)

### 大数据的影响

1. 数据的运行、计算速度越来越快 

2. 数据存储成本下降 

3. 实现信息对等解放脑力，机器拥有人的智慧

### 大数据的关键技术

1. 分布式系统基础架构Hadoop的出现，为大数据带来了新的曙光；

2. HDFS为海量的数据提供了存储；

3. MapReduce则为海量的数据提供了并行计算，从而大大提高了计算效率；

4. Spark、Storm、Impala、Flink等各种各样的技术进入人们的视野。

### 大数据与云计算物联网的关系

物联网、云计算和大数据三者互为基础。

物联网产生大数据，大数据需要云计算。

物联网在将物品和互联网连接起来，进行信息交换和通信，以实现智能化识别、定位、跟踪、监控和管理的过程中，产生的大量数据，云计算解决万物互联带来的巨大数据量，所以三者互为基础，又相互促进。如果不那么严格的说，它们三者可以看做一个整体，相互发展、相互促进。

以下关于云计算、大数据和物联网之间的关系，论述错误的是： B

A、物联网可以借助于大数据实现海量数据的分析

B、云计算侧重于数据分析

C、物联网可以借助于云计算实现海量数据的存储

D、云计算、大数据和物联网三者紧密相关，相辅相成

## hadoop简介

### Hadoop简介

hadoop是一个分布式系统基础架构，hadoop的框架最核心的设计是HDFS和MapReduce，HDFS为海量的数据提供了存储能力，MapReduce为海量数据提供了计算能力

### Hadoop特性/优点

1. 高可靠性 ：采用冗余数据存贮方式，即使一个副本发生故障，其他副本也可以保证对外工作的正常进行

2. 高扩展性 ：采用冗余数据存贮方式，即使一个副本发生故障，其他副本也可以保证对外工作的正常进行。

3. 高效性 ：作为并行分布式计算平台，hadoop采用分布式存贮和分布式处理两大核心技术，能够高效的处理PB级别的数据

4. 高容错性 ：采用冗余数据存贮方式，自动保存数据的多个副本，并且能够自动将失败的任务重新分配。

5. 经济性：hadoop采用廉价的计算机集群，普通的用户也可以pc机搭建环境
6. 运行在linux平台上，hadoop是基于java语言开发的，可以较好的运行在linux的平台上
7. 支持多种编程语言，如：C++等/

### Hadoop缺点

在当前Hadoop的设计中，所有的metadata操作都要通过集中式的NameNode来进行，NameNode有可能是性能的瓶颈。

当前Hadoop单一NameNode、单一Jobtracker的设计严重制约了整个Hadoop可扩展性和可靠性。

首先，NameNode和JobTracker是整个系统中明显的单点故障源。再次，单一NameNode的内存容量有限，使得Hadoop集群的节点数量被限制到2000个左右，能支持的文件系统大小被限制在10-50PB，最多能支持的文件数量大约为1.5亿左右。实际上，有用户抱怨其集群的NameNode重启需要数小时，这大大降低了系统的可用性。

###  Hadoop项目结构

详细介绍

![img](index/wps2.jpg)

#### 1，core/common

Hadoop Common原名为Hadoop Core,0.20版本之后改为common。自0.21版本之后，HDFS和MapReduce被分离出来作为单独的子项目，其余部分构成Hadoop Common。

Common是为Hadoop及其他子项目提供支持的常用工具，主要包括文件系统，RPC和串行化库，他们为在廉价的硬件上搭建云计算环境提供基本的服务，同时也为运行在该平台上的软件开发提供所需要的API。

#### 2，Avro

Avro是Hadoop的一个子项目，也是Apache中的一个独立项目。

Avro是一个用于**数据序列化的系统**，提供了丰富的数据结构类型，快速可压缩的二进制数据格式，存储持久性数据的文件集，远程调用的功能和简单的动态语言集成功能。

Avro可以将数据结构或对象转化成便于存储和传输的格式，节约数据存储空间和网络传输带宽，Hadoop的其它子项目的客户端与服务端之间的数据传输都采用Avro。

#### 3，HDFS

HDFS是Hadoop项目的两大核心之一，它是针对谷歌文件系统（GFS）的开源实现。

HDFS具有处理超大数据，流式处理，可以运行在廉价商用服务器上等优点。

HDFS在设计之初就是要运行在廉价的大型服务器集群上，因此，在设计上就把硬件故障作为一种常态来考虑，可以保证在部分硬件发生故障的情况下，仍能保证文件系统的整体的可用性和可靠性。

HDFS放宽了一部分POSIX约束，从而实现以流的形式访问文件系统中的数据。

HDFS在访问应用程序数据时候，可以具有很高的吞吐量，因此，对于超大数据集的应用程序而言，选择HDFS作为底层数据存储是较好的选择。

#### 4，HBase

HBase是一个提供高可靠性，高性能，可伸缩，实时读写，分布式的列式数据库，一般采用HDFS作为其底层数据存储。

**HBase是针对谷歌的BigTable的开源实现**，二者都采用了相同的数据模型，具有强大的**非结构化数据存储能力**。HBase与传统关系数据库的一个重要区别就是，前者是基于**列的存储**，而后者采用基于行的存储。HBase具有良好的**横向扩展**能力，可以通过不断增加廉价的商用服务器来增加存储能力。

####  5，MapReduce

Hadoop MapReduce是这对google 的MapReduce的实现。

MapReduce是一种编程模型，用于大规模数据集的**并行计算**，它将复杂，运行于大规模集群上的并行计算过程高度的抽象到了两个函数——**Map和Reduce**，并允许用户在不了解分分布式系统底层细节的情况下开发并行应用程序，并将其运行于廉价计算机集群上，完成海量数据的处理。

#### 6，Zookeeper

 Zookeeper是针对谷歌Chubby的一个开源实现，是高效和可靠的协同工作系统，提供**分布式锁之类**的基本服务，用于构建分布式应用，减轻分布式应用程序锁承担的协调任务。

Zookeeper使用Java编写，很容易编程接入，它使用了一个和文件树结构相似的数据模型，可以使用Java或者C来进行编程接入。

#### 7，Hive

Hive是一个基于Hadoop的数据仓库工具，可以用于对Hadoop文件中的数据集进行数据整理，特殊查询和分析存储。

Hive的学习门槛较低，因为，它提供了类似于关系数据SQL语言的特殊查询语言——Hive QL,可以通过Hive QL语句快速实现简单的MapReduce统计，Hive自身可以将**Hive QL语句转换为MapReduce任务**进行运行，而不必开发专门的MapReduce应用，因而十分适合数据仓库的统计分析。

#### 8，Pig

Pig是一种数据流语言和运行环境，适合于使用Hadoop和MapReduce平台来查询大型半结构化数据集。

Pig的出现大大简化了Hadoop常见的工作任务，它在MapReduce的基础上创建了更简单的过程语言抽象，为Hadoop应用程序提供了一种更加接近结构化查询语言的接口。

Pig是一个相对简单的语言，它可以执行SQL语句，因此，当我们需要从大型数据集中搜索满足某个给定搜索条件的记录时，采用Pig要比MapReduce具有明显的优势，前者只需要编写一个简单的脚本在集群中自动并行处理与分发，而后者则需要编写一个单独的MapReduce应用程序。

#### 9，Sqoop

Sqoop可以改进数据的互操作性，主要用来在Hadoop和**关系数据库**直接交换数据。

通过Sqoop,我们可以方便的将关系数据库之中的数据导入Hadoop，或者将Hadoop中的数据导入关系数据库。**Sqoop主要通过JDBC**和关系数据库进行交互，理论上，支持JDBC的关系数据库都可以使Sqoop和Hadoop进行数据交互。

Sqoop是专门为大数据集设计的，支持增量更新，可以将新纪录添加到最近一次到处的数据源上，或者指定上次修改的时间戳。

#### 10，Chukwa

Chukwa是一个开源的，用于监控大型分布式系统的数据收集系统，可以将各种类型的数据收集成合适的Hadoop处理的文件，并保存在HDFS中供Hadoop进行各种MapReduce操作。

Chukwa构建在Hadoop的HDFS和MapReduce框架之上，继承了Hadoop的可伸缩性和可扩展性。

Chukwa内置了一个强大而灵活的工具集，可用于展示，监控和分析已收集的数据。 

### Hadoop生态系统

详细介绍

1.Hive 2.Hbase 3.Pig 4.Sqoop 5.Flume 6.Zookeeper 7.Spark 8.Storm 9.Avr

![img](index/wps3.jpg) 



## Hdfs

HDFS( Hadoop Distributed File System)是一个易于扩展的分布式文件系统

### Hdfs体系结构

HDFS 采用的是master/slaves主从结构模型来管理数据.

这种结构模型主要由四个部分组成：

Client(客户端)、Namenode(名称节点)、Datanode(数据节点)和SecondaryNamenode(第二名称节点，辅助Namenode)。

一个真正的HDFS集群包括一个Namenode和若干数目的Datanode。

Namenode是一个中心服务器，负责管理文件系统的命名空间 (Namespace )及客户端对文件的访问。

集群中的Datanode一般是一个节点运行一个Datanode进程，负责管理客户端的读写请求，在Namenode的统一调度下进行数据块的创建、删除和复制等操作。

#### Client的主要功能

1. 在上传文件时将文件切分为Block，在文件下载时将文件合并；
2. 上传与下载数据文件时，与NameNode交互，获取文件元数据；
3. 上传与下载数据文件时，与DataNode交互，读取或写入数据。

### NameNode介绍

1. 主要功能提供名称查询服务，用来保存metadata信息
2. 管理文件系统的命名空间；（它维护着文件系统树及整棵树内所有的文件和目录。这些信息以两个文件形式永久保存在本地磁盘上
3. 管理元数据：文件的位置、所有者、权限、数据块block信息
4. 管理Block副本策略：多少个副本，默认3个副本；
5. 处理客户端读写请求，为DataNode分配任务。

### DataNode介绍

1. 主要功能保存Block。
2. Slave工作节点（可大规模扩展）；
3. 存储Block和数据校验和执行客户端发送的读写操作；
4. 通过心跳机制定期（默认3秒）向NameNode汇报运行状态和Block列表信息，如果NN10分钟没有收到DN的心跳，则认为其已经lost，并复制其上的block到其它DN；
5. 集群启动时，DataNode向NameNode提供Block列表信息。（数据块的位置并不是由namenode维护的，而是以块列表的形式，存储在datanode中，在安全模式中，datanode会向namenode发送最新的块列表信息。）

### HDFS文件的读取-重点

![image-20220425234518340](index/image-20220425234518340.png)

### HDFS文件的写入

![image-20220425234554417](index/image-20220425234554417.png)

###  Hdfs存储原理

HDFS采用master/slave架构。一个HDFS集群是由一个Namenode和一定数目的Datanodes组成。NameNode作为master服务，它负责管理文件系统的命名空间和客户端对文件的访问。DataNode作为slave服务，在集群中可以存在多个。通常每一个DataNode都对应于一个物理节点。DataNode负责管理节点上它们拥有的存储，它将存储划分为多个block块，管理block块信息，同时周期性的将其所有的block块信息发送给NameNode。

### Hadoop1.0与2.0的区别

1. 提出HDFS Federation，它让多个NameNode分管不同的目录进而实现访问隔离和横向扩展，同时彻底解决了**NameNode单点故障**问题
2. 针对Hadoop1.0中的MapReduce在扩展性和多框架支持等方面的不足，它将JobTracker中的资源管理和作业控制分开，分别由ResourceManager（负责所有应用程序的资源分配）和ApplicationMaster（负责管理一个应用程序）实现，即引入了资源管理框架Yarn。通用的资源管理模块，可为各类应用程序进行资源管理和调度

### HDFS的主要组件及功能

Block是HDFS最小存储单元，大小固定，1.X默认是64MB2.X默认为128MB，可自定义。默认情况下每个Block有（至少）三个副本，通过水平复制，达到数据冗余度的要求。

单一master（NameNode）来协调存储元数据。

| nameNode                                | DataNode                                    |
| --------------------------------------- | ------------------------------------------- |
| 存储元数据                              | 存储我呢见数据                              |
| 元数据保存在内存中                      | 文件保存在磁盘上                            |
| 保存文件，Block，DataNode之间的映射关系 | 维护了block id 到datanode本地文件的映射关系 |

### HDFS适用场景

1. 超大文件
2. 流式数据访问
   1. 一次写入、多次读取
   2. 传输时间和寻址时间

### 不适用

1. 低延时
2. 大量小文件
3. 多用户写入、任意修改文件

##  MapReduce

### MapReduce体系结

主要由四个部分组成，分别是Client、JobTracker、TaskTracker以及Task。

 

### MapReduce原理

空 

### MapReduce工作流程：

1.第一步对输入的数据进行切片，每个切片分配一个map()任务，map()对其中的数据进行计算，对每个数据用键值对的形式记录，然后输出到环形缓冲区（图中sort的位置）。

2.map（）中输出的数据在环形缓冲区内进行快排，每个环形缓冲区默认大小100M，当数据达到80M时（默认），把数据输出到磁盘上。形成很多个内部有序整体无序的小文件。

3.框架把磁盘中的小文件传到Reduce()中来，然后进行归并排序，最终输出。

 

### MapReduce shuffle过程

![img](index/wps4.png) 

## Hbase

### Hbase概念

HBase是一个高可靠、高性能、面向列、可伸缩的分布式数据库，主要用来存储非结构化和半结构化的松散数据。

###  Hbase与传统数据库的对比：

数据类型：传统数据库数据类型较丰富，Hbase数据类型更加简单。

数据操作：传统数据库涉及多表连接，Hbase不存在。

存储模式：关系数据库是基于行模式存储的。HBase是基于列存储的。

数据索引：关系数据库可以针对不同列构建多个索引，HBase只有行键索引。

数据维护：传统数据库更新会丢失版本旧的数据，Hbase更新会保留版本旧的数据。

可伸缩性：关系数据库很难实现横向扩展，纵向扩展的空间也比较有限。Hbase相反。

 

### Hbase数据模型

#### 数据模型概述

HBase是一个稀疏、多维度、排序的映射表，这张表的索引是行键、列族、列限定符和时间戳

#### 数据模型相关概念

**1.** 表：Hbase采用表组织数据，由行和列构成 

**2.** 行：由行键来标识 

**3.** 列族：基本的访问控制单元 

**4.** 列限定符：数据通过列限定符定位 

**5.** 单元格：通过行、列、列限定符确定一个单元格 

**6.** 时间戳：每个单元格都保存着同一份数据的不同版本，这些版本采用时间戳进行索引。

 

### Hbase实现原理

#### 功能组件

1.库函数 

2.一个Master主服务器 

3.许多个Region服务器

#### Hbase三层结构

一、Zookeeper文件：记录了-ROOT-表的位置信息

二、ROOT-表：记录了.META.表的Region位置信息

三、META.表：-记录了数据表的Region位置信息

##  Hive

### Hive概念

Hive是一个数据仓库基础工具在Hadoop中用来处理结构化数据。

### Hive特点

1.采用批处理方式处理海量数据 2.提供适合数据仓库操作的工具

### Hive缺点

1.延迟较高 2.不支持物化视图 3.不适用OLTP 4.暂不支持存储过程

### Hive应用场景

1.数据挖掘 2.非实时分析 3.数据汇总 4.数据仓库

### Hive系统架构

由用户接口模块、驱动模块和元数据存储模块构成

###  相关概念

1. Metastore，存储元数据的角色。Hive将元数据存储在传统的关系型数据库（mysql、derby）中。

2. Hive中的元数据包括：表的名字、表的数据所在的HDFS目录、数据在目录中的分布规则、以及其他表属性。

3. Hive计算引擎可以是Apache MapReduce或者Apache Spark。

4. 内部表和外部表

   表是数据管理和存储的基本对象，由元数据和表数据组成

   |                      | 内部表                   | ***\*外部表\**** |
   | -------------------- | ------------------------ | ---------------- |
   | 创建加载可以独立完成 | 数据移到仓库目录         | 数据位置不移动   |
   | 创建加载同时完成     | 元数据和数据会被一起删除 | 只删除元数据     |

5. 分区：通过特定条件将表的数据分发到分区目录中，或者将分区中的数据分发到子分区目录中。

   1. 分区的作用：减少不必要的全表扫描，提升查询效率。

6. 分桶：通过分桶键哈希取模的方式，将表或分区中的数据随机、均匀地分发到N个桶中，桶数N一般为质数，桶编号为0, 1, …, N-1

   1. 分桶的作用：提高取样效率，提高Join查询效率

7. 分区分桶的区别：

   1. 分区：
      1. 数据表可以按照某个字段的值划分分区。
      2. 每个分区是一个目录。
      3. 分区数量不固定。
      4. 分区下可再有分区或者桶。

   2. 分桶
      1. 数据可以根据桶的方式将不同数据放入不同的桶中。
      2. 每个桶是一个文件。
      3. 建表时指定桶个数，桶内可排序。
      4. 数据按照某个字段的值Hash后放入某个桶中。


### 用户向Hive输入一段命令或查询时，Hive需要与Hadoop交互工作来完成该操作

1. 驱动模块接收该命令或查询编译器

2. 对该命令或查询进行解析编译

3. 由优化器对该命令或查询进行优化计算

4. 该命令或查询通过执行器进行执行

## Spark

### Spark特点

1.运行速度快 

2.容易使用 

3.通用性 

4.运行模式多样

### 与Hadoop的关系

Spark在借鉴Hadoop MapReduce优点的同时，Spark编辑模型比Hadoop更灵活，spark提高了内存计算，对于迭代运算效率更高。Spark基于DAG的任务调度执行机制优于Hadoop的迭代执行机制。

### Spark生态系统

主要包含了Spark Core、Spark SQL、Spark Streaming、MLLib和GraphX 等组件。

### Spark生态系统组件应用场景

1. 复杂的批量数据处理

2. 基于历史数据的交互式查询

3. 基于实时数据流的数据处理

4. 基于历史数据的数据挖掘

5. 图结构数据的处理

### Spark运行架构

集群资源管理器（Cluster Manager）

运行作业任务的工作节点（Worker Node）

每个应用的任务控制节点（Driver）

每个工作节点上负责具体任务的执行进程（Executor）

### RDD工作原理

#### RDD概念

一个只读的分区记录集合。

#### RDD特性

1. 高效的容错性 

2. 中间结果持久化到内存 

3. 存放的数据可以是未序列化的Java 对象

### 宽依赖与窄依赖

#### 窄依赖

一个父RDD的分区对应于一个子RDD的分区或多个父RDD的分区对应于一个子RDD的分区。

#### 宽依赖

存在一个父RDD的一个分区对应一个子RDD的多个分区。

### Spark SQL工作原理

1. 将SQL转换成抽象语法树

2. 将抽象语法树转换成查询块

3. 将查询块转换成逻辑查询计划

4. 重写逻辑查询计划

5. 讲逻辑计划转成物理计划

6. 选择最佳优化查询策略

### Spark Mllib基本原理

MLlib是Spark的机器学习库，旨在简化机器学习的工程实践工作。Mllib常见机器学习问题：分类、回归、聚类、协同过滤。



## 参考

[Hadoop项目结构_weixin_33727510的博客-CSDN博客](https://blog.csdn.net/weixin_33727510/article/details/90305967)
